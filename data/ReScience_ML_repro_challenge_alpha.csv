author,title,doi,article_type,lang,pdf_url,keywords,review_url,code_url,volume,issue,year,abstract,easy,difficult
"['Ankit Ankit', 'Sameer Ambekar', 'Baradwaj Varadharajan', 'Mark Alence']",[Re] Counterfactual Generative Networks,10.5281/zenodo.6574625,Replication,Python,https://zenodo.org/record/6574625/files/article.pdf,rescience c machine learning deep learning python pytorc deep generative models counterfactuals,https://openreview.net/forum?id=BSHg22G7n0F,https://github.com/ambekarsameer96/FACT_AI/,8,2,2022,"In this paper, we attempt to verify the claims that the paper [1] makes about their pro‐ posed CGN framework that decomposes the image generation process into independent causal mechanisms. Further, the author claims that these counterfactual images im‐ proves the out‐of‐distribution robustness of the classifier. We use the code provided by the authors to replicate several experiments in the original paper and draw conclusions based on these results.","Overall, clear environment setup instructions, well working code and availability of pre‐ trained CGN models for both datasets proved valuable to validate the authors’ claim.","Some experimental details were not reported in the original paper which made vali‐ dations time consuming. ImageNet based experiments were replaced with ImageNet‐
Copyright © 2022 A. Ankit et al., released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Ankit Ankit (ankitnitt1721@gmail.com) The authors have declared that no competing interests exist. Code is available at https://github.com/ambekarsameer96/FACT_AI/. – SWH swh:1:dir:88d89da0661c0f855f7b6f27c77acac1c2572a93. Open peer review is available at https://openreview.net/forum?id=BSHg22G7n0F.
ReScience C 8.2 (#2) – Ankit et al. 2022 1
1k(mini) due to the computational limitation which made it difficult to validate the au‐ thor’s original claims. Pre‐trained classification models could have proven helpful in this case, but were unavailable, which meant we had to train the classifier from scratch. Code changes were required to obtain baseline results which was tedious considering different code architecture was implemented for MNIST & ImageNet.
Communication with original authors We emailed the authors regarding inception score, MNIST dataset hyperparameters and ImageNet hyperparameters.
ReScience C 8.2 (#2) – Ankit et al. 2022 2
1 Introduction
Neural Networks (NNs) have become ubiquitous in machine learning due to their pre‐ dictive power. However, a shortcoming of NNs is their tendency to learn simple correla‐ tions that lead to good performance on test data rather than more complex correlations that generalise better. This shortcoming is apparent in the task of image classification, where NNs tend to overfit to factors like background or texture. To address this short‐ coming, [1] proposes a method of generating counterfactual images that prevent classi‐ fiers from learning spurious relationships. The authors take a causal approach to image generation by splitting the generation task into independent causal mechanisms. The authors considered three separately learned Independent Mechanisms (IMs) to generate shapes, textures and backgrounds for an image. For the MNIST setting, all IM specific losses are optimized end‐to‐end from scratch, while in the ImageNet setting, each IM is initialized with weights from pre‐ trained BigGAN‐deep‐256 [2]. The counterfactual image is then generated by passing the result of each IM to a deterministic composer function. In this report, we use the publicly available code provided by the authors to reproduce the results of the paper and validate the authors’ claims. In this endeavour, we made modifications to the code to determine the efficacy of their generative model and vali‐ date its impact on improving the out of distribution robustness of a classifier.
2 Scope of reproducibility
In this report, we investigate the following claims from the original paper:
1. Generating high‐quality counterfactual images that decompose into independent causal inductive biases, these mechanisms disentangle object shape, object tex‐ ture and background
2. Using counterfactual images improves the shape vs texture bias which is an inher‐ ent problem of deep classifiers
3. Using counterfactual images improve the out‐of‐distribution robustness for the classifier during the classification task
4. The Generative model can be trained efficiently on a single GPU with the help of powerful pre‐trained models
We attempt to reproduce the experiments from the paper [1] and perform exploratory analysis on the abovementioned claims. We propose using an extra loss function tomit‐ igate some of the shortcomings during counterfactual generation process and generate heatmap plots to study the classifier behaviour.
3 Methodology
Alex et al. [1] propose a Counterfactual Generative Network (CGN) framework to gener‐ ate high‐quality counterfactual images, which can be used to train invariant classifiers. The architecture of a CGN is composed of three IMs that are trained to generate back‐ grounds, shapes, and textures. Each IM is provided with a label. The task of the invari‐ ant classifier is to predict the label of a specific IM, regardless of the labels of the others. In conjunction with the composer function, the use of counterfactual images generated by the three IMs prevents the classifier from learning spurious relationships that arise from training on a natural dataset only. The architecture of the CGN consists of a GAN as the backbone of each IM. Each IM sam‐ ples random noise µ ∼ N(0,1), along with an independently sampled label to generate
ReScience C 8.2 (#2) – Ankit et al. 2022 3
samples. The output xgen is generated using an analytical function from the Composer ’C’,
xgen = C(m, f, b) = m⊗ f + (1−m)⊗ b
where ’m’ is the mask (alpha map), f is foreground and b is background. ⊗ denotes the element wise multiplication. The losses Lrec (xgt, xgen), L1 reconstruction loss, Lperceptual as shown in Fig. 1 are used to improve the quality of generated images. Once the CGN is trained, u and y are randomized per mechanism such that new counterfactual xgen are generated. Further‐ more, hyperparameters such as CF ratio (the ratio indicates how many counterfactuals are generated per sampled noise) can be used to control the number of samples that are being generated. These samples are then used to train the classifier and evaluated on the corresponding test set.
cGAN
CGN
BigGAN
BigGAN
BigGAN
BigGAN U2-Net
U2-Net
3.4 Computational requirements All models are run on Nvdia GTX1080Ti GPUs (11Gb VRAM). For the MNIST datasets, training a CGN and a classifier each took approximately one hour.
4 Results
A lack of compute power prevented us from replicating the experiments on ImageNet. As aworkaround, we limit ourselves to verifying the results using the ImageNet‐1k(mini) dataset. This is beneficial because it extends the results of the paper and evaluates the method on a new dataset, and ensures that results can be reproduced with limited re‐ sources by referring to our report/code and the CGN paper.
4.1 Results reproducing original paper
Can Image generation process be decomposed into independent causal inductive biases effectively? — We begin the experiment by training a CGN on the three variants of the MNIST dataset. We observe in Fig. 2 that the digits in case of colored MNIST dataset lose their shape when reconstructed, whereas for double colored and wildlife MNIST, the digits look much better. Since we do not clearly understand why the shape in Colored MNIST is poor, we generated a mask timeline to verify any patterns. Fig. 3a details the same. Fur‐ ther analysis on this was conducted and recorded in 4.2. We also propose an additional loss function to help mitigate this problem.
ReScience C 8.2 (#2) – Ankit et al. 2022 5
Quality of Counterfactual Images on ImageNet-1k — To quantify the quality of the composite images produced by the CGN, the authors calculate the inception score (IS). The details of the IS calculations (inception model used, number of images used) were not men‐ tioned in the paper. In an attempt to recreate the results regarding IS, we use the Ope‐ nAI implementation 1. We plot the results of IS vs the number images using 10 splits in Fig. 9. We observe the IS converges to an IS of 198. Wemade use of the pre‐trained CGN trained on ImageNet‐1k that was present as part of the codebase to generate counterfactual images. Since there is no quantitative way to measure the quality of counterfactual images, we reproduced the images given in the original paper. We achieved a similar quality of counterfactual images but also noted deviations. Fig. 7 shows all the images that were given in the original paper. A deviation in the mask is observed for the class ’Agaric’ and ’Cauliflower’. The difference in the im‐ ages to the original paper prompted us to collect the classes with poorer counterfactual images to observe any patterns. Fig. 8 is generated from the pre‐trained CGN that have a low quality of images picked from random classes. Since the analysis is qualitative, we relied on the realism of the counterfactual compared to original images from that class. Images under the classes ’Cliff dwelling’ ’American Chameleon’ suffer from Texture‐background entanglement re‐ sulting in the counterfactual with no subject. On the other hand, the images under the class ’Goldfinch’, ’Junco’ suffer from reduced realism due to linear constraints applied on the composer.
Impact of counterfactual images towards shape-bias of the classifier —
Experiments conducted with ImageNet-1k(mini) dataset — In order to identify the impact of shape bias on the classifier, we made use of the proposed architecture for the classifier ensemble that included 3 different heads. The ensemble includes a pre‐trained classi‐ fier(we made use of Resnet‐50) as the backbone, while attaching 3 different heads to it. Each head controls the variance with respect to one of the 3 independent mecha‐ nism(Shape, Texture, Background) which are individually trained from scratch. The result from these heads are averaged to get the prediction accuracy of the classifier en‐ semble. The results in Table 2(a) for ImageNet‐1k(Mini) showed a considerable deviation. The shape bias is marginally lower compared to the baseline result while the texture bias is high. The reduction in the shape bias could be due to the smaller dataset that we are using. Since this is ambiguous to validate the original claim we conducted additional experiments which are detailed in section 4.2."
"['Arjun Ashok', 'Haswanth Aekula']",[Re] Does Self-Supervision Always Improve Few-Shot Learning?,10.5281/zenodo.6574629,Replication,Python,https://zenodo.org/record/6574629/files/article.pdf,rescience c machine learning deep learning python pytorch few-shot learning self-supervised learning,https://openreview.net/forum?id=ScfP3G73CY,https://github.com/ashok-arjun/MLRC-2021-Few-Shot-Learning-And-Self-Supervision/,8,2,2022,"This report covers our reproduction and extensionof the paper ‘WhenDoes Self‐Supervision Improve Few‐shot Learning?’ published in ECCV 2020. The paper investigates the ef‐ fectiveness of applying self‐supervised learning (SSL) as a regularizer to meta‐learning based few‐shot learners. The authors of the original paper claim that SSL tasks reduce the relative error of few‐shot learners by 4% ‐ 27% on both small‐scale and large‐scale datasets, and the improvements are greater when the amount of supervision is lesser, or when the data is noisy or of low resolution. Further, they observe that incorporating unlabelled images from other domains for SSL can hurt the performance of FSL, and propose a simple algorithm to select unlabelled images for SSL from other domains to provide improvements.","The paper was well written and easy to follow, and provided clear descriptions of the experiments, including the hyperparameters. The authors’ code implementation in Py‐ Torch was relatively easy to understand.","Since the codebase was incomplete, it took us a lot of time to solve bugs, and reimple‐ ment algorithms not present in the code. Further, the datasets needed a lot of prepro‐ cessing to be used. The number of hyperparameters being too many but each proving to be important, and evaluating all the claims of the paper on 5 datasets and 2 architec‐ tures was difficult to the number of experiment configurations, resulting in a very high computational cost of 980 GPU hours.
Communication with original authors Wemaintained contactwith the authors throughout the challenge to clarify implementa‐ tion details and questions regarding the domain selection algorithm. The authors were responsive and replied promptly with detailed explanations.
ReScience C 8.2 (#3) – Ashok and Aekula 2022 2
2 Content
3 Scope of reproducibility
The paper claims that
• With no additional training data, adding self‐supervised tasks such as jigsaw/rota‐ tion prediction as an auxiliary task improves the performance of existing few‐shot techniques on benchmarks across several different domains
• The benefits of self‐supervision increase with the difficulty of the task, for exam‐ ple when training with a base dataset with less labelled data, or when the dataset contains images of lesser quality/resolution
• Using unlabelled data from dissimilar domains for self‐supervision negatively im‐ pacts the performance of few‐shot learners
• The proposed domain selection algorithm can alleviate this issue by learning to pick images that are similar to the training domain, from a large and generic pool of images
We thoroughly reproduce all the experiments, and investigate whether the claims hold true, with the model and the six benchmark datasets used by the authors. Beyond the paper, we find that the results are biased towards the architecture and resolution used, and demonstrate that the gains do not hold when the input resolution and architecture differ from those reported in the paper. We also report results on the more practical cross‐domain few‐shot learning setup. Here, we find that self‐supervision does not help ImageNet‐trained few‐shot learners generalize to new domains better. Finally, along with our reproducible codebase, we open‐source processed versions of 3 datasets that previously required tedious manual processing, to facilitate their off‐the‐shelf usage.
4 Methodology
The goal of a few‐shot learner is to learn representations of base classes that lead to good generalization on novel classes. To this end, the proposed framework combines meta learning approaches for few‐shot learning with self-supervised learning. In general, learning consists of estimating functions f , the feature extractor and g, the classifier that minimize the empirical loss ℓ over the training data from base class Ds = {(xi, yi)}ni=1 consisting of images xi ∈ X and labels yi ∈ Y, along with suitable regularization R. This can be written as:
Ls = ∑
(xi,yi)∈Ds
ℓ(g ◦ f(xi), yi) +R(f, g)
In the original paper, the loss of prototypical networks (ProtoNet)[1] are used as part of the supervised loss. During meta‐training, ProtoNet computes the mean of the embed‐ dings of all samples in a class. Then, a distance metric such as Euclidean distance or cosine distance is used to classify every query sample into one of the classes, using the distance from the class‐prototypes. The loss over the query samples is backpropagated to the network, and this procedure is repeated for multiple episodes with n randomly sampled classes in each episode, with k examples in each class, hence referred to as the n‐way k‐shot setup. Hence the network meta‐learns to provide useful class‐prototypes from very few examples. At meta‐test time, class prototypes are recomputed from the few examples per each class, and query examples are classified based on the distances to the class prototypes.
ReScience C 8.2 (#3) – Ashok and Aekula 2022 3
Apart from the supervised losses, the paper uses self‐supervised losses ℓss that are de‐ rived from (x̂, ŷ). Let h denote an additional auxiliary classifier used as part of a self‐ supervised loss, and Dss denote the dataset used to construct the self‐supervised tasks. Then the self‐supervised loss is
Lss = ∑
(xi)∈Dss
ℓ(h ◦ f(x̂i), ŷi)
The jigsaw task splits an image into 9 regions (3x3) and permutes the regions to obtain the input x̂. The target label ŷ is the index of the permuatation. The total number of indices are 9! which is reduced to 35 indices [2] by grouping the possible permutations to control the difficulty of the task. The rotation task rotates the image by an angle θ ∈ 0◦, 90◦, 180◦, 270◦ to obtain x̂, with ŷ being the index of the angle. The paper uses a weighted combination of the supervised and self‐supervised losses L = (1− α) ∗ Ls + (α) ∗ Lss. The author also propose an algorithm to select images from a large‐dataset for self‐ supervision when Ds and Dss are different. Here, a classifier is trained to distinguish the ResNet‐101 features of images from Ds and images from Dss, and the top‐k images according to the ratio p(x ∈ Ds)/p(x ∈ Dp) are selected for self‐supervision.
5 Experimental settings
5.1 Details regarding the code
The authors provide a public implementation of the code1, which is built upon a pop‐ ular codebase 2 from Chen et al [3]. We find that there are a lot of errors and bugs in the code, which took a lot of time to debug. This took up a considerable part of our time. Further, the code for the domain selection algorithm was not present, and hence we had to reimplement it from scratch. Our code 3 reuses multiple files from the original codebase, corrects several errors, and provides an implementation of the domain selec‐ tion algorithm. We also provide interfaces to train models with a different architecture, and to evaluate models in a cross‐domain setup.
5.2 Model descriptions The authors use awell‐knownarchitectureResNet‐18 for their experiments. TheResNet18 gives a 512‐dimensional feature for each input. For the jigsaw task, a single fully‐connected (fc) layer with 512‐units is added in parallel to the classifier. Nine patches of an image give nine 512‐dimensional feature vectors, which are concatenated, and projected to 4096 dimensions using an fc layer, and then to a 35‐dimensional output using another fc layer, corresponding to the 35 permutations for the jigsaw task. For rotation prediction task, the 512‐dimensional output of ResNet‐18 is passed through three fc layers consecutively with 128, 128, 4 units. The 4 predictions of the last layer correspond to the four rotation angles. Between each fc layer, a ReLU activation and a dropout layer with a dropout probability of 0.5 are added. Apart from the ResNet‐18 architecture used in the paper, we use another architecture that is equally adapted in many few‐shot learning papers [3] [1] [4] [5], the Conv‐4‐64 architecture, which is a simpler architecture with 3x3 kernel size and 64 filters at each layer. Similar extensions aremade for the jigsaw and rotation tasks. Inmultipleworks in the literature, this architecture has beenused to process 84 x 84 images, while theResNet
1https://github.com/cvl-umass/fsl_ssl 2https://github.com/wyharveychen/CloserLookFewShot 3https://github.com/ashok-arjun/MLRC-2021-Few-Shot-Learning-And-Self-Supervision
ReScience C 8.2 (#3) – Ashok and Aekula 2022 4
variants have been used to process 224 x 224 images. We follow the works and report results with the respective resolutions for each architecture. Both the architectures are represented diagrammatically in tables 15 and 16 respectively in the appendix.
5.3 Datasets Following the few‐shot setup, each dataset is split into three disjoint sets namely the base training set, validation set and the test set. The model is trained on the base set, validated on the validation set, and tested on the test set. Following the paper, we exper‐ iment with multiple datasets across diverse domains and denote the number of classes in the base, val, test splits inside brackets: CUB‐200‐2011 [6](64, 12, 20) , Stanford Cars [7] (98, 49, 49), FGVC‐Aircraft [8] (50, 25, 25), Stanford Dogs [9] (60, 30, 30), Oxford Flowers [10] (51, 26, 26). These 5 datasets are henceforth referred to as ”the smaller datasets”. Apart from these, we also experiment with a benchmark dataset for few‐shot learning, the miniImageNet dataset [11] (64, 16, 20). The original paper also reports results on Tiered‐ImageNet, but we restrict to evaluating on miniImageNet due to compute and time constraints. We use the same base‐validation‐novel class splits for every dataset exactly as in the paper, which they provide in their official repository. Implementation‐wise, each class contains 3files, one for each in base, val and novel, and lists the classes to be used, along with all the image paths for each class. Among the small datasets, we found that there were no versions of the flowers and cars dataset that could be used directly. Hence we had to preprocess the two datasets ourselves, before we could use them off‐the‐shelf. With the miniImageNet dataset, we found that all the directly‐downloadable versions [12] [13] contained images resized to 84x84, however we needed a dataset that could be resized to either 84x84 or 224x224 adaptively. Hence, we had to download the ImageNet dataset (155 GB) and process the dataset from scratch, which caused storage issues and also took up a significant part of our time. Along with codebase, we also open‐source the processed flowers4 and cars5 datasets, and the miniImageNet dataset with image sizes same as that in ImageNet6. For the domain selection algorithm, the authors use the training sets of two large datasets ‐ Open Images v5 [14] and iNaturalist [15], which are 500 GB and 200 GB in size respec‐ tively. Weuse the validation splits of these datasets as unlabelled images for self‐supervision.
5.4 Hyperparameters Thehyperparameter sweepswere conductedusingWeights andBiases. Each sweepuses random search to search over the following 3 hyperparameters:
• Learning Rate: Sampled from a uniform distribution (0.0001, 0.03)
• Batch normalization mode:
1. Use batch normalization, accumulate statistics throughout training, and use the statistics during testing
2. Use batch normalization, but do not track the running mean and variance during training; estimate them from batches during training and test
3. No batch normalization
• Alpha (α), the weightage of the SSL term in the loss (only where self‐supervision is applied)
4https://www.kaggle.com/arjun2000ashok/vggflowers/ 5https://www.kaggle.com/hassiahk/stanford-cars-dataset-full 6https://www.kaggle.com/arjunashok33/miniimagenet
ReScience C 8.2 (#3) – Ashok and Aekula 2022 5
In the above grid, the batch‐norm modes especially designed to verify the claim of the paper that using batch normmode 2was found to be better for a subset of tasks that did not involve jigsaw, and vice‐versa. All models are trained with the Adam optimizer with β1 = 0.9 and β2 = 0.999. We then use the configuration which gives the best validation accuracy. Due to com‐ putational constraints, we search hyperparameters for certain datasets, and reuse the hyperparameters found for similar datasets. The selected experiment configurations are given in the appendix and the code‐base. Across all of our sweeps, we notice that α stays below 0.6, and does not go below 0.3 in our runs. Hence, we infer that an ade‐ quate amount of supervision is also needed for good performance, and too much self‐ supervision hurts accuracy. For the miniImageNet dataset, we find the values close 0.3 work the best, which the paper reiterates. The paper reports that they use 0.5 for all the SSL experiments on the small datasets, which we confirm as our α term converges to values 0.4 and 0.6 for the small datasets. All of our reported results are with the best hyperparameters found.
5.5 Computational requirements We used 4 Nvidia 1080Ti GPUs for all experiments. The run‐times differ for each exper‐ iment configuration when incorporating self‐supervision. We report the average epoch time for each experimental setup (1 epoch = 100 episodes) in table 6 in the appendix. In general, among experiments involving self‐supervised learning, rotation took the maximum amount of time. This is because 4 rotations of the same image are needed at every instance, which is more expensive than loading a single image. The jigsaw task took lesser time than rotation, and the combination of jigsaw and rotation took the high‐ est amount of time per epoch. Since the paper reports results on the combination only for the first set of experiments (claim 1), we also do the same. Further, the computa‐ tional time restricted us from performing more experiments combining the two. In total, apart from the hyper‐parameter sweeps, we perform 250 experiments, across different experimental setups and multiple datasets. All of these experiments took ap‐ proximately 700 GPU hours. Along with the hyperparameter sweeps which, the experi‐ ments took approximately 980 hours of compute time.
5.6 Experimental setup and code Following the authors, we train, evaluate and report results on the 5‐way 5‐shot setting; we also explore 20‐way 5‐shot setting but we could not continue after a few runs, re‐ stricted by the large training and testing time of 20‐way 5‐shot models. Following the paper, we use 16 query examples to evaluate the models. The batch size cannot be set in episodic few‐shot learners, and are by default given by n_way ∗ (n_support + n_query). We use 16 query images following the paper, and as a result, our batch sizes are 105 in 5‐way 5‐shot experiments, and 420 in 20‐way 5‐shot experiments. Following all previous work in few‐shot learning, we sample 100 episodes (batches) per epoch, and conduct experiments on about 600 ‐ 800 epochs. Following the paper, we use only 5 query images when trainingmodels for experiments that use lesser labelled data since the {20, 40, 60, 80}% splits of dataset do not contain 16 query images in all classes. In every iteration, an equal number of unlabelled images are sampled at random from the respective dataset(s) for self‐supervised learning. Following our paper and the base‐ line from previous work [3] in few‐shot learning and our original paper, we use the fol‐ lowing data augmentation: For label and rotation predictions, images are first resized to 224 pixels for the shorter edge whilemaintaining aspect ratio, fromwhich a central crop of 224 is obtained. For jigsaw puzzles, a random crop of 255 is done from the original image with random scaling between [0.5, 1.0], then split into 3×3 regions, from which a
ReScience C 8.2 (#3) – Ashok and Aekula 2022 6
CUB Dogs Cars Aircrafts Flowers 80
82
84
86
88
90
92
94
Ac cu
ra cy
Results on ResNet-18
ProtoNet ProtoNet + Rotation ProtoNet + Jigsaw ProtoNet + Jigsaw + Rotation
Figure 1. Results on applying SSL tasks to Pro‐ totypical networks, across 6 datasets
Method Accuracy ProtoNet 74.07 ± 0.71 ProtoNet + Jigsaw 77.29 ± 0.73 ProtoNet + Rotation 74.93 ± 0.9
ProtoNet + Jigsaw + Rotation 76.23 ± 0.9
Table 1. miniImageNet Results with ResNet‐ 18
random crop of size 64×64 is picked. For evaluation at meta‐test time, we use 600 ran‐ domly sampled episodes, and report the mean accuracy and 95% confidence intervals. We implement the domain selection algorithm following the paper: For each dataset among the small datasets, we select negative images uniformly at randomwith 10 times the size of the positive images. The loss for the positive class is scaled by the inverse of its frequency to account for the significantly larger number of negative examples. We then train a binary logistic regression classifier using LBFGS for 10000 iterations and use the logits to compute the ratio p(x ∈ Ds)/p(x ∈ Dp), whereDp represents the large pool of images, andDs represents the supervised training set. We then choose k as 80%of the total dataset size, and sample k images from the negative class (Dp) to use as unlabelled samples. On verifying that the core claim of the paper (claim 1) for all the 5 small datasets, we choose a diverse set of 2 to 3 representative datasets for claims 2 and 3. For the do‐ main selection, we evaluate on all the 5 datasets to verify our implementation of the algorithm.
6 Results
6.1 Results reproducing original paper Here, we consider the same architecture that the paper uses ‐ ResNet‐18, with an input image size of 224.
Self-supervision improves few-shot learning —Here, we successfully verify claim 1 of the pa‐ per which states that with no additional unlabelled data, SSL improves few‐shot learn‐ ing when applied as an auxiliary task. We conduct experiments across all the 5 small datasets as well as the large‐scale miniImageNet dataset. We also reproduce results on the baseline from [3], andMAML andMAML+Jigsaw. We present results in figure 1, and tables 1 and 2. All results are on 5‐way 5‐shot classification.
The benefits of self-supervision increase with the difficulty of the task —We successfully verify claim 2 of the authors that the relative gains of using SSL aremore when the difficulty of the task is higher. The authors experimentwith two types of difficult tasks: onewith low‐ resolution/greyscale images as input, and another with less labelled data from the base training set. We experiment with 3 selected datasets andwere successful in reproducing the results. We report the results on figures 2 and 4. The exact numbers are given on
ReScience C 8.2 (#3) – Ashok and Aekula 2022 7
0 20 40 60 80 68
70
72
74
76
78
80
82
Ac cu
ra cy
% of images from other domains used for SSL
CUB Cars Dogs
Figure 3. Performance on tasks where a portion of the labelled data is replaced with data from other domains
tables 12 and 10 respectively in the appendix. We find that the claims of the paper hold true, and that self‐supervision has higher gains in harder tasks.
Unlabelled data for SSL from dissimilar domains negatively impacts the few-shot learner — Verify‐ ing claim 3 of the paper, we replace a portion of the labelled data, starting from 20% of the data to 80% of the data, with data from other domains. Here, we combine the data from all other datasets together, and sample images at random. We present results on 3 chosen datasets, again, to save computation and time for other results. Results are given in figure 3 and table 11 (appendix). The claim that using data from dissimilar domains for self‐supervision is detrimental to few‐shot classification holds true.
The proposed domain selection algorithm can alleviate this issue by learning to pick images from a large and generic pool of images — To verify claim 4, we implement the domain selection algorithm from scratch, and verify it across all 5 small datasets as given in the paper, to make sure that we have got the implementation right. Results are presented in figure 5 and table 13 in the appendix. Results are shown on using only 20% of the labelled data for learning, only selecting images from other domains at random, and on using the proposed domain selection algorithm. We successfully verify and demonstrate that the algorithm proposed by the authors for selecting images from multiple dissimilar domains.
ReScience C 8.2 (#3) – Ashok and Aekula 2022 8
6.2 Results beyond original paper
Results on a different architecture - Conv4 —Here, we aim to investigatewhether the claims of the paper hold when a small architecture that needs a smaller image size (84x84) is used. In particular, we investigate claim 1 of the paper extensively. Note that the authors do not report results with this architecture. Results are given in figure 6. Exact numbers are given in tables 7 and 9 in the appendix. We find that the results do not hold true when a smaller architecture and image size is used, and that claim depends heavily on the architecture and image size. We present results across all the 5 small datasets for completeness, across both SSL tasks. To confirm our claims, we also rerun results with another seed, but get similar results (Table 8 in appendix). We next study the effect of α on the results, with the CUB and cars datasets in tables 3 and 4. Here we find that the value of α plays an important role in the performance, and that high values leading to too much self‐supervision is detrimental when the model is small. Even across training and testing with multiple α values, we find that the self‐ supervision provides only a marginal boost in 1 out of 4 cases, invalidating claim 1 of the paper that self‐supervision provides a stable boost to few‐shot learners.
Results on cross-domain few-shot learning — In another effort to extend the paper’s results, we test the results of our trained models on the BSCD‐FSL benchmark for cross‐domain few‐shot learning, introducedby [16]with their code 7. Thebenchmark requires ImageNet‐ based trained few‐shot models to evaluated on four cross‐domain datasets: CropDis‐ eases, EuroSAT, ISIC2018, and ChestX datasets, which covers plant disease images, satel‐
7https://github.com/IBM/cdfsl-benchmark
ReScience C 8.2 (#3) – Ashok and Aekula 2022 9
CUB Dogs Cars Aircrafts Flowers 60
65
70
75
80
Ac cu
ra cy
Domain selection results
No SSL SSL with random selection SSL with importance weights
Figure 5. Results of the domain selection algo‐ rithm CUB Dogs Cars Aircrafts Flowers
40
50
60
70
80
90
Ac cu
ra cy
Results on Conv-4
ProtoNet ProtoNet + Rotation ProtoNet + Jigsaw ProtoNet + Jigsaw + Rotation
Figure 6. Results of using SSL with the Conv4 architecture
lite images, dermoscopic images of skin lesions, and X‐ray images, respectively. The se‐ lected datasets reflect real‐world use cases for few‐shot learning since collecting enough examples from above domains is often difficult, expensive, or in some cases not possi‐ ble. We use this benchmark to find out if models trained with self‐supervision provide gains over normal supervised models when tested on real-world datasets. We test our mini‐ImageNet trained models on this benchmark, to find out if self‐supervision im‐ proves results on cross‐domain datasets. Results on the ResNet‐18 models are reported in table 5. Results on the Conv‐4models are given in appendix table 14. We find that self‐ supervision results in learning heavily domain‐specific representations, and that the re‐ sults of the fully‐supervised learner are much better than those with auxiliary tasks as self‐supervision.
7 Discussion
We find that the central claims of the author as given in Section 3 hold true, when the same architecture is used. Considering the ResNet‐18 model used in the paper with an input image size of 224, we find that self‐supervision ‐ in particular the jigsaw task, pro‐ vides a boost in the case of small datasets. Experimentally, we verify claim 1 of the paper on all small datasets and miniImageNet. However, going beyond the paper’s architec‐
ReScience C 8.2 (#3) – Ashok and Aekula 2022 10
ture, we find that the results depend heavily on the image size and architecture and do not give the same gains with Conv‐4‐64, another architecture common in the few‐shot learning literature, with an input image size of 84. Further ablation reveals that the jig‐ saw task in particular has a strong influence in this setup, and the rotation task requires tuning the α parameter to even reach the accuracy of the fully‐supervised model. Fu‐ ture work may investigate ways to boost the performance of few‐shot classifiers when the input sizes are small, and may also find out better architectures to use when the in‐ put size is small. Future work may also experiment with other available architectures, and find out if self‐supervision increases performances across all configurations. Regarding claims 2 and 3 such as on harder tasks and scenarios with lesser labelled data in the base dataset, our experiments on selected datasets verify that the claims hold true, with the ResNet‐18 backbone. Further, we verify claim 4 of the paper by implementing the domain selection algorithm from scratch and our experiments on all the 5 datasets show that relative gains are achieved. Future work may also investigate if the same claims hold true when different architectures were used. Finally, we evaluate the miniImageNet‐trained models on a more practical setting of cross‐domain few‐shot learning and find that SSL during the training time does not help few‐shot learners generalize across domains better. Future work may investigate why applying SSL results in domain‐specific features, and propose methods to apply SSL in a more domain‐agnostic manner. We recommend future works in few‐shot learning to train and evaluate in multiple architectures with different resolutions and verify their work more thoroughly.
7.1 Communication with original authors We maintained communication with the authors throughout our implementation and training phase, spanning two months. We were able to clarify many implementation details in the original codebase, and the authors also re‐ran an experiment on their side to test if the numbers match. Further, we received a lot of help regarding implementa‐ tion of the domain selection algorithm, and could also confirm the implementationwith them. We acknowledge and thank the authors for their help with the reproducibility of their paper.
8 Acknowledgements
The authors are grateful to Weights & Biases and DAGsHub for reproducibility grants that supported this work.
ReScience C 8.2 (#3) – Ashok and Aekula 2022 11"
"['Ioannis Athanasiadis', 'Georgios Moschovis', 'Alexander Tuoma']",[Re] Weakly-Supervised Semantic Segmentation via Transformer Explainability,10.5281/zenodo.6574631,Replication,Python,https://zenodo.org/record/6574631/files/article.pdf,rescience c machine learning deep learning python pytorch,https://openreview.net/forum?id=rcEDhGX3AY,https://github.com/athaioan/ViT_Affinity_Reproducibility_Challenge,8,2,2022,"In this work, we experimented with Layer‐wise Relevance Propagation and combined it with back‐propagation to perform classification and semantic segmentation, follow‐ ing the approach proposed by Chefer H. et al., in [1] for computer vision. Moreover, we incorporated the concept of pixel affinities, by using ViT‐based explainability as vi‐ sual seeds to drive the generation of pseudo segmentation masks by computing pixel affinities, following the approach described by Ahn J. et al. in [2].",,
"['Piyush Bagad', 'Paul Hilders', 'Jesse Maas', 'Danilo de Goede']",[Re] Reproducibility Study of “Counterfactual Generative Networks”,10.5281/zenodo.6574635,Replication,Python,https://zenodo.org/record/6574635/files/article.pdf,rescience c machine learning python pytorch deep generative models counterfactuals,https://openreview.net/forum?id=HNlzT3G720t,https://github.com/danilodegoede/fact-team3/,8,2,2022,"In this work, we study the reproducibility of the paper Counterfactual Generative Networks (CGN) by Sauer and Geiger to verify their main claims, which state that (i) their pro‐ posed model can reliably generate high‐quality counterfactual images by disentangling the shape, texture and background of the image into independentmechanisms, (ii) each independent mechanism has to be considered, and jointly optimizing all of them end‐ to‐end is needed for high‐quality images, and (iii) despite being synthetic, these coun‐ terfactual images can improve out‐of‐distribution performance of classifiers by making them invariant to spurious signals.","The original paper provides an extensive appendix with implementation details and hy‐ perparameters. Beyond that, the original code implementation was publicly accessible and well structured. As such, getting started with the experiments proved to be quite
Copyright © 2022 P. Bagad et al., released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Piyush Bagad (piyush.bagad@student.uva.nl) The authors have declared that no competing interests exist. Code is available at https://github.com/danilodegoede/fact-team3/. – SWH swh:1:dir:410075522df668dfae4742564f10b62de0cb8dc6. Open peer review is available at https://openreview.net/forum?id=HNlzT3G720t.
ReScience C 8.2 (#5) – Bagad et al. 2022 1
straightforward. The implementation included configuration files, download scripts for the pretrained weights and datasets, and clear instructions on how to get started with the framework.","Some of the experiments required severe modifications to the provided code. Addition‐ ally, some details required for the implementation are not specified in the paper or in‐ consistent with the specifications in the code. Lastly, in evaluating out‐of‐distribution robustness, getting the baseline model to work and obtaining numbers similar to those reported in the respective papers was challenging, partly due to baseline model incon‐ sistencies within the literature.
Communication with original authors We have reached out to the original authors to get clarifications regarding the setup of some of the experiments, but unfortunately, we received a late response and only a subset of our questions was answered.
1 INTRODUCTION
Despite the considerable popularity of deep learningmodels within the field of artificial intelligence, recent literature suggests that these networks have a tendency of learning simple correlations that perform well on a benchmark dataset, instead of more com‐ plex relations that generalize better [2, 3, 4]. This phenomenon, which is referred to as shortcut learning by Geirhos et al. [5], makes these models more sensitive to input perturbation and unseen input contexts.
In order to enhance the robustness and interpretability of classifiers, Sauer and Geiger [1] introduce the idea of a Counterfactual Generative Network (CGN). Using appro‐ priate inductive biases to disentangle separate components within the input images, such as object shape, object texture, and background, this model is capable of augment‐ ing training data with generated counterfactual images. The authors claim that, using this model, they were able to improve out‐of‐distribution (OOD) robustness with only a marginal performance decrease for the original classification task.
In this work, we aim to reproduce their findings, verify their claims, and perform additional experiments to provide further evidence to support their claims. In summary, this work makes the following contributions:
• We reproduce the main experiments conducted by Sauer and Geiger [1] to identify which parts of the experimental results supporting their claims can be reproduced, and at what cost in terms of resources (e.g., computational cost, development ef‐ fort, and communication with the authors).
• We improve the performance consistency of the CGN during training.
• We extend upon the work of Sauer and Geiger by empirically analyzing the deci‐ sions made by classifiers based on their proposed model. Based on this analysis, we propose a method to quantify the robustness of such classifiers against spuri‐ ous correlations.
1.1 Scope of Reproducibility Distinguishing between spurious and causal correlation is an active topic in causality research [6, 7]. One central principle in causal inference is the assumption of indepen‐ dent mechanisms (IMs), which states that a causal generative process is composed of
ReScience C 8.2 (#5) – Bagad et al. 2022 2
autonomous modules that do not influence each other [8, 1, 9]. The CGN introduced in the original paper exploits this idea to decompose the image generation process into three IMs, each controlling one factor of variation (FoV), namely the shape, texture, and background. Using this, the authors take a step towards more robust and interpretable classifiers that explicitly expose the causal structure of the classification task. In this re‐ producibility study, our main goal is to verify the following claims of the original paper:
• High‐Quality Counterfactuals (HQC): By exploiting proper inductive biases, the CGN is able to reliably learn the independent mechanisms, which allow for the generation of high‐quality counterfactual images by disentangling the shape, tex‐ ture and background of the image.
• Inductive Bias Requirements (IBR): Each independent mechanism has to be con‐ sidered, and jointly optimizing all of them end‐to‐end is needed for high‐quality images.
• Out‐of‐DistributionRobustness (ODR): Despite being synthetic, the counterfactual images can improve out‐of‐distributionperformance of classifiers bymaking them invariant to spurious signals.
The remainder of this work is structured as follows. In Section 2, we introduce the model proposed in the original paper to provide the reader with the required back‐ ground knowledge. Section 3 then summarizes our approach to reproduce the original paper. Subsequently, Section 4 presents the replicated results and compares them to the original paper. Section 5 concludes this work by discussing our experience with reproducing the research by Sauer and Geiger [1].
2 COUNTERFACTUAL GENERATIVE NETWORK
The counterfactual generative network is a manifestation of a structural causal model (SCM) for the task of image classification [1]. It decomposes the image generation pro‐ cess into four IMswhose losses are jointly optimized in an end‐to‐endmatter. Anoverview of the CGN architecture is shown in Appendix A.
Shape mechanism: The shape mechanism fshape captures the shape as a binary mask m, where 1 corresponds to the object and 0 to the background. For this purpose, it first samples a pre‐mask m̃ with exaggerated features from a fine‐tuned BigGAN [10], and extracts the binarymaskusing a pretrainedU2‐Net [11]. The shape lossLshape comprises (1) the pixelwise binary entropy of the mask, and (2) the mask loss:
Lmask(m) = Ep(u,y)
[ max ( 0, τ − 1
N N∑ i=1 mi
) +max ( 0, 1
N N∑ i=1 mi − τ
)] . (1)
The pixelwise binary entropy forces the output to be close to either 0 or 1, whereas the mask loss discourages trivial solutions that are outside the interval defined by τ .
Texture mechanism: The texture mechanism ftext generates the texture of the object. For MNIST, Sauer and Geiger use an additional layer that divides its input into patches and randomly rearranges them. In contrast, for ImageNet, they sample patches from the regions where the mask values are the highest and concatenate them into a patch grid pg. This mechanism is optimized by minimizing the perceptual loss between the foreground f and the patch grid pg. As such, the background gradually transforms into object texture during training.
ReScience C 8.2 (#5) – Bagad et al. 2022 3
Background mechanism: The background mechanism fbg models the background b of the image. It removes the object from the output of the BigGAN backbone and in‐ paints it using U2‐Net by minimizing the predicted saliency. Because there is no need for a globally coherent background in the MNIST setting, the MNIST variant of the CGN includes a second texture mechanism rather than a dedicated background mechanism.
Composer: The composerC combines the output of the aforementionedmechanisms into a single composite image
xgen = C(m,f , b) = m⊙ f + (1−m)⊙ b, (2)
wherem is the mask, f is the foreground, b is the background, and ⊙ is the Hadamard product. To optimize this mechanism, Sauer and Geiger use an external conditional GAN (cGAN) that generates pseudo‐ground‐truth images xgt from the same noise u and label y that is fed into the aforementionedmechanisms of the CGN. Using this, theymin‐ imize the reconstruction loss Lrec between the composite image xgen and the pseudo‐ ground‐truth image xgt.
During training, each independent mechanism learns a class‐conditional distribu‐ tion over shapes, textures, or backgrounds. It can then generate counterfactual images by randomizing the noise u and label input y for each mechanism. A more detailed explanation regarding the purpose of these counterfactual images and the connection with explainable artificial intelligence (XAI) can be found in Appendix B.
In order to encode invariance to spurious correlations, Sauer and Geiger train classi‐ fiers on generated counterfactual data that retain the label from the shape with random‐ ized texture and backgrounds. For MNISTs, they use a standard CNN feature extractor followed by a single classification head. For ImageNet on the other hand, they use a CNN backbone with three classifier heads: shape, texture, and background; each in‐ variant to all but one factor of variation. The final prediction is obtained by averaging the individual head predictions.
3 METHODOLOGY
The original implementation of the CGN is publicly available [12], but most of the exper‐ iments conducted in the original paper to support their claims are not. Consequently, we use the authors’ code for the implementation of the CGN, and re‐implement the ex‐ periments and relevant evaluation metrics based on the descriptions provided in the paper. Furthermore, we both improve and extend upon the work of Sauer and Geiger by providing additional experiments and results. Because a description of the GANused in the original paper was not provided, we use a DCGAN [13].
3.1 Datasets The experiments conducted in the original paper involve two tasks, namely generating counterfactual examples and training a classifier to be invariant to spurious correlations. We follow the paper and reproduce their evaluations on multiple datasets for each task. For both tasks, we present the relevant datasets and their main purpose in Table 1. Due to resource constraints, running all experiments on full ImageNet (IN‐1k) is infeasible. As a compromise, we use ImageNet‐mini (IN‐Mini) [14], a small‐scale variant of Ima‐ geNet. Although this dataset contains fewer samples, we found it to be sufficient to reproduce the main findings of the original paper and verify their claims. Moreover, this dataset includes the same classes as IN‐1k and hence does not induce any decrease in difficulty of the classification task.
ReScience C 8.2 (#5) – Bagad et al. 2022 4
To provide further evidence to support claim ODR, we conduct additional experi‐ ments to visually explain thedecisionsmadeby the invariant classifiers based ongradient‐ based localization. For this purpose, we use a PyTorch implementation of GradCAM [19, 20], a class activation map method that weighs the 2D activations by the average gradi‐ ent [20]. This method allows us to visualize the salient features on which the invariant classifiers base their predictions.
3.4 Computational requirements We perform all experiments on a cluster whose nodes are equipped with Nvidia GeForce GTX 1080 Ti GPUs. Due to constraints in resources, we run most experiments once. As such, our experiments are indicative and not conclusive. Our reproducibility study comes at a total computational cost of 112 GPU hours (see Appendix D for more details).
4 EXPERIMENTAL RESULTS
4.1 Reproducibility study Evaluating counterfactual samples To verify claimHQC,wequalitatively evaluate coun‐ terfactual (CF) samples generated using CGNmodels on each dataset. For all our repro‐ ducibility experiments, we use the pretrained weights for CGN to generate CFs. We
1This variant ofMNIST is generated by the authors themselves and can be generated using their repository.
ReScience C 8.2 (#5) – Bagad et al. 2022 5
found inconsistencies while training the CGN from scratch and refer the reader to Sec‐ tion 4.2.1 for a deeper investigation. For bothMNIST and ImageNet, our results indicate that the quality of the generated CFs matches with the quality of those reported in the original paper, as shown in Figure 1 and Figure 2 respectively. For ImageNet, although we can easily recognize the FoVs in the generated CFs, they are highly unrealistic.
Evaluating loss ablation Weattempt to reproduce the loss ablation study to verify claim IBR. The authors claim that a CGN can be trained from scratch within 12 hours on a GTX 1080Ti GPU. However, when running the experiments as described by the authors, the estimated training time exceeded 200 hours. Upon further inspection, we found an alter‐ native configuration file containing the hyperparameters the authors used to train the CGN that was inconsistent with the default hyperparameters. Using these alternative hyperparameters, we managed to decrease the training time to approximately 20 hours. While the inception score magnitude directly depends on the number of generated im‐ ages used for the calculation, the original paper did not specify the exact number of images used during the experiment. We empirically found that using 2000 images pro‐ vides inception scores that resemble those reported in the original paper.
The results in Table 2 indicate that the inception scores follow a similar trend as re‐ ported by the authors (marked as x ). However, when disabling the texture loss, we found µmask to be 0.4, whereas the original paper reported a value of 0.9. This is a crucial difference, because the value of 0.9 of the original paper indicates a mask col‐ lapse, which the authors use to support claim IBR. Nonetheless, wewere able to support this claim by performing an additional qualitative experiment. Specifically, if we look at some samples as shown in Appendix E, it is clear that the generated texture still in‐ cludes some background. This indicates that the IMs for texture and background are no longer disentangled, which shows that the texture loss is indeed necessary.
OnMNIST variants, we identify an inconsistency in the experimental setup stated in the paper and code. The paper seems to suggest using a combination of original and CF dataset, but the code only uses CF data. As reported in Table 3, we experiment with both and observe similar results for C‐MNIST and DC‐MNIST. Surprisingly, for CGN, adding original data hurts the performance for W‐MNIST (62.9 vs. 81.4). Apart from that, the majority of our results arewithin 5% variation from those reported in the paper (marked as x ), which supports the broader claim of better generalization even in the presence of spurious correlations (e.g., texture in case of colored MNIST).
To evaluate the invariance in classifier heads on IN‐mini, we first reproduce the ex‐ periment regarding shape bias from the original paper. The shape bias is defined as the fraction of test samples for which the predicted label matches the shape label of the input image [17]. In this case, we evaluate labels with predictions from each head. As reported in Table 4, our results are smaller in comparison to the IN‐1k results reported in the original paper. Nonetheless, the overall trend does support claim ODR. Addition‐ ally, we replicate the experiment regarding the evaluation of background robustness. The paper uses the notion of BG‐gap that measures classifiers’ reliance on background signal [21]. Our results, shown in Table 5, again slightly deviate from the original paper but the trend supports claimODR. Note that, although IN‐mini was used for the training set instead of IN‐1k , the evaluation has been performed using the same datasets as in the paper.
To evaluate the effect of using more counterfactual datapoints or generating more counterfactual images per sampled noise, Sauer and Geiger performed an MNIST Ab‐ lation Study in the original paper. Our reproduction for this experiment, along with
ReScience C 8.2 (#5) – Bagad et al. 2022 7
a more detailed description regarding the experiment and results, can be found in Ap‐ pendix G.
4.2 Results beyond original paper
Improving CGN training onMNISTs —While training the CGN on theMNIST, we encountered an issue that was not mentioned in the original paper. During the training process, we observed that the digit masks had a tendency of collapsing to an erroneous state, from where the digits would no longer improve during training. For this reason, it was not possible for us to reproduce the CGN training on the MNIST data using the default con‐ figuration. Therefore, we have proposed a solution that makes the CGN training on the MNIST datasets more consistent. Details regarding our solution can be found in Ap‐ pendix C.
Explainability analysis for invariant classifiers —While the reproduced experiments for the original paper provide some support for claim ODR, these results primarily show the effect of using counterfactuals on test accuracy performance. However, it is not directly clear from these quantitative experiments if the performance increase is actually due to the fact that the use of counterfactuals ensures that the classifier focuses on the right correlations (e.g., shape) and not spurious ones (e.g., background). To further verify the validity of claim ODR, we provide two additional analyses that combine qualitative and quantitative measures to evaluate the behaviour of the counterfactual classifiers.
What does the latent feature space look like? First, we visualize learnt classifier fea‐ tures using t‐SNE for a subset of the test set of original and counterfactual (CF) data for C‐MNIST. Figure 3(a) shows that a classifier trained on CF data is indeed invariant to spurious correlations (e.g. digit color). Figure 3(b) shows that a classifier trained on CF data is also better at representing OOD samples (e.g. counterfactuals). Interestingly, the latter figure also shows that the CF‐trained classifier tends to group the clusters for 4‐7‐9 and 3‐5‐8 close to each other, which was not the case for the classifier trained on origi‐ nal data. These digits are also close in shape in reality, which suggests that the model is rightly focusing on the shape while ignoring texture. The results for other MNIST variants are consistent with this finding.
What features does the model focus on? Second, we perform an experiment to visu‐ alize a spatial heatmap of areas that the model focuses on to make a prediction. Based on claims ODR and IBR, we would expect the different heads to operate separately from one another, while being completely invariant to the other FoVs. In order to generate the spatial heatmaps we use GradCAM. Some qualitative samples are shown in Figure 4. In addition to the qualitative analyses, using GradCAM provides the opportunity to for‐ mulate another quantitative measure to validate claims ODR and IBR. This quantitative
ReScience C 8.2 (#5) – Bagad et al. 2022 8
analysis aims to measure if CF‐trained models focus on shape more than those trained on original data. To this end, we compute themean Intersection of Union (IoU) between GradCAM heatmaps and binarized digit masks on the test set. We note that a classifier trained on CF data is consistently outperforms the classifier on original data.
While the quantitative results using the IoUmetric cannot be performed on the Ima‐ geNet data, due to the lack of ground truth binary object maps, it is possible to evaluate the qualitative performance of the IMs using GradCAM. As shown in Appendix H, the individual classifier heads tend to focus on meaningful aspects.
OOD generalization for invariant classifiers — In order to provide further evidence for the claim ODR, we test the model performance on alternative ImageNet datasets, which are designed to evaluate out‐of‐distribution robustness. Specifically, we evaluate the per‐ formance on ImageNet‐A (natural adversarial examples) [22], ImageNet‐Sketch [23] and Stylized‐ImageNet [24], and compare with a ResNet‐50 baseline that is pretrained on IN‐ 1k. Surprisingly, we find that the finetuned CGN‐based ensemble performs worse on all specified OOD‐benchmarks, compared to the pretrained ResNet‐50 baseline as shown in Table 6.
Throughout this work, we have conducted several experiments to reproduce the main results from the research by Sauer and Geiger [1]. The results of our reproducibility study provide support for their claims, as we were largely able to reproduce the original results. Specifically, our results showed that the test accuracy for the MNIST classifiers greatly improved when using generated counterfactual datasets. Then, we were able to use the ImageNet‐mini dataset to achieve similar performance trends compared to the original paper in terms of shape versus texture bias evaluation, and the background robustness evaluation. However, based on the qualitative analyses for claim HQC, it is clear that the quality of the generated counterfactual images could still be improved. Specifically, we have observed some distinct failure cases regarding the quality of gen‐ erated counterfactual images, which are described in Appendix I.
Interestingly, while the loss ablation study provided similar results to what the au‐ thors reported in the original paper, we did obtain different results for the experimental run without texture loss. As the authors used this study to provide evidence for claim
ReScience C 8.2 (#5) – Bagad et al. 2022 9
IBR, this difference is quite significant. Nonetheless, qualitative analysis of the images that were generated without texture loss revealed that the quality of the generated im‐ ages indeed reduced when the texture loss was omitted. Although this does provide support for claim IBR, it also shows that the IS and µmask metrics used by the authors in the loss ablation study may not be sufficient to support their claims. Since the loss ablation study is therefore not conclusive, further research is required to investigate if the inductive biases introduced by the authors are indeed ‘appropriate’. The results from our additional experiments provide further evidence that counterfactual images generated with the proposed CGN architecture can be used to train classifiers that are more robust against spurious signals. Using GradCAM, we were able to visualize this behaviour and formulate a quantitative performance metric.
Overall, the experiments from the original paperwere largely reproducible, and their main claims seem reasonably substantiated but could benefit from additional evidence in future research. The code implementation of our reproducibility study is publicly available 1.
Limitations Unfortunately, we did encounter some difficulties during the reproduc‐ tion process. First, since our model was trained on IN‐mini, we were not able to repro‐ duce the exact same results as the original paper. However, despite the slightly deviat‐ ing results, the overall trends in the results seem to correspond well with the original results. Second, as some experimental setup information wasmissing from the original paper, we had to rely on the default parameter configuration files that were provided in the original code implementation, even though we can not be completely certain that these parameters were used for the original experiments.
5.1 Reflection: What was easy, and what was difficult? The original paper provides an extensive appendix with implementation details and hy‐ perparameters. Beyond that, the original code implementation was publicly accessible and well structured. As such, getting started with the experiments proved to be quite straightforward. The implementation included configuration files, download scripts for the pretrained weights and datasets, and clear instructions on how to get started with the framework.
Nonetheless, reproducing the original results turned out to be far from trivial as the setup of some of the experiments required severe modifications to the provided code. Additionally, some details required for the implementation are not specified in the pa‐ per or inconsistent with the specifications in the code (e.g., the GAN as mentioned in Section 3). Lastly, in evaluating robustness to OOD, getting the baseline model to work and obtaining numbers similar to those reported in the respective papers was challeng‐ ing, partly due to baseline model inconsistencies within the literature.
5.2 Communication with original authors We have reached out to the original authors to get clarifications regarding the setup of some of the experiments. For example, we asked the authors if they could share pre‐ trained weights from the classifiers that were trained on full ImageNet, and which type of GAN architecture was used for the MNIST experiments. Unfortunately, we received a late response and only a subset of our questions was answered, and as a result we were not able to fully verify whether our design choices were consistent with those of the original paper.
1https://github.com/danilodegoede/fact-team3/
ReScience C 8.2 (#5) – Bagad et al. 2022 10"
"['Sarah de Boer', 'Radu Alexandru Cosma', 'Lukas Knobel', 'Yeskendir Koishekenov', 'Benjamin Shaffrey']",[Re] Data-Driven Methods for Balancing Fairness and Efficiency in Ride-Pooling,10.5281/zenodo.6574637,Replication,Python,https://zenodo.org/record/6574637/files/article.pdf,rescience c ride-pooling fairness LSTM ILP resource allocation matching algorithms reinforcement learning machine learning deep learning python pytorch,https://openreview.net/forum?id=BE3Ms3GXhCF,https://github.com/reproducibilityaccount/reproducing-ridesharing,8,2,2022,Our work attempts to verify twomethods to mitigate forms of inequality in ride‐pooling platforms proposed in the paperData-DrivenMethods for Balancing Fairness and Efficiency in Ride-Pooling [1]: (1) integrating fairness constraints into the objective functions and (2) redistributing income of drivers. We extend this paper by testing for robustness to a change in the neighbourhood selection process by using actual Manhattan neighbour‐ hoods and we use corresponding demographic data to examine differences in service based on ethnicity.,The simulation logic as well as the training and testing procedures in the provided code were straightforward to execute.,"To be able to run the authors’ code we needed to make several changes to it. Moreover, specific parts of the original research were not explicitly mentioned in the paper. An‐ other point of difficulty was the absence of preprocessing code which was not detailed properly and could not be fully reproduced. The reproducibility of the paper relied on the provided code, communication with the authors as well as previous works.
Communication with original authors We contacted the authors about the preprocessed data that was not hosted online due to licensing issues. They supplied it as well as responded very quickly and provided clarifications on the parameters and their values in the code.
1 Introduction
Ride‐pooling, where drivers can servicemultiple requests from riders simultaneously, is becoming increasingly popular [2]. Since resources are shared, ride‐pooling has the po‐ tential to reduce the aggregate VKT (”vehicle kilometres travelled”) and with that reduce petroleum usage and carbon dioxide emissions [3]. To efficiently perform the match‐ ing of riders and drivers, machine learning algorithms are used [4], which optimise for income maximisation. However, with respect to ride pooling, previous works have ob‐ served a gender wage gap [5] as well as majority Asian and Hispanic neighbourhoods being associated with less service compared to white neighbourhoods [6]. Therefore, alternative fairness notions could also be useful. Shah, Lowalekar, and Varakantham7 introduce an algorithm to solve the ride‐pooling matching problem, which maximises the number of rider requests serviced based on a Markov decision process (MDP) in combination with deep learning. The authors of the paper Data-Driven Methods for Balancing Fairness and Efficiency in Ride-Pooling [1] extend this work to comparemultiple objective functions, defined on different fairnessmetrics. Next to that, they investigate the use of income redistribution. In this reproducibility study, we attempt to verify their results and extend their experiments.
2 Scope of reproducibility
Themain contribution of the paper is introducing and evaluatingmeasures to deal with the fairness issues arising in ride‐pooling. In our reproducibility study, we first focus on reimplementing their code (implemented in TensorFlow [8]) in PyTorch [9] and compare the results we achieve to their findings. Themain claimsmade in the original paper are:
• The authors claim that they extend theMDP‐based framework (introduced in Shah, Lowalekar, andVarakantham7) by incorporating different definitions of fairness to perform non‐myopic optimisation. By incorporating fairness measures into the objective function, driver and rider inequality can be reduced while maintaining or even improving profitability.
• The state‐of‐the‐art objective function [7] can outperform the fairness objective functions in certain settings in terms of rider‐fairness and increase the average income of drivers at the cost of a higher variance.
ReScience C 8.2 (#6) – Boer et al. 2022 2
• Income redistribution can be used to reduce wage inequality while avoiding the free‐rider problem and guaranteeing a minimum wage for drivers.
The mathematical proof guaranteeing the minimum wage is not verified in our study. In addition to testing for reproducibility, we examine the robustness of the approach to changes in the neighbourhood selection method using actual tabulation areas. Using demographic data, we investigate whether the fairness objective functions are fair to all ethnicities. To investigate these aspects of the paper, we followed these steps:
1. We inspect the provided codebase and identify, analyse and solve any barriers to running the code.
2. Next, we transform the code to the PyTorch framework,matching the functionality as well as possible.
3. With the PyTorch version we attempt to reproduce the results using the dataset preprocessed by the authors. To investigate potential differences, we use different seeds to examine the effect of randomness.
4. To test the method’s robustness we utilise the authors’ approach on actual neigh‐ bourhoods in Manhattan and, using the neighbourhood demographic composi‐ tions (since individual protected data is confidential), we explore whether the in‐ troducedobjective functionsmitigate potential inequalities between ethnic groups.
3 Theoretical background
The paper we are reproducing extends the method proposed in Shah, Lowalekar, and Varakantham7. The latter presents Neural Approximate Dynamic Programming (Neu‐ rADP), which uses offline‐online learning and approximates dynamic programming to match drivers and riders non‐myopically. The following subsections explain NeurADP and the two extensions proposed in Raman, Shah, and Dickerson1, fairness‐based ob‐ jective functions and income redistribution.
3.1 NeurADP: Neural Approximate Dynamic Programming NeurADP uses neural network‐based value function approximation and updates it using the Bellman equation [10]. To break temporal dependencies between samples, mini‐ batch experience replay is used [11]. The neural network is used to rank feasible actions for each agent. To receive the opti‐ mal choices, an integer linear program (ILP) is solved considering the top 150 feasible actions. To update the neural network, the authors use a target network and Double Q‐learning [12]. The value function over individual vehicles is learned offline. When the approach is running online, the model computes the driver‐rider assignment that maximises the value function computed in the offline phase. Further details regarding the neural network inputs and its architecture are in Appendix A.
3.2 Fairness-based objective functions Prior work used profitability metrics as objective functions. The authors introduce two new objective functions to improve both driver‐side and rider‐side fairness [1] and com‐ pare them using different evaluation strategies.
ReScience C 8.2 (#6) – Boer et al. 2022 3
Profitability objectives There are two profitability measures used: the number of rid‐ ers serviced (o1) and the total income (o2).
o1(R,W ) = n∑ i=1 |pi|+ |si|, o2(R,W ) = n∑ i=1 ∑ u∈pi∪si
Eg,e + δ︸ ︷︷ ︸ πi
. (1)
The total number of rides serviced by driver i consists of the number of ongoing requests |pi| and completed requests |si|. The total income is calculated by adding the incomes πi of the individual drivers i. The income for any request u is the sum of the variable cost Eg,e (depending on the start and end locations g and e) and the fixed part of ride‐pooling pricing, represented by the constant δ.
Fairness objectives The authors define two fairnessmetrics for rider‐side (o3) anddriver‐ side (o4) fairness.
o3(R,W ) = −λVar ( hj kj ) + n∑ i=1 πi, o4(R,W ) = −λVar(πi) + n∑ i=1 πi. (2)
The former is quantified by the variance of the success rates which is computed by the ratio between serviced and total requests ( hj kj ) originating in neighbourhood j. Each crossing is mapped to one of H neighbourhoods. o4 is based on the spread of incomes πi. Both objective functions incorporate the total income o2 into the equation, λ controls the importance of the variance term.
Evaluation strategy To measure the effect of different objective functions, the authors introduce two fairness metrics. They evaluate rider‐fairness by comparing the overall and minimum success rates across neighbourhoods. They then utilise the income dis‐ tributions to assess driver‐fairness.
3.3 Income redistribution The authors also introduce an income redistribution scheme to mitigate income fluc‐ tuation and inequality in driver wages. To help estimate the true contribution of each driver, Shapley values [13] are used. In this ride‐pooling setting, a Shapley value can be intuitively interpreted as the average profit lost when a specific driver does not con‐ tribute. To reduce the difference between a driver’s pre‐redistribution income πi, and Shapley value vi, the authors use a risk parameter, 0 ≤ r ≤ 1, which designates what fraction of a driver’s income is kept. The model collects ∑n =1(1 − r)πi from all drivers and re‐
distributes it proportional to the difference between their value and earnings, which is max(0, vi − rπi). The driver’s income after redistribution, qi, is
qi = rvi + max(0, vi − rπi)∑n
j=1 max(0, vj − rπj) n∑ j=1 (1− r)vj (3)
Evaluation strategy Tomeasure the correlation between the Shapley value and income after redistribution, the gain metric gi is defined as the ratio of change in qi to vi when vi is doubled. The gain g is calculated as the average over gi. To test the effect of income redistribution, the authors determine gain and the standard deviation of the ratio of qi to vi for varying values of r. The most desirable outcome is that the driver’s redistribution value is as close as possible to their Shapley value, i.e. std = 0 and that if they double their contribution, they double their earnings after redistribution, i.e. g = 1.
ReScience C 8.2 (#6) – Boer et al. 2022 4
4 Methodology
In this section, the approaches used in our reproducibility study are outlined.
4.1 Datasets The following shows the original dataset and the demographic data to the Manhattan neighbourhoods.
NYC yellow taxi data Manhattan — Similar to Raman, Shah, and Dickerson1, we use the dataset ’Yellow taxi trip records’ from New York City [14] for training and evaluation. The original dataset contains pick‐up and drop‐off coordinates for taxi passengers. We follow the assumption of the original paper that the spatial and temporal distribution of rider requests between ride‐pooling and taxi rides are similar. The preprocessing done inRaman, Shah, andDickerson1 consists of the following steps. First, the dataset of New York City is filtered to only comprise trips starting and ending in Manhattan. Next, the coordinates are discretised into |L| locations, which are identified by taking the street network of the city from openstreetmap [15] using osmnx with ’drive’ as network type. We take the largest strongly connected component of the network discarding nodes that do not have outgoing edges. The resulting network has 4373 locations (street intersections) and 9540 edges. The pick‐ up time is converted to batches of requests corresponding to theminutes. Furthermore, the locations are grouped into 10 neighbourhoods using K‐means clustering [16]. The dataset contains on average 322714 requests in a day (on weekdays) and 19820 requests during the peak hour. The preproccessed dataset was not publicly available, although mentioned otherwise in the paper. The authors confirmed that this was due to licensing issues and provided us with the preprocessed data. The model is trained using the data from March 26th ‐ 28th 2016. The fairness objective functions are tested on the data from April 4th.
Demographics by Neighborhood Tabulation Area — The dataset ”Demographics by Neighbor‐ hood Tabulation Area” for New York City [17] allows us to investigate whether the ride demand of racial or ethnic minorities is indeed satisfied in the same way. It contains demographic data for each neighborhood tabulation area (NTA) in New York City. A NTA is an area for which census data is gathered. The demographic data relevant to this report are the race/ethnicity percentages per neighbourhood, namely Hispanic/Latino, White, Black/African‐American, Asian, Other. Instead of running K‐means clustering to obtain the neighbourhoods, we take the neighbourhoods corresponding to these NTA ar‐ eas in Manhattan. This results in 29 instead of 10 neighbourhoods for Manhattan. To be able to determine which nodes in the graph are situated in which NTA, we made use of the ”2010 Neighborhood Tabulation Areas” dataset [18] which contains coordinates specifying an approximation of the polygon shape of each neighbourhood.
4.2 Code Our implementation is based on the code of the paper which is publicly available at GitHub 1. The repository was updated after we started reproducing the paper, but we refer to the commit specified above unless stated otherwise. The published code is not functioning and does not include the preprocessing steps. However, the main frame‐ work for testing and training is provided and hyperparameters can be configured using setting files. We re‐implemented the model in the PyTorch framework [9], ensuring
1https://github.com/naveenr414/ijcai‐rideshare/tree/78d81d0f417ad4fd54ea2e967010bb221fc4e177
ReScience C 8.2 (#6) – Boer et al. 2022 5
that the default behaviour of TensorFlow which was implicitly used in the authors’ im‐ plementation is replicated. This includes weight initialisation and hyperparameters of the optimiser. To transfer the masking mechanism used to pad the sequences, we em‐ ployed PyTorch’s packed sequence implementation. Since the new framework does not support backwards LSTM, we used a bidirectional LSTM and ignored the forward pass to achieve the same functionality. In accordance with the original code, we used the CPLEX optimiser [19] to solve the ILP. To support the number of drivers and, therefore, bigger linear systems, the academic or commercial version is necessary. There were some rare situations in which the ILP failed to satisfy the constraints (one or two agents were not assigned any actions) which led to an error. This was fixed by assigning the ”take no action” action to those agents. In addition, we implemented the preprocessing steps on the original dataset [14], as this code was not available. For this, we perform the same steps indicated in Section 4.1.1, but we simplified the estimation of the travel times as this was not clear from the paper. Our code is available at GitHub. 2
4.3 Hyperparameters Focusing on reproducing the original paper [1], we tried to stay close to the original paper’s approach and did not perform hyperparameter optimisation. Hyperparameter values missing in the paper (e.g. minimum number of experiences and samples) were retrieved from the authors’ code. Additionally, there were inconsistencies, when some hyperparameters had different values in different parts of code (e.g. embedding dimen‐ sion). In this case, we reached out to the authors for clarification. More details on hy‐ perparameters are in Appendix C.
4.4 Computational requirements To increase the available computational resources, we used multiple computers with different hardware (see Table 5 in the Appendix). In general, the training time is dom‐ inated by the simulation of the environment and solving the ILP. The training of the neural network plays only a minor role. Hence, GPUs are not crucial for training, the training time is mostly determined by the single‐core performance of the CPU. A run consisting of training on three days and testing on one typically takes about 2.5 to 3 hours. In total, running all experiments took 202 hours.
4.5 Experimental setup
Experiment 1 (Objective Func‐ tions) To reproduce the results regarding claims 1 and 2, dif‐ ferent settings are needed, pre‐ sented in Table 1. All com‐ binations of these settings are used. The requests and income objective functions do not have lambda values. Furthermore, the embeddings are trained (fur‐ ther details are in Appendix A.1).
We use the same training/testing split as in the paper (described in Section 4.1), and evaluate the results based on overall and minimum success rates as well as income dis‐ tribution. To test if the differences between our findings and the original results are caused by ran‐ domness, we rerun the experiments using different seeds. Due to limited resources, we
2https://github.com/reproducibilityaccount/reproducing‐ridesharing
ReScience C 8.2 (#6) – Boer et al. 2022 6
rerun only a subset of setting combinations. Further details can be found in Appendix B.
Experiment 2 (Income Redistribution) In accordance with the original paper, the re‐ sults of the Objective Functions experiments are reused to evaluate the income redistri‐ bution for claim 3. The analysis is focused on the 200 drivers with the requests objective function using gain and standard deviation (see Section 3.3).
Experiment 3 (Neighbourhood Demographics) To test robustness we use the 29 pre‐ defined neighbourhoods and train the models using the configurations of for only 200 drivers. To incorporate the demographic data for the analysis presented in step 4 (see Section 2), we map the results per neighbourhood to the five different ethnicities, un‐ der the assumption that the distribution of ethnicities living in a neighbourhood corre‐ sponds to the distributions of riders’ ethnicities. For each group, we calculate the mean across all neighbourhoods weighted by the percentage of this group living in that area. This results in five different values per objective function. The higher this value is, the more requests of the corresponding group are serviced. Since we are interested in the difference across groups, we subtract the average of this rate. Values above zero indicate a group that is serviced above average and, hence, could be interpreted as advantaged. In addition, we evaluate the overall, minimum and per neighbourhood success rates.
5 Results
In the following, we will present the results of the three different experiments.
5.1 Reproducibility result 1 - Fairness objective functions
Looking at our findings in Figure 2a, we conclude that for 50 drivers the results for the rider‐fairnessmetric can be reproduced, the success rates for the different objec‐ tive functions match. Using the driver‐fairness objective function improves both the success rate and the rider equality. For 200 drivers, there are mi‐ nor discrepancies between our results and the original.
They can, however, be explained by stochasticity introduced by different seeds. How‐ ever, for rider‐fairness with λ = 1010, the difference can not be explained by random‐ ness. The requests objective function often results in more profit and better rider equal‐ ity. For each objective function, the payment distribution for 200 drivers is shown in Figure 2b. The variance of the distributions are similar in magnitude, the means however are slightly shifted. Looking at the differences between the results for different seeds, this could be explained by randomness. The driver‐fairness objective function is able to reduce the variance in income between drivers, but the profitability is also decreased. Appendix E shows the results presented in the original paper, the results of the different seeded runs are visualised in Figure 10.
ReScience C 8.2 (#6) – Boer et al. 2022 7
5.2 Reproducibility result 2 - Income redistribution The authors’ findings regarding the effect that varying the risk parameter r has on the gain and the standard deviation of the ratio qivi were not reproducible on the basis of the information in the paper alone, nor were they immediately reproducible from the code itself. Upon further communication with the authors, they updated their code. There was also a typo in the formula given in Equation 3 (Equation 12 in Raman, Shah, and Dickerson1). The correct equation is:
qi = rπi + max(0, vi − rπi)∑n
j=1 max(0, vj − rπj) n∑ j=1 (1− r)πj , (4)
where it can be seen that the use of Shapley values in the first term and last factor have been replaced by the amounts before redistribution. With these corrections in place, our Income Redistribution experiments yielded the results seen in Figure 3. For values of 0.4 ≤ r ≤ 0.6 the gain is non‐zero whilst maintaining a spread close to zero for the redistribution income to Shapley value ratio. In the original paper, this condition held for values of 0.5 ≤ r ≤ 0.9. Furthermore, the magnitude of the gain is far smaller at the point at which the spread begins to increase. This indicates that when r = 0.6, drivers only receive a 40% increase in their wages whilst still earning close to their true contribution. This is in contrast with the original, where, for r = 0.9, drivers receive an 80% increase in their wages while minimising the free‐rider problem. This leads us to conclude that the results of this redistribution scheme were not reproducible in this setting. The original results are shown in Figure 8 in the Appendix.
ReScience C 8.2 (#6) – Boer et al. 2022 8
5.3 Results for Manhattan neighbourhoods and incorporating demographic data We retrained the model (see Section 4.5). Comparing the resulting Figure 4 to previous findings in Figure 2a, we observe that by changing the neighbourhoods the performance of the driver‐fairness objective functions deteriorates themost. The rider‐fairness objec‐ tive functions share some similarities between the two experiments but the latter now performs best in terms of fairness across neighbourhoods (minimum request success rate).
Figure 4b shows that there are small differences in the percentage of requests ser‐ viced per ethnicity. The rider‐fairness objective func‐ tion for λ = 1010 seems to be best at mitigating inequal‐ ity. However, as seen in Fig‐ ure 4a, rider‐fairness results in low success rates. This might indicate that the ob‐ jective function merely low‐ ers success rates for oth‐ erwise well‐serviced neigh‐ bourhoods rather than im‐ provingunder‐serviced ones. To confirm this, we visu‐ alised the success rate per neighbourhood and objec‐
tive function (see Figure 5). It can be seen that rider‐fairness indeed exhibits notably reduced variance but also a lower mean when compared to the other objective func‐ tions which tend to have an upward skew. This shows that rather than benefiting under‐ serviced neighbourhoods, applying rider‐fairness only lessens the success rate of well‐ served ones.
6 Discussion
Combining the results from the reproducibility experiments (Objective Functions exper‐ iment and Income Redistribution experiment in Section 4.5), we find that the first claim mentioned in Section 2 is supported by our results for 50 drivers. Furthermore, our re‐
ReScience C 8.2 (#6) – Boer et al. 2022 9
sults substantiate the second claim. The ‘requests’ objective function can improve the rider‐fairness for 200 drivers. Additionally, it results in the highest average income per driver but exhibits a higher variance than the driver‐fairness objective function. These observations are in accordance with the ones of the original paper. For the 200 drivers setting, specific results were more sensitive to sources of stochastic‐ ity than for 50 drivers. After inspecting the code, we found that the minimum number of experiences needed to start the training of the neural network is never exceeded for the 50 drivers setup. In the 200 drivers configuration, it is reached and hence the neural network is trained. Since theweights of themodel are randomly initialised, itmight con‐ verge to a different local minimum which yields a different value function. This could explain the variance in the corresponding results. For 50 drivers, in contrast, no learn‐ ing is involved. Hence, the result goes through a randomly initialised model. Weights are typically initialised to preserve themean and variance of the input, which should be unaffected by the specific seed used. This could explain the strong similarity between our results and the original results for the 50 drivers setup. Differences found in reproducing the income redistribution scheme may also be ac‐ counted for by the above. However, while our results are not exactly the same, the third claim still holds, although to a considerably lesser degree than in the original paper. When employing the actual Manhattan neighbourhoods, the relative standing of the various objective functions was different compared to the ones determined by K‐Means. This indicates that the proposed method is sensitive to the neighbourhood selection mechanism. Looking at the demographic data, it can be seen that all objective functions exhibit small differences between ethnicities. These, however, could be attributed to stochasticity. In any case, rider‐fairness results in the least variance across ethnicities at the price of mean success rate. However, this result does not imply that rider‐fairness achieves this low variance by better servicing neighbourhoods with a lower percentage of accepted requests, but rather by servicing better‐served neighbourhoods less well. Importantly, the ethnicity‐based analyses are built on the assumption that the distribution of the ethnicities of residents and riders in a neighbourhood is similar. However, ride pooling might be used by other people like commuters or tourists. Furthermore, there could be differences between the ethnic populations regarding the percentage of ride‐sharing users.
6.1 What was easy Part of the code, namely the simulation logic, did not need any modifications. This logic is responsible for telling drivers of possible rides to accept as well as executing the drivers’ choices and keeping the simulation consistent with respect to the existing constraints. The training and testing procedure was also straightforward to execute.
6.2 What was difficult The codebase was not originally executable and required modifications. In addition to that, several aspects of the original research were not explicitly mentioned in the paper. Although, in the end, we were able to reproduce most results, this would not have been possible without consulting either the code, the authors or the paper about NeurADP [7]. Another challenge was the absence of preprocessing code which together with the lack of a detailed description in the paper (specifically for travel time estimates)made its implementation difficult. With the limited time resources we had, we did not succeed in testing if our preprocessing implementation affected the results.
ReScience C 8.2 (#6) – Boer et al. 2022 10
6.3 Communication with original authors The authors were very helpful, kind and responded very quickly, often within the same day. This was a very important factor in the production of this reproducibility report as the preprocessed data could not be hosted online due to licensing issues. Furthermore, they also provided useful clarifications with respect to the parameters used in the code and discrepancies between different parameter values in different places. The authors also updated the codebase following our discussions."
"['Matteo Brivio', 'Çağrı Çöltekin']",[¬Re] Hate Speech Detection based on Sentiment Knowledge Sharing,10.5281/zenodo.6574639,Replication,Python,https://zenodo.org/record/6574639/files/article.pdf,rescience c machine learning deep learning python tensorflow NLP hate speech sentiment,https://openreview.net/forum?id=SSSGs3M7nRY,https://github.com/matteobrv/repro-SKS,8,2,2022,"This report summarizes our efforts to reproduce the results presented in the ACL2021 paperHate Speech Detection based on Sentiment Knowledge Sharing by Zhou et al. [1], as part of the ML Reproducibility Challenge 2021. We attempt to verify themain claims of the original study by reproducing the experiments comparing models with and without sentiment knowl‐ edge sharing. Although most scores in our replication study matches with the ones reported in the original paper, our experiments result in substantially lower scores for the full model with sentiment sharing. We also investigate variation in the scores, re‐ port additional scores (more suitable for the task), and discuss possible sources for the discrepancies observed.",,
"['Maarten Burger', 'Kaya ter Burg', 'Sam Titarsolej', 'Selina Jasmin Khan']",[Re] Reproducibility Study - SCOUTER: Slot Attention-based Classifier for Explainable Image Recognition,10.5281/zenodo.6574641,Replication,Python,https://zenodo.org/record/6574641/files/article.pdf,rescience c machine learning deep learning SCOUTER XAI Explainable AI Interpretable Reproducibility Attention Self-attention Computer Vision python pytorch,https://openreview.net/forum?id=HZNlq3fmhRF,https://github.com/kayatb/reproduce_SCOUTER,8,2,2022,We aim to replicate the main findings of the paper SCOUTER: Slot Attention-based Classifier for Explainable Image Recognition by Li et al. in order to verify the main claims they make: 1) The explanations generated by SCOUTER outperform those by other explana‐ tion methods in several explanation evaluation metrics. 2) SCOUTER achieves similar classification accuracy as a fully connected model. 3) SCOUTER achieves higher confu‐ sion matrix metrics than a fully connected model on a binary classification problem.,"The paper was well written, so understanding the SCOUTER architecture was straight‐ forward. The code for training a model was available and together with the examples
Copyright © 2022 M. Burger et al., released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Maarten Burger (maarten.l.burger@gmail.com) The authors have declared that no competing interests exist. Code is available at https://github.com/kayatb/reproduce_SCOUTER. – SWH swh:1:dir:a294d795e2f9e00a93e9955b70c86a28b1c310d0. Open peer review is available at https://openreview.net/forum?id=HZNlq3fmhRF.
ReScience C 8.2 (#8) – Burger et al. 2022 1
the authors provide, this was achievable with relative ease. A checkpoint system is im‐ plemented, so training a model can be split into multiple runs. All used datasets are available and straightforward to obtain.","The original code did not contain any documentation, which made it difficult to navi‐ gate. No code for calculating the metrics was provided and this had to be implemented from scratch. During the training of the models, memory allocation issues occurred. Training and evaluating on a large dataset took a considerable amount of time.
Communication with original authors We sent the authors an e‐mail to request either the missing code or more details on how the metrics were implemented, but unfortunately we did not receive a reply.
ReScience C 8.2 (#8) – Burger et al. 2022 2
2 Introduction
Explainable Artificial Intelligence (XAI) is growing in popularity and becomes increas‐ ingly important as more and more AI applications are used in daily life. It is important to visualize both positive and negative patterns in the explanation of a model [1], but this discernment has not gained much attention yet. In [2], Li et al. introduce a model architecture that is capable of generating both positive and negative explanations based on an explainable slot attention module.
3 Scope of reproducibility
The authors sought to tackle the problem of deep neural networks being unintelligible. For this purpose they developed SCOUTER (Slot‐based COnfigUrable and Transparent classifiER) [2]. The unique aspect of SCOUTER is that every category has its correspond‐ ing positive or negative explanation as to why a particular image does or does not belong to a certain category. This offers a more in‐depth look into what a model bases its pre‐ dictions on and thus increases its explainability. The main claim of the original paper is aptly summarised in the last sentence of its con‐ clusion: ”Experimental results prove that SCOUTER can give accurate explanationswhile keeping good classification performance”. This is what we will be trying to reproduce. While this claim in itself is vague, the authors compare the score SCOUTER achieves on cer‐ tain datasets to other methods such as GradCAM [3], RISE [4], I‐GOS [5] and IBA [6] and show that SCOUTER achieves a similar or higher score in most metrics. Furthermore, they also train a model where the slot attention is replaced with a fully connected layer as an (unexplainable) baseline to compare SCOUTER to. This can be dissected into the three following claims that we will attempt to verify by reproducing the experiments of the authors:
1. SCOUTER will achieve the highest score on the following explanation evaluation metrics: area size, precision, insertion areaunder curve, deletion areaunder curve, infidelity and sensitivity on the ImageNet dataset [7] compared to other explana‐ tion methods.
2. SCOUTERwill achieve similar classification accuracy as the FCmodel trained and validated on the ImageNet, Con‐text [8], and CUB‐200‐2011 [9] datasets
3. SCOUTERwill achieve higher ROC‐AUC, Accuracy, Precision, Recall, F1‐Score and Cohen’s Kappa scores than the FC model on the ACRIMA dataset [10].
4 Methodology
The original paper provides a link to the Github repository1 with the code and instruc‐ tions necessary to train themodels whichwere reported in the paper. However, the code used to evaluate the explanations of the trained models was not included. We therefore had to implement these ourselves. The area size metric was partially implemented in the authors code, where the area size for a single imagewas calculated. We extended this code to calculate the average area size over the entire validation set. We implemented the following explanation evaluation metrics from various papers ourselves: precision [2], Insertion Area Under Curve (IAUC) [4], Deletion Area Under Curve (DAUC) [4], infi‐ delity [11] and sensitivity [11]. Interesting to note is that the precision metric is defined by the authors themselves. The papers the authors referenced for IAUC and DAUC2, and
1https://github.com/wbw520/scouter 2https://github.com/eclique/RISE
ReScience C 8.2 (#8) – Burger et al. 2022 3
infidelity and sensitivity3 provided code for the metrics implementation. We used these and adapted them slightly to integrate it with the code for SCOUTER to deviate as little as possible from the original experiments. Furthermore, there was no code available for working with the ACRIMA dataset, so we implemented this ourselves as well. Using the code of the authors composited with our own code, we conducted our experi‐ ments on the GPU nodes of the LISA cluster on SurfSara4 which uses an Nvidia GeForce 1080Ti, 11GB GDDR5X GPU.
4.1 Model description Typically a classificationmodel consists of the following: feature extractionusing a back‐ bone network, which is then mapped onto a score vector representing the confidence for each class. When using fully connected layers to map such a feature onto a score vector it results in a model that is a black‐box, which does not give much information about how or why a certain class attains a higher confidence score. Such a fully connected classifier is replaced instead by an explainable xSlot module, which is based on anobject‐centric slot attentionmodule [12]. This creates the SCOUTER model as seen in Figure 1 [2]. In order to reproduce the experiments we will train a multitude of such SCOUTERmod‐ els. All models use ResNeSt‐26 [13] as their backbone, since that was also used in the experiments we aim to reproduce. All models use the same SCOUTER loss as defined by the original authors. Since there are no pre‐trained models made available we will train all models from scratch. For all models the amount of parameters is just above 15,000,000. The full table for parameter counts can be found in Table 1.
4.2 Datasets We used various datasets during our experiments. For reproducing the original exper‐ iments we used the ImageNet, Con‐text, CUB‐200‐2011 and ACRIMA datasets. In line
3https://github.com/chihkuanyeh/saliency_evaluation 4https://userinfo.surfsara.nl/systems/lisa/description
ReScience C 8.2 (#8) – Burger et al. 2022 4
with the original experiments, we use the train part of the dataset for the training and the validation part for calculating the metrics. ImageNet. The ImageNet Large Scale Visual Recognition Challenge (ILSVRC) dataset5 [7] is widely used for classification models. The categories consist of and are organized according to nouns in theWordNet hierarchy [14]. It contains 1,000 categories, 1,281,167 images for training, 50,000 images for validation and 100,000 images for testing. We pre‐ processed the structure of the directories of the validation set to be in line with the author’s code. Con‐text. The Con‐text dataset6 [8] is focused on the use of fine‐grained classification of buildings into their sub‐classes such as cafe, tavern, diner, etc. by detecting scene text in images. The dataset consists of 28 categories with 24,255 images in total. Splitting the dataset was done by the authors using a seed, as there is no inherent split. CUB‐200‐2011. The Caltech‐UCSD Birds 200‐2011 (CUB‐200‐2011) dataset7 [9] consists of images with photos of 200 bird species (mostly North American). It consists of 200 cat‐ egories with 11,788 images in total. The train set contains 5,994 images and the test set contains 5,794 images. Note that while the original authors cite the CUB‐200 dataset [15], everything in the available code points towards the authors using the CUB‐200‐2011 dataset. For example: the code to load the ”CUB‐200” data is only functional when using the CUB‐200‐2011 dataset. As such, we made the decision to use CUB‐200‐2011 for our experiments. ACRIMA. The ACRIMA dataset8 [10] can be used for automatic glaucoma assessment using fundus images. It contains 2 categories and 705 images. It is composed of 396 glaucomatous images and 309 normal images. There is no inherent split for the data, so we made our own with 80% of the images in the train set and 20% in the validation set using a seed.
4.3 Hyperparameters Many of the hyper‐parameters were set in accordance with the original paper, as these were documented and reported. However, not all hyperparameter settings were doc‐ umented. There is a specific lack of the ”slots per class” hyperparameter. We tested both the positive and negative SCOUTER model with four different slots per class hy‐ perparameter settings, namely: 1, 2, 3, and 5. We tested this with λ values of both 1 and 10. We found there to be no significant difference in performance in classification accuracy or evaluation metrics between the different slots per class values. As such, all the models that we report on were trained with 1 slot per class since this value was set by the authors in the examples they provided with their code. The full hyperparameter settings can found in Table 2.
5Download link: https://image-net.org/download.php 6Download link: https://staff.fnwi.uva.nl/s.karaoglu/datasetWeb/Dataset.html 7Download link: http://www.vision.caltech.edu/visipedia/CUB-200-2011.html 8Download link: https://figshare.com/s/c2d31f850af14c5b5232
ReScience C 8.2 (#8) – Burger et al. 2022 5
4.4 Experimental setup and code Our code is available at: https://github.com/kayatb/reproduce_SCOUTER. We trained the models using the hyperparameter setup as described above. In order to reproduce the original results we trained six different models for the explanation eval‐ uation: both SCOUTER+ and SCOUTER− models with λ values of 1, 3 and 10. Wherever classification accuracy is reported it is the accuracy of themodel on the valida‐ tion set after the final epoch, as was done by the original authors. For the evaluation of classification on ImageNet we reused the positive and negative SCOUTER models with a λ value of 10, since this model has the same hyperparameter settings. We trained separate positive and negative SCOUTER models with λ = 10 for the Con‐text and CUB‐ 200‐2011 classification evaluation. For all datasets we also trained a fully connected classifier model (with ResNeSt‐26 as backbone) to compare the SCOUTER models to. To reproduce the confusion matrix metrics for ACRIMA we trained a positive and nega‐ tive SCOUTER model on that dataset with λ = 10. Results relating to Con‐text, CUB‐200‐2011 and ACRIMA were obtained by averaging the scores from three independent runs. Due to restricted GPU hours and time constraints, we only trained a single model for each configuration on ImageNet.
Metrics —We used several metrics to evaluate the generated explanations. The following metricswere calculated on the ground truth class for SCOUTER+ and on the least similar class for SCOUTER−. The least similar class was determined via Wu‐Palmer similarity of the WordNet synsets of the categories as implemented in NLTK [16]. This follows the same formula the original authors used to measure similarity. Area sizemeasures the average size of the generated explanations. This is calculated by summing all the pixel values in the attention map. Precision measures the relative amount of pixels of the attention map that falls within the image’s bounding box. Some images in the ImageNet dataset have multiple bound‐ ing boxes. We chose to calculate the precision as the max value of each bounding box in the image. IAUC measures the increase in accuracy under the gradual addition of pixels based on their importance in the explanation. The starting state was the image after applying a Gaussian filter of size 11 and σ = 5. DAUCmeasures the decrease in accuracy under the gradual removal of pixels based on their importance in the explanation. The final state was an image consisting of only zeroes. Infidelity measures how well the explanation captures the change in the model’s pre‐ diction under input perturbations. The image was perturbed by adding noise sampled from a unit Gaussian. This metric was calculated over the first 50 images in the valida‐ tion set. Sensitivity measures how much the explanation is affected by input perturbations. We calculated the maximum sensitivity, as was done in [11]. The image was perturbed by adding noise sampled from a uniform distribution ranging from ‐0.2 to 0.2. This metric was calculated over the first 50 images in the validation set. The authors do not give a complete description of how they implemented these metrics. We thus tried to stay as close as possible to the implementations in [4] and [11]. All pa‐ rameters were thus chosen in accordance with these implementations. Classification performance was mostly measured via accuracy. The performance of the models on the ACRIMA dataset was evaluated more extensively with several confusion matrix metrics: ROC‐AUC, accuracy, precision, recall, F1‐score and Cohen’s Kappa as implemented in Scikit‐learn [17].
ReScience C 8.2 (#8) – Burger et al. 2022 6
4.5 Computational requirements All experiments were conducted on the the GPU nodes of the LISA cluster on SurfSara using a Nvidia GeForce 1080Ti, 11GB GDDR5X. Computation time varied greatly between datasets. Training a model on the ImageNet dataset took up to 12 hours, for CUB‐200‐2011 it took around 2 hours, for Con‐text it was 1.5 hours and training on the ACRIMA dataset took less than 5minutes. The calculation of the explanation evaluationmetrics was done on the ImageNet validation set and thus took a long time as well, with IAUC and DAUC taking the longest at 1.5 hours per model.
5 Results
We chose to classify results that fall within±0.05 of the original results as reproducible. Regarding the explanation evaluation metrics, we found that we could not reproduce most results reported in the original paper. The results we acquired do not fully sup‐ port claim 1. We were able to obtain similar classification accuracy scores on the Im‐ ageNet dataset for all models, but we could not reproduce the scores for SCOUTER+ and SCOUTER− on the Con‐text and CUB‐200‐2011 datasets. Therefore we cannot ver‐ ify claim 2 with these results. Finally, we were able to reproduce all scores from the confusion matrix metrics on the ACRIMA dataset. While we were able to reproduce the scores, we cannot completely verify claim 3.
5.1 Results reproducing original paper
Result 1: reproducing evaluation metric scores — The results of our experiments regarding verifying claim 1 can be seen in Table 3. From this we can see that the area size metric is largely reproducible, but the other metrics are not. Precision deviates not too much from the original scores, but IAUC, DAUC, infidelity and sensitivity differ a lot. Com‐ pared to the original scores obtained for the other explanationmethods, SCOUTER does not outperform them with our acquired scores. Thus, we were not able to verify claim 1 with our implementation.
Result 2: Reproducing Classification Accuracy — The results of our experiments regarding the verification of claim 2 can be seen in Table 4. As we can see, we were able to reproduce all scores for the models trained on ImageNet. We could also recreate the accuracy scores for the FCmodel on the other datasets. However, we did not obtain similar scores for any of the SCOUTER models on Con‐text and CUB‐200‐2011. Our trained SCOUTER models perform significantly worse on these datasets compared to what the original paper reported and the scores we obtained for the FC models. Therefore, we did not find full support for claim 2, as we did not find SCOUTER to perform similar to the FC model on Con‐text and CUB‐200‐2011.
ReScience C 8.2 (#8) – Burger et al. 2022 7
Result 3: reproducing ACRIMA confusion matrix evaluations — The results of our experiments regarding claim 3 can be seen in Table 5. We were able to reproduce all results reported in the original paper. However, claim 3 states that SCOUTER achieves a higher score than the FCmodel in the reported confusionmatrix metrics. This was not the case with the results we found. There is a very slight difference between the scores of SCOUTER and the FCmodel, where in some cases the FCmodel obtains a marginally higher score than (one of) the SCOUTER models. In the original paper, SCOUTER also only slightly outperformed the FC model. Thus, we have been able to reproduce the reported scores, but these results do not fully support claim 3.
5.2 Results beyond original paper Since the accuracy scores we found for the SCOUTER models trained on CUB‐200‐2011 and Con‐text were so much lower, we wanted to see if training for more epochs would be beneficial. The models did not seem to have converged fully after only 20 epochs. In the examples the authors reported in their code repository, they state 150 epochs for training models on these datasets, so we tested that amount. However, for SCOUTER+ trained on CUB‐200‐2011 this only resulted in an accuracy of 0.6443, which still deviates significantly from the original score of 0.7362.
6 Discussion
Given the results presented above, we did not verify all claims presented in Section 3. Regarding claim 1, we believe this to bemostly due to the fact that we had to implement most of the metrics ourselves. The authors do not report on how they implemented their metrics and what settings they have used. That means it is highly likely that there exist discrepancies between our code and theirs. It could be the case that they have done some additional calculations on the metrics, especially sensitivity, since that met‐ ric always lies between 0 and 1 in [2], but our found scores do not. Furthermore, the sensitivity scores reported in [11] of which we have used the code also do not neces‐ sarily lie in this range. Since our found scores are not in line with what was originally reported, we cannot verify if SCOUTER outperforms other explanation methods. The fact that we were not able to obtain similar classification scores for both SCOUTER models on Con‐text and CUB‐200‐2011 could be due to the fact that the authors used different hyperparameters than we did. Not all hyperparameters were reported, so in some cases we had to make decisions ourselves. Unfortunately, we did not have the time to run an extensive hyperparameter search. We could thus not verify claim 2.
ReScience C 8.2 (#8) – Burger et al. 2022 8
While we did find similar scores for the confusionmatrix metrics on ACRIMA, we could not find support for what claim 3 states: SCOUTER outperforms the FC model on this dataset. The scores we found are very similar between the models, but we would argue that this was the case in the original paper as well. The scores may not fully support the claim that is being made. Finally, our approach has some shortcomings that is mostly due to time constraints. We did not do three separate runs for training models on ImageNet and thus our findings are based on a single run, which is not ideal. The results on the ImageNet dataset should therefore not be interpreted as final. Furthermore, we were not able to experiment with different backbones and only used ResNeSt‐26, which was the main backbone that was used in the original paper.
6.1 What was easy The original paper was well written, making it manageable to understand the SCOUTER model. Moreover, the code for training the models was available. As such, training the models was done with relative ease. A checkpoint system for the models was imple‐ mented, meaning training could be stopped and resumed later. The datasets the origi‐ nal authors used are publicly available and straightforward to find and download.
6.2 What was difficult The code of the original authors was devoid of documentation, making it difficult to navigate and pinpoint which part performed what operation. Due to this, we spent a lot of time on any implementation we had to create or extent. Furthermore, the generation of attention maps, arguably one of the most important parts, was hidden somewhere in the code and not documented. While the code for training the models was accessible, there was no code available for the evaluation metrics. During training, we would encounter a memory allocation er‐ ror every 8 to 13 epochs, meaning we had to resume from checkpoints. The ImageNet dataset is very large and thus took a lot of time to train. Lastly, there was no code pro‐ vided for working with the ACRIMA dataset. We had to implement loading the dataset and evaluating the performance ourselves.
6.3 Communication with original authors We sent an e‐mail to the authors enquiring about the missing code. However, we did not receive a reply."
"['Anirudh Buvanesh', 'Madhur Panwar']",[Re] AdaBelief Optimizer: Adapting Stepsizes by the Belief in Observed Gradients,10.5281/zenodo.6574643,Replication,Python,https://zenodo.org/record/6574643/files/article.pdf,rescience c machine learning optimizers image classification language modelling generative adversarial networks,https://openreview.net/forum?id=B9gDnMmn0t,https://github.com/anirudhb11/Adabelief-Optimizer-RC,8,2,2022,"The image classification experiments on CIFAR‐10, CIFAR‐100 and ImageNet are repro‐ duced to within 0.29%, 0.18% and 0.25% of reported values respectively. The language modeling experiments produce an average deviation of 0.22%,while the generativemod‐ eling experiments onWGAN,WGAN‐GP and SN‐GAN are replicated towithin 2.2%, 1.8% and 0.33% of value reported in the original paper. We perform ablation studies for change of dataset in language modeling and for effect of weight decay on ImageNet. We also perform analysis of generalization ability of op‐ timizers and of training stability of GANs. All of the results largely support the claims made in the paper [1].","The authors provide implementation formost of the experiments presented in the paper. Well documented code and lucid paper helped understand the experiments clearly.
1https://github.com/juntang‐zhuang/Adabelief‐Optimizer
Copyright © 2022 A. Buvanesh and M. Panwar, released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Anirudh Buvanesh (anirudhb1102@gmail.com) The authors have declared that no competing interests exist. Code is available at https://github.com/anirudhb11/Adabelief-Optimizer-RC. – SWH swh:1:dir:53eeebe14e9d02d912fc3c58c375b5095e8db941. Open peer review is available at https://openreview.net/forum?id=B9gDnMmn0t.
ReScience C 8.2 (#9) – Buvanesh and Panwar 2022 1","The challenging aspects in our study were: (1) Grid search for optimal hyperparameters (HP) in caseswhereHPwere not provided or results did notmatch, (2) time and resource intensive experiments like ImageNet ( ∼ 22 hrs.) and SN‐GAN (∼ 15 hrs.), (3) writing code to evaluate claims of the AdaBelief paper.
Communication with original authors We communicated with the author of the original paper, Juntang Zhuang, on multiple occasions for doubts related to hyperparameters and code, to which he promptly replied and helped us.
ReScience C 8.2 (#9) – Buvanesh and Panwar 2022 2
1 Introduction
Optimization is at the heart of machine learning. Training of neural networks aims to find the optimal solution (deepest valley on the loss surface) using gradient descent. The variation in method to traverse the loss landscape gives rise to different optimizers. Dis‐ covering different optimizers is an active area of research in machine learning. In this report, we reproduce and add on to the experimental analysis of an optimizer, AdaBelief [1], introduced in 2020 at NeurIPS conference. The proposed optimizer, AdaBelief, claims to outperform its counterparts on various real world deep learning tasks. As a part of the ML Reproducibility Challenge, we repli‐ cate all the experiments mentioned in the AdaBelief paper [1], comparing it with other optimizers, and also perform additional experiments to investigate the efficacy of Ad‐ aBelief.
2 Details of Optimizers
Optimizers are of two types: (1) accelerated Stochastic GradientDescent (SGD) family [2] that includes SGDwithmomentum [3] & Nestrov Accelerated Gradient (NAG) [4], and (2) adaptivemethods like Adam [5], RAdam [6], AdamW[7], RMSProp [8], Yogi [9], AdaBound [10], AdaBelief [1], MSVAG [11], Fromage [12], Apollo [13]. SGD [2] family uses the same learning rate for all parameters, whereas, adaptive meth‐ ods update their parameters as a function of gradients. While this has shown success in faster convergence due to a more streamlined trajectory, it has raised questions re‐ garding the generalization ability of adaptive methods. RMSProp [8] builds over SGD by penalizing updates in directions that have high gradients. The intuition behind this is to prevent drastic updates in particular directions. It does so by damping themagnitude of update by factor of exponential moving average (EMA) computed for squares of gra‐ dients. Adam [5] improves over RMSProp by introducing a momentum term that helps prevent over‐damping of step size as in case of RMSProp. RAdam [6] seeks to tackle the convergence problem of Adam by proposing to use a small learning rate during initial stages of training when variance is high, while AdamW [7] and MSVAG [11] address the generalization problem in Adam. AdamW does this by introducing a weight decay regu‐ larization term and MSVAG decomposes Adam as a sign update and magnitude scaling. Yogi [9] considers the effect of mini‐batch size and proposes an update equation that has shown to outperform Adam with very little hyperparameter tuning. AdaBelief [1] amplifies (or dampens) its updates by a factor proportional to the ’belief’ in observed gradient i.e. square of difference between the observed gradient and EMA of the gra‐ dient. AdaBound [10] bridges the gap between SGD family and Adaptive methods by making use of an update that smoothly transitions from Adam to SGD. Fromage [12] takes a different path to optimization ‐ it accounts for the network structure by loop‐ ing in weight matrices into the update equation. Apollo [13] takes a step forward from the aforementioned first order optimizers by approximating the Hessian via a diagonal matrix, keeping computations in‐line with first‐order schemes.
3 Scope of reproducibility
AdaBelief [1] claims to performs better than existing optimizers. To evaluate the validity of its claims, we investigate the following target questions:
• Does AdaBelief perform better in comparison to other optimizers on real world tasks of image classification, language modeling, generative modeling and rein‐ forcement learning?
ReScience C 8.2 (#9) – Buvanesh and Panwar 2022 3
S. No. Task Dataset Setup Rep. Status Our Contribution No. of Exp. GPU HPR Total GPU hours 1. Image
Classification
CIFAR‐ 10 VGG, RN, DN
✓ Exp. on Apollo [13]; bias‐variance anal. 30 2.5 75
2. CIFAR‐ 100 VGG, RN, DN
✓ Exp. on Apollo [13]; bias‐variance anal. 30 2.5 75
3. ImageNet ResNet18 ✓ Analysis of weight decay 3 22 66 4. Language
Modeling PTB, WT2
LSTM (1 layer)
✓ Fromage LRS; WT2 11 1.33 14.63
5. LSTM (2 layer)
✓ AdamW & RAdam LRS; WT2 11 2.5 27.5
6. LSTM (3 layer)
✓ AdamW & RAdam LRS; WT2 11 3.75 41.25
7. Generative Modeling CIFAR‐ 10 WGAN ✓ N/A (only reproduced paper’s [1] exp.) 70 0.89 53.55 8. WGAN‐GP ✓ N/A (only reproduced paper’s [1] exp.) 70 1 66.5 9. SN‐GAN ✓ HP search; training stablity anal. 45 15 675 10. Reinforcement
Learning N/A Space
Invaders (Atari)
✓ Beyond AdaBelief paper [1] 2 1 2
train‐test split of 50, 000 : 10, 000. (b) CIFAR‐100: It is same as CIFAR‐10 but the images are grouped into 100 classes (600 images per class). (c) ImageNet [25]: We use ILSVRC 2012 dataset6 which consists of ∼ 1.35M images of size 256× 256 split into 1000 classes. Train‐val‐test split is 1, 281, 167 : 50, 000 : 100, 000. As part of pre‐processing we remove mis‐labelled data7 (d) Penn Treebank8 (PTB) [18]: The train‐val‐test split of tokens is 887, 521 : 70, 390 : 78, 669. (e) WikiText‐2 (WT2) [19]: It is a subset of WikiText‐103, features a larger vocabulary and retains the punctuation, original case and numbers which are omitted in PTB dataset. We ran experiments on WT29 using the train‐val‐test token split of 2, 045, 059 : 213, 119 : 240, 498.
4.3 Hyperparameters In this section we mention the HP used by optimizers in our experiments. Optimal values of commonly used HP are listed in Table 2. Below we mention the source of these values and details of HP search. For most experiments, we use the optimizer‐specific HP as mentioned in the original repository5 since searching the HP for all experiments is computationally infeasible. However, the repository does not mention the HP for SN‐GAN & Fromage, and the men‐ tioned HP for 2‐ and 3‐layer LSTM models for AdamW & RAdam resulted in large devi‐ ation. So, we perform learning rate (LR) search for Fromage and 2‐ & 3‐layer AdamW and RAdam over the interval [10−3, 10−2] (5 values). For SN‐GAN, we search β1 (3 values in [0.4, 0.9]) and ϵ (3 values in [10−12, 10−6]). For Reinforcement Learning, we use LR of 10−4 and ϵ = 10−10 for AdaBelief and Adam, as mentioned on the RL repository4. Now we list the HP which are specific to each optimizer. The LR decays to 1/10th of its value at 150th epoch for image classification onCIFAR‐10 andCIFAR‐100, and at epoch 70 & 80on ImageNet. AdaBelief usesweight_decouple=False, fixed_decay=False, rectify=False for all the experiments and weight_decouple=True on ImageNet. SGDusesmomentum=0.9, andApollouseswarmup=200, weight_decay_type=’L2’ for image classification on CIFAR‐10 and CIFAR‐100. AdaBound uses final_lr=30 on PTB and final_lr=0.01 with GAN experiments.
4.4 Computational requirements We run experiments on a Portable Batch System (PBS) managed cluster. We used 8 NVIDIA V100 GPUs and 384 GB RAM. All experiments except ImageNet use a single GPU.
6ImageNet dataset (Kaggle) 7Blacklisted images (GitHub) 8Penn Treebank Dataset 9WikiText‐2 dataset
ReScience C 8.2 (#9) – Buvanesh and Panwar 2022 5
GPU runtime of all experiments are listed in table 1.
5 Experiments and Results
5.1 Experiments reproducing original paper To evaluate the performance of AdaBelief and to validate the aforesaid claims, we per‐ form experiments on various tasks like Image Classification, Language Modeling, Gen‐ erativeModeling, Reinforcement Learning and compare our results with those stated in the paper [1]. HP details can be found in Table 2.
Image classification —We run experiments on CIFAR‐10 and CIFAR‐100 using VGG11 [15], Resnet34 [16] and DenseNet121 [17] architectures, performimg 3 independent runs on 9 optimizers10. Additionally, we perform experiments using Apollo optimizer [13], that has claimed to outperform AdaBelief on CIFAR datasets with ResNet110 architecture. Fig. 1 plots test accuracy results. Plots for train accuracies are reported in Fig. 9. All the obtained results agree with those reported in the AdaBelief paper [1]. To assess the performance on large scale datasets, we ran experiments on ImageNet [25]. We follow a similar setting as the author and run experiments on AdaBelief [1] and MSVAG [11] and report results for remaining optimizers from literature (Table 3). The top‐1 accuracy lags by 0.32% and 0.18% respectively in case of AdaBelief and MSVAG. Other optimizers from literature use weight decay of 10−4 while the author performs experiments on AdaBelief using a value of 10−2. We analyse the effect of weight decay in section 6.2.
LanguageModeling —We ran experiments on Penn Treebank (PTB) dataset [18] using 1,2,3‐ layer LSTMmodels. We report test perplexities (ppl) (Fig. 6) for 3 independent runs on 9 optimizers10. Plots for train ppl are reported in Fig. 5. For Fromage, the author does not provide HP, hence we use grid search to find the optimal LR = 10−2. In case of 2 layer LSTM using AdamW & RAdam, we find that an LR = 10−3 gives a ppl of 73.78 & 74.05, while LR = 10−2 gives a ppl of 93.61 & 90.49 respectively. The author reports a ppl∼ 73, ∼ 73.5 at LR = 10−2. Similarly, in 3‐layer LSTM, LR = 10−3 for AdamW and RAdam works better than LR = 10−2. PTB is a small dataset, so, we additionally experiment on WikiText‐2 (section 6.1) for Adam and AdaBelief (top performers in case of PTB) on the setting reported here11.
Generative Modeling —We run experiments on WGAN [21], WGAN‐GP [22] & SN‐GAN [23]. SN‐GAN makes use of a ResNet generator with spectral normalization in the discrimi‐ nator and is trained for 100,000 steps. Five independent runs on 9 optimizers12 are per‐ formed. We also perform these experiments using the Padam [27] optimizer on WGAN andWGAN‐GP. FID values for SN‐GAN and Padam (Table 4, 5). Fig. 4 shows the variation in FID during training, giving an idea of stability and convergence of different optimiz‐ ers. Boxplots of FID values corresponding tomultiple runs onWGAN andWGAN‐GP are
10SGD, Adam, AdamW, AdaBelief, Yogi, MSVAG, RAdam, Fromage, AdaBound 11https://github.com/salesforce/awd‐lstm‐lm 12SGD, Adam, RMSProp, AdaBelief, Yogi, MSVAG, RAdam, Fromage, AdaBound
ReScience C 8.2 (#9) – Buvanesh and Panwar 2022 6
shown in Fig. 3. Collages of generated images for all optimizers are reported in Fig. 11, 12, 13. (a) SN‐GAN: In case of Fromage [12] and MSVAG [11], we obtain ∼4 and ∼8 worse FID than what is reported, while for AdaBound [10] we obtain a ∼40 better FID. We suspect the reason for this large deviation to be a difference in HP value being used. Since we performed a HP search for SN‐GAN, our HP (Table 2) are optimal. The results of re‐ maining optimizers were comparable to what was reported in the paper. (b) WGAN:We observe that AdaBelief outperforms other optimizers with a median FID of ∼80 which agrees with reported value. We observe a significantly worse FID with Fromage. (c) WGAN‐GP: AdaBelief and AdaBound achieve comparable results∼67 FID which are bet‐ ter than the other optimizers. Fromage shows similar deviation like in WGAN. With Padam, we find that for both WGAN and WGAN‐GP, increasing the partial (p) i.e. mov‐ ing from SGD towards Adam, decreases the FID. The FIDs obtained are found to agree with or are marginally better than what was stated in the paper.
5.2 Experiments beyond original paper
RL toy — To investigate the efficacy of AdaBelief in use cases beyond text and images we train an agent to play Space Invaders (Atari Game). We report Q value and reward func‐ tion for Adam and AdaBelief in Fig. 14, 15. We compare our results with author’s results from here13 and find that both results agree.
Image Classification on CIFAR-10 and CIFAR-100 using Apollo — Apollo [13] is another optimizer that claims to achieve better convergence speed and generalization than SGD and vari‐
13https://github.com/juntang‐zhuang/rainbow‐adabelief
ReScience C 8.2 (#9) – Buvanesh and Panwar 2022 7
ants of Adam. To investigate this, we experiment with Apollo on CIFAR‐10 and CIFAR‐ 100. Fig. 9, 10 show the train, test accuracies on VGG11, ResNet34 and DenseNet121 for the 3 independent runs. AdaBelief outperformsApollo in all settings exceptDenseNet121 on CIFAR‐100. It can also be seen that as we move from a simpler (VGG11) to a complex architecture (DenseNet121) the gap between Apollo and AdaBelief reduces. We made use of official implementation of Apollo in our experiments14.
Evaluating GAN training stability — To assess stability of AdaBelief while training GANs, we look into difference between SN‐GAN’s generator and discriminator training losses on CIFAR‐10. We do this for AdaBelief, Adam and RMSProp (since they have top‐2 FID scores on SN‐GAN) in the adaptive family, and with SGD for a comparison. Fig. 16 plots the generator and discriminator training losses. We observe that the adaptive methods aremore stable than SGD andwithin the adaptive family the order of stability frommost stable to least stable varies as RMSProp, AdaBelief, Adam.
Evaluating generalization ability — To evaluate AdaBelief’s ability to generalize, we analyze the bias and variance of image classificationmodels trained using SGD, Adam, AdaBelief and Apollo optimizers on CIFAR‐10 and CIFAR‐100. We use the method outlined here [28] for bias‐variance analysis. For each optimizer, we note its train and test accuracy (Fig. 1) corresponding to the epoch with best test accuracy (acc), and compute their dif‐ ference. This data is stated as 3‐tuples in Table 6. Lower training acc denotes high bias and vice‐versa. The difference between the train and test acc is a measure of variance. Based on Table 6, we observe that AdaBelief models have the least bias on all configu‐ rations, while they have 2nd, 3rd or 4th lowest variance. SGD has the least variance on most configurations (highlighted in red), but their bias is high (mostly ranked 3rd or 4th in low bias)."
"['Vishnu Asutosh Dasu', 'Midhush Manohar T.K.']",[Re] GANSpace: Discovering Interpretable GAN Controls,10.5281/zenodo.6574645,Replication,Python,https://zenodo.org/record/6574645/files/article.pdf,rescience c machine learning deep learning python tensorflow numpy gans image synthesis,https://openreview.net/forum?id=BtZVD2f7n0F,https://github.com/midsterx/ReGANSpace,8,2,2022,"The code that was provided by the authors in Pytorch was reimplemented in Tensorflow 1.x for the pretrained StyleGAN and StyleGAN2 architectures. This was done with the help of the APIs provided by the original authors of these models. The experimentswere runona laptopwith an Intel(R) Core(TM) i7‐8750HCPU@2.20GHz processor, 16GB RAM, NVIDIA GeForce GTX 1060 with Max‐Q Design (6GB VRAM) GPU, and Ubuntu 18.04.5 LTS.","The paper provides detailed explanations for the different mathematical concepts that were involved in the proposedmethod. This, augmentedwith a well‐structured and doc‐ umented code repository, allowed us to understand the major ideas in a relatively short period of time. Running the experiments using the original codebase was straightfor‐ ward and highly efficient as well, as the authors have taken additional steps to employ batch processing wherever possible.
Copyright © 2022 V.A. Dasu and M.M. T.K., released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Vishnu Asutosh Dasu (vishnu98dasu@gmail.com) The authors have declared that no competing interests exist. Code is available at https://github.com/midsterx/ReGANSpace – DOI 10.5281/zenodo.6511501. – SWH swh:1:dir:4dc4de7856350a4671d97840c5f9ae013c275112. Open peer review is available at https://openreview.net/forum?id=BtZVD2f7n0F.
ReScience C 8.2 (#10) – Dasu and T.K. 2022 1","Originallywewere attempting to recreate identical imageswith zero delta in the RGB val‐ ues. However, due to differences in the random number generators between PyTorch‐ CPU, PyTorch‐GPU and Numpy, the random values were not the same even with the same seed. This resulted in minute differences in the background artifacts of the gen‐ erated images. Additionally, there is a lack of open source Tensorflow 1.x APIs to access the intermediate layers of the BigGAN model. Due to time constraints, we were unable to implement these accessors and verify the images that the authors of GANSpace cre‐ ated using BigGAN.
Communication with original authors While conducting our experiments, we did not contact the original authors. The paper and codebasewere organizedwell and aided us in effectively reproducing and validating the authors’ claims.
ReScience C 8.2 (#10) – Dasu and T.K. 2022 2
1 Introduction
A Generative Adversarial Network (GAN)[1] is a machine learning framework where two neural networks, the discriminator and the generator, competewith each other in a zero‐ sum game. The generator tries to trick the discriminator into believing that artificially generated samples belong to real data. GANs have proven to be powerful image synthesis tools and are capable of producing high quality images. However, they provide little control over the features of the gen‐ erated image. Existing solutions[2] that add user control over the generated images re‐ quire expensive supervised training on latent vectors. GANSpace[3] proposes a simple technique to discover interpretable GAN controls in an unsupervised manner. This is done by identifying important latent directions based on Principal Component Analysis (PCA) applied either on the latent space or the fea‐ ture space. The author’s experiments on StyleGAN[4], StyleGAN2[5] and BigGAN512‐ deep[6] demonstrate that layer‐wise decomposition of PCA directions leads to many in‐ terpretable controls, which affect both low and high level attributes of the output image.
2 Scope of reproducibility
For our reproduction study, we aim to validate the effectiveness of the proposed tech‐ nique in offering powerful interpretable controls on the output images in an unsuper‐ vised manner. The following claims of the paper have been verified and tested successfully:
• PCA can be used to highlight important directions in the GAN’s latent space. • The GAN’s output can be controlled easily in an unsupervised fashion. • The earlier components control the higher‐level aspects of an image, while the later directions primarily affect the minute details. • Random directions do not yield meaningful decompositions as compared to the principal components identified using PCA.
3 Methodology
The principal components[7] of a collection of points in real coordinate space are a se‐ quence of p unit vectors, where the ith vector is a direction of the line that best fits the data while being orthogonal to the remaining i−1 vectors. Principal Component Analy‐ sis (PCA) is an unsupervised algorithm used to compute the principal components and perform a change of basis of the data using one or more of the computed components, increasing the interpretability of the data while minimizing its information loss[8]. It is commonly used in exploratory data analysis and for dimensionality reduction when dealing with high‐dimensional noisy data. The authors of GANSpace propose a tech‐ nique for identifying interpretable controls in an unsupervised fashion on pretrained GANs using PCA. Specifically, they show that layer‐wise perturbations along the princi‐ pal components generated using PCA on the latent space of StyleGAN based networks can be used to generate human‐interpretable transformations on the synthesized im‐ ages. Mathematically, a GAN can be expressed as a neural network G(z) that generates an image I : z ∼ p(z), I = G(z). Here, p(z) is a probability distribution from which the latent vector z is sampled. The network G(z) can be further decomposed into L inter‐ mediate layersG1 . . . GL. In the StyleGAN/StyleGAN2models, the input to the first layer is a constant y0. The output and input to the remaining layers is computed as:
yi = Gi(yi−1,w), where w =M(z) (1)
ReScience C 8.2 (#10) – Dasu and T.K. 2022 3
M is a an 8‐layer multilayer perceptron which is a non‐linear function of z. The num‐ ber of layers L depends on the resolution of the generated image. At each layer, the generated image is upsampled by a factor of 2.
The images generated by StyleGAN and StyleGAN2 can be controlled by identifying the principal axes of p(w), which is the probability distribution of the output of themapping networkM . First, we sampleN latent vectors z1:N and compute the correspondingwi = M(zi). The PCA of these w1:N values gives us the basis V for W. The output attributes of a new image given by w can then be controlled by varying the PCA coordinates of x before feeding them into the synthesis network:
w′ = w+ Vx (2)
Each entry xk of x is a separate control parameter which can be modified to update the desired attributes of the output image. We follow the same notation used by the authors to denote edit directions in this report. E(vi, j − k) means moving along component vi from layers j to k. Identifying specific edits, for example ”changing the color of a car”, is done via exploratory analysis using
ReScience C 8.2 (#10) – Dasu and T.K. 2022 4
a trial‐and‐error method. The authors have created a GUI‐based application for this purpose.
3.1 Model descriptions
We use NVIDIA’s official implementation of StyleGAN1 and StyleGAN22 models. The original code uses a PyTorch/NumPy implementation of StyleGAN and StyleGAN2which creates a PyTorch model and copies the weights from NVLabs’ implementations which are in Tensorflow. However, we directly use the NVLabs’ APIs with NumPy and make changes to the official GANSpace codebase to support the same.
3.2 Datasets The experiments in the paper were performed using the FFHQ, LSUN Car, CelebA‐HQ, Wikiart, Horse and Cat datasets. The official Tensorflow implementation of StyleGAN contains links to download pretrained models on FFHQ, LSUN Car, Wikiart, Horse and Cat. Themodels trainedonWikiartwere downloaded fromawesome‐pretrained‐stylegan3. In addition to the datasets used by the authors, we also perform our own experiments on the Beetles dataset which was downloaded from awesome‐pretrained‐stylegan24.
3.3 Experimental setup All the experiments were conducted on a laptopwith an Intel(R) Core(TM) i7‐8750HCPU @ 2.20GHz processor, 16GB RAM, NVIDIA GeForce GTX 1060 with Max‐Q Design (6GB VRAM) GPU, and Ubuntu 18.04.5 LTS. The generated images from our experiments were evaluated visually to determine whether the edits were working as expected.
4 Results
We were able to reproduce the results and verify the claims (mentioned in Section 2) made by the authors for the StyleGAN and StyleGAN2models by recreating themodified images, given the configuration parameters. Additionally, we also perform our own ex‐ periments to provide additional results that validate the effectiveness of the technique employed by GANSpace.
4.1 Effectiveness of PCA
1https://github.com/NVlabs/stylegan 2https://github.com/NVlabs/stylegan2 3https://github.com/justinpinkney/awesome-pretrained-stylegan 4https://github.com/justinpinkney/awesome-pretrained-stylegan2
ReScience C 8.2 (#10) – Dasu and T.K. 2022 5
Figure 3 highlights the effectiveness of PCAon changing the lowandhigh level attributes of the image. We are able to control object shape, colour and pose as well as nuanced landscape attributes. The edit directions corresponding to eachof the edits are: E(v22, 9−10) (”ChangeColor”), E(v11, 9− 10) (”Add Grass”), E(v0, 0− 4) (”Rotate”) and E(v16, 3− 5) (”Change type”).
4.2 Unsupervised vs. Supervised methods
Previous methods for finding interpretable directions in GAN latent spaces require ex‐ ternal supervision, such as labeled training images or pretrained classifiers. GANSpace, on the other hand, automatically identifies variations intrinsic to the model without su‐ pervision. This has been validated using the CelebA‐HQ Faces dataset by comparing the edit directions found through PCA to those found in previous works using supervised methods. Figure 4 shows that comparable edits can be obtained in a completely unsupervised fashion. Additionally, GANSpace can be used to identify new edits which have not been previously demonstrated. Supervisedmethods are not viable for this task as supervising each new edit would be costly. It is also difficult to know in advancewhich edits are even possible in supervised approaches.
ReScience C 8.2 (#10) – Dasu and T.K. 2022 6
4.3 PCA components vs. Random directions
The original authors claim that the earlier PCA components primarily control the geom‐ etry and other high‐level aspects (pose and style), while the lower components capture minute details. Additionally, they claim that fixing and randomizing randomly‐chosen directions do not yield PCA‐like meaningful decompositions, thus showing the impor‐ tance of identifying good directions using PCA. This has been illustrated in Figure 5, where different subsets of principal coordinates and random coordinates are random‐ ized while keeping the latent vector constant. In Figure 5a, the first eight principal co‐ ordinates x0:7 are fixed and the remaining 504 coordinates x8:512 are randomized. This changes the background and appearance of the cat while keeping the cat’s pose and cam‐ era angle constant. Conversely, Figure 5b shows that fixing the last 504 coordinates and randomizing the first eight yields images where the camera and orientation vary, but the color and appearance are held roughly constant. Figure 5c and Figure 5d shows the results of the same process applied to random directions. The images illustrate that any given 8 directions have no distinctive effect on the output.
4.4 Additional results not present in the original paper
New edits —We identify new edits on the Stylegan2 Beetles dataset. Edit E(v2, 0 − 17), referred to as ”Patterns”, adds a pattern on the shell of the beetle as well as increasing the overall size of the beetle. The generated pattern varies depending on the seed used to sample w.
ReScience C 8.2 (#10) – Dasu and T.K. 2022 7
Truncation Trick on StyleGAN — The ”Truncation Trick” is a procedure applied to the latent vectors to improve the quality of the generated images at the expense of variety in the images. It does this by sampling the latent vectors from a truncated distribution that is closer to the average of the latent vectors sampled during training, thereby reducing the variance of the latent vectors used during inference. The authors of [6] show that using the truncation trick improves the Fréchet Inception Distance (FID) and Inception Score (IS). In the StyleGAN/StyleGAN2models, the truncation trick is applied on the latent spacew, which is the output of the mapping networkM . During the training process, a running average wavg of the latents is computed. Later, the latents sampled during inference are truncated to lie close to wavg. Equation 3 shows the truncation process on Style‐ GAN/StyleGAN2 models:
w′ = wavg + ψ(w−wavg) (3)
During our experiments, we noticed that the original authors use the truncation trick on images generated using StyleGAN2 to reduce the number of artifacts. However, this is not enabled for StyleGAN images. We found that enabling truncation while applying edits on StyleGAN images improved their quality as well. We demonstrate this using the Wikiart dataset through the ”HeadRotation” (E(v7, 0−1)) and ”Simple Strokes” (E(v9, 8− 14) edits. In Figure 7, we can see that the generated faces contain less noise and artifacts when the truncation trick is used. For example, the lower half of the person’s face in the ”Head Rotation” image does not contain as much noise as their counterpart which does not employ the truncation trick. Here, we can also observe the change in the generated images as truncation psi is decreased a lower value of 0.25. This truncates the sampled latents to lie very close to the average and results in images that look very similar to each other. If truncation psi is set to 0, then according to Equation 3, we can see that the truncated latent w′ is always equal to wavg.
5 Discussion
After performing our experiments, we feel that the results justify the claims of the pa‐ per. This is further bolstered by the fact that the proposed method worked on different datasets which were not covered by the original authors.
ReScience C 8.2 (#10) – Dasu and T.K. 2022 8
ReScience C 8.2 (#10) – Dasu and T.K. 2022 9
We were not able to replicate the author’s experiments on BigGAN512‐deep due to time constraints.
5.3 Communication with original authors While conducting our experiments, we did not contact the original authors. The paper and codebasewere organizedwell and aided us in effectively reproducing and validating the authors’ claims."
"['Karolina Drabent', 'Stefan Wijnja', 'Thijs Sluijter', 'Konrad Bereda']","[Re] Replication study of ""Privacy-preserving Collaborative Learning""",10.5281/zenodo.6574647,Replication,Python,https://zenodo.org/record/6574647/files/article.pdf,rescience c machine learning deep learning python pytorch pytorch lightning federated learning data augmentation privacy,https://openreview.net/forum?id=SY84JTG73CK,https://github.com/stfwn/ats-privacy-replication,8,2,2022,"Weperformall experiments using themodel architectures, hyperparameters anddatasets as used in the original work. We also extend the experiments to a new dataset. We fur‐ ther contribute a reimplementation of the work in PyTorch Lightning to provide a mod‐ ular framework for future research into this area. All experiments are performed on Nvidia GTX 1080 GPUs. Our logs and checkpoints are made available for download via our code repository.",,
['Benjamin Džubur'],[Re] A Cluster-based Approach for Improving Isotropy in Contextual Embedding Space,10.5281/zenodo.6574649,Replication,Python,https://zenodo.org/record/6574649/files/article.pdf,rescience c machine learning natural language processing python,https://openreview.net/forum?id=rxWeB3zQ2CY,https://github.com/Benidzu/isotropy_reproduction,8,2,2022,"The authors of the paper, which we reproduced, introduce a method that is claimed to improve the isotropy (a measure of uniformity) of the space of Contextual Word Repre‐ sentations (CWRs), outputted bymodels such as BERT or GPT‐2. As a result, the method would mitigate the problem of very high correlation between arbitrary embeddings of such models. Additionally, the method is claimed to remove some syntactic informa‐ tion embedded in CWRs, resulting in better performance on semantic NLP tasks. To verify these claims, we reproduce all experiments described in the paper.","The described methods were easy to understand and implement, as they rely on PCA and K‐Means clustering.
Copyright © 2022 B. Džubur, released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Benjamin Džubur (bd5830@student.uni-lj.si) The authors have declared that no competing interests exist. Code is available at https://github.com/Benidzu/isotropy_reproduction. – SWH swh:1:dir:407d517fb5299301bcfc7f8aa461a4c3bf7c36b0. Open peer review is available at https://openreview.net/forum?id=rxWeB3zQ2CY.
ReScience C 8.2 (#12) – Džubur 2022 1","There were many ambiguities in the paper: which splits of data were used, the proce‐ dures of the experiments were not described in detail, some hyperparameters values were not disclosed. Additionally, running the approach on big datasets was too compu‐ tationally expensive. There was an unhandled edge case in the authors’ code, causing the method to fail in rare cases. Some results had to be submitted online, where there is a monthly limit of submissions, causing delays.
Communication with original authors Weexchangedmany e‐mailswith the authors, whichwere very responsive andhelpful in describing themissing information required for reproduction. In the end, we still could not completely identify the sources of some remaining discrepancies in the results, even after ensuring the data, preprocessing and some other implementation details were the same.
ReScience C 8.2 (#12) – Džubur 2022 2
2 Introduction
Embeddings from popular contextual NLPmodels such as BERT [2], GPT‐2 [3], RoBERTa [4], etc. suffer from the so‐called representation degeneration problem [5], where the individual tokens’ embeddings form an anisotropic cone‐like shape in the embedding space. This means that even unrelated words can have excessively positive correlations. Methods which study and attempt to improve the isotropy (a measure of uniformity) of the space on a global level (e.g. [1]) have been predominantly used so far to tackle this problem. However, due to the clustered structure of these Contextual Word Representa‐ tions (CWRs), the authors of the chosen paper [6] propose a local, cluster‐basedmethod, which could further improve on the existing global approaches. Apart from further improving isotropy, the method supposedly also removes some local structural and syntactic information within the clusters, improving the CWRs perfor‐ mance on semantic tasks.
3 Scope of reproducibility
Throughout the paper, the authors use contextual embeddings of three models to sup‐ port their claims: BERT, RoBERTa and GPT‐2. Various datasets are used to generate these contextual embeddings, which are then enhanced with the proposed method, evaulated and used to support claims about the performance of the method. Specifi‐ cally, these claims are:
• Claim 1: The cluster‐based method outperforms the baseline and global method, in all cases in terms of isotropy of CWRs as well as in almost all cases in terms of Spearmancorrelationperformance, on 7 Semantic Textual Similarity (STS) datasets.
• Claim 2: A wide and shallow Multi‐Layer Perceptron (MLP) performs the best in terms of accuracy on all 6 chosen binary classification tasks from the GLUE [7] and SuperGLUE [8] benchmarks, when trained on BERT emebeddings which were enhanced by the cluster‐based approach.
• Claim 3: A MLP described as in Claim 2 also converges to an optimum in fewer epochs, when the embeddings are enhanced by the cluster‐based approach.
• Claim 4: Removing dominant directions from CWRs of punctuations and stop words in sentences with the same syntactic structure (same group) results in fewer nearest neighbors of the CWRs being from the same group, as syntactic informa‐ tion is discarded.
• Claim 5: The cluster‐based approach brings together verbs which have the same meaning (sense) but different tense as seen in the SemCor corpus, by decreasing the average euclidean distance between their CWRs, relative to the distance be‐ tween verbs in the same tense but with a different sense.
In our reproduction, we verify all the listed claims by reproducing all the related exper‐ iments. Claims 1 and 2 are the most important ones as they directly address the perfor‐ mance of the cluster‐based method, while Claims 3, 4 and 5 are essentially attempted explanations of different side effects of the proposed method. In addition to these claims, the authors analyze the effect of the number of clusters in the K‐Means algorithm on isotropy as well as evaluate the layer‐wise isotropy of the contextual models. We have also reproduced these, purely statistical experiments for the sake of completeness of our reproduction.
ReScience C 8.2 (#12) – Džubur 2022 3
4 Methodology
The paper referenced a Github repository 1, in which we found a single Jupyter note‐ book with the implementation of the cluster‐based method, the isotropy metric, as well as an example of evaluating the isotropy and Spearman correlation performance on the STS‐B dataset. We first re‐implemented the cluster‐based method and verified that it works the same way – however in the end we used the authors implementation due to its slightly better runtime. There was an unhandled edge case in the original implemen‐ tation however – if fewer embeddings belonged to some cluster than the number of PCs to be removed, the original implementation would result in an out‐of‐bounds exception. We fixed this by repeating the clustering step until each cluster was sufficiently repre‐ sented. The method uses the Scipy library for K‐Means clustering and ScikitLearn for PCA. As the global method is simply a special case of the cluster‐based method with the num‐ ber of clusters k = 1, its re‐implementation was trivial. Wedidhowever have to re‐implement all of the experiments only from their descriptions in the paper and based on the help we got from our correspondence with the authors. We did not require a GPU for any of our experiments.
4.1 Model descriptions & hyperparameters For the contextualmodels, we used the Transformers library and the default pre‐trained weightswereused (specifically the casings bert-base-uncased, gpt2 and roberta-base). These models all output 768‐dimensional embeddings at each of their 12 layers. As reported in the original paper, the hyperparameters of the global and local, cluster‐ based approach were set for each model separately, as seen in Table 1. These values were used for all experiments.
When it comes to GLUE and SuperGLUE binary classification tasks, the contextual em‐ beddings were used to train a fully‐connected MLP. It’s structure remains the same across all tasks, using the hyperparameters communicated to us by the authors. Specifi‐ cally, for a single data sample (which is either a sentence or a pair of sentences), we only consider the first 64 tokens’ representations, which we flatten into a vector of length 64× 768, which represents our input layer. The next layer is a 100‐dimensional hidden layer with ReLU activation, followed by the output layer – a single neuron with sigmoid activation. The MLP is trained using binary cross‐entropy loss and uses the Adam opti‐ mizer with step size 0.005, for a maximum of 10 epochs. The reported results are based on the model which achieves the best validation set score. For the experiment where we analyze the CWRs of punctuations and stop words, we use the K‐nearest‐neighbor implementation by ScikitLearn with k = 6, which is exactly the number of possible neighbors from the same structural group (we only use the first CWR of the respective punctuation or stop word in a sentence). We then calculate the relative part of nearest neighbors belonging to the same group for each individual embedding and average the results. Note that each stop word or punctuation type (e.g. comma) is analyzed separately and the search is performed only amongst CWRs of the same type.
1https://github.com/Sara-Rajaee/clusterbased_isotropy_enhancement/
ReScience C 8.2 (#12) – Džubur 2022 4
Lastly, for the verb tense experiment, we consider verbswithmultiplemeanings (senses) and in two tenses – present simple and past simple (e.g. ”say” and ”said” correspond to the same verb in different tenses by our definition). Then, for each verb, we calculate all possible euclidean distances between representations of same tense and samemeaning, same tense and different meaning, different tense and same meaning. We then finally average across all distances at the lowest level of hierarchy. We repeat the calculation for the representations enhanced by the cluster‐based method.
4.2 Datasets For the main experiment on which Claim 1 in Section 3 is based, 7 Semantic Textual Similarity (STS) datasets were used. The STS‐2012 to STS‐2016 [9, 10, 11, 12, 13] as well as STS‐B are available at: https://ixa2.si.ehu.eus/stswiki/index.php/Main_Page , while the SICK‐ R [14] dataset is available at: https://marcobaroni.org/composes/sick.html. Individual data samples of these datasets are comprised of two sentences, and their semantic similari‐ ty/relatedness score, which is a real value on the scale from 0 to 5. In Table 2, the total number of data samples for each dataset after filtering is seen. Note that only the En‐ glish test splits were used, as in the original paper. Four of the seven datasets had some badly encoded samples (nomore than 10), whichwe simply discarded, after preliminary testing which showed that they do not noticeably affect the results. The two sentences of each sample were sent through the contextual models separately.
For the classification experiment on which Claim 2 in Section 3 is based, a selection of tasks (datasets) from GLUE [7] (https://gluebenchmark.com/) and SuperGLUE [8] (https:// super.gluebenchmark.com/) were used. In some cases, data sampleswere composed of pairs of sentences, while in others, a single sentence was given. In the first case, the pairs of sentences were encoded together, by concatenating their tokens and adding special tokens in the following way: [CLS]<sentence1>[SEP]<sentence2>[SEP]. The embeddings of these special tokens were also considered by the MLP classifier. Note that for the purpose of this experiment, we first merged the train, validation and test splits before applying the global or local enhancement method, as did the authors originally. Due to the big size of SST‐2 and BoolQ datasets, we had to limit the size of training and/or validation splits by randomsub‐sampling. The number of samples for each task are seen in Table 3. We found that 10745 × 64 was near the maximum number of embeddings that we could affoard to run PCA on, given our hardware. For the punctuation / stop word experiment, the authors provided a dataset based on Ravfogel et al. [15] (available at https://nlp.biu.ac.il/~ravfogs/resources/syntax_distillation/)which consists of 150000 groups of 6 sentences, where sentences from each group have the same syntactic structure but different semantics. For each of the tokens of interest sep‐ arately (”the”, ”of”, ”,” and ”.”), we randomly sampled 200 groups, where each group con‐ tained at least one appearance of the token per sentence. For the verb tense experiment, we used the SemCor corpus [16], available at http://web. eecs.umich.edu/~mihalcea/downloads.html#semcor. Out of over 30000 sentences, weused 11838
ReScience C 8.2 (#12) – Džubur 2022 5
of them, which contained the verbs wewere interested in. Specifically, these were verbs that appeared in present and past tense and also occurred in at least 2 different senses at least 10 times. The analysis of layer‐wise isotropy and the number of clusters in K‐Means is done on the STS‐B dev split.
4.3 Experimental setup and code The code of our reproduction is available at https://github.com/Benidzu/isotropy_reproduction. The isotropy measure (as defined in the original paper), Spearman performance (which is just the Spearman coefficient multiplied by 100) and accuracy were the main metrics used to evaluate our experiments. In order to evaluate the uncertainty in some of the main results, we resorted to bootstrap as well estimation of variance across multiple re‐runs of procedures containing stochasticity (e.g. initial positions of centroids in K‐ Means, initial weights of MLP classifiers).
4.4 Computational requirements The experiments were reproduced on a sytem with the 8‐core, 16‐thread Ryzen 3700x processor, 16GB of RAM and RTX3060Ti GPU (which was not explicitly used for any ex‐ periment). On a set of 30000 768‐dimensional embeddings, the global method ran for 12.5 seconds and the local, cluster‐based method for 14 seconds. On a bigger set of 200000 embed‐ dings, the global method ran for 98.9 seconds and the local method ran for 79.8 seconds. In addition, the local method requires a lot less memory at once, as it performs PCA for each cluster of embeddings separately. The training of MLP classifiers for the classification experiments required nomore than a minute on average.
5 Results
The reproduced results support some of the claims of the original paper. Specifically, the cluster‐based method indeed consistently outperforms the global and baseline in terms of isotropy. However, when it comes to Spearman performance on Semantic Tex‐ tual Similarity tasks, the local method performs better than the global method on some datasets andworse on others. Similar is true for the classification tasks, where the differ‐ ence in performance is mostly within margin of error. Analyzing verb tense, the Claim 5 from Section 3 is fully supported by our reproduction, while some discrepancies are observed when it comes to Claim 4.
5.1 Results reproducing original paper
Semantic Textual Similarity experiment — In this section we address Claim 1 from Section 3. In Figure 1 we plot the Spearman correlation performance for each method, contextual model and STS dataset. Due to the random nature of K‐Means, we repeat the experi‐ ment with the local method 5 times. We plot the results for each of the five repetitions individually. Additionally, we report the averages of these five repetitions in Table 4. Compared to the numbers in Table 2 of the original paper, our results are slightly more pessimistic. Embeddings enhanced by the local method perform noticeably better than those, enhanced by the global method, on some datasets and worse on others. There are also many cases where the difference in performance is within margin of error. In Table 5 we report the isotropy values of CWRs from each of the STS datasets, for each contextual model and enhancement method. These results support the original results achieved by the authors, as seen in Table 6 of the original paper.
ReScience C 8.2 (#12) – Džubur 2022 6
GLUE & SuperGLUE classification tasks — In this section we address Claim 2 from Section 3. In Table 6 we report average scores (accuracy / Matthew’s correlation) of the MLP classi‐ fier on the test set based on 5 repetitions. Each repetition, we re‐ran the corresponding embedding enhancement method and randomly re‐initialized and re‐trained the MLP, accounting for both sources of variance. It seems that the classifier trained on locally enhanced embeddings achieves the best scores on most of the tasks, however, due to the high uncertainty and small differences betweenmethods, we cannot confidently argue that onemethod is better than the other. Due to this uncertainty, our results do not fully support the original findings as seen in Table 3 in the paper.
Convergence time — In this section we address Claim 3 from Section 3. In Figure 2, we plot the per‐epoch performance of the MLP for two SuperGLUE tasks on the validation split. Our results support the original claim, as the MLP converges to an optimum in only a few iterations when trained on enhanced embeddings, while the same does not hold for baseline embeddings.
Punctuation and stop word experiment — In this section we address Claim 4 from Section 3. In Figure 3, we plot the percentage of nearest neighbors from the same structural (syn‐
ReScience C 8.2 (#12) – Džubur 2022 7
tactical) group, for baseline and enhanced embeddings. The results line up with the authors’ results (Figure 3 in original paper) for BERT and RoBERTa embeddings, where the removal of dominant directions via the method decreases the percentage of neigh‐ bors from the same group. However, this does mostly not hold for GPT‐2 embeddings in our reproduction.
Verb tense experiment — In this section we address Claim 5 from Section 3. In Table 7, we report the results of the corresponding experiment, described in Section 4.1. The results support the claim, as they are very similar to authors’ results in Table 4 of the original paper.
Additional isotropy analysis — In this last section, we report the reproduction results of the additional isotropy analysis of the contextual models’ embeddings. The results, ana‐
ReScience C 8.2 (#12) – Džubur 2022 8
lyzing the impact of number of clusters in K‐Means and the layer‐wise isotropy of the contextual models are seen in Tables 8a and 8b respectively. Our results support the original results, as seen in Tables 1 and 5 in the original paper.
In general, many of the original authors’ claims are supported by our experimentation. The achieved isotropy scores across the reproduced experiments are similar to the orig‐ inal ones, implying that the cluster‐based method is working as intended. However, even in situations with seemingly no randomness (extracting baseline embeddings of datasets and evaluating isotropy), we could not perfectly reproduce the original results. This might imply discrepancies on hardware‐level computation or due to different ver‐ sioning of used libraries (e.g. Transformers). Consequently, this perhaps implies that the local method is not robust enough to such variations, to consistently outperform the global method (e.g. in terms of Spearman coefficient performance on STS tasks), as originally claimed. Similarly, for the classification tasks, after our own re‐implementation, we found out that authors used Keras for theMLP classifier, while we used ScikitLearn (albeit with all hyperparameters set equivalently). This was another source of potential discrepancies, but the similar results reflect that this was not a real issue. Amore likely reason for some differences in this experiment might be the fact that, while the authors stated that they re‐trained the MLP multiple times before submitting and reporting the results of the best classifier (chosen by validation set performance), we opted for themore robust and
ReScience C 8.2 (#12) – Džubur 2022 9
less biased score estimation via averaging across multiple submissions and additionally estimating the errors of our estimates. When it comes to Claims 3 and 5 from Section 3, our results fully support these claims, although again, we are unable to get exactly the same numbers, perhaps due to the reasons listed above or due to minor differences in implementation. Finally, with the punctuation and stop word experiment, we were surprised by the fact that by removing local dominant directions of CWRs from the GPT‐2 model, we actu‐ ally increased the percentage of neighbors from the same structural group. Since the percentage of nearest neighbors with the same syntactical structure was relatively low to begin with in this case (compared to BERT and RoBERTa), we believe the dominant directions carried mostly semantic information, and by removing them, the syntactical information in the embeddings became more dominant.
6.1 Recommendations for further experimentation Unfortunately, due to various limitations and our budget, we could not afford much ad‐ ditional experimentation beyond the scope of the paper. However, during our analysis, we came up with some ideas and experiments, which could be further looked into. We list some of these ideas the following. Firstly, for the GLUE & SuperGLUE classification tasks, the authors first merge train and test splits and then run the embedding enhancement method and then train the MLP. In a practical scenario, where we would like to predict the class for a completely new data sample, repeating this whole process becomes computationally infeasible. Therefore, the following experimental procedure, where the learning step is performed only once (and updated on a less regular basis), could be evaluated and compared to the original one:
1. Run the cluster‐based method on contextual embeddings of the training set. Save the centroids of each cluster in original space as well as its corresponding top prin‐ cipal components to be removed.
2. Train the MLP on the enhanced embeddings.
3. At prediction time (for test data), extract the contextual embeddings of the new data sample. For each CWR, enhance it by doing the following: assign it to the nearest cluster, based on the saved centroids in step 1, then subtract the centroid and remove the corresponding PCs.
4. Pass the enhanced embeddings of the data sample to the MLP for prediction.
Other additional ideas include experimentingwith differentMLP architectures, or some of the remaining GLUE / SuperGLUE tasks, namely COPA, QNLI, QQP, etc. Additionally, using a different clustering algorithm or distance measure could prove to be beneficial.
6.2 What was easy The explanations of the methods and experiments in the original paper were easy to fol‐ low. The cluster‐based method relies on K‐Means clustering and PCA, both of which we were already familiar with. The code present in the referenced repository was therefore easy to understand.
6.3 What was difficult Some key implementation details of various experiments and hyperparameters of al‐ gorithms were not disclosed in the original paper, making exact re‐implementation of the experiments more difficult. Even after receiving the necessary information, there
ReScience C 8.2 (#12) – Džubur 2022 10
were discrepancies in results which could not be attributed to randomness, differences in data, or some differences in implementation (assuming authors used the published code). Due to some big datasets used in some experiments, we had to subsample the num‐ ber of data samples to be able to run the described algorithms. Our system would in some cases completely freeze due our CPU usage reaching 100% because of PCA com‐ putations. Additionally, extracting embeddings, re‐running themethodsmultiple times and performing expensive procedures such as bootstrap took a lot of time. The most time‐consuming step by far was estimating the performance and error of our estimates on GLUE and SuperGLUE classification tasks. In order to get test split results, one has to manually submit the predictions through the official website. This was an issue in our case due to the restrictions of submissions – a team is only allowed to make up to two submissions a day and six per month, which dragged out our collection of results.
6.4 Communication with original authors Weexchangedmany e‐mailswith themain author of the paper, in order to enquire about various hyperparameters and other implementation details of each experiment and to ensure we set up our experiments the same way. The author was quite helpful and re‐ sponsive. Unfortunately, we had to accept that some discrepancies between our results would still be present (see Sections 6 and 6.3 for our comments on these discrepancies), after much time spent attempting to reduce them."
"['Erica Eaton', 'Pirouz Naghavi']","[Re] Reproduction and Extension of ""Queens are Powerful too: Mitigating Gender Bias in Dialogue Generation""",10.5281/zenodo.6574651,Replication,Python,https://zenodo.org/record/6574651/files/article.pdf,rescience c machine learning natural language processing deep learning python bias mitigation,https://openreview.net/forum?id=StblE2MQ3AY,https://github.com/Pnaghavi/Mitigating-Gender-Bias-in-Generated-Text,8,2,2022,"We fine‐tuned a transformer model, pre‐trained on Reddit data2, using the ParlAI API3 with counterfactual data augmentation, positively biaseddata collection, bias controlled training, and all three biasmitigation techniques combined, as discussed in the original paper1. We implemented counterfactual data augmentation and bias controlled train‐ ing ourselves. All models were trained and evaluated using a single NVIDIA Tesla P100 PCIe GPU, which took between 1.3 and 4.6 GPU hours approximately.","When reproducing the original paper1, implementing counterfactual data augmenta‐ tion and bias controlled training was easy since these techniques were well‐described
Copyright © 2022 E. Eaton and P. Naghavi, released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Erica Eaton (eatone3@uw.edu) The authors have declared that no competing interests exist. Code is available at https://github.com/Pnaghavi/Mitigating-Gender-Bias-in-Generated-Text. – SWH swh:1:dir:320f7080ccd0edd611da07e9dbd9dbe4bbd18758. Open peer review is available at https://openreview.net/forum?id=StblE2MQ3AY.
ReScience C 8.2 (#13) – Eaton and Naghavi 2022 1
in the original paper1. Also, combining all three bias mitigation techniques was sim‐ ple, as we applied the same techniques used to implement each bias mitigation method individually.","The only difficulty we encountered, albeit minor, was learning how to use ParlAI, which was necessary to use the same model as in the original paper1. However, after reading through the ParlAI documentation and experimenting with the ParlAI Google Colabora‐ tory tutorial4, we understood how to use ParlAI to fine‐tune the model, pre‐trained on Reddit conversations2, for the datasets we create.
Communication with original authors
We communicated with Emily Dinan, an author of the original paper1, who clarified whatmodel was used in the original paper1 and provided us with the command to down‐ load the model as well as the hyperparameter settings used when fine‐tuning.
1 Introduction
Ad‐hocmethods formitigating social bias in natural language data remain an active area of modern research. As transfer learning with pre‐trained models such as BERT5 and GPT‐26 continue to be pervasive, the inherent issues in their training data have come to light. Large corpora of unstructured text from the Internet reflect the biases and inequal‐ ities of society, and are consequently learned by these models and their fine‐tuned vari‐ ants. To this end, Dinan et al.1 proposed three techniques to specificallymitigate gender bias in fine‐tuned languagemodels, using the LIGHTdataset7 as an example. The LIGHT dataset is a crowdsourced collection of dialogues spoken between ”personas,” characters played by either humans or models, in a fantasy adventure game, LIGHT7. Dinan et al. applied the following techniques to this dataset: 1) counterfactual data augmentation, in which genderedwords are replacedwith their opposite, i.e., replacing ”he” with ”she”; 2) positively biased data collection, in which new, less biased female character personas and dialogues are created via crowd‐sourcing; and 3) bias controlled training, in which the dialogue is placed in groups based on the number of gendered words it contains and this group number is included with the dialogue as a special token when training the model1. The model itself is a transformer pre‐trained on a dataset of Reddit con‐ versations2 and then fine‐tuned on LIGHT using the three techniques described above, individually, as well as one combining all three techniques.
2 Scope of reproducibility
The aim of this paper is to evaluate the following hypotheses made by Dinan et al.1 by reproducing their experiments.
• Combining counterfactual data augmentation, the positively biased data collected by Dinan et al.1, and bias controlled training for the LIGHT dataset yields gener‐ ated dialogue in which the percent of genderedwords andmale bias closelymatch the ground truth.
• Bias controlled training for the LIGHT dataset yields generated dialogue in which the percent of gendered words and male bias closely match the ground truth.
ReScience C 8.2 (#13) – Eaton and Naghavi 2022 2
3 Methodology
We fine‐tuned the transformer model, pre‐trained on Reddit data2, using the ParlAI API3 with counterfactual data augmentation, positively biased data collection, bias con‐ trolled training, and all three bias mitigation techniques combined, as discussed in the original paper1. We generated training, test, and validation datasets for counterfac‐ tual data augmentation and bias controlled training from the original LIGHT dialogue dataset. We also formatted the dataset used for each bias mitigation technique, extract‐ ing the dialogue from each dataset and placing it in the proper format, such that every‐ thing said in the dialogue so far is used to predict the next response in the dialogue, which is the label. All models were trained and evaluated using a single NVIDIA Tesla P100 PCIe GPU.
3.1 Model descriptions
Dinan et al.1 used a transformer with 8 encoder layers, 8 decoder layers, embedding dimension of 512, and 16 attention heads. This model was pre‐trained on Reddit con‐ versations from the pushshift.io Reddit dataset, which contains 2.2 billion samples for training after removing comments that contain URLs or that are less than 5 characters long1. Specifically, the model was trained on all comments in each thread and learned to predict the next comment in the thread1. Thus, this pre‐training makes the model well‐suited for the dialogue generation task2. The model contains 87, 508, 992 trainable parameters and the training objective is to minimize the cross entropy loss on the origi‐ nal and augmented LIGHT dialogues.
3.2 Datasets
We used the ParlAI API command from the paper’s ParlAI project page8 to obtain the fol‐ lowing data: the LIGHT dataset7, a list of counterfactuals, a list of gendered words9, and the positively biased data collected by Dinan et al.1. The LIGHT dataset and positively biased data collected by Dinan et al. contain information about interactions between characters in the game, LIGHT, such as the character names and personas, dialogue, and environment where the interaction took place, to name a few. The LIGHT dataset contains approximately 11, 000 interactions and 111, 000 utterances7. An utterance is a single occurrence of a character talking during a dialogue. The LIGHT dataset is used to fine‐tune the baseline model. Each biasmitigationmethod employed by Dinan et al.1 also requires fine‐tuning the pre‐ trainedmodel on a new dataset. For counterfactual data augmentation, we used the list of counterfactuals to replace every gendered word, according to the list of gendered words from Zhao et al.9, in the LIGHT dialogue dataset with its counterfactual. The list of genderedwords9 has 1, 049words. The list of counterfactuals contains each gendered word and its opposite gendered counterpart. For example, the counterfactual for ”he” is ”she”. In addition, the list of counterfactuals, containing 421 words, was constructed by Dinan et al.1 using the list of gendered words from Zhao et al.9. For positively biased data collection, Dinan et al. crowdsource new dialogue data, ask‐ ing workers to create dialogue assuming gender equality1. This dataset contains 507 interactions and 6, 658 utterances. Given the time and resource constraints, we used Dinan et al.’s positively biased data1 rather than crowdsourcing the data ourselves. For bias controlled training, we appended ”fx my” after the last utterance in an episode, which is a portion of a dialogue between two characters, based on the label, which is the next utterance in the dialogue. In ”fx my,” x is 1 if there is at least one female gen‐ dered word in the label and 0 otherwise, and y is 1 if there is at least one male gendered word in the label and 0 otherwise. Thus, each label falls into one of four bins: ”f0 m0” which has no gendered words; ”f0 m1” which has no female gendered words but at least
ReScience C 8.2 (#13) – Eaton and Naghavi 2022 3
one male gendered word; ”f1 m0” which has at least one female gendered word but no male gendered words; and ”f1m1” which has at least one female and onemale gendered word. Placing the dialogue labels in these bins causes themodel to learn the gender bias present in an utterance, allowing us to specify the desired gender bias in the model’s generated dialogue using one of the four bins. We used the list of gendered words from Zhao et al.9 to determine the number of gendered words and proper bin for each label and model generated utterance. We split the datasets used for fine‐tuning each model into approximately 90% for train‐ ing and 10%for anunseen test set. The training setwas further split into 80%for training and 20% for validation.
3.3 Hyperparameters As previouslymentioned, themodel, pre‐trained onReddit conversations, has 8 encoder layers, 8 decoder layers, 16 attention heads, and an embedding dimension of 5122. In addition, this model has 2, 048 nodes in the hidden layer, uses GeLU activation function, and truncates each dialogue to at most 512 characters and each label to at most 128 char‐ acters. Other hyperparameters for each model are an initial learning rate of 3.1e − 7, memory‐efficient Adam optimizer, gradient clipping of 0.1, inverse square root learn‐ ing rate scheduler with a decay factor of 0.5 and patience of 3, no activation or attention dropout, batch size of 20, and dropout of 0.1 or 0.15 depending on hyperparameter tun‐ ing results. Emily Dinan, one of the authors of the original paper1, provided some of the hyperparameter values, but we reduced the batch size due to memory constraints with Google Colaboratory resources. Since most hyperparameters were provided by Emily Dinan and the learning rate is adjusted by the inverse square root learning rate sched‐ uler and batch size could not be increased due to GPU limitations, the only remaining hyperparameter that we could effectively tune to improve perplexity, based on our expe‐ riencewith deepNLPmodels, particularly pre‐trained transformers, was dropout. Thus, we tuned dropout, applied to the embeddings and before layer normalization, for the model combining all three bias mitigation techniques, since this model provided the best results according to the original paper1, to obtain lower perplexity on the valida‐ tion set. In order to tune dropout, we increased dropout in increments of 0.025, starting from a value of 0.1, which was given by Emily Dinan, up to 0.2. After training a number of models with different dropouts, we found that 0.15 dropout resulted in the lowest perplexity. In addition, for the extension with neutral, generated data, we again tuned dropout, and found 0.15 to be the optimal value.
3.4 Experimental setup and code Similar to the Reddit dataset used for pre‐training themodel as well as the training done by Dinan et al.1, we generated the datasets based on the entire history of conversations so far, predicting the next utterance in each conversation. For each biasmitigation tech‐ nique and combining all three techniques, we generated the datasets from the original conversations in the LIGHT dataset7 for training, evaluation, and response generation. Using ParlAI’s API, we fine‐tuned 5 versions of the model, pre‐trained on Reddit conver‐ sations2: baseline, counterfactual data augmentation, positively biased data collection, bias controlled training, and all three bias mitigation techniques combined. When fine‐ tuning eachmodel, the best model is saved according to the perplexity on the validation set. As long as the perplexity on the validation set continues to improve, the model con‐ tinues training and at every quarter epoch, the version of themodel achieving the lowest perplexity on the validation set is saved. If the model does not improve after 10 quarter epochs, training will be automatically stopped to avoid overfitting or unnecessary train‐ ing. After training is complete, we run further evaluation to obtain F1 scores on the validation and test datasets as well as F1 scores pertaining to the labels for each bin for these two datasets. Finally, we pass every dialogue episode in the test set through the
ReScience C 8.2 (#13) – Eaton and Naghavi 2022 4
model to generate responses. These generated responses are used to compute statistics defined by Dinan et al.1 to evaluate gender bias in generated responses from themodel.1 All experiments were run on Google Colaboratory using a single NVIDIA Tesla P100 PCIe GPU. After fine‐tuning each model, the labels in the test set are split into the bias con‐ trolled training bins and within these bins, each model’s generated utterances are also grouped into the same bins. This allowed us to compute the percent gendered words and male bias for the generated utterances within each bin of labels for the test set. In addition, we computed the F1 score for predicted tokens in generated responses sepa‐ rately for each bin of test labels.
3.5 Computational requirements
The model used by Dinan et al. in the original paper1 was pre‐trained on Reddit con‐ versations in the same manner as the polyencoder transformer model from Humeau et al.10, and contains the same number of encoder layers, decoder layers, attention heads, and embedding dimension size. Training the polyencoder transformer on the ConvAI2 dataset, which has about 131, 000 elements11, took 2.7 hours using 8 NVIDIA Volta 100 GPUs10. Since the polyencoder transformer has about 20% more parameters than the model used by Dinan et al. and the LIGHT dataset is about 15% smaller than the Con‐ vAI2 dataset, we estimated it tookDinan et al. about 2.3 hours or less, which is 85%of 2.7 hours, using 8 GPUs to fine‐tune each model or about 11.5 hours total for all 5models.
We initially estimated we could also fine‐tune all 5 models in approximately 11.5 hours using Google Cloud Platform. Instead, we used a single NVIDIA Tesla P100 PCIe GPU on Google Colaboratory. During training, each model required about 16 GB of GPU mem‐ ory, maximizing the GPU memory available with the aforementioned batch size of 20. Table 1 lists runtime information for fine‐tuning each model, where the model combin‐ ing all three bias mitigation techniques uses dropout of 0.15 for the embeddings and before layer normalization, as previously mentioned. The runtime for this model with other values for dropout was approximately the same. The actual training time for our models was substantially lower than our estimate, likely due, at least in part, to the un‐ predictability of Google Colaboratory providing the full computational GPU resources assigned to a particular session.
1The GitHub repository for our project is located at https://github.com/Pnaghavi/Mitigating‐Gender‐Bias‐ in‐Generated‐Text
ReScience C 8.2 (#13) – Eaton and Naghavi 2022 5
4 Results
Below are the results from reproducing and extending the experiments in the original paper1. Overall, our results support the hypotheses previously identified. Further dis‐ cussion of the results in relation to the hypotheses is provided below. We also imple‐ ment 3 extensions to the original paper1, two of which are aimed at addressing the high time andmonetary cost of positively biased data collection, which requires crowdsourc‐ ing data. Figure 1 shows the percent gendered words, percent male bias, and F1 score of each model’s generated utterances for conversations in the test set, separated according to the test label bins, where ”Baseline” is themodel trained only on the LIGHT dataset, ”CDA” is counterfactual data augmentation, ”Pos Data” is positively biased data collection, ”Bias” is bias controlled training, and ”All” combines all three bias mitigation techniques. In Figure 1, each set of three graphs corresponds to one of the four bias controlled training bins for test labels. The results shown in Figure 1 are quite similar to those in Figure 1 of the original paper1 in terms of how the percent gendered words, percent male bias, and F1 score for each model in each bin compare. Although our results are not exactly the same as those in the original paper1 in terms of values, the main trends in our results
ReScience C 8.2 (#13) – Eaton and Naghavi 2022 6
are the same as those in the original paper1. The main differences between our results and those in the original paper1 are lower male bias in each bin for the baseline and a percent gendered words for ”CDA” that is closer in value to the baseline in our results.
4.1 Results for First Hypothesis According to the first hypothesis, the number of gendered words in the generated ut‐ terances for the ”All” model for each bin should be similar to the number of gendered words in the labels of the test set. This is observed in all four bins in Figure 1. Specif‐ ically, for the F0M0 bin, the test labels have no gendered words, which means the gen‐ erated utterances for both models should have a very low number of gendered words and approximately 50% male bias. The ”All” model satisfies these two requirements, as depicted in the first set of charts in Figure 1, because the generated utterances from this model are less than 1%gendered words and the percentmale bias is approximately 44%. For the F+M0 bin, the test labels have at least one female gendered word and no male gendered words, which means the generated utterances should have a higher number of gendered words and a smaller percentage of male bias. This is observed for the ”All” model in the second set of charts in Figure 1, since the percent gendered words for the ”All” model is higher than the baseline and the percentmale bias is under 5%, compared to about 42%male bias for the baseline. Similarly, in the F0M+ bin, the test labels have at least one male gendered word and no female gendered words. Thus, the generated utterances for the ”All” model should have a higher number of gendered words and a larger percentage of male bias, which is depicted in the third set of charts in Figure 1. In the F0M+ bin, the percent of gendered words for the ”All” model is about 1% higher than the baseline and themale bias is approximately 97%, compared to only 52% for the baseline. For the last bin, F+M+, the test labels have at least one male and one female gendered word. As a result, the generated utterances for the ”All” model should have a higher percentage of gendered words and closer to 50% male bias. As shown in the last set of charts in Figure 1, the ”All” model does have a higher percentage of gendered words than the baseline, specifically 13%, compared to 8% for the baseline. However, the male bias is about 43% for the ”All” model, which is not as close to an even gender bias split, 50% male and 50% female, as the baseline, which has about 46% male bias. In the discussion section, we give a possible cause for this discrepancy in our results.
4.2 Results for Second Hypothesis Based on the second hypothesis, the number of gendered words in each utterance gen‐ erated by the ”Bias” model should be similar to that of the labels in the test set for each dialogue. This can be clearly seen for all four bins in Figure 1. In the F0M0 bin, the test labels have no gendered words. If the model has learned from bias controlled train‐ ing, producing properly gender biased text according to the bin appended to the end of the dialogue, then the generated text for the ”Bias” model in the F0M0 bin should have very few gendered words and about 50%male bias. As depicted in the first set of charts in Figure 1, for the F0M0 bin, the ”Bias” model has less than 1% gendered words and approximately 57% male bias, as desired. For the F+M0 bin, the generated text should have more female gendered words and few to no male gendered words, matching the gender bias in the test set label. This is observed in the second set of charts in Figure 1, since the ”Bias” model yields a higher percent of gendered words than the baseline and less than 5% male bias, compared to 42% male bias for the baseline. Generated text in the F0M+ test label bin should have more male gendered words and few to no female gendered words, which is depicted in the third set of charts in Figure 1. Specif‐ ically, the percent gendered words for the ”Bias” model is 1% higher than the baseline and male bias is approximately 94%, compared to only 52% for the baseline. In the last bin, F+M+, the generated text should ideally have an even distribution of male and fe‐ male gendered words and a higher percentage of gendered words overall. This is shown
ReScience C 8.2 (#13) – Eaton and Naghavi 2022 7
in the last set of charts in Figure 1, since the ”Bias” model has a higher percentage of gendered words than the baseline, specifically 11% for the ”Bias” model and 8% for the baseline, although male bias is 36% for the ”Bias” model compared to 46% for the base‐ line, which is not an even distribution. A possible cause for this discrepancy in our results is described in the discussion section.
4.3 Effect of Removing Positively Biased Data Collection Given the time and monetary cost involved in crowdsourcing data, specifically the pos‐ itively biased data Dinan et al. collected1, a natural question is whether adding this positively biased data to counterfactual data augmentation and bias controlled training is worth the cost. In other words, what is the performance loss if positively biased data collection is excluded from the model, instead relying only on counterfactual data aug‐ mentation and bias controlled training.
Implementation and Experimental Setup —We fine‐tuned the model, pre‐trained on Reddit conversations2, on the data generated fromcounterfactual data augmentation andusing bias controlled training. The implementation and experimental setup is the same as that for themodel that combines all three biasmitigation techniques, exceptwe excluded the positively biased data collected by Dinan et al.1.
Results and Discussion — Figure 2 depicts, for each bin, the percent gendered words and percent male bias in the generated utterances as well as the F1 score for the ”All” model, which combines all three bias mitigation techniques, the ”CDA + Bias” model, which uses counterfactual data augmentation and bias controlled training, and the baseline. As expected, for all four bins, the percent gendered words, percent male bias, and F1 score for ”All” achieves better results than ”CDA + Bias,” in terms of higher F1 scores and the percent gendered words and male bias being closer to ground truth, except ”CDA + Bias” achieves a slightly higher F1 score for the F0M0 bin. However, results for ”CDA + Bias” are always within about 2% of the results for ”All” and the overall F1 score for ”CDA + Bias” is within 0.25% of the overall F1 score for ”All,” specifically an F1 score of 15.31 for ”CDA + Bias” and 15.56 for ”All.” Although incorporating positively biased data collection does yield better results, given how small the difference is between including vs. excluding this technique, it may not be worth the necessary time or money. Instead, one could simply use counterfactual data augmentation and bias controlled training or find a less costly way to collect positively biased data, which is the focus of the next extension.
4.4 Generating Gender Neutral Data In the previous section, we created a model incorporating counterfactual data augmen‐ tation and bias controlled training, removing positively biased data collection. Instead of completely removing this additional, positively biased data, an alternative, which
ReScience C 8.2 (#13) – Eaton and Naghavi 2022 8
still avoids the cost of crowdsourcing data, is to generate new, gender neutral data us‐ ing code. Incorporating gender neutral data can help shift the gender bias of the data, whether male or female, closer to 50%.
Implementation and Experimental Setup —We fine‐tuned the model, pre‐trained on Reddit conversations2, using counterfactual data augmentation and bias controlled training, then generated responses from this model for all dialogue episodes in the training data. For each generated response, we set the response to be either the model’s generated response or the actual label. If the generated response is neutral, meaning it contains approximately the same number of male and female gendered words or no gendered words, we use the generated response 90% of the time, selecting the actual label in all other cases. These neutral generated responses were used to reconstruct the conversa‐ tions. We then created new training and validation datasets from these conversations that partially included neutral model generated utterances. Finally, a new model was fine‐tuned on these datasets. The experimental setup is the same as that for the model that combines all three bias mitigation techniques, except we excluded the positively biased data collected by Dinan et al.1 and used the gender neutral data we generated instead. An important point to note is that the test dataset for this new model is the original test dataset. Thus, the F1 scores obtained for each bin and the overall F1 score are from the original test dataset, containing 100% natural conversations.
Results and Discussion — Figure 3 shows, for each bin, the percent gendered words and percent male bias in the generated utterances as well as the F1 score for the ”All” model, which combines all three bias mitigation techniques, the baseline, and the ”CDA + Bias + Our Gen Data” and ”CDA + Bias” models, which use counterfactual data augmentation and bias controlled training with and without our neutral, generated data, respectively. Results for our new model, ”CDA + Bias + Our Gen Data,” are within 2% of the results for ”All” in all cases except male bias for F0M0, F+M0, and F0M+. For F0M0, our model yields male bias closer to 50% than ”All” by 6%, specifically male bias of about 43% for ”All” and 49% for our model. Also, our model results in about 4% higher male bias than ”All” for the F+M0 bin and about 4% lower male bias for the F0M+ bin. However, these are actually the desired results because for each bin, the male bias for our model is closer to 50%, at least slightly, than ”All.” Thus, our model results in more gender neu‐ tral responses overall, which was the goal of this method. In addition, all results for our new model are still relatively close to the results of ”All,” demonstrating the effective‐ ness of our new method, as it did not require any crowdsourced data, only additional training. One concern with using model generated responses is that they may not be as coherent as natural dialogue, but the F1 scores for our new model are comparable to those for the ”All” model. For future work, if we repeatedly use the dialogues with our neutral, generated responses to create new generated responses, coherency will be‐ come a greater concern and necessitate the use of a coherency assessment model, such as some of the machine‐learned evaluation metrics highlighted by Celikyilmaz et al.12. Given that adding our neutral, generated data to counterfactual data augmentation and bias controlled training yields approximately the same or slightly higher F1 scores than the ”All” model, using only neutral, generated responses with high coherency, accord‐ ing to themetrics introduced by Celikyilmaz et al.12, in the reconstructed conversations, we can continue to shift the model towards gender neutrality, while maintaining high F1 scores.
4.5 Percent Generated Responses with Respect to Bins To better evaluate the degree towhich our extensions generate gender neutral responses in comparison to the ”All” model, we placed the generated responses from these three models into one of the bias controlled training bins based on the presence of gendered
ReScience C 8.2 (#13) – Eaton and Naghavi 2022 9
words in the generated response, and computed the percent of generated utterances in each bin for each of the three models.
Results and Discussion — Figure 4 depicts the percent of generated responses in each bin for the baseline, when combining all bias mitigation techniques, denoted ”All,” and us‐ ing counterfactual data augmentation and bias controlled trainingwith andwithout our neutral, generated data, denoted ”CDA + Bias + Our Gen Data” and ”CDA + Bias,” respec‐ tively. These results demonstrate that the ”CDA + Bias + Our Gen Data” model generates more gender neutral responses overall, compared to ”All” and ”CDA + Bias.” Specifically, for the F0M0 and F+M+ bins, which are themore gender neutral bins, ”CDA + Bias + Our Gen Data” has the highest, or near highest, percentage of generated responses. For the F+M0 and F0M+ bins, which are not gender neutral, ”CDA + Bias + Our Gen Data” has the lowest percent of generated responses. In addition to generating more neutral re‐ sponses, ”CDA + Bias + Our GenData” achieves approximately the same F1 score for each bin as ”All,” as depicted in Figure 3, demonstrating that the control over gender bias pro‐ vided by bias controlled training is still present despite the responses beingmore gender neutral overall. This indicates an opportunity for future work to shift the overall bias of the model’s generated responses to any direction, male biased, female biased, or neu‐ tral, by selectingmodel generated responses that belong to the bin with the desired bias to infuse the original dialogues with this bias and train a model to generate more re‐ sponses with the desired bias. By repeating this process, we can reinforce the model to generate more responses biased in the desired direction, as long as we can still achieve a high F1 score and maintain coherency, which can be checked by machine‐learned co‐ herency metrics12 as a form of second or outsider opinion on the generated responses during the infusion process.
5 Discussion
Given how closely our experimental results for bias controlled training and combining all three original bias mitigation methods matched the ground truth, these two tech‐ niques can be used to control the gender bias of these models’ generated text. Thus, gender neutral dialogue could be created by constructing ground truth data with either no gendered words or 50% male bias and 50% female bias within the gendered words. Given that we reproduced the results from the original paper1 for bias controlled train‐ ing and combining all three bias mitigation techniques, we feel that overall our results support the claims in the original paper1, despite the differences in value between our results and those in the original paper1. One possible cause for the differences between our results and those in the original paper1 is our training method, since we achieve higher F1 scores for each model and stop training when perplexity stops decreasing, which may not be the same criteria Dinan et al. used to determine when to stop train‐ ing. It is also possible that in the original paper1, the list of gendered words used to place utterances in bins was a subset of the original gendered word list9, most likely the list of counterfactuals. This could also account for the lower male bias we observed for
ReScience C 8.2 (#13) – Eaton and Naghavi 2022 10
the baseline in our results compared to Dinan et al.’s, however Dinan et al. explicitly stated they used the gendered word list from Zhao et al.9. Evaluating our approach to reproducing the original paper1, one of the strengths of our approach is that we ran all code on Google Colaboratory with one GPU, a free resource, in a reasonable amount of time. However, Google Colaboratory imposes GPU limitations and as a result, we could not use the same batch size as that in the original paper1, although we achieve higher F1 scores than those in the original paper1.
5.1 What was easy
When reproducing the original paper1, implementing counterfactual data augmenta‐ tion and bias controlled training and combining all three bias mitigation techniques was easy. Specifically, counterfactual data augmentation and bias controlled training were well‐described in the original paper1 and the list of counterfactuals needed for counterfactual data augmentation was provided by Dinan et al. in an easy‐to‐use for‐ mat. Combining all three bias mitigation techniques was also an easy part of reproduc‐ ing the original paper1, as we simply needed to apply the same techniques used when implementing each bias mitigation method individually.
5.2 What was difficult The only difficulty we encountered, albeit minor, was learning how to use ParlAI, which was necessary in order to use the same model as that in the original paper1. However, after reading through the ParlAI documentation and experimenting with the ParlAI Google Colaboratory tutorial4, we understood how to use ParlAI to fine‐tune the model, pre‐trained on Reddit conversations2, for the datasets we created.
ReScience C 8.2 (#13) – Eaton and Naghavi 2022 11
5.3 Recommendations for reproducibility
Overall, reproducing the original paper1 was fairly straightforward, butwe dohave three recommendations to further improve reproducibility. The first is more clearly indicat‐ ing what model, pre‐trained on Reddit conversations, is used, because the source of the model is not provided in the original paper1, only that the model is based on the implementation by Miller et al.3, who introduce ParlAI in that paper. The second rec‐ ommendation is to specify the hyperparameters used when fine‐tuning each model, as these were not provided in the original paper1. The last recommendation is to describe the stopping condition for fine‐tuning the models. We stopped training when perplex‐ ity stopped improving, but this resulted in higher F1 scores for the models than those achieved in the original paper1.
5.4 Communication with original authors
We communicatedwith Emily Dinan, one of the authors of the original paper1, who clar‐ ified what model, pre‐trained on Reddit conversations, was used in the original paper1 and provided us with the command to download the model as well as the hyperparam‐ eter settings for training the models."
"['Floor Eijkelboom', 'Mark Fokkema', 'Anna Lau', 'Luuk Verheijen']",[Re] Reproduction Study of Variational Fair Clustering,10.5281/zenodo.6574653,Replication,Python,https://zenodo.org/record/6574653/files/article.pdf,rescience c machine learning python pytorch clustering fairness,https://openreview.net/forum?id=rq8fRhMm20F,https://github.com/MarkiemarkF/FACT,8,2,2022,"Variational Fair Clustering (VFC) is a general variational fair clustering framework that is compatible with a large class of clustering algorithms, both prototype‐based and graph‐ based [1]. VFC is capable of handling large datasets and offers a mechanism that allows for a trade‐off between fairness and clustering quality. We run a series of experiments to evaluate the major claims made by the authors. Specifically, that VFC is on par with SOTA clustering objectives, that it is scalable, that it has a trade‐off control, and that it is compatible with both prototype‐based and graph‐based clustering algorithms.",,
"['Chase van de Geijn', 'Victor Kyriacou', 'Irene Papadopoulou', 'Vasiliki Vasileiou']",[Re] Explaining in Style: Training a GAN to explain a classifier in StyleSpace,10.5281/zenodo.6574655,Replication,Python,https://zenodo.org/record/6574655/files/article.pdf,rescience c machine learning deep learning python pytorch,https://openreview.net/forum?id=SK8gAhfX2AK,https://github.com/irenepap2/Re_StylEx.git,8,2,2022,"This work aims to reproduce Lang et al.’s StylEx [1] which proposes a novel approach to explain how a classifier makes its decision. They claim that StylEx creates a post‐hoc counterfactual explanation whose principal attributes correspond to properties that are intuitive to humans. The paper boasts a large range of real‐world practicality. However, StylEx proves difficult to reproduce due to its time complexity and holes in the informa‐ tion provided. This paper tries to fill in these holes by: i) re‐implementation of StylEx in a different framework, ii) creating a low resource training benchmark.","The notebook supplied by the authors loads their pre‐trained models and reproduces part of the results in the paper. Furthermore, their algorithm for discovering classifier‐
Copyright © 2022 C.V.D. Geijn et al., released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Chase van de Geijn (chase.vandegeijn@student.auc.nl) The authors have declared that no competing interests exist. Code is available at https://github.com/irenepap2/Re_StylEx.git – DOI 10.5281/zenodo.6508290. – SWH swh:1:dir:f0871f3a14e536717d3225180942c4a385ce39e3. Open peer review is available at https://openreview.net/forum?id=SK8gAhfX2AK.
None 8.2 (#15) – Geijn et al. 2022 1
related attributes, AttFind, is well outlined in their paper making the notebook easy to follow. Lastly, the authors were responsive to our inquiries.","A major difficulty was that the authors provide only a single pre‐trained model, which makes most of the main claims require training code to verify. Moreover, the paper leaves out information about their design choices and experimental setup. In addition, the authors do not provide an implementation of the models’ architecture or training. Finally, the practical audience is limited by the resource requirements.
Communication with original authors We had modest communication with the original author, Oran Lang. Our discussion was limited to inquiries about design choices not mentioned in the paper. They were able to clarify the encoder architecture and some of their experimental setup. However, their training code could not be made available due to internal dependencies.
None 8.2 (#15) – Geijn et al. 2022 2
1 Introduction
As the field of machine learning (ML) develops and its algorithms become more preva‐ lent in society, concerns on the explainability of black‐box models become pivotal. For problems that have a high societal impact, there is understandable apprehension to‐ wards trustingmodels that do not provide justification. For applications such asmedical imaging and autonomous driving, there is a need for some level of human supervision. Even if a model has high performance, such as neural networks, without the ability for human interpretation, its use will be limited. In order to gain trust in systems powered by ML models, the models need to be inter‐ pretable and explainable. The two concepts are regularly used interchangeably, yet have subtle differences. Interpretability is the degree to which humans can understand the cause of a decision [2]. Deep neural networks, such as classifiers are often perceived as “black boxes” whose decisions are opaque and hard for humans to understand. Ex‐ plaining the decision of classifiers can reveal model biases[3] and also provide support to downstream human decision‐makers. On the other hand, explainability is linked to the internal logic of a model. It focuses on explaining the data representation within that network. Explainability implies interpretability, however, the implication is not bidirectional. In recent years, there has been increasing attention to the field of explainability of deep network classifiers. Among the various ways of explanations, counterfactual explana‐ tions are gaining increasing attention [4, 5, 6]. To discover and visualize, the attributes used to generate counterfactual explanations, a natural candidate is generative models. In [7] they observed that StyleGAN2 [8], tends to contain a disentangled latent space (i.e., the “StyleSpace”) which can be used to extract individual attributes. The authors based their proposed methodology [1] on this observation. Though [9] propose a similar archi‐ tecture, Lang et al. assert that by integrating the classifier into the training of StylEx they can obtain principal attributes that are specific for the classification task. Additionally, they suggest that StylEx can be applied to a large variety of complex, real‐world tasks, which makes its replicability especially intriguing. Our work aims to reproduce the claims made by Lang et al. and confirm their results. Their paper reports in detail many experiments to justify their claims, but does not dive into their experimental setups for architecture and training. Since not all the informa‐ tion needed is available without contacting the authors, we argue that this paper cannot be considered fully reproducible. To remedy the holes in reproducibility and aid future work that builds on or applies StylEx, we build their proposed architecture and training algorithm, after correspon‐ dence with the authors.
2 Scope of reproducibility
To determine the scope of reproduction, we quote Lang et al.’s main claims:
Claim 1 [They] propose the StylEx model for classifier‐based training of a StyleGAN2, thus driving its StyleSpace to capture classifier‐specific attributes
Claim 2 A method to discover classifier‐related attributes in StyleSpace coordinates, and use these for counterfactual explanations.
Claim 3 StylEx is applicable for explaining a large variety of classifiers and real‐world com‐ plex domains. [They] show it provides explanations understood by human users.
To reproduce Claim 2, a trained model and the AttFind algorithm are sufficient; both of which are contained in the authors’ notebook. Claim 1 requires a network trained con‐ ditioned on a classifier and a network trained without, while Claim 3 requires multiple
None 8.2 (#15) – Geijn et al. 2022 3
networks trained on multiple domains. However, to train these models, the architec‐ ture and training code is necessary; which, as stated previously, are not open source or thoroughly documented. In addition, the computational cost to train the models is expensive. Thus, to verify these claims our goals will be to:
• Reconstruct their architecture and port the pre‐trained weights in PyTorch
• Evaluate whether the principal attributes we obtain correspond to the same fea‐ tures using their pre‐trained weights
• Retrain on datasets of smaller images and analyze the scalability of their method using fewer training steps and smaller architecture
• Conduct two user studies on visual coherence and distinctness to prove that at‐ tributes extracted are interpretable by humans
To ease reproduction for future work, we built the StylEx architecture into a different framework, to get a deeper understanding of the model, and become more equipped to tackle training. As an addition, this contribution allows StylEx to bemore accessible for classifiers trained in PyTorch.
3 Background
There have been many attempts to extract explanations from classifiers most of which utilize heatmaps of important features. However, heatmaps struggle to visualize fea‐ tures that are not spatially localized such as color or shape. Rather than identifying ar‐ eas of interest, one can provide an explanation through a ”what‐if” example where the features are slightly altered. These forms of justification have been found to be more in‐ terpretable for non‐localized features, and are known as counterfactual examples. How‐ ever, it often requires domain knowledge and handcrafting examples to be appropriate. Lang et al. automate this and utilize machine learning to generate realistic counterfac‐ tual examples. This section will outline how they claim to achieve this with their two major contributions, StylEx and AttFind.
3.1 StylEx ThewayLang et al. generate examples is through aneural generativemodel they dubbed StylEx. StylEx expands on thepopular generative adversarial network StyleGANv2, which generates realistic images by creating competition between two networks. One of these two networks, referred to as the Generator,G, attempts to generate a realis‐ tic image. To this end, the generator samples from a latent space, z ∈ Rn, with a simple probability distribution such as zi ∼ N (0, 1). The sampled vector is pushed through a series of linear layers called mapping network to create a new latent vector, w, with a more complex probability distribution. This vector is used as input to a number of StyleBlocks based on the logarithmic resolution of the image. StyleBlocks consist of an affine transform and an upsampling layer. The affine transform, Ar, maps w to yet another vector sr, where r denotes the block number or resolution of the block. This concate‐ nation of all sr is known as the style, or attribute, vector, and the space that it spans is known as the StyleSpace. The attribute space is emphasized due to recent observations that it is less entangled than the latent space. The second network is the discriminator, D. This network is trained to differentiate between fake and real images. This forces the generator to slowly improve its creation of fake images. In this way, the discriminator can be seen as an adaptive loss function. The flawwith the direct application of StyleGAN is that it generates froma random latent space. To explain a classification, we would like to condition it on a particular image of
None 8.2 (#15) – Geijn et al. 2022 4
interest, but StyleGAN has no mechanism for extracting the attributes of an image. To fix this, Lang et al. added a third, encoding network to StylEx, E. Rather than using a randomly sampled z and themapping network to obtainw, StylEx uses the output of the encoder, z = E(x), where x is an input image. StylEx adds an extra loss condition that the reconstructed image, x′ = G(E(x)), should be approximately x. Thus, the encoder combined with the affine transformations allows us to extract the attributes of an input image. StylEx is not unique in adding an encoder to the StyleGAN to explain a classifier. How‐ ever, other methods do not include the classifier in the training of the network. Style‐ GAN incorporates the classifier into training by appending its output to the encoded z vector. This results in another loss condition C(x) ≈ C(x′).
3.2 AttFind Once the attributes of an image have been extracted, a counterfactual explanation can be achieved from the attributes with the most affect on a classifier’s decision. Lang et al. propose attribute find (AttFind) to discover the most influential attributes. The al‐ gorithm adjusts all the attributes one at a time by a fixed amount d and observes their effect on the classification∆cs. The k attributes with the highest∆c create a local expla‐ nation for an image’s classification. To approximate a global explanation, the principal attributes are determined by the mean∆c across images in a set.
4 Reproduction approach
Reimplementing StylEx has been split into twomain tasks to ease resource requirements. The first task consists of rebuilding StylEx in a different framework; the second is train‐ ing the model from scratch. In this section, we discuss how we rebuilt the model archi‐ tecture and training process. Additionally, we include details obtained through corre‐ spondence missing from the original paper.
4.1 Model descriptions To test Claim 1 and Claim 3, at least two models are necessary. Because only one pre‐ trained model is available, a new model needs to be trained. However, this is compu‐ tationally expensive as it builds on StyleGAN 1. This led us to evaluate reproducibility in two ways. Firstly, we recreate their architecture in PyTorch, using their pre‐trained weights to bypass the training limitation. Secondly, we attempt to train a model from scratch using less complex datasets with smaller resolutions to verify claims requiring multiple models. In the following sections, we explain how we reconstruct the StylEx architecture and training process.
Rebuilding StylEx — The author’s notebook includes a TensorFlow StylEx pre‐trained on the FFHQ[10] dataset to find the attributes most influential in age classification. Taking advantage of the pre‐trained model’s raw parameters, we reverse engineer the architecture of each component of StylEx and implement it in PyTorch. Subsequently, the pre‐trained weights are transferred into the reconstructed StylEx to confirm the cor‐ rect implementation of the structure. Transferring the pre‐trained parameters from a TensorFlow model to a PyTorch model turned out to be challenging and non‐trivial. We start by building the architecture of the MobileNetV1 [11] classifier, as described in the summary of their model, in both TensorFlow and PyTorch. We follow this ap‐ proach so that we can compare how the results of each layer differ, depending on the framework. We notice that for the 2D convolutional layers PyTorch and TensorFlow pad
1StyleGAN can take on the order of 40 days on one GPU for high resolutions [10]
None 8.2 (#15) – Geijn et al. 2022 5
the images differently, leading to different results. To address this, we add a Constant‐ Pad2D layer in our PyTorch architecture before each convolution with a stride of 2. In addition, we change the default hyperparameters of PyTorch’s BatchNorm2D to match the corresponding TensorFlow defaults. The next step is to follow the same procedure for the encoder and the StyleGAN com‐ ponents. We use the official StyleGAN2 implementation in PyTorch by NVlabs[8] and modify the initial architecture to align with the StylEx model. In particular, instead of only using the encoding of an image X as input to the generator, we also concatenate the classifier’s output logits. Additionally, their generator returns the StyleSpace which contains classifier‐specific attributes. For the encoder, we use the same architecture as StyleGAN2’s discriminator. Finally, we transfer the pre‐trained weights, to our compo‐ nents. The last step is to load the rebuilt StylExmodel in the provided notebook to confirm that the conversion of the models is successful and reproduce the results provided in the notebook.
Training the model — Lang et al. asserted that StylEx works for a wide range of classifiers and datasets. The results they show in their paper are all with high‐resolution images. The high resolution comes with a high computational cost as StylEx is built on top of a StyleGAN. High‐resolution StyleGANs can take over amonth to train on a single GPU sys‐ tem. To tackle this, we train our model on a low‐resolution MNIST dataset. In this way, we investigate whether their model works well on low‐resolution datasets and relieve computational requirements. The training is as outlined in their paper. The loss function for the StylEx model is bro‐ ken into seven parts: Lx, Lw, LLPIPS, Ladv, LPLR, LKL, and the LGP . Lx is the L1 loss between the real image, x, and the reconstruction of that image, G(E(x)). LLPIPS is the Learned Perceptual Image Patch Similarity (LPIPS) of the two images. This loss is a metric other than raw pixel value error for the similarity between two images. Lw is the L1 loss between the encoding of the original image, w = E(x), and the encoding of the reconstructed image w′ = E(G(E(x))). Collectively, these three losses make up the reconstruction loss, Lrec, ie,
Lrec = Lw + Lx + LLPIPS .
In the implementation, each loss term in Lrec had a weighting coefficient to even out the magnitude of their contributions. The weights are detailed further in Section 5.2. LKL is the KL divergence loss between the classification probabilities of the original image and its reconstructed classification probabilities. LGP and LPLR are the gradient penalty and path length regularization losses described in the WGAN‐GP[12] and Style‐ GAN2 paper[8] respectively. Ladv is the Wasserstein adversarial generator loss of x′. Fi‐ nally, the discriminator’s loss is the Wasserstein adversarial discriminator loss.
5 Experimental setup
5.1 Datasets The pre‐trainedmodels the authors offer are trained on the Flickr‐Faces‐HQDataset [10] 2. The dataset contains 70,000 high‐quality PNG images at 1024×1024 resolution with large variations in terms of age, ethnicity, and image background. They use it to find the top attributes which contribute to perceiving a person’s age (young or old) or gender (male or female). They also preprocess the images by lowering the resolution to 256x256. The official dataset is unlabeled. It is not clearwhether the authors’ dataset is an internal, labeled Google version or an unofficially labeled dataset.
2https://github.com/NVlabs/ffhq‐dataset
None 8.2 (#15) – Geijn et al. 2022 6
For training, the MNIST [13] dataset is used due to its simplicity. Only the examples with labels 8 or 9 are kept and the resolution is increased to 32x32. MNIST was chosen because images compressed to 16x16 or even 8x8 tend to be recognizable for humans. Unfortunately, LPIPS relies on neural networks that have a fixed number of pooling lay‐ ers. Without editing reimplementation of LPIPS, the lowest resolution possible is 32.
5.2 Hyperparameters A complete list of hyperparameters can be found in Table 2 (see Appendix 10). A hyper‐ parameter search was not performed for two reasons. First, the training time is long – even for very low resolutions, this is constraining. Second, the criteria for evaluating success is based on a human user, making automated hyperparameter tuning unintu‐ itive.
5.3 Computational requirements Most of our experiments were conducted on Google Colab along with our systems. For training our models we use Colab’s NVIDIA Tesla K80 GPU. Our code is provided in the following GitHub repository: MLRC_2021_FALL‐E358. Thebasic architecture of the StyleGAN2was adapted fromNVlabs’ GitHub repository. As previouslymentioned, wemodify the basic architecture, to align with StylEx’s generator and load Lang et al.’s pre‐trained weights. The training code was adapted from labml.ai Annotated Paper Implementations’ StyleGAN implementation. Training the model on MNIST for 50,000 iterations takes on the order of nine hours to train on Colab. The time required for AttFind is dependent on the resolution, latent dimension, and the number of images in the dataset. Finding the attribute of a single image took approximately oneminute for an imagewith resolution 32 and a latent space of 514.
6 Results
6.1 Rebuilding StylEx results To support Claim 1, we recreate their pre‐trained models to PyTorch and test if our re‐ sults agree. In Figure 3 (seeAppendix 8), we compare the results fromour PyTorch StylEx to their TensorFlow implementation. There are minor differences in the probabilities from the PyTorch classifier which are likely caused by differences in default values or module implementations in the two frameworks.
6.2 AttFind results We are now equipped to test our PyTorchmodels on the AttFindmethod and inspect the principal attributes of the age classifier; meaning the attributes with the highest contri‐ bution to young or old classification. To this end, we compute the AttFind algorithm – with our classifier and generator as inputs – using the 250 latent variables of the FFHQ dataset. As can be seen in Figures 1 and 5 (see Appendix 9), our model obtains the same attributes as in the original paper. In addition, we implement the Independent selection strategy, to generate image‐specific explanations as described in the original paper. This method is a local explanation that returns the top‐k attributes affecting a classifier’s decision for a single image rather than the entire dataset. The results are shown in Figure 2. These results support the author’s Claim 2, that AttFind discovers significant attributes for a classifier’s decision. Notably, in 1c the reported probability of the top left image is
None 8.2 (#15) – Geijn et al. 2022 7
17% in the paper, while the probability we find with our and their notebook classifier is 39%.
Theirs Ours
Perceived Gender 0.96(±0.047) 0.94(±0.031) Perceived Age 0.983(±0.037) 0.978(±0.025)
Table 1 shows that the results we obtain are within a standard deviation of their results; verifying their contribution that StylEx provides attributes that are easily distinguish‐ able by humans. Table 3 depicts the three most common words used, to describe the most prominent attribute that changes in the images (see Appendix 12). By inspecting the results, we draw two main conclusions. First, for all coordinates except skin color (i.e. 5th row in Face(age/gender) classifiers), the majority of the users use the same word in their descriptions. Second, the most common word used is different per attribute, proving that each attribute is unique. Our results agree with the results provided in the original paper.
6.4 Reconstruction Generalization To further investigate the proposed model, we create new latent variables using images from theFFHQdataset on our architectureswith their pre‐trainedweights. Then, weuse the obtained latent variables to reconstruct the images using our pre‐trained generator. Finally, we follow the same process using their architecture and compare the resulting images. Our StylEx reconstructs a clearer image, compared to theirmodelwhich ismore blurred. This may occur because of some differences in the formatting between the frameworks.
6.5 Training The training proved quite volatile. The Lrec would get stuck in local minima during training. Examples of the images reconstructed by the fully trainedmodel (seeAppendix 11). Lang et al. experimented with two training regimens. The first regimen was trained us‐ ing onlyE(x) as w, the inputs to the generator, and the above loss. The second regimen alternated between usingE(x) and a randomly generated encoding, w̄. This w̄ is created by applying a mapping network to z, where z ∼ N (0n, 1n) and n is the dimensionality of w. For this randomly generated x̄′ = G(w̄), only the adversarial loss is calculated. Training using w̄ can be viewed as the same as training a vanilla StyleGAN. Because we are unsure which method was used for the results in their paper and notebook, we experimented with both. However, the first regimen was the only one that converged. Though we were able to train a model, due to time constraints, we were unable to fully investigate Claim 1. Again due to time constraints, we were unable to run AttFind on the trained model to fully test Claim 3.
7 Discussion
Using the definition of reproducibility3 by the U.S. National Science Foundation (NSF) subcommittee on replicability in science, it is difficult to determine Lang et al.’s repro‐ ducibility. All details regarding the experimental setup, such as the hyperparameters, the hours of training, the number of steps, the labels of the datasets, etc. are omitted, thus recreating the exactmaterials of the original investigators is difficult. Since our def‐ inition is an implication and we cannot satisfy the first condition, we cannot determine the reproducibility. Instead, wewill use a looser definition of reproducibility. Wewill refer to reproducibility as the ability for another researcher to test their claims. We found that, given enough time, the StylEx is seemingly reproducible. However, given a limited time budget such
3“reproducibility refers to the ability of a researcher to duplicate the results of a prior study using the same materials as were used by the original investigator”
None 8.2 (#15) – Geijn et al. 2022 9
as our own, the paper is not fully reproducible. We, therefore, can only provide unit tests of their claims. The following sections will discuss information from the results section 6 and to what degree they confirm reproducibility claim by claim.
7.1 Claim 1 The most difficult claim to investigate, given a limited time budget, is the effect of classifier‐based training on the StyleSpace. The original paper trains three models, the StylEx with and without integration of the classifier in training and the StyleGAN v2. We found, once the training algorithm is implemented correctly, just training all threemod‐ els will take at least 24 hours for 50,000 epochs on one GPU even for the simple MNIST dataset. The authors stated that it took approximately a week to train StylEx with 8GPUs. Over two weeks of training time is beyond our time constraints. In addition, we observed that training is volatile.4 The reconstruction error stagnates in a local minimum before suddenly dipping. However, the model was not always able to escape the local minima within 50,000 iterations. This suggests that, though their results are likely replicable, their replicability may be stochastic. This again hinders reproducibility when time is limited.
7.2 Claim 2 The claim that the authors document the most was Claim 2, their AttFind method. Be‐ cause the method was implemented in the notebook provided, testing reproducibility was easy. We were able to verify that for the perceived age classifier, our model obtains the same top attributes. Weconclude that theirmethod candiscover themost influential classifier‐ related attributes. In addition to their notebook, we modified the AttFind method to find the principal attributes of a single image as shown in Figure 2. This validated the sub‐claim of AttFind that StylEx can provide image‐specific explanations. Rather than finding the globally important attributes, the model can find the locally important attributes for a particular image.
7.3 Claim 3 The authors claim that StylEx is applicable to a variety of real‐world problems. Applica‐ bility can be interpreted in two different ways. One can interpret it as being possible to apply StylEx to a variety of domains, or as practical to apply StylEx to a variety of domains. From what we have seen in Figures 1, 2, it is possible to use StylEx for explaining an age classifier, thus it can explain a real‐world problem. From Figure 6 (see Appendix 11), we found that the StylEx can be trained to, at minimum, reconstruct MNIST data, thus multiple domains. Though we have found that it is possible, we have also found that it is seemingly imprac‐ tical. Every domain requires the model to be retrained, meaning every domain requires days or weeks of training.
7.4 What was easy The open‐source notebook is very well structured, which combined with the pseudo‐ code outlined in Algorithm 1 of their paper, made the AttFind method easy to replicate. In addition, the provided pre‐trained models helped to derive some of the vague com‐ ponents of StylEx model.
4An example of successful training can be found here and one where the model failed to converge here
None 8.2 (#15) – Geijn et al. 2022 10
7.5 What was difficult As we already emphasized, there are many difficulties in reproducing this paper. StylEx is built on top of several previous papers making the knowledge needed for implemen‐ tation substantial. Lang et al. proposed a model without providing code, that is compu‐ tationally expensive, and with volatile training behavior. In addition, that is sensitive to hyperparameters, which in our case were unknown. Even when scaling down the com‐ plexity of the model using smaller resolutions, the time cost of training exceeds what was feasible with our time constraints. Taking shortcuts to subvert these difficulties had a multitude of challenges. We found loading weights from TensorFlow to PyTorch deceptively complex and far from trivial due to differences between the frameworks. Even evaluating their notebook came with difficulties as the dataset they trained on FFHQ does not officially have labels, so the details of their dataset were unknown.
7.6 Future Work Theprimary goal of this paperwas to reproduce thework of Lang et al., however, through reimplementing their code, we found two open avenues for future research. Firstly, the paper focused on general image explanations but did not show examples of misclassi‐ fied data. It would be interesting to see what insights can be obtained through StylEx. Secondly, the paper compared StylEx only with StyleGAN v2 models. AttFind seems applicable to general autoencoders, and not specific to GANs. Viewing StylEx as an au‐ toencoder, rather than a GAN seems like a promising angle for scalability to a similar counterfactual generator."
['Ian Hardy'],[Re] An Implementation of Fair Robust Learning,10.5281/zenodo.6574657,Replication,Python,https://zenodo.org/record/6574657/files/article.pdf,rescience c machine learning deep learning python pytorch adversarial training fairness robustness,https://openreview.net/forum?id=Sczshz7h0K,https://github.com/Ian-Hardy/Fair_Robust_Modeling,8,2,2022,"In the spirit of education and public accessibility, this work attempts to replicate the re‐ sults of the paper from first principles using Google Colab resources. To account for the limitations imposed by Colab, a much smaller model and dataset are used. All results can be replicated in approximately 10 GPU hours, within the usual timeout window of an active Colab session. Serialization is also built into the example notebooks in the case of crashes to prevent too much loss, and serialized models are also included in the repository to allow others to explore the results without having to run hours of code.","It was easy to identify the unfairness resulting from existing adversarial training meth‐ ods and implement the authors’ FRL (reweight) and FRL (remargin) approaches for com‐
Copyright © 2022 I. Hardy, released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Ian Hardy (ihardy@ucsc.edu) The authors have declared that no competing interests exist. Code is available at https://github.com/Ian-Hardy/Fair_Robust_Modeling – DOI 10.5281/zenodo.6506696. – SWH swh:1:dir:bd6142ce2ce3fd99fab9918a6c6754115035abe4. Open peer review is available at https://openreview.net/forum?id=Sczshz7h0K.
ReScience C 8.2 (#16) – Hardy 2022 1
bating this bias. The algorithm and training approaches are well outlined in the original paper, and are relatively accessible even for those with little experience in adversarial training.","Because of the resource limitations imposed, I was unable to successfully implement the suggested training process using the authors’ specific model and dataset. Also, even with a smallermodel and dataset it was difficult to thoroughly tune the hyperparameters of the model and algorithm.
Communication with original authors I did not have contactwith the authors during theprocess of this reproduction. I reached out for feedback once I had a draft of the report, but did not hear back.
ReScience C 8.2 (#16) – Hardy 2022 2
1 Introduction
The advent of adversarial examples [1][2] has motivated the need for procedures which decrease the sensitivity to noise of learned models (which I will call adversarial robust‐ ness or simply robustness.) Once such method is adversarial training [3][4], in which adversarial examples are generated during the training process and are mixed in with ”clean” examples to create mixed training batches of both manipulated and unmanipu‐ lated images. Learning on these batches has been shown to improve the robustness of models to adversarial attacks, often at a slight cost to standard performance (accuracy.) To be Robust or to be Fair: Towards Fairness in Adversarial Training [5] identifies that adversarial training creates unfairness in the resulting robust model. While the overall robustness of the model improves, some classes in the resulting model are more robust to adversarial attacks than others. Not only are the robustness benefits unfairly dis‐ tributed, so too are the standard performance losses; the classes which are less robust at the end of the procedure tend to be the ones which suffer more in terms of standard performance. Moreover, these classes tend to be the ones which were harder to learn before adversarial training. As Xu et al. describe it: ”adversarial training tends to make the hard classes even harder to be classified or robustly classified.” Motivated by this unfairness, Xu et al. conduct a theoretical analysis of the problem to explain this empirically observed phenomenon. They then draw on [6] to describe ro‐ bust error in terms of the sum of standard errors (i.e. the probability that a class will be incorrectly classified without manipulation) and boundary errors (i.e. the probability that there exists some ϵ‐ball attack which can change a classifier’s decision on a given class.) Using this description, they reformulate the learning problem into a series of cost‐ sensitive classification problems that can be penalized for violating fairness constraints. With this reformulation, they present two FRL algorithms for making adversarial train‐ ing more fair: one which upweights the error of classes which violate the fairness con‐ straints during training, and one which increases the attack radius for classes which violate fairness constraints during training.
2 Scope of reproducibility
The focus of this reproduction will be attempting to demonstrate the following:
• Claim 1, which is supported by Experiment 1 in Figure 1, is that adversarial train‐ ing creates unfair outcomes in terms of both robustness and standard error.
• Claim2, which is also supported byExperiment 1 in Figure 1, is that this unfairness exacerbates existing biases in model performance.
• Claim 3, which is supported by Experiment 2 in Figure 2, is that upweighting the er‐ ror of classes which violates fairness constraints (using the authors’ FRL: reweight algorithm) can improve the both the standard errors for the most poorly perform‐ ing classes, and to a lesser degree their robustness.
• Claim 4, which is explored by Experiment 3 in Figure 3, is that increasing the mar‐ gin of attack for classes which violates fairness constraints (using the authors’ FRL: remargin algorithm) can also improve the fairness of the model– perhaps more ef‐ fectively than reweighting.
3 Methodology
As an educational exercise, I aimed to re‐implement the authors’ training approaches from their descriptions in the paper. Because of the limitation imposed on the resources, however, I opted to use a simpler model and dataset in my experiments.
ReScience C 8.2 (#16) – Hardy 2022 3
3.1 Model descriptions The paper used the PreAct‐ResNet18 and WRN28 architectures for their experimenta‐ tion; I opted for the LeNet‐5 architecture in the interest of efficiency. Though it is a much simpler model than the paper’s originals, it provided enough complexity to con‐ duct my experiments.
3.2 Datasets The paper used the CIFAR10 and SVHN datasets for their experimentation; I used the Fashion‐MNISTdataset. The train set is comprised of 60,000 examples, the test set 10,000. Both have a uniform label distribution across all 10 classes. The original train and test sets are used Experiment 1, while Experiments 2 and 3 split the train set into an 80/20 train/validation set for the FRL process. The only preprocessing done was to resize the images from 28x28 to 32x32. The data is freely available here.
3.3 Hyperparameters The fairness tolerance hyperparameter was selected based on the recommendations in the paper (5%), as was the baseline ϵ (8/255 for the PGD attack.) For Experiment 1 I used a learning rate of 1e‐3 for regular training and adversarial training, as the paper recommended. Due to resource constraints I had to limit the number of epochs I trained for to 15, and from convergence behavior I decayed the learning rate more often than the original paper (every 4 rounds by a factor of 3, as opposed to every 40 rounds by a factor of 10.) For the simpler model and dataset, this worked well. For Experiments 2 and 3 I used a baseline learning rate of 1e‐4, which I selected based on unstable behavior at a rate of 1e‐3. I suspect this is due to differences in the model and dataset used, as well as the way I implemented the reweighting and remargining systems. I utilized the results of the fairness evaluation (ϕ values) in the training process by ap‐ plying a Softmax function to creating cross‐entropy loss weightings, and as such the α valueswere different than the original paper’s. I tried a variety ofα values in the space of (1, 2, 5, 10,) and a variety of ratios of natural‐αs to boundary‐αs. The best results came from a ratio of 5:1 natural:boundary error weighting, which decreased the worst‐case standard error by 25%, and the worst case robust error by 11%.
3.4 Experimental setup and code For Experiment 1, I defined the LeNet‐5 architecture and trained a classifier on the Fashion‐MNIST dataset for 15 epochs at a learning rate of 1e‐3. I then adversarially trained a new LeNet‐5 model using a PDG attack for the same number of epochs at the same learning rate, with a 50/50 mixture of clean and manipulated images. I then com‐ pared the classwise standard accuracy (i.e. ability to predict a ”clean” image correctly) and robust accuracy (i.e. ability to predict a image correctly despite manipulation) of the natural model and adversarially trained model. The results are recorded in Figure 1. For Experiments 2, I retrained the unfair adversarially‐trained model under the FRL (reweight) paradigm. During this procedure, I recorded the overall and classwise stan‐ dard and boundary errors of the model during each batch, and based on these errors I re‐calculated loss weights for each class. The loss function used was the sum of the standard loss and the loss for adversarially manipulated images with respect to the pre‐ dictions on their unmanipulated counterparts (corresponding to standard error and boundary error, respectively.) Classes were penalized based on violations of fairness constraints, i.e. how greatly they differed from the average standard and boundary er‐ rors for all classes. I ran 10 rounds of retraining, and then compared the original unfair
ReScience C 8.2 (#16) – Hardy 2022 4
adversarially trained model with its retrained counterpart, comparing classwise stan‐ dard and robust accuracy. These results can be found in Figure 2. Experiment 3 was much the same as Experiment 2, the only difference being that in‐ stead of simply upweighting the loss of classes which violated fairness constraints, the radius of a class’ attack during training was increased or decreased based on the size of their violation. Again, I ran 10 rounds of retraining, and then compared the original unfair adversarially trained model with its retrained counterpart, comparing classwise standard and robust accuracy. These results can be found in Figure 3. All the code for these experiments, as well as example notebooks that walk through the procedure, can be found here.
3.5 Computational requirements As mentioned, I used Google Colab for all of the experimentation. As such, it is difficult to describe the exact hardware that was used, or to even be confident of the consistency of the hardware throughout this process. I did use GPU resources, though I cannot speak to any specific type. Experiment 1 can be run in approximately 15minutes of GPU time. Experiment 2 can be run in approximately 5 hours of GPU time (for all alpha‐combinations) and Experiment 3 can be run in approximately 3 hours. All three notebooks can sometimes be run in parallel, but not always. Colab can be a bit unpredictable.
4 Results
In my experiments, I found that:
• Adversarial training does in fact lead to classwise discrepancies in standard error and adversarial robustness, that the least robust classes in the resulting model are the ones the model originally had a hard time learning, and that the penalties to standard performance brought on by adversarial training exacerbate existing biases in model performance.
• Reweighting the natural and boundary errors to penalize classes violating fairness constraints during adversarial retraining can improve the fairness of the model with respect to standard error, and to a lesser degree robust error.
• Remargining the attack radius for classes violating fairness constraints during ad‐ versarial retraining can also improve the fairness (i.e. lower the variance across classes) of the model’s robustness (at a cost to robust performance) as well as im‐ prove the standard error.
Most of these results agree with the paper’s conclusions, although the results in Experi‐ ment 3 differ in that Iwas not able to improve the robustness of themodelwith remargin‐ ing as well as I could with reweighting. The original paper showed the opposite: that reweighting was unable to improve robustness for the most poorly performing classes. One experiment I did not conduct was to try both reweighting and remargining together, which the authors suggest might be fruitful. I leave that as a further exercise.
4.1 Results reproducing original paper
Result 1 — The result of Experiment 1 (shown in Figure 1) relates to claims 1 and 2 in Section 2. I found that in the naturally trained model, the standard error is quite low and the adversarial error (PGD error) is quite high. The adversarial error is not quite as
ReScience C 8.2 (#16) – Hardy 2022 5
uniform as in the original paper, I suspect because of the simplicity of the dataset and model I used. Still it is observable that after adversarial training, themodel’s adversarial error is much lower across the board, but not in a fair way. Certain classes are much more robust to attack than others, and in particular the classes which had poorer initial standard performance are the ones with worse adversarial robustness. Moreover, we can see that there are penalties to standard performance incurred as a result of adversarial training, and the classes which suffer the most are the ones the natural model already had a hard time learning. Indeed, as Xu et al. put it, ”adversarial training tends to make the hard classes even harder to be classified or robustly classified.” This is exactly what I found, even with a totally different model and dataset.
Result 2 — The result of Experiment 2 (shown in Figure 2) relates to claim 3 in Section 2. Here we can see the result of my best attempt at reweighting the loss of classes during adversarial retraining based on their violation of fairness constraints. As per the paper’s FRL retraining algorithm, I began with an adversarially trained model and iteratively tried to retrain it, adjusting the loss of each class as I went depending on whether it violated fairness, and to what degree. As such, I compared the ”vanilla” adversarially trained model with the resulting model after retraining. I observed that for the hardest class to classify, there is a 25% reduction in standard error (bringing it nearly in line with the naturally trained model) and an 11% reduction in robust error. This is not totally free; we can observe, for example, that the standard and robust error for some of the easier classes suffers as a result. Still, the resulting model is fairer than it originally was. These results seem relatively in‐line with the original paper’s, though again because of the different model and dataset selected it is hard to quantify the exact similarity. The overall conclusion is much the same though: reweighting is hugely successful in de‐ creasing the classwise standard error discrepancies brought on by adversarial training, and to a lesser degree in decreasing classwise robustness discrepancies.
Result 3 — The result of Experiment 3 (shown in Figure 3) relates to claim 4 in Section 2. This is the result of my best attempt at remargining during the retraining procedure. I observed a slight improvement in the worst‐case standard error, but little to no im‐ provement in theworst case robustness, and indeed a general degradation in robustness across most classes.
ReScience C 8.2 (#16) – Hardy 2022 6
These results were not in line with the paper’s, which found FRL (Remargin) to be more effective than FRL (Reweight.) Thismay be due to differences in our datasets, or artifacts of my implementation. It should be noted that because of the greater expense of this procedure, it was harder to thoroughly explore its hyperpaprameters, and this is still an interesting area of exploration for me.
5 Discussion
I believe that overall my results are quite in line with the original paper’s. I found that adversarial training does produce unfair results, both in the improvements to robust‐ ness the model receives as well as the degradation of standard error it experiences. I also found that these unequal costs penalize classes that are harder for the model to learn, making it worse at what classifying what it already had trouble with. Finally, I found that the FRL (reweight) approach was able to mitigate most of the degradation in standard performance for the hardest to learn classes, and to a lesser degree improve the robustness for that class as well as well as the overall robustness. One weak point of my implementation was in the FRL (Remargin) procedure. I was unable to successfully improve the model’s robustness via remargining, though I am not confident that I thoroughly explored the space. It was the most costly procedure I ran, and it ran into its fair share of Colab timeouts, making hyperparameter tuning
ReScience C 8.2 (#16) – Hardy 2022 7
tricky. One last experiment I did not have time for was a combination of reweighting and re‐ margining, which Xu et al. suggest is the most effective means increasing adversarial fairness. This is because I wanted positive results in remargining before attempting to combine the two approaches, which I was unfortunately unable to achieve. This is still an open question to pursue.
5.1 What was easy One of the paper’s easiest claims to verify was that adversarial training creates the unfair outcomes described above. Evenwith little experience in adversarial training, we found that with only a bit of effort I could observe this phenomenon myself. It was also fairly easy to implement Xu et al’s FRL algorithms; the remargining and reweighting procedures are very clearly explained in the paper andwere straightforward to put into code. One aspect of the paper not discussed in this report is their theoretical analysis, which was also very clear and helped motivate and explain the FRL problem formulation.
5.2 What was difficult As mentioned above, the part I had the most difficulty with was the remargining proce‐ dure. It took much longer than anticipated, and its expense made automated hyperpa‐ rameter searches difficult. Because I was unsuccessful in improving the model’s robust‐ ness with remargining, I was also hesitant to implement a combined FRL (Reweight) and FRL (Remargin) approach, which the authors suggest might be the most effective result. As mentioned, this is an area in which I am still actively exploring. Hopefully in the future I can replicate their success there too.
5.3 Communication with original authors As mentioned in my summary, I did not have contact with the authors throughout this process. It was only upon drafting my report that I learned it was encouraged to contact the original authors; in the future, I think it would be a great idea to communicate with them sooner. I reached out with a preprint of the report for any feedback or suggestions, but did not hear back."
"['Tobias Höppe', 'Agnieszka Miszkurka', 'Dennis Bogatov Wilkman']",[Re] Understanding Self-Supervised Learning Dynamics without Contrastive Pairs,10.5281/zenodo.6574659,Replication,Python,https://zenodo.org/record/6574659/files/article.pdf,rescience c machine learning deep learning python pytorch,https://openreview.net/forum?id=r4xe3nMQ3AY,https://github.com/miszkur/SelfSupervisedLearning,8,2,2022,"Weshow that the theoretical assumption regarding eigenspace alignment and symmetry hold also for a different dataset other than the oneused in the original paper. In addition, we reproduce ablations regarding learning rate, weight decay and Exponential Moving Average. Since we used CIFAR‐10 in all experiments we can not directly compare accuracies. However, we show the same relative behaviour of different networks given hyperparam‐ eter changes. We can directly compare performance for one of the experiments (Table 8. in [1] bottom left part). Our models, namely SGD Baseline, DirectPred (with and without frequency=5), achieve comparable accuracy which differ by at most 1%. We also con‐ firm the claim thatDirectPred outperforms its one‐layer SGDalternative. Our code canbe accessedunder the following link: https://anonymous.4open.science/r/SelfSupervisedLearning-FD0F.","The architecture of the Siamese network and training schemes were both straightfor‐ ward to implement and easy to understand.
Copyright © 2022 T. Höppe, A. Miszkurka and D.B. Wilkman, released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Dennis Bogatov Wilkman (dwilkman@kth.se) The authors have declared that no competing interests exist. Code is available at https://github.com/miszkur/SelfSupervisedLearning – DOI 10.5281/zenodo.6508184. – SWH swh:1:dir:ec5169f4713c6c67088d980c76f1c25bc1c399bc. Data is available at https://www.cs.toronto.edu/~kriz/cifar.html. Open peer review is available at https://openreview.net/forum?id=r4xe3nMQ3AY.
ReScience C 8.2 (#17) – Höppe, Miszkurka and Wilkman 2022 1","We could not run our code on STL‐10 dataset due to time and resource constraints. Due to differences between PyTorch and TensorFlow libraries, we had to implement some parts by hand to keep our code as close to the original work as possible. Also, original repository is not easy to read and does not cover all the experiments (e.g. eigenspace alignment experiment). Correctly applying data‐augmentation was also a hard task due to assumptions of how the individual data augmentations functions actually work.
Communication with original authors We did not contact authors of the paper since we did not encounter any major issues during the reproducibility study.
ReScience C 8.2 (#17) – Höppe, Miszkurka and Wilkman 2022 2
1 Introduction
Self‐Supervised learning has become an important task in many domains, since labeled data is often rare and expensive to get. Many modern methods of Self‐Supervised learn‐ ing are based on Siamese‐networks [4] which areweight sharingNeural networks for two or more inputs which representations then will be compared in latent space. The rep‐ resentation created by this approach can then be used for classification by fine‐tuning on fewer labelled data‐points. Traditionally, during pre‐training positive pairs (same image, or two images from the same class) and negative pairs (different images or two images from a different class) are used. The distance of the representation of positive pairs is minimized while the distance of the representation of negative pairs is maxi‐ mized, which prevents the networks from collapse (i.e mapping all inputs to the same representation). These methods have shown quite some success in the past [5], [6], [7], [8]. However, these methods rely on negative pairs, and large batch sizes which makes the training less feasible. Recently, new methods have been proposed which rely only on positive pairs and yet don’t collapse [2], [3]. In the paper ”Understanding Self‐Supervised Learning Dynamics without Contrastive Pairs” by Tian et.al. [1] the underlying dynamics are explored and based on the theoretical results, a new method, DirectPred, was proposed which does not need an update of the predictor via gradient descent but instead is set directly each iteration. The focus of this work is to test several assumptionsmade in [1] for the theoretical analy‐ sis and see if they hold. For this, wewill concentrate especially on the eigenvalues of the predictor network and the eigenspace alignment with its input. Also, we will reproduce the results from [1], [2] and [3] on CIFAR‐10 to compare their learned representation using linear probing.
2 Related work
A common approach to representation learning without Siamese networks is genera‐ tive modelling. Typically these methods model a distribution over the data and a la‐ tent space, fromwhich then embeddings can be drawn as data representations. Usually these approaches rely on Auto‐encoding [9, 10] or Adversarial networks [11, 12]. How‐ ever, generative models are often computationaly heavy and hard to train. Discriminativemethods using Siamese networks like SimCLR [5, 6] andMoco [7] outper‐ form generative models and have lower computational cost. However, these methods rely on very large batch sizes since they use contrastive pairs. Most recent methods, replicated in this work, like BYOL [2] and SimSiam [3], only rely on positive pairs and therefore can make use of smaller batch sizes. To understand why these methods do not collapse, the dynamics of these networks are analysed with linear models in [1, 13]. From this analysis, the authors could derive ablations of BYOLwhere part of the network is directly set to its optimal solution instead of being trained by gradient descent.
3 Method
In this section we will describe the methods of BYOL and SimSiam as well as their suc‐ cessor DirectPred.
3.1 BYOL & SimSiam The network architecture of the models is shown in Figure 1. First, two augmented viewsX ′1 andX ′2 of an imageX are created and fed into the online networkW and target
ReScience C 8.2 (#17) – Höppe, Miszkurka and Wilkman 2022 3
network Wa respectively. Both of these networks have the same architecture, a ResNet‐ 18 (W xenc) as encoder [14], which is supposed to create hidden features and a projector headW xpro, which is a two layerMLP, with purpose tomap the feature space into a lower dimensional hidden space. The online network also has an additional predictor head, again consisting of a two layer MLP. The target network has a StopGrad function instead of a predictor head. Therefore during back propagation, only the weights of the online network are updated via gradient decent. The loss between the output of the online and target network is equal to the cosine‐similarity loss function.
L(Ẑ(O)1 , Ẑ (T ) 2 ) = − ⟨Z ′1, Z ′2⟩ ||Z ′1||2||Z ′2||2
(1)
Note, that the final loss of one image is the symmetric lossL(Ẑ(O)1 , Ẑ (T ) 2 )+L(Ẑ (O) 2 , Ẑ (T ) 1 ), since each augmentation is given to both networks. As mentioned, the target network is not updated with gradient descent, but with an exponential moving average (EMA). After each batch the target network will be set to Wa = Wa + (1 − τ)(W − Wa). In SimSiam the target network is set directly to the online network after each update, i.e τ = 0.
3.2 DirectPred [1] derives a one layer predictor head analytically with the analysis of the underlying learning dynamics of the models presented in Section 3.1 with an approximation of the actual network as a purely linear model. The learning dynamics of the networks are
Ẇp = αp(−WpW (X +X ′) +WaX)W⊤ − ηWp (2) Ẇ = WTp (−WpW (X +X ′) +WaX)− ηW (3) Ẇa = β(−Wa +W ) (4)
With X = E[x̂x̂⊤], where x̂ is the average augmented view of a datapoint and X ′ is the covariance matrix of the augmented views. αp and β are multiplicative learning rate ratios, i.e αp = αpred α and β = 1−τ α (here α and αpred are the learning rates forW andWp respetively). In addition to the linearity of the network, three simplifying assumptions where made:
• The target network is always in a linear relationship with the online network (e.g. Wa(t) = τ(t)W (t)
ReScience C 8.2 (#17) – Höppe, Miszkurka and Wilkman 2022 4
• The original data distribution p(X) is Isotropic and its augmentation p̂(X ′|X) has meanX and covariance σI
• The predictorWp is symmetric
Based on these assumptions, one can show, that the eigenspaces of the output of the online network and the predictor Wp align. Let F = WXW⊤ (i.e. the output of the on‐ line network when it is approximated as a linear model), then it follows with the three assumptions, that the eigenspaces of these two matrices align over time (e.g. for all non‐zero eigenvalues λWp , λF ofWp and F , the corresponding normalized eigenvectors vWp , vF are parallel, v⊤WpvF = 1). With this alignment one can derive decoupled dynam‐ ics for the eigenvalues of W and Wp. By analysing this system, it can be shown that it has, depending on the weight decay parameter, several fixpoints, from which some are stable and some not. The trivial solution (the collapse) is one of them and the basin of attraction of these fixpoints varies with the relative learning rate of the predictor αpredα . With this analysis, [1] derives conditions under which the trivial fixpoint can be avoided. For a thorough mathematical analysis, we refer to [1]. In Section 5.1 we will present em‐ pirical evidence, that the symmetry assumption holds, and that the eignenspaces align. Furthermore, in Section 5.3 we will investigate the role of weight decay and the learning rate. From the decoupled dynamics of the eigenvalues, we can also derive an analytical ex‐ pression for the predictor Wp. Let F = UΩU⊤ be the eigen‐decomposition of F with Ω = diag(λ(1)F , ..., λ (d) F ) the diagonal matrix with the eigenvalues of F , then we can ap‐ proximate the eigenvalues ofWp with
λ (j) Wp = √ λ (j) F + ϵmaxj λ (j) F (5)
and therefore setWp to Wp = Udiag(λ (1) Wp , ..., λ (d) Wp )U⊤ (6)
Note, that we cannot compute F directly, which is why we use a running average F̂ as approximation in practice
F̂ = ρF̂ + (1− ρ)Ẑ (7)
where Ẑ = Ẑ(O)1 Ẑ (O)⊤ 2 . Wedenote thismethodDirectPred and in Section 5.2we show, thatDirectPred canperform similar to BYOL and SimSiam
4 Data & Configurations
We ran our experiments on Google Cloud Platform using Virtual Machine with a V100 GPU. All experiments are conducted on CIFAR‐10 [15], which contains 60 000 RGB images uni‐ formly distributed over 10 classes. The pre‐training and the linear evaluation are done on the entire training set, which consists of 50 000 images. For the linear evaluation, only a linear layer is used on top of the encoder, where the weights of the encoder are frozen (i.e. we test how linearly separable the encoders output is). The reported accu‐ racy results are produced from a test set containing 10 000 images. Also, to account for the small dimension of the CIFAR‐10 images (32× 32× 3) we use 3× 3 convolutions and stride 1 without maximum pooling in the first block of the encoder. To augment each image, we first do a random flip, take a random crop (up to 8% of the original size) of the image. Then we randomly adjust brightness, saturation, contrast
ReScience C 8.2 (#17) – Höppe, Miszkurka and Wilkman 2022 5
and hue of the RGB image by a random factor 1. Finally with a 20% chance we convert the image to grey scale.
Self‐supervised pretraining In the basic setting, the online network use ResNet‐18 as encoder, two layer projector MLP, two layer predictor MLP, where the first layer consists of 512 nodes, followed by BatchNorm and ReLU, and then a linear output layer with 128 nodes. For BYOL we use EMA to update target network and for SimSiam we directly set encoder and projector of target network to the weights of the online one (τ = 0). We use SGD optimizer with learning rate 0.03, momentum 0.9 and weight decay (L2 penalty) of 0.0004. The predictor of DirectPred is set directly and are not trained with gradient descent and consist of one linear layer with 128 nodes. By SGD baseline for those methods we mean a network pre‐trained with a one linear layer predictor with or without EMA. In all experiments, we use batch size of 128. For updating the target network we used the EMA parameter τ = 0.996. For DirectPred we use ϵ = 0.1 and ρ = 0.3.
Linear evaluation In order to test the performance of the different models, we use lin‐ ear evaluation, i.e. we train a linear layer on top of the ResNet‐18 encoder with frozen weights for 100 epochs. This measures how linearly separable the learned representa‐ tions of the encoder are. We use Adam optimizer [16] with polynomial decay of learning rate from 5e‐2 to 5e‐4. Images are normalized but we do not use augmentation for this part of training just as in the original repository for DirectPred.
5 Experiments and findings
In this section, we will first show that the assumptions and theoretical findings from Section 3.2 hold in practice. Finally, we will pre‐train and use linear evaluation on the different models presented in Section 3 in order to test their performances.
5.1 Eigenspace alignment First, we pre‐train BYOL and SimSiam keep track of the predictor heads symmetry and eigenspace alignment. In Figure 2 we can see, that the assumption of an symmetric predictor Wp holds. Even without symmetry regularisation, Wp approaches symmetry during training. Also, we can see that for all non‐zero eigenvalues ofWp the eigenspaces between F andWp align as the training progresses. We ran the same Experiment for SimSiam, and can also see the same effect on the pre‐ dictor and the alignment (Figure 3). If we don’t use a symmetric predictor, we also see that the eigenspaces for the non‐zero eigenvalues align. However, once we use symme‐ try regularisation on Wp, all eigenvalues become zero, which shows that the network collapses. We will see later in Section 5.3 that we can prevent this collapse by using different learning rates α, αpred and weight decay η, ηpred forW andWp respectively.
5.2 Performance Byol & SimSiam In table 1 we can see that the performance of BYOL increases slightly when using symmetry regularisation on the predictor. However, as already seen in Fig‐ ure 3, whenusing noEMA,we observe that the network collapses. We observe in general better performance formodels trainedwith EMA, given the same hyperarameters. How‐ ever, we did not use extensive hyperparameter tuning, as performance is not the focus of our work.
1for brightness, saturation and contrast we chose a value uniformly at random between 0.6 and 1.4. For adjusting the hue, we set the maximal value to 0.1
ReScience C 8.2 (#17) – Höppe, Miszkurka and Wilkman 2022 6
DirectPred As we can see in Figure 2 & 3, the eigenspaces for both models align and therefore the theoretical assumptions of [1] hold. As we can see in Table 2, all mod‐ els perform reasonably well, and can achieve almost the same performance as BYOL or SimSiam. However, as already mentioned earlier, we can see that models with EMA out‐ perform models without EMA. I addition, we run an experiments where the predictor is only updated every 5th step according to Equation 6 and otherwise is updated with gradient decent, we call this method DirectPred5. We can see that the hybrid method DirectPred5 does not increase performance, however, according to [1] when training for 500 epochs,DirectPred5 can outperformDirectPred. Due to computational constraints we cannot reproduce this experiment.
5.3 Influence of weight decay and learning rate As we can see in Figure 3, SimSiam with symmetric predictor does collapse. However, we can prevent this by adjusting the weight decay and learning rate. To make sure the network does converge to a stable non‐collapsing fix‐point, the weight decay of the pre‐
ReScience C 8.2 (#17) – Höppe, Miszkurka and Wilkman 2022 7
dictor should be set higher than the rest of the network (ηpred > η, for mathematical analysis see [1]). By omitting weight decay, we are not able to stabilize the training of SimSiam with symmetric predictor and we can also see, that methods without weight decay performworse, than with weight decay (Table 3). Also, to decrease the basin of at‐ traction, of the trivial fixpoints, the learning rate of the predictor should be rather large compared to the learning rate of the rest of the network, i.e αpredα >> 1 (see Section 3.2 in [1]).
6 Challenges
The original paper describes the methods and mathematical derivations well. Authors also share which hyperparameters they used in most of the experiments. Since the au‐ thors provided the open‐source repository for the paper, we could check some of the details of the experiments there. However, as the code is not well‐structured it was at times challenging to analyse. Furthermore, not all of the experiments are shared in the repository, for example there is no codewhich produces eigenspace experiments results or config for weight decay experiment. The reproducedpaper didnot outlined self‐containeddescriptionon themethods it used as it built upon previous works. Thanks to the detailed description of BYOL by Grill et. al. [2] we were able to reproduce the paper achieving similar results as the authors. Due to time constraints we decided to use CIFAR‐10 instead of STL‐10 which was used in most of the experiments in the reproduced paper. However, claims tested by us in this work are not restricted to one dataset and we shown that they indeed hold in a different setting. One of the main challenges was the large amount of computations required for all the experiments, it took around 4 hours and 30 minutes to pre‐train and fine tune a single model, and in total we trained for around 100+ hours.
ReScience C 8.2 (#17) – Höppe, Miszkurka and Wilkman 2022 8
Our work is implemented in TensorFlow and one of the challenges was differences be‐ tween TensorFlow and PyTorch libraries. For instance, in PyTorch one of the parame‐ ters of the SGD optimizer is weight decay (L2 penalty), in TensorFlow we had to imple‐ ment it by hand as TensorTlow’s SGDW implements only Decoupled Weight Decay Reg‐ ularization [17]. Furthermore, image augmentation methods such as ColorJitter from PyTorch do not have exact corresponding methods in Tensroflow. We used a custom way to do it so that augmentations are as close as possible to the original version.
7 Conclusion
In this work we study and reimplement three architectures used to give insight into self‐ supervised representation learning without contrastive pairs namely BYOL, SimSiam, DirectPred and their ablations. Our experimental results aligned well with both the theo‐ retical analysis about the eigenspaces and the symmetric assumptions made in [1] and translate to other dataset than used in the paper. Lastly, we confirmed that SimSiam can be prevented from collapsing with the use of weight decay and adjusting a learning rate of predictor. Furthermore, we confirm the claim that DirectPred outperforms its one‐layer SGD alter‐ native. However, we cannot report that DirectPred could outperform Byol. This may be due to the fact that we used CIFAR‐10 as opposed to STL‐10 in the original paper. This leaves us with the conclusion, that DirectPred gives valuable insights into the dynamics of unsupervised representation learning without contrastive pairs, but do not necessar‐ ily build new state of the art models themselves.
8 Ethical considerations
Self‐supervised learning circumvents label scarcity which is one of the most common problems when applyingML to new scenarios. This can have both positive and negative consequences. On one hand, it can accelerate important developments for example in medical diagnosis. However, it can also be used in unethical ways such as in surveil‐ lance or military equipment. Furthermore, there will be less need for people labelling datasets which will result in reduction of job positions in this area."
"['Richard Jiles', 'Mohna Chakraborty']",[Re] Domain Generalization using Causal Matching,10.5281/zenodo.6574661,Replication,Python,https://zenodo.org/record/6574661/files/article.pdf,rescience c machine learning deep learning python pytorch,https://openreview.net/forum?id=r43elaGmhCY,https://github.com/rjiles/causalmatching,8,2,2022,"We reproduced the results of the paper ”Domain GeneralizationUsing CausalMatching.” The standard supervised learning framework considers that the labels assigned to in‐ stances seen in the testing process must have appeared during the training phase. How‐ ever, real‐world designs may violate these considerations. For instance, in e‐commerce, new products are released every day with different labels, and the labels may not be part of the model training. A generalized framework should be capable of detecting un‐ seen labels. If a framework fails to detect unseen labels, it may face challenges in open domains and thus may not be generalizable. The objective of domain generalization is to learn representations independent of the domain. Previous works model this objective by learning representations by condition‐ ing on the class label. The authors provide counterexamples to show that the objective is not sufficient and propose a new objective to learn representations of inputs across domains such that they have the same representations if derived from the same object.","The authorized GitHub page of the paper has the open‐source code, which was bene‐ ficial as it was well organized into multiple files. Thus, it was easy to follow. The ex‐ periments described in the paper were done on widely‐used benchmark open‐source datasets. Therefore, implementing each experiment was relatively easy to do. Likewise, since most of the parameters were reported in the scripts, we did not needmuch tuning in most experimentations.","Though running each experiment is relatively simple, the numerosity of experiments was a demanding task. In particular, each experiment in the actual setting requires training a network for a significant number of iterations. Having restricted access to computational resources and time, we sometimes changed the settings, sacrificing gran‐ ularity. Nevertheless, these changes did not impact the interpretability of the final re‐ sults.
Communication with original authors We emailed the authors and received prompt responses to our questions regarding the provided Jupyter reproduction notebooks. Some tables had multiple runs for the same technique, but it was unclear how to execute the alternative runs.
1 Introduction
Learning is a dynamic process in an open environment where some new labels may not belong to any training set; therefore, recognizing these novel labels during classifica‐ tion presents a vital problem. The purpose of domain generalization is to learn a single classifier with training data sampled from M domains that generalize well to data from unseen domains. For example, a prototype trained on certain attributes of one region may be deployed to another, or an image classifier may be deployed on slightly rotated images. This proposition assumes that stable (causal) features lead to an optimal classi‐ fier uniform to the domains. The paper illustrates that the class‐conditional domain invariant objective for represen‐ tations is not always sufficient. They provide simple counterexamples to validate the class‐conditional domain invariance deficit theoretically and empirically. Differing dis‐ tributions of stable causal features within the same class label are commonly observed in real‐world datasets, e.g., in digit recognition, the stable feature like shape may differ based on people’s handwriting, or medical images may have variations due to differing body characteristics in the sample. The paper proposes the importance of assuming within‐class variation in stable features. This report repeats the original paper’s experiments and compares them with the re‐ ported results. Also, we expand the original paper results by investigating the effect of data augmentation on Rotated‐MNIST and Rotated Fashion‐MNIST datasets under vari‐ ous settings. We report and discuss our results in later sections. Domain generalization is a phenomenon that can generalize to unseen data distribu‐ tions after training on more than one data distribution. For example, a model trained on one domain may be deployed to another, i.e., domain adaptability, or an image clas‐ sifier may be deployed on slightly rotated images. The goal is to ”learn representations independent of the domain after conditioning on the class label” [6].
ReScience C 8.2 (#18) – Jiles and Chakraborty 2022 2
The paper analyzes the observation through a structural causal model (SCM) and dis‐ cusses the importance of modeling within‐class variations for generalization. The au‐ thors [6] propose newmethods RandMatch, MatchDG, andMDGHybrid to increase per‐ formance over the previous state‐of‐the‐art methods for various ML problems. In ad‐ dition to reproducing the original paper’s results, we propose different state‐of‐the‐art datasets where the analogy can be implemented and evaluate the efficacy of the propo‐ sition.
2 Scope of reproducibility
The paper broadly dives into the issue of spurious correlation, where some predictive attributes in the training time might not be predictive at the test time. For example, in Figure 1, we can observe the two different domains in which a cow could appear and/or be trained. If a learning algorithm does not use domain‐independent attributes and has most if not all training images of an object in one domain, it may fail when attempting to identify it in other domains.
Hence, there is a need to design ways to prevent machine learning models from retain‐ ing these spurious correlations, confining their generalization capability. Since amodel cannot generalize to any arbitrary unseen domains, therefore an assumption has been made by the authors that we have an invariant predictor based on the stable causal fea‐ tures across domains. Prior works like [8] propose an additional domain classifier trained from the representa‐ tions learned by the feature extractor module. The network is then trained to minimize the label prediction loss and maximize the domain classification loss hence learning domain invariant representations. However, it has been seen that the domain invariant representations fail when the domain and the label are correlated. We investigate the subsequent claims from the original paper:
• Claim 1: The paper proposes an object invariant condition to estimate stable fea‐ tures to overcome the loopholes of the prior works.
• Claim 2: The paper proposes a novel 2‐phase iterative algorithm to approximate the object‐based matches.
ReScience C 8.2 (#18) – Jiles and Chakraborty 2022 3
3 Methodology
We utilize the code made available by the original authors for our study. Our major emphasis was to verify that the providedmodels and descriptions stay true to the claims made in the paper. We further retrain their models on the provided dataset of Rotated‐ MNIST and Rotated Fashion‐MNIST.
3.1 Method descriptions The problem statement that the paper is trying to solve is domain generalization, where we have access to data from numerous domains and distributions. The objective is to generalize to unseen domains during the testing phase. In order to overcome the flaws of the priorworks, the authors in thepaper further analyzewhether the class conditional domain invariance objective is sufficient or not.
An easy counterexample has been shown in Figure 2, which illustrates a binary predic‐ tion task with two class labels on the slab dataset [9]. It has two types of features where the first kind of feature, X1, leads to a linear classifier separating the labels from the slab. The second feature, X2, leads to a more complex piecewise linear classifier splitting the labels. The slab feature also has a little noise represented by the low density of the oppo‐ site label. Overall, all the odd numbers slab correspond to the red colored points, and all the even numbers slab correspond to the blue colored points. The noise in the slab feature does not alter across domains. On the other hand, the linear feature X1 has very low noise in the source domain, but it is completely noisy in the target domain. Due to the simplicity of the linear feature, a model might still learn the spurious linear feature over the stable slab feature. One of the proposed methods is perfmatch. The method of perfmatch involves mini‐ mizing the loss L across m‐dimensions of the mapping function h of the learnt repre‐ sentation of X (denoted as Φ(X)) to the output Y . The function also minimizes the distance between the learnt representations Φ() objects of the same class j, k that exist in different domains d, d′ where the learnt matching Ω() of the same class objects j, k Ω(j, k) is 1 for the different domains d ̸= d′.
fperfmatch = argminh,Φ m∑ d=1 Ld(h(Φ(X)), Y ) + λ · ∑ Ω(j,k);d ̸=d′ dist((Φ(x (d) j )), (Φ(x (d′) k )))
The causal diagram in Figure 3 details the backdoor pass from an object to a domain, with the objects and features separated into two categories, domain‐dependent, and domain‐independent. From the equation, the objective is to learn the correct Y for a given X, and this is achieved by using the domain‐independent featuresXc to generalize across domains.
ReScience C 8.2 (#18) – Jiles and Chakraborty 2022 4
3.2 Datasets Thepaper assessed thematching‐basedmethods onRotated‐MNIST andFashion‐MNIST, PACS, and Chest X‐ray datasets.
Rotated-MNIST and Fashion-MNIST: It contain rotations of grayscaleMNISThandwritten digits and fashion images from 0◦ to 90◦ with an interval of 15◦ [10]. Here, each angle represents a domain, and the task is to predict the class label. Following CSD, the paper reports the accuracy of 0◦ and 90◦ together as the test domain and the rest as the train domains. PACS dataset: It contains a total of 9991 images from four domains: Photos (P), Art paint‐ ing (A), Cartoon (C), and Sketch (S). The task is to classify objects over 7 classes. Inspired by [3, 4], the paper trains 4 models with each domain as the target using Resnet‐18 [11], Resnet‐50 [11], and Alexnet [12] network. Chest X-ray: The paper introduces a harder real‐world dataset based on Chest X‐ray im‐ ages from three different sources: NIH [13], ChexPert [14], and RSNA [15]. The objec‐ tive is to identify patients with pneumonia. The original authors inserted a spurious correlation in the test domain by vertically translating class 0 in the training domains downwards, withholding the transformation from the test domain.
3.3 Hyperparameters We used hyperparameters stated in the original paper for most of our experiments. In cases where we deviated from the reported values, mostly due to computational re‐
ReScience C 8.2 (#18) – Jiles and Chakraborty 2022 5
sources and time limitations, we reported them in the discussion section. If a hyperpa‐ rameter is not reported in the original paper, we either communicated with the authors to ask about the hyperparameters or try out different values and report the result for all of them.
3.4 Experimental setup and code We reran the code of the original authors on both public cloud infrastructures, such as Google Colab, and private GPUs that were available to us. We closely follow the exper‐ imental setup in the original paper for our experiments. Our scaling extension can be easily integrated with the source code and optimized similarly. Our implementations for all the experiments in this work are available in the supplementary material and further support the reproducible research.
3.5 Computational requirements We reran the code of the original authors on both public cloud infrastructures, such as Google Colab, and private GPUs that were available to us. Google Colab provides a single 12GBNVIDIA Tesla K80 GPU that can continuously be used for 12 hours. We also ran the code locally on two different machines. The first machine: The GPU in question is an Nvidia GeForce RTX 3080 10Gb GDDR6X. The CPU in thismachine is an AMDRyzen(TM) 7 5800 (8‐Core, 36MB Total Cache, Max Boost Clock of 4.6GHz). The memory used was 32.0 GB DDR4 3466MHz, XMP. The second machine: i9‐9900k, 1080Ti with 128 Gb DDR4 2666Mhz. We followed the setup in the original paper and implemented the network with the same number of iterations. Evaluating all the results with the saved models takes a good amount of time. It nearly took two days for some of the tables to generate the results. In conclusion, the code is not fast, but it can be run on a local machine. A GPU is heavily recommended because the code is slower without access to GPU.
4 Results
To reproduce the authors’ experiments, we achieve approximately similar results to the original paper. We describe the results in the following sections:
Result 1 — Table 1 presents an empirical analysis of various algorithms on the slab dataset to understand which invariance criteria can help to capture the stable (causal) features. The algorithms are evaluated based on the domain invariance and class conditional do‐ main invariance criteria and experiment with the perfect match’s new approach, which aims for domain invariance conditioned on the stable features. The results show that the perfect match approach does better than the domain invariance and class condi‐ tional domain invariance objective in learning stable features, emphasizing the need to choose the correct invariant criteria. The original authors made the observation that in‐ variant representation learning by unconditional (DANN [8], MMD [16], CORAL [17]) and conditional distributionmatching (CDANN [18], C‐MMD [16], C‐CORAL [17]), andmatch‐ ing same‐class inputs (Random‐Match [19]) have poor performance for the Target. We also observed this from our repeated experiment.
Result 2 — Table 2 shows the replicated results for Rotated‐MNIST & Rotated Fashion‐ MNIST for test domains 0◦ & 90◦. MatchDG outperforms the comparison baselines for most of source distribution(CSD [20], MASF [21], IRM [22]). Source domains having the following angles (30, 45, 60) for Rotated Fashion‐MNIST, MatchDG achieves an accuracy of 45.0%, and the next best method, CSD, achieves 38.9%.
ReScience C 8.2 (#18) – Jiles and Chakraborty 2022 6
As of December 2021, the MatchDG algorithm holds the #1 ranking on the PapersWith‐ Code website for Rotated Fashion‐MNIST, with CSD as #2. The results we got for table 2 confirm that MatchDG performs better than the previous state‐of‐art technique CSD [20].
Result 3 — Table 3 shows the repeated results whereby MatchDG outperforms ERM for overlap %. The table shows the benefit of PerfMatch for all 3 metrics over the default MatchDG variant for all metrics, and each metric aligns with the other metrics for all baselines and models. This aligns with the results from the original authors as well.
Result 4 — Table 4 shows that for PACS dataset with ResNet‐18 architecture, the results are competitive to the authors selected state of the art baselines (JiGen [23], DDAIG [24], SagNet [25], G2DM [26], CSD [20], RSC [27]) averaged over all domains. The MDGHybrid has the 3rd highest average, being beaten by DDEC [28] and RSC [27]. The paper reports
ReScience C 8.2 (#18) – Jiles and Chakraborty 2022 7
MatchDG and MDGHybrid using a test domain validation, where MDGHybrid obtains comparable results to the best‐performing baseline.
The authors original results for MatchDG also claim high rankings for the PACS [3, 4] dataset for both resnet18 and resnet50 on the PapersWithCode website. Our replicated results confirm these claims.
Result 5 — Table 5 implementMatchDGonResnet50model usedby theERM inDomainBed. Adding MatchDG loss regularization improves the accuracy of DomainBed, from 84.79 to 87.86 with MDGHybrid. Also, MDGHybrid performs better than the prior approaches using Resnet50 architecture.
Result 6 — Table 6 provides results for the Chest X‐rays datasets from 3 different sources: RSNA, ChexPert and NIH. MDGHybrid outperforms other baselines for RSNA and Chex‐ pert. Nevertheless, NIHMDGHybrid is outperformed by both ERM and CSD. The paper reasons these inconsistent trends due to the intrinsic variability in ”source domains, in‐ dicating the challenges of buildingdomain generalizationmethods for real‐world datasets”. The replicated results commonly alignwith the original paper, butMDGHybrid exceeded Chexpert for our results. The original paper underperformed in the same manner that our results had an under‐performance for NIH even though the original paper MDGHy‐ brid attained the best result for NIH. Generally speaking, the results hold.
Additional Result 1 — Table 8 contain the results for Rotated MNIST datasets using the LeNet architecture [16]. In this setup, there are six domains in total (0◦, 15◦, 30◦, 45◦, 60◦, 75◦). The remaining five domains are used as source training domains for each test domain. Matching‐based training methods RandMatch andMatchDG outperform prior work on all the domains.
ReScience C 8.2 (#18) – Jiles and Chakraborty 2022 9
Tables 9, 10, and 11 contain the results for appendix section results of DomainBed, frac‐ tion of perfect matches and overlap % when training on all domains.
Additional Result 2 — The chars74k [29] dataset in Figure 5 offers an additional dataset to test the proposed algorithm in the paper. It contains characters A‐Z, a‐z, 0‐9 from several domains, more specifically 64 classes (0‐9, A‐Z, a‐z), 7705 characters obtained from natu‐ ral images, 3410 hand‐drawn characters using a tablet PC, 62992 synthesized characters from computer fonts. With the characters gathered from various sources, these sources can be considered in different domains. Thus, the algorithm should extract the causal features and be domain‐independent, reflected in the results. Comparison to baselines should show it has an advantage. Unfortunately, time did not allow this testing, but it should be easy to see why this would be a fair comparison for domain generalization.
ReScience C 8.2 (#18) – Jiles and Chakraborty 2022 10
5 Discussion
We observed several problems in the code; for example, in the dataset generation pro‐ cess, the authors randomly flipped the digits of the MNIST dataset during training, i.e., when they rotated a digit by 45◦, it is not consistent with whether it will be clockwise or anticlockwise rotation. The issue was because they were using an inbuilt library of PyTorch, and because of that, when we modified the code to make the rotation con‐ sistent, the results improved. Also, for Table 1, during code execution, we observed several errors andmade necessary modifications. For instance, there were errors in the paths in slab_data.py. The same error was rectified by adding the correct path in the file: base_dir= os.getcwd() + ’/data/datasets/slab/’. Secondly, during executingdata_gen_syn.py for preparing slab dataset, datasets with spurr_list of 1.0 were not created. Therefore, in the file data_gen_syn.py we appended 1.0 i.e., themodified spur_corr_list is [0.0, 0.10, 0.20, 0.90, 1.0]. On Windows machines, a freeze_support() error was encountered, and thus train.py and test.py needed to have themain()method added (problem is specific to windows only, believed to be an underlying issue with python). Some basic installations were needed for the libraries like torchcsprng and opacus.
ReScience C 8.2 (#18) – Jiles and Chakraborty 2022 11
5.1 What was easy The official GitHub page of the paper has the authors’ open source code, which was helpful. The experiments described in the paper were done on widely‐used standard datasets. Therefore, implementing each experiment was relatively easy to do. Further‐ more, since many of the parameters were reported in the scripts, we did not needmuch tuning in most experiments.
5.2 What was difficult Though implementing each experiment is relatively simple, the numerosity of experi‐ ments proved to be demanding. In particular, each experiment in the original setting requires training a network for many iterations. We sometimes changed the settings in these cases. However, these changes did not affect the interpretability of the final results.
5.3 Communication with original authors We emailed the authors and received prompt responses to our questions regarding the provided Jupyter reproduction notebooks. Some tables had multiple runs for the same technique, but it was unclear how to execute the alternative runs. For reproducing Ta‐ ble 1 in the original paper, it was unclear how we could obtain quantitative values for source 1, source 2, and target. As per the script, it was producing values for source and target. Therefore, we communicated with the authors via email and asked them to explain the condition used in the experiments more clearly. They stated that the num‐ bers obtained are evaluated on the target domain/test dataset under different validation strategies. Accordingly, we cannot break them down into source 1 and source 2. Execut‐ ing the script with the evaluate flag would evaluate the trained model and provide per domain accuracy (source 1, source 2)."
"['Isa-Ali Kirca', 'Daniël Hamerslag', 'Afra Baas', 'Juno Prent']",[¬Re] Reproducibility Study of 'Exacerbating Algorithmic Bias through Fairness Attacks',10.5281/zenodo.6574663,Replication,Python,https://zenodo.org/record/6574663/files/article.pdf,rescience c machine learning deep learning python,https://openreview.net/forum?id=rKbgh3fXnRK,https://github.com/DCHamerslag/FACT,8,2,2022,"Copyright © 2022 I.-A. Kirca et al., released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Daniël Hamerslag (d.c.hamerslag@gmail.com) The authors have declared that no competing interests exist. Code is available at https://github.com/DCHamerslag/FACT – DOI 10.5281/zenodo.6491095. – SWH swh:1:dir:25564a437957494e991b5205e262159e75d84d59;. Open peer review is available at https://openreview.net/forum?id=rKbgh3fXnRK.",,
"['Guilly Kolkman', 'Jan Athmer', 'Alex Labro', 'Maksymilian Kulicki']",[Re] Strategic classification made practical: reproduction,10.5281/zenodo.6574665,Replication,Python,https://zenodo.org/record/6574665/files/article.pdf,rescience c machine learning deep learning python pytorch,https://openreview.net/forum?id=rNgg03fXnRY,https://github.com/GuillyK/FACT-ai,8,2,2022,"The reproduction of the original paper as well as the extended implementationwere suc‐ cessful. We were able to reproduce the original results and examine the performance of the proposed model in an environment where strategic and non‐strategic users both present. Linear models seem to struggle with different proportions of strategic users, while the non‐linear model (RNN) achieves good performance regardless of the propor‐ tion of strategic users.",,
"['Evaline Bosch', 'Rutger Ettes', 'Daan Korporaal', 'Gijs van Meer']",[Re] Replication study of 'Explaining in Style: Training a GAN to explain a classifier in StyleSpace',10.5281/zenodo.6574667,Replication,Python,https://zenodo.org/record/6574667/files/article.pdf,rescience c machine learning deep learning python pytorch AI GANs SyleSpace reconstruction,https://openreview.net/forum?id=BtIz0nz7hRY,https://github.com/Gijsvanmeer/FACTinAI,8,2,2022,In this report claims made in the paper ”Explaining in Style: Training a GAN to explain a classifier in StyleSpace” will be tested. This paper claims that by creating a generative model based on pre‐trained classifier it is possible to discover and visually explain the underlying attributes that influence the classifier output which can lead to counterfac‐ tual explanations. From this it can be deduced what classifiers are learning.,"Pretrained models and the AttFind algorithm were available for execution. It was there‐ fore possible to quickly obtain some results given in the original paper by the authors. It gave a good baseline of what to expect should everything run correctly.
Copyright © 2022 E. Bosch et al., released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Daan Korporaal (daankorporaal@gmail.com) The authors have declared that no competing interests exist. Code is available at https://github.com/Gijsvanmeer/FACTinAI – DOI 10.5281/zenodo.6508302. – SWH swh:1:dir:1d0dbddb7bc7060aee89621b45cea15325dca1b1. Open peer review is available at https://openreview.net/forum?id=BtIz0nz7hRY.
None 8.2 (#21) – Bosch et al. 2022 1","No training code or information on the training procedure was available publicly, mean‐ ing it had to be created from scratch. Although the AttFind algorithm was available, it was in TensorFlow and not PyTorch therefore this needed to be converted. Implement‐ ing and training everything ended up taking a lot of time and resources, causing a hy‐ perparameter search and further research not to be possible.
Communication with original authors We have had contact with the original authors and many of our questions about their paper were answered. Response time was fast as well, usually taking no longer than 40 hours.
1 Introduction
The task of classification is a common task in the field machine learning. The ability to recognize complex attributes and separate large quantities of data into categoriesmakes deep models useful tools for this task. A disadvantage to using these deep classifiers can be that deep models are not easily explained, which makes it unclear why data is classified in a certain way. This is a problem because without a method to explain the classifier’s decisions, it is not clear whether the model bases its decisions on valid at‐ tributes or on some bias. Onemethod to explain a deep classifier is to use counterfactual explanations.[1] [2] Here, decisions of the classifier can be explained by observing how changes in the input data influence the classifier output. If changing an attribute of some data point has some substantial influence on the classification of that data point, it can be learned that this attribute was important for the classification. In the paper ”Explaining in Style: Train‐ ing a GAN To Explain a Classifier in StyleSpace” [3] the authors expand on this idea by developing a method that can find and visualise the most important attributes for a spe‐ cific classifier’s decisions. Lang et al. state that by using the ”StyleGAN2” architecture [4], they can utilize the trait that this has a disentangled latent space [5] to extract individual attributes that are se‐ mantically interpretable. Furthermore by incorporating a fully trained classifier into the training process of the styleGAN2 architecture, this disentangled latent space can be manipulated to find the attributes that change the prediction of the classifier. The following paper will be an analysis of the research performed and will asses its claims and its reproducibility.
2 Scope of reproducibility
The original paper proposes the StylEx model. This model is an adaptation of the Style‐ GAN2 model. It adds an encoder, which makes it so that counterfactuals of specific images can be generated, and a classifier, which makes it so that classifier specific ob‐ servations can be made. The paper also proposes its AttFind algorithm, which is de‐ signed to find classifier‐specific attributes in the trained models. The paper makes the following main claims about these implementations:
• The StylEx model is able to reconstruct images based on a specific classifier’s out‐ put by incorporating this classifier in its training and model input.
• The AttFind algorithm can find important style space coordinates for the classifier, which can be used to generate counterfactual explanations where semantically
None 8.2 (#21) – Bosch et al. 2022 2
interpretable attributes are changed in images to show their importance in the classifier’s decision making.
• Their model is able to more effectively find features that more accurately explain the classifier, meaning that changing these features should allow the classification to flipmore frequently than previousmethods. Themain comparison done is with the work of Wu et al.[5], where changing the 10 most important features proved much more effective on the StylEx method for all datasets used.
This paper will focus on these three claims by examining the extent to which they hold. For this both a pretrained model that was provided by the authors of the original paper, as well as some models that were trained from scratch will be researched.
3 Methodology
3.1 Models
Classifier — The MobileNetV2 architecture was used as the classifier. No pretrained mod‐ els exist for the classification task at hand, thus an untrained model was taken and trained on the chosen datasets.
Encoder and Discriminator — The discriminator architecture is defined in the styleGAN2 pa‐ per [4]. The encoder and decoder have the same architecture, the architecture of these two models is therefore a residual discriminator without progressive growing. The only difference between the two architectures is the final linear layer, where for the encoder the output is mapped to an encoding dimension of 512 and for the encoder the output is mapped to a single value. Even though the encoder and discriminator share almost the same architecture their functionality and training is different. The encoder is utilized to encode an image into a latent vector to input into the generator model whereas the discriminator is used to classify whether an image is generated by the generator or is a real image.
Generator — For the generator a modified version of the StyleGAN2 architecturewas used. Figure 1 illustrates this architec‐ ture. As its input it takes the encoded la‐ tent vector of some image concatenated with the classifier output on this image. This is then mapped to the style space by multiple affine transformations. These style vectors can then be input to the syn‐ thesis network, which uses a multitude of convolutional layers and skip connec‐ tions to generate an image. The origi‐ nal StyleGan2 architecture also utilised a mapping network that mapped some noise vector z to the latent vector. Con‐
tact with the authors of the original paper revealed that the reported results in their paper were achieved by alternating between using the encoder and using this mapping network during training. However, since this was not mentioned in the paper and since the authors advised that only using the encoder would also give good results and would lead to a faster convergence, the decision was made to only use the encoder to obtain the latent vector in this research.
None 8.2 (#21) – Bosch et al. 2022 3
3.2 Training the StylEx model During the training process of the StylEx model, the encoder, discriminator, and gen‐ erator are all trained simultaneously. At each iteration the encoder and classifier get a batch of training images. The output of both these models are concatenated and used by the generator network to reconstruct the original images. To calculate the loss there are four main loss terms, namely the adversarial loss, the path regularization loss, the reconstruction loss and the classifier loss. The adversarial loss is a general loss term for GANs over the outputted image from the generator inputted into the discriminator [6]. The path regularization loss causes the la‐ tent vectors w to be regularized based on current and previous latent vectors such that the path length does not diverge from the mean path lengths leading to more consis‐ tently behaving models [4]. The reconstruction loss is made up of an Learned Perceptual Image Patch Similarity(LPIPS) distance between the real image and the generated image [7], an L1 loss between the image and the generated image and an L1 loss between the the output of the encoder on the real image and the generated image. From further communication with the authors it was found that the LPIPS loss and L1 loss between the image and the generated image have a weight of 0.1. Lastly, the classifier loss is the Kullback–Leibler(KL) divergence between the classifier output on the original image and the generated image.
3.3 AttFind TheAttFind algorithm is an algorithm thatwill try to uncover classifier specific attributes. The input of AttFind is the classifier, the generator, the threshold, and a set of images whose predicted label by the classifier differs from the label of the images that are to be generated. For every image the algorithm will iterate through the style coordinates and apply a different direction for every style coordinate on the image and calculate its effect on the classifier. The coordinate with the largest effect on the classifier output over the set of images is selected. All images on which this style coordinate has a large effect will be removed from the images list and the style coordinate will be put in a list. Finally, when all the images are removed from the images list or if all the style coordi‐ nates have resulted in a large change in the classifier the output of the algorithmwill be the style coordinates that had a large effect on the classifier and the direction in which they where changed. With these coordinates and directions of each feature new images can be generated where the effect of changing these coordinates shows a difference in the image and the classification.
3.4 Datasets The datasets used for the experiments are shown in Table 1. Both the StylEx and classi‐ fier datasets match those used in the original paper. Due to computational limitations all images were scaled down to 64x64.
3.5 Hyperparameters Although they were not included in the paper itself the authors responded quickly and supplied the hyperparameter details. The learning rate of the original model was set to 0.002 and the batch size was set to 16. The authors had 8 GPUs at their disposal
None 8.2 (#21) – Bosch et al. 2022 4
and therefore the batch size per GPU was 2. Furthermore the original experiment was run for 250k iterations. During training for this paper however, problems were encoun‐ tered using these hyperparameter settings due to the decreased resolution of the im‐ ages and GPU limitations. Therefore the batch size was decreased to 4 and the learning rate was decreased by a factor 10 to 0.0002 accordingly. Furthermore, 220k iterations were run, which took approximately 48 hours. This was chosen to be slightly lower than the amount of iterations run in the original paper, both because of time and resource constraints and because of the lower resolution images in this research leading to an observably faster convergence.
3.6 Experimental setup and code
Available resources — The available resources for the experiments are limited. Although the AttFind algorithm with some pretrained models is publicly available 1, the current implementation is in TensorFlowmeaning it had to be adapted into PyTorch first. Aside from this no training code is available, and the pretrained models do not offer many insight towards the training procedure. This means the StylEx model and training code had to be implemented again based on the details provided by the paper and the authors. This self implementation was done by adapting an existing PyTorch implementation2 of StyleGAN2 into the StylEx model. The full code and other resources are available on GitHub 3.
Image reconstruction — As stated before, the original paper claimed the StylEx model is able to reconstruct images based on the classifiers output. This claim is verified through visual representation and will thus be done the same in this review. Analyzing random selections of image generations compared to their original should give a quick overview of how effective these reconstructions are.
Semantically interpretable features — The original paper claims that the AttFind algorithm is able to generate counterfactual explanations of images, which describe semantically in‐ terpretable attributes. If the counterfactual explanations are semantically interpretable attributes, these would have to be noticeably different from one another. To test this first the top 4 features are extracted. The user study from the original paper is then re‐ made. At each section this user study contains two GIFs of the same feature changing in different images. The users then have to choose from two different GIFs of changing images which one has the same change in feature as the first two. The user study was shared with personal connections from various backgrounds.
Flipping the prediction — Finally in order to test the validity of the claim that the StylEx model is more effectively able to flip the classifier prediction than other models such as the one by Wu et al., the experiment from the original paper is recreated. The Wu et al. algorithm works by considering the normalized differences of style space values of images in one classifier class with the mean of all images. Wu et al. ensure images that strongly exhibit one class by selecting the top 2% of images that conform to the class the most. Due to limited computing resources this would result in few examples, so a classifier logit threshold of 0.9 is used instead. Wu et al. also do originally consider the direction of change necessary for the desired classifier effect. For fair comparison, These directions are obtained by examining whether themean of the differences is posi‐ tive or negative. It is not knownwhether Lang et al. do the same. To recreate the original experiment the latent vectors are used to generate images that have their top k features
1https://github.com/google/explaining-in-style 2https://github.com/rosinality/stylegan2-pytorch 3https://github.com/Gijsvanmeer/FACTinAI/code
None 8.2 (#21) – Bosch et al. 2022 5
flipped, in this case 10 features. The classification is then compared against the original image, where an image will count as flipped if it is now classified as another class. The results are calculated as the total percentage of images where classification flipped after the attributes were changed within the style space.
3.7 Computational requirements The StylExmodel, which include the encoder, generator and discriminator, were trained on one GeForce 1080 TI GPU. The total runtime for the training was 48 hours using a batch size of 4. The cat/dog classifier model was trained on the Google Colab GPU, an NVIDIA Tesla K80 GPU, for approximately 30 minutes. The age classifier model was trained on one GeForce 1080 TI GPU for approximately 6 hours.
4 Results
The results of the experiments will be shown and discussed in the following sections. In section 4.1 the overall reconstruction will be analysed, in order to determine how effective the reconstructions have been. Next in section 4.2 the findings of the style space coordinates will be discussed together with the results of the user study, to test how semantically interpretable the found features truly are. Finally in section 4.3 the results of the feature change on the classifier output will be analysed and shown. The images shownwere randomly selected among the images belonging to the required task according to the classifier.
4.1 Image reconstruction
When looking at the visual results of the recon‐ struction of the images by the AttFind algorithm which are shown in Figure 2, it can be seen that there is some clear reconstruction, but that the model does not recreate the images perfectly using this lower resolution data. One issue to note is how the model handles younger animals. When look‐ ing at the second column in Figure 2, it can clearly be seen that this is reconstructed as a more adult version of the dog instead of the puppy it originally was. This could be a limitation of the StylEx style space, or it could be due to the amount of available training data on younger animals. Some other an‐ imals appear to be changing features all together. When observing the changes in the third column of Figure 2, the generated cat only seems to share its colour with the original cat, as well as the over‐
all pose. Aside from these two features the images are completely different cats. Results for the FFHQ model were similar.
4.2 Semantically interpretable features
Features for the pretrained model — In Figure 3, qualitative results of the pretrained model architecture are shown. The features shown are clearly semantically interpretable, and change the classification score significantly. The top 4 features found for the pretrainedmodel on the FFHQ by the AttFind algorithm
None 8.2 (#21) – Bosch et al. 2022 6
were: skin complexity, eyebrow thickness, glasses, and hair colour. This matches the results reported in the original paper.
Features for the new models — Running the same experiment for the StylEx model gave the following results as shown in Fig. 4. In these images it is much less clear what distinct features exist for the low resolution AFHQ data. Not only are the features barely dis‐ tinguishable, but the changes that are visible do not necessarily apply to any real world semantics. This could possibly be due to the complexity of the data, as themodel trained on AFHQ data set was found to perform less well thanmodels trained on human data in the original paper as well. Alternatively, this could be because of an issue in either the AttFind algorithm or the StylEx style space. As can be seen in Figure 5, the results for the FFHQ data is very similar to the results for the AFHQ data, although a bit better. The first two features found by AttFind do not seem to be connected to any semantically interpretable features. Looking at the
None 8.2 (#21) – Bosch et al. 2022 7
third most important feature however there seems to be some form of change in skin colour, although the change itself is not exactly realistic. The final feature seems to ref‐ erence back to the opening of the mouth, which is the most semantically interpretable feature of the four. These results therefore somewhat confirm the hypotheses made above, since the model indeed seems to perform slightly better on the FFHQ data set, but still does not validate the claim that semantically interpretable features are found.
Features for the StyleGAN2 model — To research the cause of the slightly disappointing re‐ sults of the trained StylEx models, an investigation of the original StyleGAN2 model could give some more insight. Figure 6 shows the results of the AttFind algorithm on a StyleGAN2model trained on the AFHQdata and a StyleGAN2model trained on the FFHQ data with the same hyperparameters as the models in the previous section. Note that these images are not counterfactuals of specific images in the validation data as before, but rather they are counterfactuals of images generated from some randomly generated z vector, since the original StyleGAN2 architecture does not include an encoder. As can be seen, changing the attributes found by AttFind does give some different results here than in the previous section. The changed attributes seem to be semantically impactful, since clear changes in respectively facial structure, coat colour, glasses, and skin colour can be seen. From this it could be concluded that the problem in the previous section is not the AttFind algorithmnor is it the image resolution, since both are the samebetween these two sections. Therefore it would be likely that the problem lies somewhere in the trained StylEx model. The most likely theory for this is that our implementation does not use these randomly sampled z vectors that the StyleGAN2 model does use. There‐ fore it could be the case that without this random sampling the model only gets similar images, namely only the training data, which could result in a less defined style space and thus in that less interpretable features are found.
User study — In total 61 responses were recorded in the user study. The original paper achieved an accuracy of 0.983 (±0.037) on an unknown amount of questions and par‐ ticipants. The results of the new poll include 3 questions for each feature in the top 6 features found by AttFind for a total of 18 questions. The overall score of this poll was lower, as it achieved a score of 0.918 (±0.038), possibly due to a difference in demo‐ graphic. The user study still shows an overall good understanding of the features, as a score of over 90% was achieved. The first question got the worst results, possibly due to people not fully understanding how the study worked or due to the more subtle feature (skin complexity) shown.
None 8.2 (#21) – Bosch et al. 2022 8
4.3 Flipping the prediction
Table 2 shows the results of running theWu et al. algorithm as well as the StylExmethod with AttFind. The new results aremuch lower than those found in the original paper. As mentioned before, our most likely hypothesis for this is that this is because of the lack of z mapping performed, resulting in a lesser style space. The model had more trouble with the AFHQ classification than the FFHQ, which does fall in line with the original results. This is probably due to the fact that cats and dogs are far more binary than age and therefore when z mapping is not performed the model does not obtain enough varied inputs. An interesting point to note is that the results of the Wu et al. paper are much higher than reported in the original report. Especially the AFHQ results are of note here, as only a 1.0% flip rate was achieved originally, but the StyleGAN2 model with the reduced resolution achieves a flip rate of 20.8%.
5 Discussion
5.1 Conclusions From section 4, the different claims stated in section 2 can be supported or contradicted. The first claim states that the StylEx model is able to reconstruct images based on a spe‐ cific classifier. In the results some clear reconstruction could be seen although the im‐ ages still had a lot of problems. This concludes that with the available resources and information the StylEx model is able to reconstruct images based on specific classifier but not to the same complexity as stated in the paper. Furthermore, the second claim states that the AttFind algorithm can be used to find the most important attributes that explain the classifier. From the results this claim seems to be supported. This is mostly because although the results from the AttFind algorithm on the stylEx model are suboptimal, the results on the StyleGAN2 model are feasible. From this it can be concluded that the AttFind algorithm performs as expected and the attributes it finds could be used to generate counterfactuals. Lastly, the third claim states that the StylEx model can more accurately explain the clas‐ sifier than previous methods. In the results it was found that this was not the same for this implementation. The flip rate of the StylEx model trained on age classification was better than the wu et al. results but not better than the StyleGAN2 results and the StylEx model on the AFHQ data was the worst performing. From this it can be concluded that given the resources and time it was not possible to reproduce these results.
5.2 What was easy The authors of the original paper made the AttFind algorithm as well as the pretrained models publicly available. This allowed results to be effectively extracted from them, and also allowed to easily validate some of the claims made in the paper and gave an overall good baseline for the experimentation. The results obtained were also mostly in line with what the paper reported. With the AttFind algorithm it was also possible to effectively obtain the results on newly trained models.
None 8.2 (#21) – Bosch et al. 2022 9
5.3 What was difficult Since no training code was made publicly available by the authors this needed to be implemented from scratch in PyTorch, which took a significant amount of resources to complete. Although the AttFind model was publicly available, documentation itself was very limited, meaning that translating it from TensorFlow to PyTorch was a non‐ trivial task as well. These bottlenecks ended up affecting the amount of experiments that could be performed, and limited the opportunity to expand upon the paper as well. Another bottleneck that affected the experimentation of the report is the available re‐ sources. Only having access to Google Colab (which limits GPU usage) and a single GeForce 1080TI GPU limited the amount of time to run experiments, with training tak‐ ing up a large portion of available GPU usage. This also meant the image quality had to be scaled down in order to effectively train themodel, although this negatively impacted the quality of the obtained results. In the original paper the authors trained eachmodel on 8 computationally stronger GPUs, which resulted in this difference in overall image reconstruction quality and resolution. After this little room was left to do things like hyperparameter search or further research given these constraints, which would have added to this review.
5.4 Communication with original authors There was communication with the original authors about the internal structure of the models, as well as the hyperparameters which were not included in the original paper. They also answered any additional questions about the latent vectors and the use of lower dimension images for the model. It was also recommended to not use the z map‐ ping if time was limited too much."
"['Matteo Tafuro', 'Andrea Lombardo', 'Tin Hadži Veljković', 'Lasse Becker-Czarnetzki']",[Re] Exacerbating Algorithmic Bias through Fairness Attacks,10.5281/zenodo.6574669,Replication,python,https://zenodo.org/record/6574669/files/article.pdf,rescience c rescience x reproducibility machine learning deep learning fairness python tensorflow adversarial attack fairness attack algorithmic bias influence attack on fairness anchoring attack,https://openreview.net/forum?id=H4lzChGmhCK,https://github.com/imandrealombardo/FACT-AI,8,2,2022,"The presented study evaluates ”Exacerbating Algorithmic Bias through Fairness Attacks” by Mehrabi et al. [1] within the scope of theML Reproducibility Challenge 2021. We find it not possible to reproduce the original results from sole use of the paper, and difficult even in possession of the provided codebase. Yet, we managed to obtain similar findings that supported three out of the five main claims of the publication, albeit using partial re-implementations and numerous assumptions. On top of the reproducibility study, we also extend the work of the authors by implementing a different stopping method, which changes the effectiveness of the proposed attacks.","The novel attacks proposed in the paper are presented intuitively, so even with the lack of background in topics such as fairness, we managed to easily grasp the core ideas of the paper.","The reproduction of the results requires much more details than presented in the pa‐ per. Thus, we were forced to make many educated guesses regarding classifier details, defense mechanisms, and many hyperparameters. The authors also provide an open‐ source implementation of the code, but the code uses outdated dependencies and has many implementation faults, which made it hard to use as given.
Communication with original authors Contact was made with the authors on two occasions. First, we asked for some clarifica‐ tions regarding the provided environment. They promptly repliedwith lengthy answers, which allowed us to correctly run their code. Then, we requested additional details con‐ cerning the pre‐processing of the datasets. The authors pointed at some of their previ‐ ous projects, where we could find further information on the processing pipeline.
1 Introduction
Machine Learning models have shown impressive performance in countless domains in the last decade. However, it has been demonstrated that an adversary can input carefully‐crafted perturbations to subvert the predictions of these models. The area of Adversarial Machine Learning has emerged to study vulnerabilities of machine learn‐ ing approaches in adversarial settings and to develop techniques that make them robust against malicious attacks. Most of the research has focused on studying malign interventions that degrade the accuracy of a system: imagine, for example, the consequences of inducing wrong pre‐ dictions in an autonomous driving system. Only recently, fairness has become a rising concern for the performance of machine learning models, especially for sensitive fields such as criminal justice and loan decisions. Along these lines, “Exacerbating Algorith‐ mic Bias through Fairness Attacks” [1] proposes two families of poisoning attacks that inject malicious points into the models’ training sets and intentionally target the fair‐ ness of a classification model. The first, the influence attack, extends the optimization‐based technique introduced by Koh, Steinhardt, and Liang [2] by incorporating in the loss function a constraint for fair classification. An attacker can hence harm both accuracy and fairness simultaneously, with a trade‐off regularized via a parameter λ. The second type of attack, the anchoring attack, affects solely fairness and aims to place poisoned data points to bias the decision boundary without modifying the attacker loss. Depending on whether the target point is chosen at random, anchoring attacks are classified as random or non-random.
2 Scope of reproducibility
This report investigates the reproducibility of the original paper by Mehrabi et al. [1] and aims to verify its main claims. Since these heavily rely on the datasets and metrics
ReScience C 8.2 (#22) – Tafuro et al. 2022 2
used by the authors, the reader is invited to consult Sections 3.2 and 3.3 – respectively – for a refresh of such concepts. Then, the main claims can be summarized as follows: – Influence Attack on Fairness (IAF):
• Claim 1: Increasing the parameter λ results in stronger attacks against fairness. Contrarily, for lower values themodel acts similarly to the original influence attack [2] targeted towards accuracy;
• Claim2: Theproposed IAFoutperforms the attack of Koh, Steinhardt, andLiang [2] in affecting both fairness metrics (SPD and EOD), on all three datasets;
• Claim 3: The proposed IAF also outperforms the attack based on the loss function proposed by Solans, Biggio, and Castillo [3] in affecting SPD and EOD, on all tested datasets.
– Anchoring Attack:
• Claim 4: Both randomandnon‐randomanchoring attacks (RAA andNRAA, respec‐ tively) outperform Koh, Steinhardt, and Liang [2] in degrading the SPD and EOD of the classification model, on all three datasets;
• Claim 5: On the German and Drug Consumption datasets, RNAA and NRAA have a greater impact on fairnessmetrics (SPD and EOD) compared to the attack based on Solans, Biggio, and Castillo [3]. However, the latter outperforms the proposed an‐ choring attack in affecting fairness when classification is performed on the COM‐ PAS dataset.
3 Methodology
The authors provided an open‐source implementation of their code on GitHub [4]. Un‐ fortunately, the repository has several issues: dependencies are not sufficiently speci‐ fied, and simply running the code in the given environment results in conflicts. Further‐ more, the code does not provide an option to run baseline methods used in the paper, nor does it include the essential hyperparameter λ, which is used in the experiments. The majority of the code is based on Koh, Steinhardt, and Liang [2]’s public implemen‐ tation [5], and a code coverage analysis revealed that more than 50% is not used for running experiments related to this paper1. Moreover, the repository comes with pre‐ processed datasets and while this may sound advantageous, there is no mention of the processing procedure in the paper nor on GitHub. Finally, the code is generally complex and hard to understand due to insufficient comments and documentation. Therefore, we used the codebase provided by the authors and customized it for our pur‐ poses. First, to aid maintainability and scalability, as well as to ensure future repro‐ ducibility of the original experiments, the code was modernized and made compatible with the latest version of every dependency. This involved major changes to migrate from Tensorflow 1.12.0 to 2.6.2 and to update CVXpy from version 0.4.11 to 1.1.182. Secondly, datasets were downloaded from the original sources [7, 8] and pro‐ cessed from scratch. The procedure is thoroughly reported in Section 3.2. Furthermore, the codewas trimmed down to the essential, and the userwas given the option to choose any of the available models and the corresponding parameters. Lastly, we added com‐ prehensive documentation to make the code more interpretable.
3.1 Model descriptions It appears that the authors of the original paper donot specify themodel that they use for the given classification task. From the implementation details given in Koh, Steinhardt,
1The coverage.py tool [6] was used to measure code coverage, and the study was performed considering all possible attacks‐datasets combinations.
2In our repository we provide a YAML configuration file to quickly set up the required environment.
ReScience C 8.2 (#22) – Tafuro et al. 2022 3
and Liang [2], as well as from [1]’s codebase, we assume the use of a Support Vector Machine (SVM) trained with a smooth hinge loss and L2 regularization (refer to [2] for further details). Additionally, the optimization algorithm is not indicated; we assumed it to beNewtons Conjugate Gradient (Newton‐CG)method, as suggested by the codebase. Such a method is used for both the minimization of the parameters on the training set and the update step of the poisoned points (for attacks utilizing an adversarial loss). The gradient is computed using the full datasets, i.e., without using mini‐batches. Although hardly recognizable, this follows the implementation of the original paper: from our interpretation of the code, it seems that the authors define a variable containing the size of the mini‐batch size and the necessary functionality, but then never use it. Our base algorithmic setup for the IAF, RAA, and NRAA attacks is described in theMethods section of the original paper. However, the authors omitted important details that we consequently had to assume based on more or less concrete evidence. First, an ad‐ vantaged and disadvantaged group for the sensitive attribute (i.e., gender, as per the original work) has to be specified for all attacks. Since the rationale behind this choice does not seem to be included in the paper, we infer from the codebase that the authors did it automatically and deduced it from the datasets. More specifically, we assume that the advantaged group is chosen as the group with the highest ratio of data points with positive label (y = 1), regardless of the actual class label it corresponds to. This method is simple yet fallacious: for instance, itmeans that the group taking on the label ”likely to perform a crime soon” more often (in the context of the COMPAS dataset) is considered ”advantaged” in terms of the algorithm. Secondly, for the computation of the feasible set using an anomaly detector B, we as‐ sume that the intersection of the Slab defense and the L2 defense was originally em‐ ployed, as described in Koh, Steinhardt, and Liang [2]. For reprojecting poisoned data points into the feasible set, we again use the approach of [2], which incorporates LP rounding for discrete variables. Moreover, we implement twobaselines. The three proposed attacks are compared against the original accuracy‐targeting attack proposed by Koh, Steinhardt, and Liang [2], and another attack that uses a loss function proposed by Solans, Biggio, and Castillo [3], which targets fairness3. Lastly, themodel‐specific changes/improvements are presented below:
IAF. As mentioned before, we modified the code to include the hyperparameter λ which controls the trade‐off between the accuracy and the fairness loss in the adver‐ sarial loss.
Koh attack. We were not able to find a way of running this baseline attack using the given codebase. Wehave decided to implement it from scratch, treating it as the limiting case of the IAF attack when λ = 0 (meaning no fairness loss in the adversarial loss function). Consequently, it is not exactly as presented in [2]: in the original Koh attack sampling, the initial poisoned points are not drawn from advantaged and disadvantaged groups, contrary to the IAF attack. However, we argue that equalizing the sampling method provides a stronger comparison between the two methods, as we alleviate the issue of the missing inductive bias from the original Koh influence attack.
Solans attack. This attack serves as the second baseline. We could not find it in the codebase, thus we implemented it by replacing the adversarial loss in the IAF attack with a weighted sum loss, as presented in [3]. Implementing this change posed a bigger issue than expected, due to the inflexibility of the TensorFlow‐based implementation. Thus, major revisions were required.
3For simplicity, we will refer to the influence attack presented in [2] as the Koh attack, and we will also refer to the attack presented in [3] as the Solans attack.
ReScience C 8.2 (#22) – Tafuro et al. 2022 4
3.2 Datasets The authors provide compressed npz files of the three real‐world datasets used for their experiments – the German Credit Dataset [7], the COMPAS Dataset [8] and the Drug Con‐ sumption Dataset [7]. However, these are already pre‐processed, and the processing procedure is not reported nor documented in the code. This constitutes an important re‐ producibility barrier, because raw datasets4 are not directly usable with the given code‐ base. In this section, we present our pre‐processing pipeline, which was mainly determined by reverse engineering of the given files. Like the authors, we provide a set of npz files containing already‐processed data to run our implementation, but we also include the scripts used to pre‐process each dataset in the Custom_data_preprocessing di‐ rectory. Lastly, to run the attacks, we assume that the advantaged and disadvantaged groups are males and females respectively. We accordingly map them to 0 and 1 to cre‐ ate the group_label binary array. In the rest of this section, we outline our dataset‐specific details of the pre‐processing pipeline and the assumptions that were made for the sake of reproducibility of the orig‐ inal results.
GermanCredit Dataset. The dataset contains the credit profile of 1000 individuals with 20 attributes associated with each person. In our experiments, we use all of them, as in [1]. The attributes are both numerical and categorical, and we assumed the original authors used one-hot representations to encode the latter. The assumptionwas based on an extensive study of the provided datasets, with particular attention to their shapes. We then autonomously standardize the data, as it is common practice inMachine Learning, and split the data into an 80‐20 train and test split, as indicated in the original paper.
COMPAS Dataset. ProPublica’s COMPAS dataset [8] contains information about 7214 defendants from Broward County. We use the features specified in Table 1 of [1]. In this case, based on the provided dataset, we concluded that the authors must have used numerical label encoding to represent the categorical attributes. Finally, we standardize the data and split it into an 80‐20 train and test split.
DrugConsumptionDataset. Thedataset contains information about the drug consump‐ tion of 1885 individuals [9]. We use the attributes indicated in Table 1 of the original pa‐ per. The pre‐processing procedure is as follows: first, we binarize the categorical data linked to cocaine consumption into users and non-users. Intuitively, non‐users should be mapped to 0 (and 1 in the opposite case), but an inspection of the provided npz file sug‐ gests that the authors reversed the mapping. We decided to adhere to their choice for the sake of reproducibility. Moreover, we suspect that the dataset was shuffled before splitting it into training and test sets5. By doing so, we obtain similar results in the ex‐ periments. Finally, we standardize the data. The original processing of this dataset was particularly difficult to replicate, because contrary to what was reported in the paper, the authors did not follow an exact 80‐20 train and test split. Rather, the two contained 1500 and 385 data points respectively. To conclude, it is noteworthy that even the pre‐processed datasets provided by the au‐ thors are not immediately usable: the position (specified as index) of the sensitive fea‐ ture (i.e., gender) is different for each dataset and is only given for the German dataset in the running instructions. To account for this unnecessary confusion, our custom pre‐processing procedure includes the moving of the gender column to the 0th index,
4The German Credit Dataset and the Drug Consumption Dataset can be downloaded from the UCImachine learning repository [7], while the COMPAS can be found in the corresponding GitHub repository[8].
5The main author followed a similar pre‐processing procedure in another project that is publicly available on their GitHub [10].
ReScience C 8.2 (#22) – Tafuro et al. 2022 5
which is taken as default by the main function. In this way, we simplify the running instructions and make them coherent across datasets. Still, the user is given the ability to pass the sensitive feature index as an argument, to facilitate future experiments on different and untested data.
3.3 Metrics The attacks are evaluated in terms of accuracy and fairness. Along with classification (test) error, the original paper uses two importantmetrics to evaluate the attack in terms of fairness: Statistical Parity Difference and Equality of Opportunity Difference.
Statistical Parity Difference. Statistical Parity Difference (SPD) was first introduced by Dwork et al. [11] and is used to capture the predictive outcome differences between different (advantaged and disadvantaged) demographic groups. The mathematical for‐ mulation is reported in Equation 1.
SPD = ∣∣∣ p(Ŷ = +1 | x ∈ Da)− p(Ŷ = +1 | x ∈ Dd)∣∣∣ (1)
where Da denotes the advantageous group and Dd denotes the disadvantageous group.
Equality of Opportunity Difference. Equality of Opportunity Difference (EOD) (Hardt, Price, and Srebro [12]) captures differences in the true positive rate between different (advantaged anddisadvantaged) demographic groups. It is defined as shown inEquation 2.
EOD = ∣∣∣ p(Ŷ = +1 | x ∈ Da, Y = +1)− p(Ŷ = +1 | x ∈ Dd, Y = +1)∣∣∣ (2)
3.4 Experimental setup and hyperparameters All experiments shown in this paper can easily be reproduced using our code, which is publicly available on GitHub6. There we also provide technical details on how to run experiments and test different attacks in various settings. In this section, however, we list some additional details necessary to replicate the exact setup.
• The original code constrains themaximum iterations of an attack to 10000 anduses early stopping to interrupt training if the accuracy on the test set does not decrease for a specific number of iterations, which is hardcoded to be 2. We follow this strategy but adapt it for our experiments. First, we implement early stopping on both accuracy and fairness, meaning that the user can also choose to stop training in the absence of changes in fairness. Weutilize average fairness (SPD+EOD)/2 as the stopping criteria7 since the twometrics have similar behavior and equal range [0, 1]. Then, we set the early stopping patience as a controllable hyperparameter.
• It is unclear from the paper how the best‐performing model was selected by the authors. The code suggests theusage of themodel after the last attack iteration and training of themodel parameters. Instead, we decided to save the best‐performing model on the test set according to the chosen stopping metric (average fairness or accuracy), to better reflect the actual best performance. By selecting the best model based on fairness, we hope to choose more relevant states of the poisoned data affecting the fairness metrics. We compare the results in Section 4.
• The computation of the feasible set and the reprojection of poisoned points onto it is handled as a convex optimization problem (see [2]). Since we upgraded CVXpy
6https://github.com/imandrealombardo/FACT-AI 7In the rest of the paper, we might refer to it simply as the fairness stopping metric.
ReScience C 8.2 (#22) – Tafuro et al. 2022 6
to its newest version, we can let the library select the most appropriate solver for the given problem, instead of specifying one (the authors of [1] seem to have used the SCS solver).
• Following the original implementation, we utilize the fmin_ncg optimizer of the scipy library [13] for theNewton‐CG optimization. We complywith the choices of the authors and set the convergence threshold of the fmin optimizer to 10−8, and the maximum number of iterations to 100. We follow the implementation details specified in [2] for computing the inverse Hessian‐vector.
• During training, the temperature of the smooth hinge loss is chosen to be 0.001, as found hardcoded in the original implementation. The value for the weight decay is set to 0.09 for all datasets (apart from the code of the authors, this assumption is also backed up by the main experiments of Koh, Steinhardt, and Liang [2]). The step size utilized in the IAF algorithm (and thus also in the Koh and Solans attack) is set to 0.1 for all experiments, as found in the codebase.
• The threshold of the anomaly detector (see [2]) is controlled by a hyperparameter named ”percentile”, which specifies the percentage of the data left after apply‐ ing the anomaly detector. We first experimented with a value of 95 as suggested by Koh, Steinhardt, and Liang [2] but, as this seemed to lead to some training failings, we settled on 90 (the default value given in the codebase).
• The number of injected poisoned points is proportional to the number of clean data points, such that |Dp| = ϵ|Dp| (where Dc and Dp are the set of clean and poisoned data points respectively). The authors control such quantity by using the proportionality factor ϵ as a changeable parameter. Accordingly, we do the same and also make λ a controllable parameter.
• After careful inspection and testing of the authors’ code, the EOD metric calcula‐ tionwas found to be faulty andwas consequently re‐implemented. Our adaptation is based on the paper that originally proposed it [12] and inspired by the implemen‐ tation found in the AIF360 library [14].
• Finally, the distance to original points in anchoring attacks τ was set to 0 for all experiments, as in the original paper.
• The random seed in all experiments was set to 1.
3.5 Computational requirements To give a complete overview of our experimental setup, we collect the average runtimes per iteration for different datasets and types of attacks. These are presented in Table 1. All models have been trained on a local machine with an AMD Ryzen 5 5600x CPU (6 cores, Base clock 3.7 GHz). Since the datasets are small, there is no need for more than 4Gb of RAM. In this sense, training should be virtually possible on any entry‐level PC.
4 Results
4.1 Results reproducing original paper As stated in Section 2, five main claims were identified in the original paper. In our specific setting, we were able to reproduce three of these, as summarized in Table 2. In this section we elaborate on our reproduction results: first, in section 4.1.1 we show the effect of the hyperparameter λ on variousmetrics (Claim 1). In section 4.1.2 we compare the newly proposed attacks and the baselines (Claims 2-5).
ReScience C 8.2 (#22) – Tafuro et al. 2022 7
0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6 1.8 2.0 Lambda ( )
0.0
0.2
0.4
0.6
0.8
1.0
Te st
E rro
r
German Dataset = 0.0 = 0.1 = 0.5 = 1.0
0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6 1.8 2.0 Lambda ( )
0.0
0.2
0.4
0.6
0.8
1.0
St at
ist ica
l P ar
ity D
iff er
en ce
(S PD
)
German Dataset = 0.0 = 0.1 = 0.5 = 1.0
0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6 1.8 2.0 Lambda ( )
0.0
0.2
0.4
0.6
0.8
1.0
Eq ua
lit y
of O
pp or
tu ni
ty D
iff er
en ce
(E OD
)
German Dataset = 0.0 = 0.1 = 0.5 = 1.0
0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6 1.8 2.0 Lambda ( )
0.0
0.2
0.4
0.6
0.8
1.0
Te st
E rro
r
Compas Dataset
= 0.0
= 0.1
= 0.5
= 1.0
0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6 1.8 2.0 Lambda ( )
0.0
0.2
0.4
0.6
0.8
1.0
St at
ist ica
l P ar
ity D
iff er
en ce
(S PD
)
Compas Dataset
= 0.0
= 0.1
= 0.5
= 1.0
0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6 1.8 2.0 Lambda ( )
0.0
0.2
0.4
0.6
0.8
1.0
Eq ua
lit y
of O
pp or
tu ni
ty D
iff er
en ce
(E OD
)
Compas Dataset
= 0.0
= 0.1
= 0.5
= 1.0
0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6 1.8 2.0 Lambda ( )
0.0
0.2
0.4
0.6
0.8
1.0
Te st
E rro
r
Drug Dataset = 0.0 = 0.1 = 0.5 = 1.0
0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6 1.8 2.0 Lambda ( )
0.0
0.2
0.4
0.6
0.8
1.0
St at
ist ica
l P ar
ity D
iff er
en ce
(S PD
)
Drug Dataset = 0.0 = 0.1 = 0.5 = 1.0
0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6 1.8 2.0 Lambda ( )
0.0
0.2
0.4
0.6
0.8
1.0
Eq ua
lit y
of O
pp or
tu ni
ty D
iff er
en ce
(E OD
)
Drug Dataset = 0.0 = 0.1 = 0.5 = 1.0
Stopping metric: accuracy
Figure 1. Influence of λ on the different metrics for different ϵ on the German dataset, using accu‐ racy as the stopping criteria during training.
Effect ofλ on the differentmetrics — To verifyClaim1, we conducted the same experiment as the authors. We run an IAF attack for each dataset using different ϵ values and increas‐ ing λ, to recreate Figure 3 of the original paper (see Appendix B.3, Fig. 8). However, compared to the original experiment we test a larger range of λ values (from 0 0 to 2.0) to gain better insights into its effects. As depicted in Figure 1, increasing λ does result in stronger attacks against fairness. Here we use the German dataset and accuracy as the stopping metric, but similar trends were observed on the other datasets and using fairness for early stopping. The plots are included in Appendix B.1 for the sake of com‐ pleteness. Therefore in this specific setup, we were able to reproduce the claim.
Comparison between the proposed attacks and the baselines — To investigate Claims 2-5 we de‐ sign an experiment that is heavily inspired by the work of the authors. We perform each attack on each dataset, fixing λ = 1 and gradually increasing ϵ (from 0.0 to 1.0, with steps of 0.1), and repeat this procedure for each stopping metric. The results essentially repli‐ cate Figure 2 of the original paper (as seen in Appendix B.3, Fig. 7) and are collected in Figures 5 and 6 of Appendix B.2. However, to facilitate a comparative study between the proposed attacks and the baselines, we average the metrics over the ϵ values and report the results in Table 3. In this way, we can base our observations on quantifiable measures instead of solely using visual inspection. Assuming that the authors used accuracy as the early stopping criteria, the correspond‐ ing values in the table reveal that – in this specific setting:
• Claim 2 is reproducible. On average, IAF has a much stronger influence on SPD and EOD compared to Koh’s attack, on all three datasets.
• Claim 3 is not reproducible, because Solan’s attack outperformed IAF in affecting the EOD on the Compas dataset.
• Claim4 is reproducible. NRAAandRAAwere found to degrade the fairnessmetrics (SPD and EOD) more than Koh’s attack, on all three datasets.
ReScience C 8.2 (#22) – Tafuro et al. 2022 8
• Claim 5 is not reproducible. Solans’ attack had a greater impact on the SPD than NRAA on the German and greater impact than NRAA on both SPD and EOD on the Compas dataset. It also has a greater impact on the EOD than the RAA attack on the Compas dataset.
4.2 Results beyond the original paper: using fairness as the early stopping metric While the original codebase seems to use accuracy as the early stopping metric (and hence for selecting and saving the best model), we investigate the change in the results if fairness is used instead. The main motivation behind such an experiment lies in the assumption that interrupting training based on the fairnessmeasures supposedly yields more relevant states of the poisoned data, effectively resulting in more efficient attacks against fairness. Since the SPD and EOD have similar behavior and equal range [0, 1], we employ average fairness (SPD + EOD)/2 for the task at hand. Figure 2 depicts the test accuracy and the average fairness over epochs for two differ‐ ent dataset‐attack combinations. An analysis of the curves confirms that the maximum achievable average fairness is much greater than the same measure at the point of min‐ imal accuracy (see Table 4). The same phenomenon is observed for any dataset‐attack combinations, as reported in Table 3: fairness undergoes a stronger degradation if av‐ erage fairness is used to interrupt the training process and save the best model. This is reflected in the corresponding values of the fairness measures, which appear much higher compared to when accuracy is used.
5 Discussion
Our reproduction reveals that although the proposed methods represent valid novel at‐ tacks against the fairness of a model, they are not always superior to other methods
ReScience C 8.2 (#22) – Tafuro et al. 2022 9
in the literature. IAF showed important performance in terms of SPD and EOD degra‐ dation, but anchoring attacks were outperformed by the baseline models on multiple occasions. This result conflicts with the findings of the main paper (see Appendix B.3, Fig.7)where the baselines are generally inferior to the proposed attacks. Wehad tomake several assumptions to solve issues and inconsistencies between the original paper and corresponding implementation (many of which have already been mentioned through‐ out the report, but we systematically collect them in Appendix A). These assumptions are, by definition, uncertain andmight have been the cause of the discrepant results. To better understand the source of discrepancy, we initially planned to perform an ablation study, which would have also unveiled more information regarding the model’s behav‐ ior. This was ultimately not possible, given the time constraints and the contingencies encountered in the reproduction process. In the remainder of this section, we elaborate on the main claims and our ability to reproduce them. We then present some personal reflections on the overall execution of the work and conclude with a summary and look into future works.
5.1 Discussion of the results The first claim was found to be reproducible under our experimental setup, as we ex‐ pected. The parameter λ is specifically designed to control the trade‐off between accu‐ racy and fairness, hence a rejection of the claim would have implied a major flaw in the core idea of the paper. The other claims focused on the comparison with the two baselines and, while the results presented in Section 4.1.2 are explicative enough, some remarks are still noteworthy. In general, better statistics of the results would give us a clearer insight into the relative performance of the models. However, only four weeks were allocated for this project and we were unable to re‐run the experiments with multiple seeds. For example, the Solans attack outperformed the IAF attack in terms of EODmetric on theCompas dataset (when using accuracy as the stopping method) and led to the non‐reproducibility of Claim 3. Yet, this difference is relatively small and a measure of uncertainty could po‐ tentially reverse our decision. Furthermore, it was shown that the final fairness metrics can highly vary depending on the chosen stopping method. This is especially prominent for Claim 4, which was accepted under the assumption that accuracy was used for stopping and saving the best model. In reality, Koh attack outperforms NRAA on both Compas and Drug datasets in the terms of SPD/EODmetrics, if fairness is used instead. Since the validity of the claim depends on the stopping metric of choice, we argue that the claim is much weaker than originally proposed. Similarly, compare the IAF and the Koh attack in terms of fairness measures, using accuracy as the stopping criteria. On the Drug dataset, IAF’s SPD/EOD metrics are respectively 2.89×/2.62× higher than Koh’s. This gap tightens if fairness is used: IAF’s SPD/EOD metrics become 1.022×/1.024× higher. Although these numbers indicate the same result, we find the claim to be weaker than proposed, as the superior performance of the IAF attack is diminished by the use of a different stopping metric. Finally it is important to notice the different behavior of the test accuracy and the aver‐ age fairness (Fig. 2) used as stopping criteria. While the latter has a relatively high vari‐ ance, the former is pretty constant, meaning that using fairness as the stopping metric does not result in significant variations in the model’s accuracy. Contrarily, as empiri‐ cally proved by our experiments, it can be highly beneficial for the fairness measures.
5.2 Reflection: What was easy? What was difficult? The new methods presented in the paper were described both intuitively and formally, with a clear mathematical structure. The authors also provided figures to aid the in‐ tuition on how new attacks can affect decision boundaries, which allowed us to easily understand the core novel ideas presented in the publication.
ReScience C 8.2 (#22) – Tafuro et al. 2022 10
However, it was not trivial to re‐implement the proposed methods, because many de‐ tails required for the implementation do not appear in the paper. The provided open‐ source implementationwas ultimately hard to follow due to its convoluted organization, lack of documentation, poorly named functions/variables, and abundance of unused code. Even setting up a working environment using the authors‐given dependencies took longer than one would expect, prompting us to get help from the authors. Eventu‐ ally, the hope to aid future experiments motivated the decision to make the code com‐ patible with up‐to‐date dependencies. This was one of the biggest struggles because the codebase heavily relies on packages that underwent major updates (e.g. TensorFlow and CVXpy). The authors also provided pre‐processed datasets. We spent a considerable amount of time trying to replicate their exact pipeline through reverse‐engineering of the given files. Additionally, after recognizing some imperfections in the code and inconsisten‐ cies with the paper, we verified all of the existing implementation details to make sure that no further errors were made. This was a daunting task, given the complete lack of documentation and intuitive variable use.
5.3 Communication with original authors To reiterate, we have initially contacted the main author to aid us with the dependency issues, who helped us with setting up a working environment. We then had additional contacts regarding the dataset pre‐processing procedure. The author provided us with some indications on the pipeline and pointed at some useful resources. Eventually, we decided to gain a better understanding of the datasets through reverse‐engineering.
5.4 Conclusion In this paper, we have presented a reproducibility study of ”Exacerbating Algorithmic Bias through Fairness Attacks”, whereon we can draw some conclusions. Due to all the mentioned issues and inconsistencies (collected in Appendix A), we find it not possi‐ ble to reproduce the original results from sole use of the paper, and difficult even in possession of the provided codebase. Yet, we managed to obtain similar findings that supported three out of the five main claims of the publication, albeit using partial re‐ implementations and numerous assumptions. Ascertaining the validity of such assump‐ tions is therefore important for future works. Moreover, further studies could extend the classifier to work with multiple demographic groups and investigate the results us‐ ing different fairness metrics."
['Andra\\vz De~Luisa'],[Re] Thompson Sampling for Bandits with Clustered Arms,10.5281/zenodo.6574671,Replication,R,https://zenodo.org/record/6574671/files/article.pdf,Multi-armed bandits Thompson sampling R rescience c machine learning,https://openreview.net/forum?id=r5LS3fmh0t,https://github.com/andrazdeluisa/reproducibility_challenge,8,2,2022,"This report covers our reproduction of the paper ‘Thompson Sampling for Bandits with Clustered Arms’ by Carlsson et al. (IJCAI 2021) [1]. The authors propose a new set of al‐ gorithms for the stochasticmulti‐armed bandit problem (and its contextual variant with linear expected rewards) in settings when the arms are clustered. They show both theo‐ retically and empirically that exploiting the cluster structure significantly improves the obtained regret over the traditional assumption with non‐clustered arms. Furthermore, they compare the proposed algorithms to previously proposed and well‐known bench‐ marks for the bandit problem. We aim to reproduce just the empirical evaluations.","The authors have included in the paper all the necessary details to reimplement their proposed algorithms, recreate the synthetic datasets, and reproduce the experiments for the first part, i.e. the traditional multi‐armed bandits setting.
Copyright © 2022 A. De Luisa, released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Andraž De Luisa (ad9366@student.uni-lj.si) The authors have declared that no competing interests exist. Code is available at https://github.com/andrazdeluisa/reproducibility_challenge – DOI 10.5281/zenodo.6498328. – SWH swh:1:dir:d1d7fa93e952cf14154d5415f253b6507af22833. Open peer review is available at https://openreview.net/forum?id=r5LS3fmh0t.
ReScience C 8.2 (#23) – De Luisa 2022 1","It is much harder to reimplement some of the referenced benchmarks. The main rea‐ sons for these struggles are the inconsistent nomenclature, important details missing in the referenced papers, and some of the compared benchmarks being originally de‐ signed to run in a different setting. Furthermore, some additional research into the field of contextual bandits is needed to reproduce the second part of the experiments.
Communication with original authors There has been no communication neither with the authors of the original article nor with any authors of the referenced papers.
1 Introduction
Themulti‐armed bandit is a classical reinforcement learning problem, formally defined for the first time already by Robbins in 1952 [3], focused on the exploration versus ex‐ ploitation trade‐off. Its name is derived from gambling: imagine a gambler sitting in front of a row of slot machines, deciding which arm to pull next hoping to maximise the prize money (to minimise his loss, actually). The same name is used for whatever problem involves a learner and a fixed set ofN actions to repeatedly choose from, with each action returning a stochastic reward. The learner aims to maximise its obtained reward in a finite number of steps T . He does therefore repeatedly face the dilemma of whether to exploit what he believes to be themost convenient action, or to explore other actions, hoping to find an even better one. In the beginning the learnermight have been provided with some additional info about the available actions or not, it depends on the setting of the problem. Anyway, he constantly updates his knowledge about the actions based on the obtained rewards. An interesting and useful generalisation is the contextual bandit. At each iteration the learner gets an additional context vector which he can use, in addition to the past re‐ wards, to choose his next action. His goal over time is to get enough information about how the context vectors and rewards are related, to be able to predict the best arm by looking at feature vectors. Both mentioned types of multi‐armed bandits are analysed also in the paper we aim to reproduce, Thompson Sampling for Bandits with Clustered Arms by Carlsson et al. [1]. The problems defined in the article have an additional, defining characteristic: the arms are clustered (both in the analysed classical and contextual bandits). The leading idea is to understand howmuch can the obtained reward be optimised if the learner can leverage the additional knowledge on the relations between arms. Themulti‐armed bandit problem (with itsmultiple variants) can be successfully applied to some common usecases. Let’s take a recommender system on an e‐commerce web‐ site as an example to better explain all the mentioned settings. When a user visits the homepage of the website, an agent in the background has to decide which product to show him first, hoping he will eventually buy it (thus obtaining a reward). Without any additional knowledge about the user, this example represents a classical multi‐armed bandit. However, the items on sale are not completely unrelated between them. If they can be grouped in meaningful clusters, for which we expect similar selling success, the problem translates to a multi‐armed bandit with clustered arms. These clusters might even be hierarchically structured (e.g. the items are clustered into electronics and clothes, with the latter further divided into sports and elegant clothing). Furthermore, if some data about the user is also available (i.e. a context vector), we talk about a contextual multi‐armed problem, with the context influencing the obtained reward (since users’ preferences vary).
ReScience C 8.2 (#23) – De Luisa 2022 2
2 Scope of reproducibility
The main goal of the original paper is “to show, both theoretically and empirically, how exploiting a given cluster structure can significantly improve the regret and computational cost compared to using standard Thompson sampling” [1]. To achieve it, new algorithms based on a multi‐level Thompson sampling scheme [4] are proposed. These algorithms are de‐ signed to solve the stochastic multi‐armed bandit with clustered arms (MABC) problem and its contextual variant (CBC) with linear expected rewards (linearly dependent on the given context vector). Under some specific assumptions (mainly strong dominance of the best cluster and Bernoulli distributed arm rewards), theoretical bounds on the regret are provided, with the dependence on the number of armsN removed in favor of dependence on the properties of the selected clustering. The algorithms are then tested on some specifically constructed datasets that meet the assumptions, as well as com‐ pared with other recently proposed algorithms that solve the MABC and CBC problems even in settings where the theoretical assumptions are violated. The results indicate the theoretical guarantees hold true and the proposed algorithms are at least comparable with the evaluated baselines (and most often outperforming them). In this work, we aim to fully reproduce all the experiments described in the paper. We divide the claims we focus our work on into three subsections for clearness.
1. ClassicalMABC settingwith clusterings thatmeet the required theoretical assump‐ tions
• In flat clusterings, the proposed algorithm (TSC) outperforms the baseline (Thompson sampling – TS).
• In hierarchical clusterings, the proposed algorithm (HTS) outperforms the baseline (TS).
• Regret does only depend on the clustering quality, not on the number of arms N .
2. Classical MABC setting with clustering that violates the defined assumptions
• The proposed algorithms (TSC, HTS) still perform better than TS (in both flat and hierarchical settings).
• TSC and HTS are at least comparable (and most often better) than other, re‐ cently proposed algorithms that also solve the MABC problem.
3. Contextual bandits variant (CBC)
• The proposed algorithm LinTSC outperforms the baseline LinTS. • LinTSC is at least comparable and most often better than other, recently pro‐ posed algorithms that also solve the CBC problem.
3 Methodology
Given that no code was provided alongside the original paper (and neither with any of the articles where the benchmarks used for comparison are described), we implement everything from scratch 1. Additional details about the proposed algorithms and how we implement them follow in the next section 4.
1The code required to reproduce all the experiments is available on the GitHub repository https://github.com/ andrazdeluisa/reproducibility_challenge
ReScience C 8.2 (#23) – De Luisa 2022 3
3.1 Datasets We don’t use any externally provided dataset, all the experiments are run with synthet‐ ically generated data, following the instructions in the paper. For each experiment we prepare a separate dataset. The multi‐armed bandit is a special case of a reinforcement learning problem, and as such doesn’t require any split into training or test data, the agents learn and take actions simultaneously.
3.2 Computational requirements We write our code exclusively in R [2], the well‐known programming language for sta‐ tistical computing, and use some of its basic libraries for data manipulation and visu‐ alisation (ggplot2 [5], stats [2], mvtnorm [6]). We run the experiments on a laptop with a dual‐core Intel i7 6th generation processor and 8 GB of RAM. We don’t use a GPU. The computational resources are very limited, but the nature of the problem doesn’t require huge processing, thus allowing us to smoothly run all the required experiments. Some slow down is observed in the runs with a higher number of arms and actions, but we still manage to evaluate the models over multiple (up to 100) seeds in a couple of hours, which is crucial to get accurate estimations of their performance.
4 Experiments
As described in [1], a standard multi‐armed bandit (MAB) problem is defined with a set of N arms A, a finite number of steps T and reward functions rt(at) which depend on the played arm at at the timestep t, but might as well depend on the timestep t itself. In MABC and CBC problems, the arms are additionally divided into (flat/disjoint or hierar‐ chical) clusters. Rewards are drawn from some distribution rt ∼ Dat , with an unknown mean EDat [rt] = µat . The goal of the learner is to maximise the expected cumulative reward over a sequence of T time steps or, equivalently, to minimise its expected cu‐ mulative regret E[Rt] w.r.t. the optimal arm at∗ = argmaxat∈Aµat∀t ≤ T (the cumula‐ tive regret represents how much reward did the learner lose due to not always playing the best arm 2). Rewards might be drawn from arbitrarily chosen distributions, but to simplify the derivation and proof of theoretical bounds for the cumulative regret, only Bernoulli and uniformly distributed rewards are used in the original paper. Since the reward functions differ in different MAB settings, we provide additional details about them in the following sections.
4.1 Classical MABC In the experiments with classical MABC problems, all the rewards are drawn from a Bernoulli distribution rt(at) ∼ Bernoulli(θat). The parameters θa are defined in ad‐ vance (but not known to the learner) and constant for each arm a, therefore the cumu‐ lative regret can be defined as R = ∑T t=1 θa∗ − rt(at), where θa∗ = maxa∈Aθa is the
expected reward for playing the best arm. The arms are divided into clusters based on their θ value. These clusters might be disjoint (each arm gets assigned to exactly one cluster) or hierarchical (each arm gets assigned to exactly one leaf in a clustering tree). Not all algorithms can solve both types of the MABC problem. The baseline algorithm that solves a MAB problem is Thompson sampling (TS) [4], first designed by Thompson in 1933 (much before the MAB problem was even formalised). It doesn’t take into account any clustering information (thus being able to solve all the proposed MABC settings). The main idea behind it is to select which arm to play at the
2Notice that the regret might be (and often is) negative at single timesteps when positive rewards are ob‐ served.
ReScience C 8.2 (#23) – De Luisa 2022 4
current step probabilistically, i.e. with respect to the current belief about the arms re‐ ward distributions. The learner starts with assigning uninformative Beta(1, 1) priors over expected rewards θa ∈ [0, 1] to each arm a (the Beta distribution was chosen due to its conjugate characteristic). Then, at each step, it takes a random sample from the Beta(St(a), Ft(a)) distribution for each arm, and plays (greedily) the arm with the high‐ est sampled expected reward. The posterior belief in that arm’s true θ value is then up‐ dated according to the observed reward r: St+1(a) = St(a)+r, Ft+1(a) = Ft(a)+(1−r). Since the learner doesn’t get any information about the arms that were not played, the other posteriors are not updated. The newly proposed algorithm that exploits the disjoint clustering structure (TSC [1]) is based on the exact same idea as TS, but adds an additional level to the selection of the arm to play. Instead of sampling from the arms’ priors directly, it keeps prior beliefs for the clusters too and samples from themfirst. When the cluster with the highest sampled expected reward is selected using TS, the procedure is repeated for the arms within that cluster. Then the posteriors (both for the selected cluster and played arm) are updated according to the observed reward. The proposed algorithm for theMABC problemwith hierarchically clustered arms (HTS [1]) is a natural extension of TSC: it applies the Thompson sampling at each node to select in which subtree to search for the arm to play. TSC is basically a HTS on a tree with depth 2, while TS is a HTS on a tree with depth 1 (a single node with N leaves). The assumptions on the clustering structures required for the theoretical regret bounds to hold are quite tight, assuming strong dominance (and hierarchical strong dominance) between the clusters. This actually means that every arm from the optimal cluster must have a higher expected reward than any other arm from the other clusters (in the hier‐ archical structure, this condition is applied at each node level). The authors, therefore, provide precise instructions for the construction of synthetic datasets on which the al‐ gorithms are tested. To build a strongly dominant disjoint clustering structure on which to test the proposed algorithms, we need to define the following hyperparameters:
• the number of arms N ,
• the number of clustersK,
• the size of the optimal cluster A∗,
• the width of the optimal cluster w∗,
• the distance of the other clusters to the optimal one d,
• and the number of timesteps T .
The arms are divided into clusters randomly. The probabilities assigned to the arms in the optimal cluster are sampled uniformly from U(0.6 − w∗, 0.6), while those in the other clusters are sampled from U(0.5 − w∗ − d, 0.6 − w∗ − d). In all the clusters, two arms get assigned the upper and lower bound of the interval their values were sampled from (e.g. the highest expected reward is always 0.6). In the Results section 5, we show how those hyperparameters influence the obtained cumulative regret. The hierarchical datasets are built in a completely different way (and require fewer hy‐ perparameters). The probabilities assigned to the arms are sampled uniformly from U(0.1, 0.8) and then recursively sorted and merged into a balanced binary tree that meets the hierarchical strong dominance assumptions (i.e. at each node, the top half of the arms gets assigned to a subnode and the bottom half to the other). Other than the number of arms N and timesteps T , the defining hyperparameter is the number of levels L 3.
3Notice that a single‐level tree represents a MAB, and a two‐level one a MABC problem.
ReScience C 8.2 (#23) – De Luisa 2022 5
Classical MABC with violated assumptions — The strong dominance condition is difficult to meet in real‐life scenarios, therefore we evaluate the performance of the proposed al‐ gorithm also on datasets where this assumption is not met, and compare them to other well‐knownalgorithms that solve theMABCproblem. Wegenerate the synthetic datasets in a completely different way: we assign a parameter xa ∼ U(0, 1) to each arm, group them intoK clusters using the K‐means algorithm and then convert their parameters to probabilities with θa = f(xa), where f(x) = 12 (sin (13x) sin (27x) + 1). The function is smooth, therefore arms in the same cluster have similar expected rewards, but its peri‐ odicity ensures there are no strongly dominant clusters. For the hierarchical structure, we repeat the same process at each level. The proposed algorithms based on Thompson sampling are compared to the following ones:
• The UCB1 [7] (Upper Confidence Bound) algorithm solves the MAB problem (ig‐ nores the clustering structure). It is based on a deterministic policy, which at each step selects the arm that maximises the expression r̄a + cp √ 2lnn na
, where r̄a is the average reward obtained from arm a so far, na the number of times a was played and n the total number of plays. Each arm needs to be played once at the begin‐ ning for initialisation.
• The UCBC algorithm (designed as TLP – Two Level Policy – by Pandey et al. [8], named UCBC in [9]) is an extension of UCB1 to clusters. It uses a two‐level selec‐ tion schema, with first selecting the best cluster with respect to the UCB1 formula, and then playing the best arm from the cluster. A policy on how to represent the clusters need to be chosen. Since the authors of [1] don’t mention which one they use, we choose to implement the MAX policy (which [8] states to perform best). With the MAX policy, each cluster is represented by its best arm (other proposed policies are MEAN and PMAX).
• The TSMax algorithm (named HTS when first proposed in [10], renamed to avoid misunderstandings) is extremely similar to the TSC. The only difference is that the clusters’ posterior beliefs are defined as the posterior of the current best arm inside the cluster.
• The UCT algorithm (Upper Confidence Bound for Trees [11]) is an extension of the UCB1 algorithm to hierarchical clustering structures. It applies theUCB1 selection procedure recursively at each node and selects the most promising one until a single arm is selected.
4.2 Contextual CBC In the experiments with CBC problems, the expected values of the rewards are linearly dependent on the context vector xt ∈ Rd and arm parameters θa ∈ Rd: E[rt(a)|xt] = xTt θa. The parameters θa are defined in advance (but not known to the learner) and re‐ main constant throughout the experiment, while a different context xt is observed at each timestep t ≤ T . The rewards are uniformly distributed rt(at) ∼ U(0, 2xTt θat). The cumulative regret is defined as ∑T t=1 x T t θa∗t − rt(at), where θa∗t = argmaxa∈A x T t θa is
the best arm for the given context (the best arm is not always the same). The arms are grouped into clusters based on their θa parameter vector. We use only disjoint cluster‐ ings in our experiments. A baseline algorithm, derived from Thompson sampling, that solves the CBCwith linear expected rewards is the LinTS (first mentioned by Agrawal et al. [12]). It’s similar to TS in the MABC setting: at every step it samples from the prior distributions of the arms’ parameters, plays the arm with the highest sampled expected reward and it doesn’t use any clustering information. The learner startswith uninformative standardmultivariate
ReScience C 8.2 (#23) – De Luisa 2022 6
normalN(0, I) priors for parameter θa distributions (the Gaussian distribution was cho‐ sen due to its conjugate characteristic). At each step it samples fromN(xTt µa, xTt B−1a xt) for each arm, and plays (greedily) the arm with the highest sampled expected reward. The posterior belief in that arm’s θc value is then updated according to the observed context and obtained reward: Bat = Bat + xtxTt , fat = fat + rxt, µat = B−1at fat . The posteriors for the other arms are not updated. The newly proposed algorithm that exploits the disjoint clustering structure (LinTSC [1]) is based on the same idea as LinTS, but adds an additional level to the selection of which arm to play (it keeps prior beliefs also for each cluster, and updates them according to the obtained rewards). LinTSC relates to LinTS in the same way as TSC relates to TS. The proposed algorithms based on Thompson sampling are compared to the following ones:
• The LinUCB (Linear Upper Confidence Bound [13]) algorithm solves the CBC prob‐ lem (it ignores the clustering structure). The arm selection procedure is inspired by its MABC counterpart: the learner plays the arm that maximises the expres‐ sion: xTt θa α √ xTt Baxt. It basically applies online ridge regression to estimate the
parameters. The values for θa and Ba are computed and updated in the same way as in LinTS.
• The LinUCBC (Linear Upper Confidence Bound for Clusters [9]) algorithm is an extension of LinUCB to clustered set of arms. It is based on the LinUCB algorithm, but adds another level to the arm selection procedure: it first selects which cluster and then which arm to play next.
There are no strict assumptions that the synthetic datasets for CBC problems should meet. Contextual data is generated in the same way as in [9]: we have N arms and K clusters, each arm j is uniformly randomly assigned to a cluster i. For each cluster we sample a centroid θci ∼ N(0, I5) and assign the parameters to its arms as follows: θj = θ c i + ϵν, ν ∼ N(0, I5). We control the expected diameter of a cluster by varying ϵ. We generate the context at each timestep as is described in [9], sampling them from a multivariate standard normal distribution.
5 Results
There are no exact numbers in the original paper to reproduce, rather the main claims are supported with visualisations. With this in mind, our reproduction confirms the advantage provided by clustering over the assumption of independent arms, as well as the newly proposed algorithms outperforming the referenced benchmarks. We repeat all the experiments with multiple seeds to obtain robust estimates of the algorithms’ performance and reduce the risk of drawing any conclusions out of results obtained by chance. We show the obtained results in Figures 1 and 2 (the estimates are obtained with evaluations over multiple – 25 to 100 – random seeds). We provide details on single reproduced claims (as defined in Section 2) in the following subsections.
5.1 Classical MABC In Figure 1 we show all the obtained results from the experiments within the classical MABC problem setting (as described in the previous section), with plots 1a ‐ 1e present‐ ing the disjoint and plot 1f the hierarchical clustering. The results clearly show that taking into account the clustering structure of the arms significantly increases perfor‐ mance (i.e. lowers the cumulative regret). Our results are perfectly in line with those reported in the original paper. In each one of the plots we show how a dataset’s hyper‐ parameter affects the learner’s performance:
ReScience C 8.2 (#23) – De Luisa 2022 7
0
200
400
600
0.01 0.05 0.1 0.15 0.2 0.25 0.3 d
C um
ul at
iv e
re gr
et
TS TSC
(a) w* = 0.1, N = 100, A* = K = 10.
0
200
400
600
0 0.1 0.2 0.3 w*
C um
ul at
iv e
re gr
et
TS TSC
(b) d = 0.1, N = 100, A* = K = 10.
0
200
400
600
10 30 50 70 90 110 130 150 N
C um
ul at
iv e
re gr
et
TS TSC
(c) w* = d = 0.1, A* = K = ⌊ √ N⌋.
0
200
400
600
2 5 10 15 20 25 K
C um
ul at
iv e
re gr
et
TS TSC
(d) w* = d = 0.1, N = 100, A* = 10.
0
200
400
600
10 20 30 40 50 A*
C um
ul at
iv e
re gr
et
TS TSC
(e) w* = d = 0.1, N = 100, K = 10.
0
250
500
750
1000
0 1 2 3 log2(N) L
C um
ul at
iv e
re gr
et
HTS N = 50 HTS N = 100 HTS N = 1000 HTS N = 5000
(f) Dependence on the number of levels L.
paper. Since TSMax does also exploits clustering and just slightly differs from TSC, we believe the authorsmust havemade somemistakes in its implementation (they report a worse performance than UCBC).
• Figure 2b: TSC clearly stands out from the others in term of performance when we significantly increase the number of arms N . Again we observe better TSMax performance than reported.
• Figure 2c: UCT algorithm performmuch worse than HTS (note that TSC is an HTS with L = 1). The obtained regrets are in line with the original paper, but we ob‐ serve higher uncertainty in our estimations (although we repeated each experi‐ ment the same number of times and show the errorbars in the same way – ± 1 standard deviation).
5.3 Contextual CBC In Figures 2d ‐ 2f we show the results of our experiments with the contextual bandits algorithms. The single plots present the evaluations on datasets generated with differ‐ ent hyperparameters, however they all have the same shape, hence we can analyse all of them together. We can see that in the CBC problem, the algorithms that leverage the clustering information heavily outperform the others, while there is no significant dif‐ ference between UCB‐ and TS‐based methods. The authors of the original paper here claim that LinTSC slightly outperforms LinUCBC, but fromour results we definitely can’t draw the same conclusion.
6 Discussion
With our work we are able to successfully reproduce the results obtained by the authors of the original paper. As explained in the previous section, some of our results differ slightly from those reported in the paper mostly with respect to variance of the esti‐
ReScience C 8.2 (#23) – De Luisa 2022 9
mates, but they still support the main claims. However, we have to point out a couple of potential issues that we identified in their work. First of all, Upper Confidence Bound algorithms rely on the initialisation step during which each arm should be played once. If we look again at Figures 2b or 2c, we see that those learners spent a significant amount of the allocated time just playing each arm one by one. Furthermore, for t < 1000, the presented numbers are just the result of playing the first N arms, therefore determined by their ordering. Some more concerns arise when dealing with the CBC problem. In the original paper, each arm has its own parameter vector θa that we want to learn from the obtained re‐ wards and given contexts xt. They mimic the same setting as in Bouneffouf et al. [9]. However, the other two algorithms (LinTS and LinUCB) are designed for a different set‐ ting, where a different context is given for each arm at every timestep. Furthermore, per [9], the expected reward should be linearly dependent on the context and played arm’s feature vector, but the reward itself should lie inside [0, 1]. This is clearly in contrast with our CBC setting, where both negative and larger rewards are possible (and actually really common too). We can’t expect dot products of normally sampled vectors to always fulfill these conditions.
6.1 What was easy The authors have included in the paper all the necessary details to reimplement their proposed algorithms, recreate the synthetic datasets, and reproduce the experiments for the first part, i.e. the classical MABC setting.
6.2 What was difficult It is much harder to reimplement some of the referenced benchmarks. The main rea‐ sons for these struggles are the inconsistent nomenclature (the referencedpaper presents multiple algorithmswhichwere designedwith a different name than the one used in the reproduced paper), important details missing in the referenced papers, no code avail‐ able whatsoever and some of the compared benchmarks being originally designed to run in a different setting (especially true for CBC problems). Furthermore, some addi‐ tional research into the field of contextual bandits is needed to reproduce the CBC part of the experiments, since due to all the inconsistencies between the different papers, we had a hard time understanding how are contextual bandits supposed to work.
6.3 Communication with original authors There has been no communication neither with the authors of the original article nor with any authors of the referenced papers."
"['Diego van der Mast', 'Soufiane Ben Haddou', 'Jacky Chu', 'Jaap Stefels']","[Re] Replication Study of ""Fairness and Bias in Online Selection""",10.5281/zenodo.6574673,Replication,Python,https://zenodo.org/record/6574673/files/article.pdf,rescience c rescience x Python machine learning fairness,https://openreview.net/forum?id=SNeep2MXn0K,https://github.com/Di-ayy-go/fact-ai,8,2,2022,"In this paper, we work on reproducing the results obtained in the ’Fairness and Bias in Online Selection’ paper [1]. The goal of the reproduction study is to validate the 4 main claims made in [1]. The claims made are: (1) for the multi‐color secretary problem, an optimal online algorithm is fair, (2) for the multi‐color secretary problem, an optimal offline algorithm is unfair, (3) for the multi‐color prophet problem, an optimal online algorithm is fair (4) for the multi‐color prophet problem, an optimal online algorithm is less efficient relative to the offline algorithm. To test if the results of the secretary algorithmgeneralize to other data sets, the proposed algorithms and baselines are applied to the UFRGS Entrance Exam and GPA data set [2].","The concepts behind the algorithms were straightforward. The existing code base pro‐ vided a solid reference point to verify the results of the original paper by compiling and running the provided code.
Copyright © 2022 D.V.D. Mast et al., released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Diego van der Mast (diego.vandermast@student.uva.nl) The authors have declared that no competing interests exist. Code is available at https://github.com/Di-ayy-go/fact-ai – DOI 10.5281/zenodo.6518051. – SWH swh:1:dir:45176f5005ed390a349cd01e61ed37711095879e. Open peer review is available at https://openreview.net/forum?id=SNeep2MXn0K.
None 8.2 (#24) – Mast et al. 2022 1","Implementing the prophet algorithm, in comparison to the secretary algorithm, was complex. C++ is a more efficient compiler (time complexity, etc.) compared to Python. For the reproduction of the algorithms, this needed to be taken into account. While it might be possible to execute transliterated code on a powerful machine, with the avail‐ able resources the code would have taken over 96 hours to run. In order to tackle this problem, some of the data structures needed to be converted to NumPy arrays to de‐ crease computation time.
2 Introduction
As more machine learning algorithms are used in decision‐making circumstances, it is important to ensure that social norms are not violated. The social norm that serves as the pivot of this research is fairness. Specifically ’fairness’ in the use of selectionmodels. The importance of fairness is to avoid undesirable biases. Selection models are models that input a finite amount of agents and attempt to pick the best possible candidate (agent). The goal is to design algorithms that can fairly judge between agents regardless of any unfair bias. In some real‐life implementations of selection models, there is no clear overview of all agents. For example, in the online selection problem, the agents enter the algorithm sequentially. For every agent, a decision has to bemadewhether this is the best possible agent. The complexity of this task is not being able to have any knowledge on agents that might come in the future. As soon as the decision is made that an agent is the best fit, the algorithm should stop as that agent is the optimal candidate (according to the model). Multiple attempts have been made to create the most accurate algorithm for these online selection models. For this research, we reproduce the ’Fairness and Bias in Online Selection’ paper [1]. In this paper, the authors focus on 2 main problems: the secretary problem and the prophet problem. The secretary problem is a scenario for the sequential selection prob‐ lem where an attempt is made to select the candidate with the highest value without knowing the value of the candidates to come. An immediate decision has to be made on the candidate, the candidate either gets picked or gets passed on. For the prophet algorithm the same assumptions are made as for the secretary algorithm, but we know the distributions the candidate values are drawn from. The probability of the candidate is based on these distributions. In the case of both problems, the goal is to stop at the best possible candidate based on the assigned probabilities. In order to include a form of fairness in these models, a concrete definition needs to be given to fairness in online selection models. Based on the [1] paper, fairness is defined as an unbiased evaluation of agents in a selection model. A selection algorithm is fair if it selects the best candidate, closely following the original probability of the best can‐ didate existing in that group. Along with fairness, efficiency has also been used as an evaluation metric in the original paper. Efficiency is a measure of how accurately the online algorithm picks the actual best candidate. By creating a ’fair’ version for these problems, the authors claim to have created a fair use of sequential single item selection models. Through categorization of the agents by color, a distinction between the agents can be made. However, the qualities these agents possess might be different enough that they could be considered incomparable. So implementing a multi‐color version of the sequential selection models and picking the best possible candidate, taking color into account, an ’unfair’ comparison is avoided.
None 8.2 (#24) – Mast et al. 2022 2
3 Scope of reproducibility
In this reproduction study, we focus on the authors’ claims that the use of a multi‐color version of the secretary and prophet problem would make the use of these algorithms fair. The authors of the paper implement these algorithms on synthetic data sets and real‐world data sets. For our study, we put an effort into reproducing the results given by the paper. The goal of this reproduction is to either validate or deny the claimsmade in the paper. This effort has been fulfilled by re‐implementing the code publicly available for the algorithm. This re‐implementation is done in Python in comparison to the C++ code provided by the authors. Most of the code has been written using NumPy to try and achieve about the same efficiency as the C++ code. However, the setup for the experiments corresponds to that of the authors. To show that the claims generalize well over differently distributed data sets, we run the proposed algorithms and baselines on the UFRGS Entrance Exam and GPA data set [2]. The claims made in the [1] paper are:
• Claim 1: For themulti‐color secretary problem, an optimal online algorithm is fair.
• Claim 2: For the multi‐color secretary problem, an optimal offline algorithm is unfair.
• Claim 3: For the multi‐color prophet problem, an optimal online algorithm is fair.
• Claim 4: For the multi‐color prophet problem, an optimal online algorithm is less efficient relative to the offline algorithm.
To test these claims we use the algorithms mentioned above on 4 types of data sets. These data sets are further discussed in section 3.3.
4 Methodology
In this section, our approach to the re‐implementation of the experiments will be dis‐ cussed and an additional experiment will be proposed.
4.1 Code The code accompanying the paper is provided in C++. As required for this study, we reproduced the work in Python, and subsequently made use of the inherent Pythonic efficiencies. The provided code allowed for a smooth initial reproduction. However, many optimisations were required to decrease computation duration.
4.2 Model descriptions In the original paper, two types of single item selection models are considered: the sec‐ retary algorithm and the prophet algorithm. Candidates are partitioned into different groups which the authors refer to as colors. Every candidate has a numerical value that indicates the capabilities of that candidate. The authors refer to these indicators as values. Candidates arrive sequentially, and upon arrival, the algorithms decide whether the candidate is the best candidate overall. The best candidate is defined as the candi‐ date with the highest value of the sequence of candidates. For clarity, the main parts of the Methodology and Results sections are divided per model.
None 8.2 (#24) – Mast et al. 2022 3
Secretary Algorithm — For the secretary algorithm, it is assumed that candidates arrive in uniformly random order. To verify the claims made by the author, we compare the optimal online algorithm as proposed by [1] to two baselines. Additionally, the algo‐ rithm and its baselines are applied on different data sets, either synthetically generated or composed from real‐word data sets. The optimal online algorithm proposed by the authors (Fair secretary algorithm) is denoted formally as:
where the input t = (t1, ..., tk) is a vector of thresholds, one for each color j ∈ [k]. The algorithmfirst checks if the candidate i arrived after the threshold of its color tc(i). If this condition is met, it accepts the candidate if its value exceeds the value of all previous candidates of color tc(i), indicating that it is the best candidate for that color. After having chosen the best candidate of each color, we are interested in selecting the best overall candidate. We denote the probabilities with which the best candidate of group j is the best among all colors by pj , which results in the vector p = (p1, ..., pk) covering all colors. We use this in our experiments to verify the claims of the author using equal, and unequal values for p among colors.
Prophet Algorithm — For the prophet algorithm, the same assumptions aremade as for the secretary algorithm, but we know the distributions Fi the candidate values are drawn from. In the paper, the authors propose two optimal online algorithms specified in figure 1, where q1, · · · , qn denote the marginal probabilities that the optimal fair offline algorithm picks the candidates i = 1, · · · , n. Figure 1a shows the general Fair prophet al‐ gorithm (Fair prophet algorithm). This algorithm does notmake any assumptions about the underlying probability distribution, it can be different for every candidate. Figure 1b shows the Fair independent and identically distributed prophet algorithm (Fair IID prophet algorithm). This algorithm assumes that the values of the candidates are drawn from the same distribution.
None 8.2 (#24) – Mast et al. 2022 4
4.3 Data sets The experiments involving the SA algorithm are conducted on two synthetic data sets and two real‐world data sets. The data sets and their properties are summarised below:
1. Synthetic data set, equal p values contains four different colors with 10, 100, 1000, and 10000 occurrences. The value of each element is chosen independently and uniformly at random from [0, 1].
2. Synthetic data set, general p values contains a similar setup as 1, but with p = (0.3, 0.25, 0.25, 0.2).
3. Feedback maximization (Bank) contains records of direct marketing campaigns (phone calls) by a Portuguese banking institution [3]. The clients are split into 5 colors by age: under 30, 31‐40, 41‐50, 51‐60, and over 61 years old. The value of every client is the duration of the phone call. Moreover, an equal p of 0.2 was used for all colors.
4. Influence maximization (Pokec) contains records of the influence of users of the Pokec social network [4]. We pre‐process the data by dividing the users into 5 dif‐ ferent colors according to their body mass index (BMI): under weighted (BMI < 18.5), normal (18.5 <= BMI < 25), over weighted (25.0 <= BMI < 30.0), obese type 1 (30.0 <= BMI < 35), and obese type 2 (BMI >= 35.0). The value is computed as the number of the followers for each user. Again, an equal p of 0.2 was used for all colors.
4.4 Experimental setup In this subsection, the experimental evaluation performed by the authors is discussed. As before, a distinction between the two problems is made for clarity. Additionally, an extra experiment will be considered where the secretary algorithm will be evaluated on another real‐world data set. Secretary experiments The authors propose two different baselines to compare the Fair secretary algorithm to. Firstly, the classic secretary algorithm (SA), which does not take the colors of the candidates into account. Secondly, the single‐color secretary algorithm (SCSA). This algorithm picks a color proportional to the p values and then runs the classic secretary algorithmon the candidates of only that color. To evaluate the claims by the authors, the three mentioned algorithms are evaluated against the four data sets discussed earlier. The parameters of these experiments consist of the size of the data sets and the number of repetitions. For the experiments on the Synthetic data sets (equal p / general p) and the Bank data set, all available candidates were used in 20.000 repetitions. In the orig‐ inal paper, the authors used all ± 650.000 candidates of the Pokec data set in 1000.000 repetitions. In our experiment, we had to limit these parameters due to time constraints. We only considered the first 40.000 candidates and used 40.000 repetitions."
"['Andy Chen', 'Shion Matsumoto', 'Rohan Sinha Varma']",[Re] Projection-based Algorithm for Updating the TruncatedSVD of Evolving Matrices,10.5281/zenodo.6574675,Replication,Python,https://zenodo.org/record/6574675/files/article.pdf,rescience c machine learning python pytorch,https://openreview.net/forum?id=HN2xWpMQ30K,https://github.com/andyzfchen/truncatedSVD,8,2,2022,"Kalantzis et al. [1] present a method to update the rank‐k truncated SVD of matrices where the matrices are subject to periodic additions of rows or columns. The main claim of the original paper states that the presented algorithms outperform other state‐ of‐the‐art approaches in terms of accuracy and speed. However, no results were given comparing the proposed methods to other state‐of‐the‐art methods. Accordingly, we reproduce their results and compare it to the state‐of‐the‐art FrequentDirections streaming algorithm [2].","The benchmark algorithm was fairly simple to implement. Furthermore, running the experiments did not place any computational resource burden as all experiments could be run on a laptop.
1https://github.com/andyzfchen/truncatedSVD
Copyright © 2022 A. Chen, S. Matsumoto and R.S. Varma, released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Andy Chen (andych@umich.edu) The authors have declared that no competing interests exist. Code is available at https://github.com/andyzfchen/truncatedSVD. – SWH swh:1:dir:4116fecf6ec4ac207cdad025ec62b25839a75678. Open peer review is available at https://openreview.net/forum?id=HN2xWpMQ30K.
ReScience C 8.2 (#25) – Chen, Matsumoto and Varma 2022 1","The most difficult part of the reproduction study was understanding the justification underlying the construction of the algorithm as it involved several complex proofs from numerical linear algebra to provide bounds on the accuracy. Demystifying the specifics of constructing the projection matrix for the main algorithm the author’s propose was also initially difficult until we gained access to their code.
Communication with original authors
We contacted one of the authors by email and received their data and MATLAB imple‐ mentation of the algorithm and experiments.
ReScience C 8.2 (#25) – Chen, Matsumoto and Varma 2022 2
1 Introduction
The singular value decomposition (SVD) remains a fundamental dimensionality reduc‐ tion technique inmachine learning and continues to be used in a variety of applications. In a traditional formulation, the entirety of the matrix to be decomposed is available at the time of application of the SVD. However, certain applications, such as latent se‐ mantic indexing (LSI) and recommender systems, have matrices that are subject to the periodic addition of new rows and/or columns. A naïve solution is to recalculate the SVD each time the matrix is updated, but such an approach quickly becomes impracti‐ cal when updates are frequent. For this reason, algorithms that exploit information on the previous SVD of the matrix to calculate the SVD of the updated matrix are crucial. Such schemes have been proposed for both the full SVD and rank‐k SVD. The algorithm presented in [1], which is the focus of our study, is for the rank‐k truncated SVD case. Following the notation introduced in [1], the problem of updating the rank‐k truncated SVDof anupdatedmatrix is as follows. LetB ∈ Cm×n be amatrix forwhich a rank‐k SVD Bk = UkΣkV H k = ∑k j=1 σju
(j)(v(j))H where Uk = [u(1), . . . , u(k)], Vk = [v(1), . . . , v(k)], and Σk = diag(σ1, . . . , σk) where σ1 ≥ σ2 ≥ · · · ≥ σk > 0 is known. The goal is to approximate the rank‐k SVD Ak = ÛkΣ̂kV̂ Hk = ∑k j=1 σ̂j û
(j)(v̂(j))H of the updated matrix
A = ( B E ) , or A = ( B E ) whereE ∈ Cs×n orE ∈ Cm×s is thematrix containing the newly added rows or columns, respectively. We focus on the row‐update case in this study as is the case in [1]. The remainder of this study is outlined as follows. In Section 2, we introduce the central claim of the original paper that we tested in our study. Following that, in Section 3, we introduce the necessary background prior to describing the proposed algorithm. In Section 4, we describe the experimental setup: our implementation of the algorithm, datasets used, and experiments run. We present the experimental results in Section 5 along with our interpretation of the results and thoughts on the overall study in Section 6.
2 Scope of reproducibility
In this study, we aimed to verify the central claim of the original paper, which stated that the proposed algorithm outperforms other state‐of‐the‐art approaches at calculat‐ ing the truncated SVD of evolving matrices. In particular, they claimed that the method had especially high accuracy for the singular triplets with the largest modulus singular values. We sought to verify this claim by evaluating two metrics using our implemen‐ tation of the method as well as with FrequentDirections, a state‐of‐the‐art matrix sketching and streaming algorithm [2]:
1. Relative approximation error rel_err of leading k singular values of A (Equa‐ tion 1) is smaller when using the proposed algorithm compared to previous meth‐ ods.
rel_err = ∣∣∣∣ σ̂i − σiσi ∣∣∣∣ (1) 2. Scaled residual norm res_norm of leading k singular triplets {û(i), v̂(i), σ̂i} (Equa‐
tion 2) is smaller when using the proposed algorithm compared to previous meth‐ ods. res_norm = ∥∥Av̂(i) − σ̂iû(i)∥∥2
σ̂i (2)
Additionally, we also sought to verify the original paper’s claims about the runtime per‐ formance of the proposed algorithm.
ReScience C 8.2 (#25) – Chen, Matsumoto and Varma 2022 3
3 Projection-based update algorithm
In the following sections, we first introduce the original zha-simon algorithm, then introduce the proposed projection‐based update algorithm. Note that there are two im‐ plementations to the proposed algorithm: one which uses the same projection matrix as the zha-simon algorithm (Algorithm 2.1) and another that uses an enhanced projec‐ tion matrix (Algorithm 2.2).
3.1 Zha-Simon algorithm As motivated in the introduction, an update algorithm that uses prior knowledge re‐ garding the SVD of the matrix is crucial for it to be useful in practice. The algorithm proposed in [1] is based on an algorithm proposed in [3], the latter of which we will re‐ fer to as the zha-simon algorithm (Algorithm 1). Using zha-simon in the row‐update case A = ( B E ) , the QR decomposition of the row space of E that is not captured by the
range of the right singular vectors Vk can be expressed as (I − VkV Hk )EH = QR. Using this result and the previously known rank‐k SVD Bk = UkΣkV Hk , the updated matrix A can be decomposed approximately as follows:
A = ( B E ) ≈ ( UkΣkV H k E ) = ( Uk
Is )( Σk EVk R H )( V Hk QH ) (3)
If we let FΘGH be the compact SVD of (
Σk EVk R H
) , then Equation 3 can be further
decomposed as follows: A ≈ ( Uk
Is
)( FΘGH )(V Hk QH ) = (( Uk
Is
) F ) Θ (( Vk Q ) G )H (4)
The key here is to notice that the approximation of the rank‐k truncated SVD of A us‐ ing the zha-simon algorithm does not require access to the previous matrix B – only the rank‐k SVD Bk = UkΣkV Hk of the matrix from the previous iteration is needed. We can further simplify Equation 4 and see that it approximates the SVD of A as A ≈
(ZF )Θ(WG)H where Z = ( Uk
Is
) and WH = ( Vk Q )H are orthonormal matrices with ranges that approximately capture range(Ûk) and range(V̂ Hk ), respectively.
Algorithm 1 zha-simon algorithm Require: A,E,Uk,Σk, Vk, k
1: Z ← ( Uk
Is ) 2: [Q,R]← qr(I − VkV Hk )EH 3: W ← ( Vk Q
) 4: [Fk,Θk, Gk]← svd(ZHAW, k) 5: Uk ← ZFk 6: Σk ← Θk 7: V k ←WGk
Ensure: Uk ≈ Ûk,Σk ≈ Σ̂k, V k ≈ V̂k
Algorithm 2 Proposed row‐update algo‐ rithm Require: B,E, k 1: [Uk,Σk, Vk]← svd(B, k) 2: Construct projection matrix Z 3: [Fk,Θk] ← svd(ZHA, k) where A =(
B E ) 4: Uk ← ZFk 5: Σk ← Θk 6: V k ← AHUkΣ −1 k
Ensure: Uk ≈ Ûk,Σk ≈ Σ̂k, V k ≈ V̂k
3.2 Proposed row-update algorithm In practice, computing the rank‐k truncated SVDofAusingAlgorithm1 is expensive due to the QR (Step 2) and SVD (Step 4) steps and possibly inaccurate based on the structure
ReScience C 8.2 (#25) – Chen, Matsumoto and Varma 2022 4
of A [1]. The cost of the QR decomposition can be mitigated by setting W = In by observing that v̂(i) ⊆ range(In) for i = 1, . . . , n. Therefore, ZHAW in Step 4 can be replaced with ZHA and the QR decomposition in Step 2 can be eliminated. With these modifications, we have the newproposed row‐update algorithm (Algorithm2). Note that Step 2 has intentionally not been specified as the authors proposed two options for the construction of the projection matrix Z. The first option (Algorithm 2.1) uses the same Z matrix as in Algorithm. Although the construction of Z andZHA are presented in two separate steps in Algorithm 2, ZHA for Step 3 is directly computed as 1. Below are the expressions forZ andZHA for Algorithm 2.1.
Z =
( Uk
Is
) (5a)
ZHA =
( ΣkV H k
E
) (5b)
In the casewhere the rankofB is larger than k and the singular valuesσk+1, . . . , σmin(m,n) are not small, the approximation returned by Algorithm 2.1 can be of poor accuracy. Al‐ gorithm 2.2 addresses this by using an enhanced version of the projection matrix by adding a term −B(λ)BEH in the Z matrix such that
Z =
( Uk −B(λ)BEH
Is
) (6)
Setting X = −B(λ)BEH , the additional term is equal to the matrix X that satisfies the equation
−(BBH − λIm)X = (Im − UkUHk )BEH , (7)
which can be computed using the block conjugate gradient (BCG)method [4]. To ensure that the matrix −(BBH − λIm) is positive definite for BCG, a lower bound of λ > σ21 is imposed. The leading singular value canbe estimatedusing a few iterations of truncated SVD. However, to reduce the number of columns in X and keep Z manageable, the randomized rank‐r SVD ofX can be taken so that
−B(λ)BEHR ≈ Xλ,rSλ,rY Hλ,r (8)
where R is a matrix with at least r columns whose entries are i.i.d. Gaussian random variables with zero mean and unit variance. WithXλ,r, the Z and ZHAmatrices can be calculated as
Z =
( Uk Xλ,r
Is
) (9a)
ZHA = ΣkV HkXHλ,rB E  (9b) For more detailed explanations and derivations of the algorithms and their associated proofs, we refer readers to [1].
4 Methodology
Professor Vassilis Kalantzis, who we contacted via email, generously provided us with the relevant MATLAB code and data; however, we chose to re‐implement the algorithm from scratch in Python with standard packages (NumPy [5], SciPy [6], and scikit‐learn [7]) and used the MATLAB code to confirm our implementation. We compared the per‐ formance of Algorithms 2.1 and 2.2 with FrequentDirections [2], a state‐of‐the‐art streaming algorithm. Experiments were conducted on a MacBook Pro with a 2.3 GHz
ReScience C 8.2 (#25) – Chen, Matsumoto and Varma 2022 5
Dual‐Core Intel Core i5 processor with 16 GB of RAM, and the code is publicly available on GitHub2. All plots were generated using Matplotlib [8].
4.1 Implementation We chose to implement the three truncated SVD update algorithms as methods of an EvolvingMatrix class, which we will refer to as EM from here on out. With each ex‐ periment, the EM class was initialized with various parameters (initial matrix, matrix to be appended, number of batches, etc.) and updates were carried out using one of the up‐ date methods. A simplified version of the experiment is shown in Listing 1. Algorithms 2.1 and 2.2 were written based on the pseudo‐code presented in Algorithm 2, where the Z and ZHAmatrices were calculated using their respective formulas.
# Initialize EM object with initial matrix, number of batches, and desired rank model = EM(initial_matrix, n_batches, k_dim)
# Set entire matrix to be appended model.set_append_matrix(E)
# Update over specified number of batches for i in range(n_batches):
model.evolve() # append rows to matrix model.update_svd() # update truncated SVD
# Calculate metrics for pre-selected updates if model.phi in phis2plot:
model.calculate_true_svd() model.save_metrics()
Listing 1. Simplified experiment structure
Algorithm 2.1 The Z and ZHA matrices were constructed as in Equations 5a and 5b, respectively.
Algorithm 2.2 The main difficulty in implementing Algorithm 2.2 was in the calcula‐ tion of Xλ,r. We chose to solve for X in Equation 7 using the block Conjugate Gradi‐ ent method (BCG) [4] as recommended in [1]. Though [1] specified, at maximum, one iteration of BCG, we found that the MATLAB code set the limit to two iterations. As the additional iteration did not greatly increase the computational cost, we chose to run BCG a maximum of two iterations as well. Once X was calculated, we calculated Xλ,r as per Equation 8 using randomized SVD [9]. For this, we used the scikit‐learn randomized_svd implementation [7]. Based on the description for calculating Xλ,r in [1], we set n_components= r, n_oversamples= 2r, and n_iter= 0. The Xλ,r returned was then used to calculate Z and ZHA as in Equations 9a and 9b, respectively.
Frequent Directions Amodified version of FrequentDirections3 was incorporated as an update method into the EM class. Since FrequentDirections is a line‐by‐line updatemethod as opposed to a batch updatemethod, the updatemethod in the EM class was constructed to receive a matrix E containing the rows to be added and performs the FrequentDirections algorithms for each row of theE. Any form of error metric
2https://anonymous.4open.science/r/truncatedSVD‐0162/ 3https://github.com/edoliberty/frequent‐directions
ReScience C 8.2 (#25) – Chen, Matsumoto and Varma 2022 6
calculation or subsequent update is performed only after the entire matrix E has been processed using the line‐by‐line update method. Since the updatedmatrixB for theFrequentDirectionsmethodhas constant dimen‐ sions throughout the update process, the residual norm error calculation is modified to measure the error betweenB andA′ whereA′ is a truncated version ofA that only holds the first 2l singular vectors and values of A and where 2l is the number of rows in B.
4.2 Datasets In total, we conducted experiments on five datasets. MED, CRAN, CISI, and Reuters‐ 21578 are term‐document matrices from latent semantic indexing applications [10, 11, 12, 13, 14] and ML1M is a movie rating dataset from MovieLens [15]. Table 1 lists the dimensions of the matrices as well as the average number of nonzero (nnz) entries per row and Figure 1 shows the leading 100 singular values for each matrix. It should be noted that the matrices used for CISI, CRAN, and MED in [1] had slightly different di‐ mensions compared to what was listed on [10]. We received these datasets along with the MATLAB code and chose to use their versions of the data for ease of comparison; as we were interested in the accuracy of singular value reconstruction we determined that somewhat corrupted data merely introduced a different set of singular values to recon‐ struct. Furthermore, as the Reuters and ML1M datasets were intact, we used them as controls against the corruption of the other sets.
ReScience C 8.2 (#25) – Chen, Matsumoto and Varma 2022 7
4.3 Experiments We conducted two sets of experiments: one to confirm the results of [1] in a series of re‐ producibility studies and another to furthermeasure the performance of the algorithms using two additional metrics as well as observing the effect of the number of batches on the runtime and performance.
Update method comparison As a first step, we sought to reproduce the results in Fig‐ ures 3 and 4 of [1]. To do this, we conducted the sequence updates experiment. The initial matrix B ≡ A(0) was set equal to the first µ rows of A ∈ Cm×n and the remain‐ ing m − µ rows of A were appended to the initial matrix over a sequence of ϕ updates, each with τ = ⌊(m − µ)/ϕ⌋ rows. Following the notation of [1], the i‐th update would
yield A(i) = (
B ≡ A(i−1) E ≡ A(µ+ (i− 1)τ + 1 : µ+ iτ, :)
) with the exception of the last update
which is likely to have fewer rows in E. After each update, the rank‐k truncated SVD was calculated by one of the three algorithms. The parameters used in [1], and thus in our experiments as well were µ = ⌈m/10⌉ rows, ϕ = 10 updates, and rank k = 50. The relative errors and residual norms were reported for the k = 50 leading singular triplets for ϕ = 1, 5, 10. For Algorithm 2.2, we set the coefficient λ = 1.01σ̂21 and r = 10.
Algorithm 2.2 r parameter study Next, we varied the r parameter in Algorithm 2.2 to evaluate its effect on the accuracy as was presented in Table 4 by [1]. For this, we set µ = ⌈m/10⌉, ϕ = 10, and k = 50 for all three update methods as with the previous experiment and set r = 10, 20, 30, 40, 50 for Algorithm 2.2.
Runtime comparison We compared the runtimes of the algorithms for the CRAN, CISI, and MED as a function of the rank k = 25, 25, 50, 75, 100, 125 and the total number of updates ϕ = 2, 4, 6, 8, 10 (Figure 2 left and middle plots in [1]).
Varying number of batches and desired rank In addition to the experiments that we replicated based on [1], we also varied the number of batches ϕ = 2, 4, 6, 8, 10 and the desired rank k = 25, 50, 75, 100, 125 of the truncated SVD and evaluated the performance of each of the update methods to further observe the effects of each of these parameters on the methods’ performances.
5 Results
Relative error and residual norms of singular triplets The relative error and residual norm of the leading k = 50 singular triplets for the CRAN dataset at ϕ = 1, 5, 10 us‐ ing Algorithms 2.1, 2.2, and FrequentDirections are shown in Figure 2. Due to the large number of figures, the complete set of plots for the standard experiments are pre‐ sented in Sections A to E in the Supplementary Materials. When comparing the relative error and residual norm plots for Algorithm 2.1 on CRAN, CISI, and MED, our results matched those of [1] exactly. For Algorithm 2.2, the plots did not match exactly, though the differences never exceeded half an order of magnitude and are attributable to the randomness inherent in Algorithm 2.2. Our comparison of the relative error and residual norm of the k = 50‐th singular triplet for Algorithm 2.2 with various values of r revealed a similar result to [1] – across the three methods, Algorithm 2.2 had the lowest errors, and within variations of Algorithm 2.2, larger values of r yielded higher accuracy.
ReScience C 8.2 (#25) – Chen, Matsumoto and Varma 2022 8
Runtime For all three of the datasets which wemeasured runtimes on, we found Algo‐ rithm 2.2 to require a substantially longer amount of time to complete all of its updates. Algorithm 2.1 and FrequentDirections required a similar length of time, though Algorithm 2.1 was consistently faster than FrequentDirections by a small margin. The runtime plots for the standard experiments are shown in Section F of the Supple‐ mentary Materials.
Number of batches and rank Due to space‐related constraints, we chose to only in‐ clude two examples from the array of plots generated (Figure 4). Despite the large varia‐ tion in the parameters, we can see that the residual norm for overlapping update num‐ bers and k share very similar values.
ReScience C 8.2 (#25) – Chen, Matsumoto and Varma 2022 9
6 Discussion
Ultimately, the reproduced results confirm the original results. Specifically, Table 2 verifies that Algorithm 2.2 outperforms Algorithm 2.1 in terms of accuracy. Further‐ more, Figure 3 clearly demonstrates that Algorithm 2.1 far outperforms Algorithm 2.2 with respects to wall clock speed. However, as there were no benchmarks, we viewed the comparison with FrequentDirections as a much stronger barometer. At first glance, Table 2 and Figures 2c and 2f suggest that both Algorithm 2.1 and 2.2 outperform FrequentDirections in terms of accuracy. However, upon considering the steps in‐ volved in FrequentDirections (namely the step involving the thresholding of the sin‐ gular values), we realize that the relative error and residual normof singular tripletsmay not be an applicable metric for FrequentDirections. This is further demonstrated by the irregular profile of the residual norm as a function of the singular value index (Figure 2f)). Thus it cannot conclusively be said that FrequentDirections is signif‐ icantly under‐performing the paper’s proposed algorithms. Consequently, the overall conclusion becomes that while the results presented in the paper are sound, there is still need for further benchmarking to determine where the proposed algorithms stand relative to the state‐of‐the‐art in the field.
ReScience C 8.2 (#25) – Chen, Matsumoto and Varma 2022 10
6.1 Future Work We believe a weakness of the paper to be the lack of benchmarking ‐ and as discussed above, our results do not conclusively resolve this. However, they do motivate the need for metrics that will allow for a fair comparison between the proposed algorithm and state‐of‐the‐art algorithms such as FrequentDirections.
6.2 What was easy Algorithm 1.1 was quite simple to understand and implement, and was exactly repro‐ duced quite early on. Once we received code, implementation of Algorithm 2.2 and the evaluation metrics was simplified.
6.3 What was difficult In addition to the challenges constructingXλ,r forAlgorithm2.2, another challenging/time‐ consuming aspect was designing the experiments as sweeping through various combi‐ nations of the parameters required thorough planning for data management."
"['Aryan Mehta', 'Karan Uppal', 'Kaushal Jadhav', 'Monish Natarajan', 'Mradul Agrawal', 'Debashish Chakravarty']",[Re] Background-Aware Pooling and Noise-Aware Loss for Weakly-Supervised Semantic Segmentation,10.5281/zenodo.6574677,Replication,Python,https://zenodo.org/record/6574677/files/article.pdf,rescience c machine learning deep learning python pytorch,https://openreview.net/forum?id=rUQllTGQhAY,https://github.com/karan-uppal3/BANA,8,2,2022,The paper’s central claim revolves around the newly introduced Background Aware Pool‐ ing (BAP)method to generate high‐quality pseudo labels using bounding boxes as super‐ vision and Noise Aware Loss (NAL) to train a segmentation network using those noisy labels. The authors assert that these two techniques combined set the new state‐of‐the‐ art for weakly supervised semantic segmentation on PASCAL VOC 2012 [1].,"The completed code for training the classification network and pseudo label generation using BAP was available in the authors’ code‐base, and the results associated with them were straightforward to reproduce.","Implementing someparts of Stage 1 and Stage 2 and the complete Stage 3 code, including NAL and further experimenting with them to resolve the minute issues, was the most
Copyright © 2022 A. Mehta et al., released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Karan Uppal (karan.uppal3@iitkgp.ac.in) The authors have declared that no competing interests exist. Code is available at https://github.com/karan-uppal3/BANA. – SWH swh:1:dir:24495d2fbb5d4af66607261c2171ed42173a72cf. Open peer review is available at https://openreview.net/forum?id=rUQllTGQhAY.
ReScience C 8.2 (#26) – Mehta et al. 2022 1
challenging part of the reproduction. Even though authors gave detailed feedback, VOC‐ to‐COCO conversion for unseen classes also posed many challenges.
Communication with original authors Contact with authors was made via Email regarding specifications in methodologies in‐ volving pseudo label generation and VOC‐to‐COCO experiments. Apart from the code, comprehensive and helpful replies were given by them.
ReScience C 8.2 (#26) – Mehta et al. 2022 2
1 Introduction
Semantic segmentation, which is the pixel‐wise classification of objects in images, finds crucial applications in areas such as autonomous driving, medical imaging, and aug‐ mented reality, to name a few. Training deep neural networks to perform this task accurately requires extensive and quality training data and annotating it, which is la‐ borious and intensive. Weakly‐supervised semantic segmentation (WSSS) techniques aim to ease the task of annotation by using image‐level labels or object bounding boxes as a weak form of supervisory signal to generate possibly noisy ”pseudo‐ground‐truth labels.” While existing methods come at the expense of additional overheads, WSSS us‐ ing background‐aware pooling (BAP), introduces a technique to discriminate foreground and background regionswithin bounding boxes to generate quality pseudo labels at neg‐ ligible overhead. On the other hand, Noise‐Aware Loss (NAL) improves the performance of models by lessening the effect of incorrect pseudo labels during training.
2 Scope of reproducibility
The paper introduces a new weakly supervised semantic segmentation technique using bounding box annotations to generate pseudo labels and train a segmentation network using those labels as supervisors. Here are the major claims, summarized as follows:
1. High‐quality pseudo segmentation labels are generated with the proposed Back‐ ground Aware Pooling method using bounding box annotations in comparison to the conventional Global Average Pooling method [2, 3].
2. The novel Noise Aware Loss can use the unreliable regions present in the noisy pseudo labels.
3. Fully trained classification and Segmentation networks achieved the current state‐ of‐the‐art performance for weakly‐supervised semantic segmentation on PASCAL VOC data‐set using the above‐presented methods.
3 Methodology
The main experiments of the paper are divided into three stages, as shown below:
1. Training a classifier network using Background‐Aware Pooling (BAP) on the VOC dataset.
2. Generation and Evaluation of Pseudo labels generated on VOC for a model trained using BAP.
3. Training and evaluation of a model using Noise‐Aware Loss (NAL) on the pseudo labels generated in Stage 2.
ReScience C 8.2 (#26) – Mehta et al. 2022 3
3.1 Method Descriptions
BAP in the training of Classification Network — The task of discriminating the foreground and background regions within a bounding box is approached as a retrieval task. Firstly, the feature map f obtained from the model is divided into N x N regular grids denoted by G(j). For each G(j), features are aggregated as per Eq. (1) and are used as queries qj for the retrieval of background features within each bounding box. For this purpose, a binary maskM is defined, where for a position p within a bounding boxM(p) = 0, and one otherwise.
qj =
∑ p∈G(j) M(p)f(p)∑
p∈G(j) M(p) (1)
For a given grid cellG(j), the termA(j) is computed as shownbyEq. (2). Upon averaging overallAj(p), attentionmap,A is obtained, corresponding to the likelihood that a given pixel belongs to the background. This is represented by Eq. (2), where J denotes the total number of valid grid cells.
A(p) = 1
J ∑ j Aj(p), where Aj(p) =
{ ReLU ( f(p)
∥f(p)∥ · qj ∥qj∥
) ,p ∈ B
1 ,p /∈ B (2)
For a given bounding box Bi, foreground features ri are aggregated using the attention map A(p) by means of a weighted average pooling, as per Eq (3). The authors refer to this process as Background‐Aware Pooling (BAP). Finally, the (L + 1) ‐ way softmax classifier w is applied to ri and qj corresponding to the foreground and background features, respectively, to train the model using standard cross‐entropy loss.
ri =
∑ p∈Bi(1−A(p))f(p)∑
p∈Bi(1−A(p)) (3)
Generation of Pseudo Labels — Two pseudo ground‐truth labels namely Ycrf and Yret are generated from two complementary approaches. The first method involves using the background attention map and class activation maps (CAMs) [3] obtained from the clas‐ sification network, and using them as the unary term for DenseCRF [4, 5, 6, 7]. The unary term for the background u0 and unary term for object class c denoted by uc, is computed as shown in Eq. (4) and Eq. (5). The terms u0 and uc for each class c are then concatenated and provided as the unary term for DenseCRF to obtain Ycrf . Here Bc de‐ notes the regions within bounding box(es) for class c and wc is the classifier weight for object class c.
u0(p) = A(p) (4)
uc(p) =
{ CAMc(p)
maxp(CAMc(p)) ,p ∈ Bc 0 ,p /∈ Bc , where CAMc(p) = ReLU (f(p) · wc) . (5)
Generation of Yret, on the other hand, involves capturing the high‐level features ob‐ tained from the classifier. Queries qc corresponding to prototypical features for each class c is computed as per Eq. (6), whereQc is the set of regions in Ycrf labelled as class c. Following this, the correlation map Cc for each class c is shown below.
qc = 1 |Qc| ∑ p∈Qc f(p), and Cc(p) = f(p) ∥f(p)∥ · qc ∥qc∥ . (6)
ReScience C 8.2 (#26) – Mehta et al. 2022 4
However, the authors have applied the ReLU function over the mentioned cosine simi‐ larity in their official implementation. Finally, the argmax function is applied over the correlation map Cc to obtain pseudo labels Yret.
Pseudo‐labels for Unseen Classes: ”VOC‐to‐COCO” The authors mention in the paper that their pseudo label generator is generic in that for classes unseen during training, 1−u0 can be used as a class agnostic foreground attentionmap in place of the attention map obtained using the corresponding CAM. We illustrate this in Eq (7).
uc(p) =  CAMc(p) maxp(CAMc(p)) , c ∈ C and p ∈ Bc 1− u0(p) , c /∈ C and p ∈ Bc
0 ,p /∈ Bc (7)
Where C represents the set of classes whose classifier weights are available with the generator, and u0 corresponds to the background attention map attained in Eq. (5).
Noise-Aware Loss for Semantic Segmentation with Noisy Labels — The authors use Noise‐Aware Loss to train DeepLab [8] models using Ycrf and Yret . Feature map ϕ is extracted from the backbone network and probability map Ypred is obtained by passing feature map ϕ through the forward classifier. Probability mapH is obtained by passing Ypred through Softmax classifierW . The authors denote the regions where both Ycrf and Yret give the same label as S and where both give different labels as ∼ S. For the confident regions S, ce loss is calculated using Eq. (11).
Lce = − 1∑ c |Sc| ∑ c ∑ p∈Sc logHc(p), (8)
HereHc is a probability for the class c and Sc is the set of locations labeled as the class c in S. The unreliable regions ∼ S cannot be ignored, and for determining the accuracy of the label prediction,wce loss is proposed. For the loss computation, the authors build upon the assumption that the weights of the classifier network Wc can be treated as a feature representing the corresponding class c. A correlation map Dc is calculated per class using cosine similarity as a metric as described in Eq. (9).
Dc(p) = 1 + (
ϕ(p) ∥ϕ(p)∥ · Wc ∥Wc∥
) , (9)
σ(p) = (
Dc∗(p) maxc (Dc(p))
)γ (10)
A confidence map is then calculated using Eq.(10). Here c∗ is obtained as Ycrf labels corresponding to the respective class. γ is a damping parameter that is always set greater than 1. The confidence map can predict the probability of each label being correct. Thus, wce loss is calculated according to Eq.(11).
Lwce = − 1∑
c ∑ p∈∼Sc σ(p) ∑ c ∑ p∈∼Sc σ(p) logHc(p) (11)
The final loss is calculated using Eq. (12), where λ is a weighing parameter which bal‐ ances Lce and Lwce .
L = Lce + λLwce (12)
ReScience C 8.2 (#26) – Mehta et al. 2022 5
3.4 Code details The complete code containing the proposed NAL and all ablation studies both using Py‐ Torch [13] and PyTorch Lightning along withWandB [14] integration is available at these links: (PyTorch, PyTorch Lightning). Links to all obtained pseudo labels and pre‐trained models are also provided in README. Detailed discussion about the implementation is provided in the following sections.
Pseudo label generation fromVOC toCOCO —Weperformacross‐dataset evaluation of pseudo generator on the MS COCO dataset for a model trained of PASCAL VOC. While the au‐ thors do not provide an implementation for the same, we implement the experiment from details provided in the paper and communication with the authors. We appro‐ priately map the VOC classes to the corresponding classes in COCO using information available about both datasets to facilitate Eq (6). We follow standard protocols for eval‐ uating the pseudo labels using the official COCO API.
Semantic segmentation with NAL — The original authors’ code implementation contained Stage 1 and Stage 2, but the Stage 3 codewas incomplete. We thus implemented the com‐ plete Stage 3 training from scratch, including the proposed NAL and the other loss func‐ tions discussed in section 4.2.2 based on the details from the paper. We train the model using cross‐entropy loss and Noise Aware Loss and utilize the Polynomial LR Scheduler. Dense‐CRF is also applied as post‐processing as per the code provided in the authors’ repository.
ReScience C 8.2 (#26) – Mehta et al. 2022 6
4 Results
Weexperimented and verified all the central claimsmadeby thepaper about BAPmethod‐ ology and NAL on PASCAL VOC 2012 dataset. Following are the detailed description of the results obtained.
4.1 Results reproducing original paper
Experimentswith BackgroundAwarePooling —Wesuccessfully replicated the results reported in Table 3 from the original paper, and it supports claim 1 of BAP being a superior method to GAP presented in Section 2 .
As discussed in section 3.1.2, we verified the authors’ claims that the classifier model is generic and can be used for the detection of classes unseen during training. We trained the classifier model over the Pascal VOC dataset and generated pseudo labels over the MS‐COCOdataset. Weuse the COCO‐API evaluator of pycocotools to evaluate our results on the COCO benchmark. The comparison of our results with the authors’ results is given in Table. 4.
ReScience C 8.2 (#26) – Mehta et al. 2022 7
Experiments with Noise Aware Loss — Comparison between our and the authors’ results re‐ gardingNAL is provided inTable 5, which shows thatNALoutperforms the cross‐entropy loss computed on Ycrf and Yret, thus supporting the claim 2 presented in section 2.
4.2 Results beyond original paper
Experiments with grid size —We performed a hyperparameter search for the grid size (N) and observed that lower values of N for generating pseudo labels provide the best results. In contrast, the opposite was true for training the classification network.
ReScience C 8.2 (#26) – Mehta et al. 2022 8
Experiments with NAL and it’s counterpart losses — Besides NAL, various other losses have been defined in the paper to deal with unreliable regions such as entropy regularisation andbootstrapping. The comparison between our results and the authors’ results is given in Table 7, with both before and after applying Dense‐CRF.
Experimentswith different values of lambda anddampparameters. — To justify the selection of the values of lambda anddamppa‐ rameters, comparison studies were performed by choosing different values of lambda and damp parameters. We train the DeepLabV1 (LargeFOV) model for a range of lambda and damp parameters and report the results as a heat‐map representation in Fig. 3.
5 Discussion
Through our experiments, we reproduce and verify the cen‐ tral claims of the original paper about the two newly intro‐ duced techniques ‐ BAP and NAL. We additionally perform ablation studies on differentmodel hyper‐parameters and various losses to gain insights into the original author’s choice of the same. We obtained very similar results in the reproducibility of BAP. The above claim that BAP is a superior method to GAP is well verified by the increased results obtained using BAP compared to GAP on PASCAL VOC, as reported in Table 3. We further analyze that usingu0 (corresponding to background attentionmap) yields better results thanusingub (corresponding to background class activation map) for generation of the pseudo labels, suggesting superior discrimination of background regions in this method. In implementing the authors’ cross‐dataset evaluation results on the COCO dataset, we obtain considerably lower results despite following the protocols mentioned in the pa‐
ReScience C 8.2 (#26) – Mehta et al. 2022 9
per. However, our results support the claim that BAP serves as a promising technique in implementing a class‐agnostic pseudo label generator. We implemented NAL from scratch and performed all the weakly‐supervised training experiments with the obtained pseudo labels Ycrf and Yret. We report slightly lower results compared to authors, which we attribute to the minor implementational differ‐ ences and a possible tuning of the parameters in DenseCRF. This can be shown by Ta‐ ble 7 in which all the results before DenseCRF match the author’s results, but there are some differences after using DenseCRF. However, a relative gain in performance for both DeepLab v1 and v2 is clearly observed from Table 5 when unreliable regions are exploited with the help of NAL. Furthermore, our experiments using different losses for regions with different predicted labels in Ycrf and Yret, as listed in Table 7, provide supporting evidence that NAL outperforms the contemporary losses and suggests it is a robust technique for weakly‐supervised training when there are regions with less confi‐ dence. For Stage 1 and Stage 2, we perform experiments with different choices of grid size in BAP, and for Stage 3, we analyze model performance for different values of damping parameter γ and weighting parameter λ. From Table 6, we infer that the best result is obtained for grid size 4 for training and 1 for label generation, which is in coherencewith the values used in the original paper. For Stage 3, Fig. 3 supports the authors’ choice of values assigned to γ and λ. Using a higher damping coefficient value (γ) makes the model biased towards most confident labels. On the other hand, using a higher value of λ gives more weight to wce loss, increasing the reliance on regions with low confidence. All the ablation experiments with the selected hyper‐parameters yielded validation IoU lower than that obtained in Table 5. In our qualitative analysis of the generated pseudo labels (refer Fig. (2)) Ycrf and Yret we infer that Ycrf particularly performs well in capturing low level image features. In Fig. 2, it is seen to discriminate the background region between the wheel’s spokes cor‐ rectly. Yret, on the other hand, captures high‐level features in the same image although mildly exaggerated. Thus, the two labels complement each other, and together is a good indication of unreliable regions identified and suppressed by NAL. After porting the code base into PyTorch Lightning, we also concluded the implemen‐ tations and experiments that ensured the correctness of various bits of training and evaluation process such as data loading, loss calculation, model weights optimization, and checkpoint re‐loading for further reproducibility experiments in the future.
6 Conclusion
In this paper, we reproduce all the original results provided by the authors. Reproduc‐ ing the first claim involving Background Aware Pooling, we were able to achieve similar results to the author. Hence, we support the claim that BAP is a superior method for WSSS than GAP. Cross dataset evaluation was performed on the COCO dataset. Our experiments verify the claim that the model works as a class agnostic pseudo label gen‐ erator and achieves satisfactory results in performing VOC‐to‐COCO evaluation. For Stage 3, we implemented Noise Aware Loss from scratch and trained the DeepLab mod‐ els for WSSS. Our results are slightly lower than the actual results. Nonetheless, our experiments still support the claim that NAL outperforms the contemporary losses and suggests it is a robust technique for weakly supervised learning. Our additional experi‐ ments also provide further insights on the performance of NAL for different values of hy‐ perparameters. We thus believe it would be of interest to perform further experiments focused on modifying NAL, which might lead to better results.
ReScience C 8.2 (#26) – Mehta et al. 2022 10"
['Szymon Mikler'],[Re] Reproducibility Study: Comparing Rewinding and Fine-tuning in Neural Network Pruning,10.5281/zenodo.6574679,Replication,Python,https://zenodo.org/record/6574679/files/article.pdf,rescience c machine learning deep learning python tensorflow computer vision pruning,https://openreview.net/forum?id=HxWEL2zQ3AK,https://github.com/gahaalt/reproducing-comparing-rewinding-and-finetuning,8,2,2022,"We are reproducing Comparing Rewinding and Fine-tuning in Neural Networks, by [1]. In this work the authors compare three different approaches to retraining neural networks after pruning: 1) fine‐tuning, 2) rewindingweights as in [2] and 3) a new, originalmethod involving learning rate rewinding, building upon [2]. We reproduce the results of all three approaches, but we focus on verifying Renda’s original approach: learning rate rewinding, since it is newly proposed and is described as a universal alternative to other methods. As the authors of [1], we used CIFAR10 for most of the experiments, but we added exper‐ iments on a larger version of this dataset: CIFAR100. We have also extended the list of tested network architectures to include Wide ResNets [3]. The new experiments led us to discover the limitations of learning rate rewinding which in some cases can worsen pruning results on large neural network architectures.","Re‐implementation of pruning and retraining methods was technically easy, as it is based on a popular and simple pruning criterion – magnitude pruning. Original work was descriptive enough to reproduce the results with satisfying results without consult‐ ing the code.","Not every design choice was mentioned in the paper, thus reproducing the exact re‐ sults was rather difficult and required a meticulous choice of hyper‐parameters. Exper‐ iments on ImageNet andWMT16 datasets were time consuming and required extensive resources, thus we did not verify them.
Communication with original authors We did not consult the original authors, as there was no need to.
ReScience C 8.2 (#27) – Mikler 2022 2
2 Introduction
Neural network pruning is an algorithm that intends to decrease the size of a network, usually by removing someof its connections or setting theirweights to 0. This procedure generally allows obtaining smaller and more efficient models. It often turns out that these smaller networks are as accurate as their bigger counterparts or the accuracy loss is negligible. A common way to obtain such high quality sparse network is to prune it after the training has finished [2], [4]. Networks that have already converged are easier to prune than randomly initialized networks [5], [4]. After pruning, more training is usually required to restore the lost accuracy. Although there are a few ways to retrain the network, finetuning might be the easiest and most often chosen by researchers and practitioners [1], [4]. Lottery Ticket Hypothesis from [2] formulates a hypothesis that for every non‐pruned neural network, there exists a smaller subnetwork that matches or exceeds results of the original. The algorithm originally used to obtain examples of such networks is iter‐ ative magnitude pruning with weight rewinding, and it is one of the three methods of retraining after pruning compared in this work.
2.1 Structured and Unstructured Pruning One of the first papers about neural network pruning [6] focused solely on unstructured pruning. However, current hardware limitations do not allow to take full advantage of this form of pruning. Structured pruning is a workaround to this problem. In struc‐ tured pruning, we remove the basic building blocks of a network instead of single con‐ nections. In the case of dense linear neural networks, these structures are neurons and their connections – neuron’s inputs and outputs. Depending on the network’s type, this can be something else. In every case, it should be a minimal unit such that the remain‐ ing neural network can be represented as a smaller, but still dense (non‐pruned) neural network. In the case of structured pruning of convolutional neural networks, whole channels and their corresponding parameters in convolutional filters are removed.
3 Scope of reproducibility
Our reproducibility study tries to confirm claims from [1]. Following claims were for‐ mulated:
Claim 1: Widely usedmethod of training after pruning: finetuning yieldsworse results than rewinding based methods (supported by figures 2, 3, 1, 4 and Table 5)
Claim 2: Newly introduced learning rate rewindingworks as goodor better asweight rewind‐ ing in all scenarios (supported by figures 2, 3, 1, 4 and Table 5, but not supported by Figure 5)
Claim 3: Iterative pruning with learning rate rewinding matches state‐of‐the‐art pruning methods (supported by figures 2, 3, 1, 4 and Table 5, but not supported by Figure 5)
4 Methodology
We aimed to compare three retraining approaches: 1) finetuning, 2) weight rewinding and 3) learning rate rewinding. Our general strategy that repeated across all experi‐ ments was as follows:
1. train a neural network to convergence,
ReScience C 8.2 (#27) – Mikler 2022 3
2. prune the network using magnitude criterion: remove parameters with the small‐ est absolute value,
3. retrain the network using one of the three retraining approaches.
In the case of structured pruning: in step 2, we removed structures (either neurons or convolutional channels) with the smallest L1 norm [7], rather than removing separate connections. In the case of iterative pruning: the network in step 1 was not randomly initialized, but instead: weights from a model from a previous iterative pruning step were loaded as the starting point. Then the three steps were repeated. On the other hand, one‐shot pruning is a procedure where pruning is done only once, so there was only one cycle. In some methods, this might be done on a randomly initialized neural network, like in [5]. Here, however, one‐shot pruning is done after the network reaches convergence. So the three steps are not repeated in case of one‐shot pruning. We trained all our networks using Stochastic Gradient Descent with Nesterov Momen‐ tum [8]. The learning rate was decreased in a piecewisemanner during the training, but momentum coefficient was constant and equal to 0.9.
5 Model descriptions
In this report, wewere focusing on an image recognition task using convolutional neural networks [9]. For most of our experiments, we chose to use identical architectures as [1] to better validate their claims and double‐check their results, rather than only provide additional ones. Therefore, most of the used networks are residual networks, which were originally proposed in [10]. Additionally, to verify the general usefulness of pruning and retrainingmethods proposed in [1]we extend the list of tested network architectures to much larger wide residual networks from [3].
5.1 Residual networks (ResNet) Just as [1], we chose to use the original version of ResNet as described in [10] rather than the more widely used, improved version (with preactivated blocks) from [11]. We created the models ourselves, using TensorFlow [12] and Keras. We strove to replicate the exact architectures used by [1] and [10] and train them from scratch.
ResNet hyperparameters — Learning rate started with 0.1 and was multiplied by 0.1 twice, after 36 000 and 54 000 iterations. One training cycle had 72 000 iterations in total. For all batch normalization layers, we set the batch norm decay to 0.997, following [1], which is also the default used in the original TensorFlow implementation1. We initialize net‐ work’s weights with what is known as He uniform initialization from [13]. We regularize
1https://github.com/tensorflow/models/blob/r1.13.0/official/resnet/resnet_model.py
ReScience C 8.2 (#27) – Mikler 2022 4
ResNets, during both training and finetuning, usingL2 penalty with 10−4 coefficient. In other words, the loss function (from which we calculate the gradients) looks as follows:
L = CC(y, p) + 10−4 × ∑ i∈W w2i (1)
where:
L = value of the final loss function
CC = categorical crossentropy loss function
y = ground truth label of a sample or batch
p = model’s prediction
W = parameters of the model
5.2 Wide Residual Networks (Wide ResNet, WRN) WRN networks were introduced in [3]. They are residual networks created by simply increasing the number of filters in preactivated ResNet networks [11].
WRN hyperparameters — AsWide ResNets are newer andmuch larger than ResNets, hyper‐ parameters are slightly different. To choose them, we follow [3]. Learning rate starts with 0.1 and multiplied by 0.2 thrice: after 32 000, 48 000 and 64 000 iterations. Training lasts for 80 000 iterations. For all batch normalization layers, we use hyper‐parameters from the newer TensorFlow implementation2 with batch norm decay set to 0.9. Follow‐ ing [3], we use larger L2 penalty for this network: 2× 10−4. Finally, the loss function is as follows:
L = CC(y, p) + 2× 10−4 × ∑ i∈W w2i (2)
where:
L = value of the final loss function
CC = categorical crossentropy loss function
y = ground truth label of a sample or batch
p = model’s prediction
W = parameters of the model
2https://github.com/tensorflow/models/blob/r2.5.0/official/vision/image_classification/resnet/resnet_model.py
ReScience C 8.2 (#27) – Mikler 2022 5
5.3 Datasets CIFAR‐10 and CIFAR‐100 are image classification datasets introduced in [14]. Following [1], we use all (50 000) training examples to train the model.
5.4 Preprocessing and data augmentation We used a standard data processing for both CIFAR‐10 and CIFAR‐100 datasets [1], [2], [3]. During training and just before passing data to the model, we:
1. standardized the input by subtracting the mean and dividing by the std of RGB channels (calculated on training dataset),
2. randomly flipped in horizontal axis,
3. added a four pixel reflection padding,
4. randomly cropped the image to its original resolution.
During the validation, we did only the first step of the above.
5.5 Experimental setup and code Our ready‐to‐use code, which includes experiment definitions, can be found at https: //github.com/gahaalt/reproducing-comparing-rewinding-and-finetuning. It’s written using Tensor‐ Flow [12] version 2.4.2 in Python. More details are included in the repository.
5.6 Computational requirements Recreating the experiments required amodern GPU, training all models on CPUwas vir‐ tually impossible. Training time varies depending on a lot of factors: network variation and size, exact version of the deep learning library, and even the operating system. In our case, using TensorFlow 2.4.2 on Ubuntu and a single RTX 3080 GPU, the smallest of the used models, ResNet‐20, takes about 20 minutes to train on CIFAR‐10 dataset. To replicate our experiments, training at least a single baseline network and then, once more, a single pruned network, is required. To reduce computational requirements, we reused one non‐pruned baseline for multiple compression ratios. Approximated train‐ ing time requirements can be seen in the table below.
ReScience C 8.2 (#27) – Mikler 2022 6
For all our experiments together, we estimate the total number of GPU hours spent to be around 540.
6 Method description
We compare three methods of retraining after pruning. For all of them, the starting point is a network that was already trained to convergence, then pruned to a desired sparsity. The difference between the three retraining methods is what follows after it.
6.1 Fine-tuning Fine‐tuning is retraining with a small, constant learning rate – in our case, whenever fine‐tuning was used, the learning rate was set to 0.001 as in [1]. We finetune the net‐ work for the same number of iterations as the baseline – 72 000 iterations in the case of the original ResNet architecture. In this method, such long retraining would not be necessary in practical applications, since the network converges much faster.
6.2 Weight rewinding Weight rewinding restores the network’s weights from a previous point (possibly begin‐ ning) in the training history and then continues training from this point using the origi‐ nal training schedule – in our case a piecewise constant decaying learning rate schedule. When rewinding a network to iteration K that originally trained for N iterations: first prune the non‐pruned network that was trained forN iterations. Then, for connections that survived, restore their values toK‐th iteration from the training history. Then train to the convergence for the remaining N −K iterations.
6.3 Learning rate rewinding Learning rate rewinding continues training with weights that have already converged, but restores the learning rate schedule to the beginning, just as if we were training from scratch, and then trains to the convergence once again. This reminds the cyclical learn‐ ing rates from [15]. Learning rate rewinding really is weight rewinding for K = N , but the final retraining is always for N iterations.
7 Results reproducing original paper
In most of our experiment, just as [1], we investigate how does the trade‐off between prediction accuracy and compression ratio look like. In one of the experiments (Table 5)
ReScience C 8.2 (#27) – Mikler 2022 7
we verify only one compression ratio, but for the rest, we verify multiple. We report a median result out of 2 up to 12 trials for each compression ratio. To better utilize our compute capabilities, wedecided to spendmore training cycles in situationswhere there is no clear winner between the compared methods. On each plot, we include error bars showing 80% confidence intervals. In this section, we include experiments that we successfully reproduced. Most of them match the original ones within 1% error margin. We noticed some of our results were slightly better than authors of [1] originally reported. Across all scenarios where finetuning was tested, it was by far the worst of the three methods, which directly supports claim 1 (Section 3). Weight rewinding and learning rate rewinding most often are equally matched, but in some cases learning rate rewind‐ ing works a little better.
7.1 ResNets on CIFAR-10 dataset Results we observe here are consistent with what we see in [1], [2]. Iterative pruning is better than one‐shot pruning, but more time consuming. In extreme cases, iterative pruning requires 20 times as many iterations than one‐shot pruning to complete. But it is not as bad for moderate sparsity pruning. Larger networks work better than smaller ones. Even when the number of parameters left after pruning is the same – originally larger network will outperform the smaller one. Out of the retraining methods, weight rewinding and learning rate rewinding seem to be similar, but finetuning is visibly worse. In some cases, learning rate rewinding out‐ performs weight rewinding. Similar conclusions can be drawn from both structured and unstructured pruning results.
ReScience C 8.2 (#27) – Mikler 2022 8"
"['Angelos Nalmpantis', 'Apostolos Panagiotopoulos', 'John Gkountouras', 'Konstantinos Papakostas']",[Re] Exacerbating Algorithmic Bias through Fairness Attacks,10.5281/zenodo.6574681,Replication,Python,https://zenodo.org/record/6574681/files/article.pdf,rescience c machine learning python pytorch fairness adversarial attacks,https://openreview.net/forum?id=rYLMJ6zX3RF,https://github.com/toliz/fairness-attacks,8,2,2022,"We conducted a reproducibility study of the paper Exacerbating Algorithmic Bias through Fairness Attacks [1]. According to the paper, current research on adversarial attacks is primarily focused on targeting model performance, which motivates the need for ad‐ versarial attacks on fairness. To that end, the authors propose two novel data poisoning adversarial attacks, the influence attack on fairness and the anchoring attack. We aim to verify the main claims of the paper, namely that: a) the proposed methods indeed af‐ fect a model’s fairness and outperform existing attacks, b) the anchoring attack hardly affects performance, while impacting fairness, and c) the influence attack on fairness provides a controllable trade‐off between performance and fairness degradation.","The original paper is well‐structured and easy to follow, with the principal ideas behind the proposed algorithms being very intuitive. Additionally, the datasets used in the ex‐ periments are publicly available, small in size, and the authors provide their code on GitHub.","During our study, we encountered a few unforeseen issues. Most importantly, we were not able to identify critical technical information required for the implementation of the proposed algorithms, as well as a detailed description of the models used, their training pipeline, hyperparameters, and data pre‐processing techniques. Furthermore, the pub‐ licly available code is convoluted and employs out‐of‐date libraries, making it difficult to set up the necessary environment.
Communication with original authors We contacted the paper’s first author once to confirm our understanding of certain el‐ ements of the paper that were either not specific enough or missing. Although they responded fairly quickly, their answer prompted us back to the paper and the provided codebase, while not encouraging any further communication.
None 8.2 (#28) – Nalmpantis et al. 2022 2
1 Introduction
Adversarial attacks have becomepopular in themachine learning community since they allow scientists to understand and mitigate the weaknesses of the employed models. Current research is primarily focused on adversarial attacks targeting the performance of machine learning systems [2, 3], but recent studies indicate that adversarial attacks can also be used to target fairness [1, 4, 5]. In the studied paper, the authors propose two novel families of adversarial attacks ‐ the influence attack on fairness and the anchor‐ ing attack ‐ and demonstrate their effect in exacerbating algorithmic bias by evaluating them on three datasets using two well‐known fairness metrics. Both of the proposed methods belong to the family of data poisoning attacks, in which the adversary attempts to inject malicious data points into the training data. In par‐ ticular, given a “clean” training dataset Dc, i.e. a dataset containing only the original training samples, the adversary generates a “poisoned” dataset Dp and integrates it into the original one, resulting in the final train set Dtrain = Dc ∪ Dp. The poisoned dataset Dp is generated in such a way that training with Dtrain results in a model with degraded performance or, in our case, a less fair model. The paper considers a binary classification scenario, under a common fairness setup with two demographic groups; the advantaged Dadv and the disadvantaged Ddisadv. Un‐ der this setting and given an adversarial loss that increaseswhen themodelmakes unfair decisions, the influence attack on fairness finds adversarial data points by performing gradient ascent on the adversarial loss. On the other hand, the anchoring attack places poisoned points in the close vicinity of two target points, one from Dadv and one from Ddisadv, with the opposite labels but the same demographic.
2 Scope of reproducibility
In this reproducibility study we aim to verify the following main claims of the paper:
• Both of the proposed attacks impact the fairness of the targeted model, outper‐ forming other attacks in the literature, such as Koh’s basic influence attack [6] and Solan’s gradient‐based poisoning attack [5].
• The anchoring attack has little to no impact on the model’s accuracy, making it more difficult to detect.
• The influence attack on fairness provides a controllable trade‐off between the im‐ pact on performance and fairness via a regularization term λ.
Additionally, we extend the evaluation set up to test whether current methods can be used to invert the inherent bias of a dataset. To this end, we re‐implement the entire experimental setup, and hence contribute:
• an extensive study and evaluation of the adversarial attacks proposed by Mehrabi et al. [1].
• amodification to the influence attack on fairness which can invert or diminish the inherent bias of a dataset.
• a comprehensible and easily extensible codebase, which can be used both in the evaluation of current methods and as a framework for further research on adver‐ sarial attacks on fairness.
None 8.2 (#28) – Nalmpantis et al. 2022 3
3 Methodology
3.1 Poisoning Attacks Poisoning attacks are a category of adversarial attacks where the attacker impacts a sys‐ tem by injecting a small portion of engineered malicious data into its training set. In particular, we consider that the system is trained on a clean dataset Dc and evaluated on a test datasetDtest. The attacker has knowledge of both sets, as well as of the system’s architecture and its training pipeline. With this information, the attacker creates a poi‐ soned dataset Dp, with |Dp| = ϵ|Dc|, so that training the attacked system on Dc ∪ Dp impacts its performance, or in our case its fairness. The parameter ϵ controls the per‐ centage of poisoned points, which depends on the nature of the application. Finally, we assume that the attacked system has a defense mechanism B that possibly removes poisoned data with the use of anomaly detection techniques.
Influence Attack on Fairness — The Influence Attack on Fairness (IAF) is a gradient‐based data poisoning attack, derived from a combination of the works of Koh et al. [7], which introduces the basic influence attack, and Zafar et al. [8], which proposes a novel fair‐ ness loss. Themain idea is to buildDp from copies of two datapoints (x̃1, ỹ1) and (x̃2, ỹ2) sampled from Dc, and progressively update them to decrease model fairness, as mea‐ sured by an adversarial loss Ladv. The authors propose to use Ladv = Lbc +λ · Lf , where Lbc is any binary classification loss and Lf is the aforementioned fairness loss. To update (x̃1, ỹ1) and (x̃2, ỹ2), the paper suggests to perform gradient ascent on Ladv and then updateDp with their copies. Since Ladv depends on the trainedmodel’s param‐ eters θ̂, the gradient ascent follows an expectation‐maximization scheme, where in the expectation step the model is trained on B(Dc ∪ Dp)1and in the maximization step the points move on the gradient direction. Although this idea is very intuitive, calculating the gradient of Ladv w.r.t each adversarial point is challenging. The approach presented in [6] is to apply the chain rule as ∂L∂x̃i = ∂L ∂θ̂ ∂θ̂ ∂x̃i , with the later derivatives calculated in Equations 1 and 2. Here, ℓ is the model’s train loss for the single data point and Hθ̂ is the Hessian of the train loss at θ̂ w.r.t. the adversarial sample x̃i. More details for the derivation of these formulas, as well as how to compute them efficiently, can be found in Section 2.2 of [7] and Section 4.1.1 of [6].
gθ̂,Dtest def = ∂L ∂θ̂ = 1 |Dtest| ∑
(x,y)∈Dtest
∇ℓ(θ̂; x, y) (1)
∂θ̂ ∂x̃ = −H−1 θ̂ ∂2ℓ(θ̂; x̃, ỹ) ∂θ̂∂x̃
(2)
Anchoring Attack — The anchoring attack places poisoned datapoints, which act as an‐ chors, in the near vicinity of two target points. In particular, the attacker samples two target points xtarget−, and xtarget+ from the advantaged Dadv and disadvantaged Ddisadv groups of the train dataset. Subsequently, |ϵn| poisoned datapoints {x̃i}|ϵn|i=1 are gener‐ ated in the near vicinity of the target points, placing them in the same demographic group but on opposite categories ỹi ̸= ytarget. Intuitively, this aims to move the decision boundary so that more advantaged points have a positive predictive outcome and more disadvantaged points have a negative outcome, hence inducing more biased outcomes. The paper proposes two methods to sample xtarget− and xtarget+ from the dataset:
• RandomAnchoring (RAA): xtarget is sampleduniformly for eachdemographic group. 1In the original paper, the authors mention that training is performed onDc∪Dp, but we deem that using
B(Dc ∪ Dp) is more sensible and congruent with the basic influence attack [6].
None 8.2 (#28) – Nalmpantis et al. 2022 4
• Non‐RandomAnchoring (NRAA): xtarget is the point close to themost similar points given its label and demographic. This aims to affect as many points as possible when placing poisoned points within its vicinity.
In the latter case, the authors suggest to consider two points, x and x′, as neighbors if and only if ||x − x′|| < R, R ∈ R. The choice of R and the specific norm || · || is not defined in the paper. After careful examination of the provided code, we found that the L1 norm was used and the R values were hard‐coded for each dataset. To avoid manual experimentation for each dataset’s R, we propose the following definition for the most popular point in a dataset X :
xpop def = argmax
x∈X ∑ x′∈X exp
( −d(x, x ′)
σ2d(X )
) (3)
where d is a distance metric and σ2d(X ) denotes the variance of the points’ distances to each other under d. Motivation for this choice and implementation details can be found in Appendix B.
3.2 Defenses The authors use a defense mechanism B in both of the proposed attacks, along with a corresponding projection function that bypasses it, without specifying the actual type of the defense. Although this information is not crucial for the comprehension of the attacks, we deem it critical for their reproducibility. After inspecting the code and the cited literature, we found that the defensemechanism used is a combination of the L2 defense and the slab defense [9]. The L2 defense removes points far from their corresponding class’ centroid according to the L2 distance:
βy = ED[x | y], sβ = ||x− βy||2
The slab defense projects points onto the line between the class centroids and then re‐ moves the points too far from the centroids:
βy = ED[x | y], sβ = ∣∣(β1 − β−1)⊤(x− βy)∣∣
The feasible set Fβ ⊂ X × Y encodes the defenses, as well as the constraints for the in‐ put’s features, and contains all of the points that would not be discarded by the defender. For the L2 constraint, we apply the LP relaxation technique as described in [6] and end up with a feasible set:
FLP = { (x, y) : E [∥∥x̂− µy∥∥22] ≤ τ2y ∧ x ∈ R≥0} where µy denotes the centroid of the subset of points in class y. The parameter τy is chosen dynamically for each y, such that 90% of the points in the Dy subset satisfy the L2 constraint. For the slab constraint, we construct a feasible set:
Fslab = { (x, y) : |(µ1 − µ−1)⊤(x− µy)| ≤ τ ′y ∧ x ∈ R≥0 } where µ1 and µ−1 denote the centroids of classes 1 and −1 respectively. Once again, the parameter τ ′y is chosen dynamically for each y such that 90% of the points in theDy subset satisfy the slab constraint. Our final feasible set is the intersection of the feasible sets under the two constraints, plus any additional input constraints imposed by X . Projecting points ontoFβ takes the formof anoptimizationproblem, namely calculating argminx∈Fβ ∥x− x̃i∥2, where x̃i denotes the poisoned point. We then simply solve the optimization problem using the library CVXPY with the SCS solver. This procedure is extensively discussed in [6], Section 3.3.
None 8.2 (#28) – Nalmpantis et al. 2022 5
4 Experimental Setup
4.1 Model and training pipeline We did not manage to find a detailed description of either the model used or its training pipeline in the original paper. The authors mention that the hinge loss was used, lead‐ ing us to assume that benchmarked model was a Support Vector Machine. However, after examining their code, we identified that the default model used was a Logistic Re‐ gression model. We also followed this choice, as it allows for an easy calculation of the fairness loss used in the influence attack on fairness. Additionally, the authors seem to use SciPy’s fmin_ncg optimizer to train the model, which is a second‐order opti‐ mization algorithm that uses conjugate gradients. In our implementation, we opted for Stochastic Gradient Descent, which should be able to converge to the same parameters, as the minimization problem is convex. In our reported results, we used the average over three runs to account for any stochasticity in the pipeline.
4.2 Datasets We carry out our experiments on the same three datasets as the original paper and con‐ sider “gender” to be the sensitive attribute. We use a pre‐processed version of each dataset, as provided by the authors, to have a common starting point. However, we later discovered a few issues regarding the pre‐processing pipeline, which we elaborate on in Appendix A. In all cases, the test set consists of 20% of the total data and there is no validation set. A short description of each dataset is presented below: German Credit Dataset2 [10]. This dataset has 1000 entries of loan applicants. Each applicant is characterized by 13 categorical and 7 numerical features describing their credit risk and is classified as either “good” or “bad”, in terms of their ability to repay the loan. COMPAS Dataset3 [11]. This dataset has 7214 entries of criminal defendants. We utilize 8 categorical features from the dataset to predict whether a defendant will recommit a crime within 2 years. Drug Consumption Dataset4 [12]. This dataset has 1885 entries of people alongside their drug history. Each person is described by 13 numerical attributes, which can be used to infer drug usage of 18 different substances. We focused on predicting whether indi‐ viduals have used cocaine in their lifetime, akin to the original paper.
4.3 Fairness Metrics We evaluate the impact of our attacks both in terms of performance and fairness. For performance, we use the accuracy error, while for fairness we use the Statistical Parity Difference (SPD) [13] and the Equality of Opportunity Difference (EOD) [14]. This eval‐ uation protocol matches the one in the original paper, although our implementation of EOD gives different results. We were able to verify our results’ validity by compar‐ ing them with the AI Fairness 360 library [15]. Moreover, the original paper used the absolute values of the aforementioned metrics, which we followed for the reproduced experiments but not for our extensions, as the metrics’ signs contained the necessary information. Statistical Parity Difference. Statistical parity is used to ensure that the demographic distribution of the samples being classified positively (or negatively) is similar to the distribution of the entire population. As a result, when we measure the difference in
2https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data-numeric 3https://github.com/propublica/compas-analysis/blob/master/compas-scores-two-years.csv 4https://archive.ics.uci.edu/ml/machine-learning-databases/00373/drug_consumption.data
None 8.2 (#28) – Nalmpantis et al. 2022 6
statistical parity between the twodemographics (advantaged and disadvantaged groups), we can deduce whether a model is biased in favoring or harming one of the two groups.
SPD = ∣∣ P (ypred = +1 | x ∈ Dadv)− P (ypred = +1 | x ∈ Ddisadv) ∣∣
Equality of Opportunity Difference. Equality of opportunity is used to guarantee that samples with a positive ground truth label are just as likely to be classified positively, regardless of the demographic group they belong in. By measuring the difference in equality of opportunity for the two groups, we can identify whether the model is biased towards classifying positively more often for either demographic group, given that they have a positive ground‐truth label."
"['Vera Neplenbroek', 'Sabijn Perdijk', 'Victor Prins']",[Re] Replication study of 'Data-Driven Methods for Balancing Fairness and Efficiency in Ride-Pooling',10.5281/zenodo.6574683,Replication,Python,https://zenodo.org/record/6574683/files/article.pdf,rescience c machine learning deep learning python pytorch ridesharing fairness,https://openreview.net/forum?id=BEhgn2zm3CK,https://github.com/Veranep/rideshare-replication,8,2,2022,"We evaluate the following claims related to fairness‐based objective functions presented in [1]: (1) For the four objective functions, the success rate in the worst‐served neighbor‐ hood increases monotonically with respect to the overall success rate. (2) The proposed objective functions do not lead to a higher income for the lowest‐earning drivers, nor a higher total income, compared to a request‐maximizing objective function. (3) The driver‐side fairness objective can outperform a request‐maximizing objective in terms of overall success rate and success rate in the worst‐served neighborhood. This means that this objective, whilst reducing the spread of income, also positively impacts rider fairness and profitability.","The paper is written engagingly and the theoretical sections, in particular, give a clear description of the problem setup and objectives. The paper is also accompanied by an open‐source code base, which supports reproduction efforts.","The provided code lacks a script to preprocess raw data, which is required to reproduce the experiment, nor was the preprocessed data openly available. Additionally, complex code structure and scarce commenting complicated replication.
Communication with original authors Due to the absence of preprocessed data, we contacted the authors, who quickly pro‐ vided the requested data.
ReScience C 8.2 (#29) – Neplenbroek, Perdijk and Prins 2022 2
1 Introduction
Ride‐pooling platformsmatch independent drivers with multiple riders. This matching is performed by machine learning algorithms, which are designed to maximize com‐ pany profit. The profit motive behind these algorithms can cause unfairness among drivers and riders, for instance by unequally distributing rides between drivers, or by servicing requests originating in some neighborhoods at lower rates [1, 2, 3]. The paper Data-Driven Methods for Balancing Fairness and Efficiency in Ride-Pooling [1] (henceforth referred to as “the paper” or “the authors”) explores the tradeoff between rider fairness, driver fairness, and total income (i.e. company profitability) by measur‐ ing fairness and profitability metrics across simulations using four objective functions. These objective functions are maximized by an algorithm that matches rider requests to drivers, using actual request data from the New York Yellow Taxi dataset. The follow‐ ing metrics are studied: a) the percentage of all requests that are serviced (the overall success rate), b) the success rate in the neighborhood with the lowest local success rate (the success rate in the worst-served neighborhood), and c) the distribution of income across drivers. The overall success rate is used as a proxy for company profitability, whereas the success rate in the worst‐served neighborhood and the income of the least‐earning drivers are measures of rider and driver fairness, respectively. The matching algorithm, introduced by [4], uses a Markov decision process (MDP) in combination with a neural value estimator to match rides to drivers non‐myopically, that is, with awareness of future events that could impact the value of a match. The pa‐ per’s algorithm requires a strongly connected graph (i.e. street network) on which the taxis operate, precomputed routes and travel times between all pairs of nodes (i.e. inter‐ sections), and a dataset of requests, each containing an origination node, a destination node, and the time the request was issued. Thepaper compares twoprofitability‐focusedobjective functions and two fairness‐focused objective functions. Theprofitability‐focused request objectivemaximizes the total num‐ ber of requests serviced during the simulation, given by the sum of ongoing requests pi and completed requests si, for each driver i:
orequest(R,W ) = n∑ i=1 (|pi|+ |si|), (1)
where R and W are sets respectively containing the states of the drivers, and all pre‐ viously unaccepted and accepted requests. The profitability‐focused income objective maximizes the total income of all drivers:
oincome(R,W ) = n∑ i=1 πi, (2)
where πi is the income of driver i, which is made up of a constant part and a variable part that depends on the distance of the trip. The rider fairness objective maximizes profit whilst minimizing the variance of the success rate across all neighborhoods j:
orider(R,W ) = −λV ar( hj kj ) + n∑ i=1 πi, (3)
where hj is the number of serviced requests originating in neighborhood j, kj is the total number of requests originating in j, and λ a hyperparameter moderating the reg‐ ularization. The driver‐side fairness objective maximizes profit whilst minimizing the variance of the income across all drivers i:
odriver(R,W ) = −λV ar(πi) + n∑
i=1
πi. (4)
ReScience C 8.2 (#29) – Neplenbroek, Perdijk and Prins 2022 3
2 Scope of reproducibility
We focus our reproducibility study on the claims related to the fairness‐based objective stated in the previous section. These claims (henceforth referred to as the claims) can be summarized as follows:
1. For the four objective functions, the success rate in theworst‐servedneighborhood increases monotonically with respect to the overall success rate.
2. The proposed objective functions do not lead to a higher income for the lowest‐ earning drivers, nor a higher total income, compared to a request‐maximizing ob‐ jective function. This extends claim 1, suggesting that a profit motive generally leads to increased fairness for drivers and riders alike.
3. The driver‐side fairness objective (4) can outperform a request‐maximizing objec‐ tive (1) in terms of overall success rate and success rate in the worst‐served neigh‐ borhood. This means that this objective while reducing the spread of income, also positively impacts rider fairness and profitability.
The authors have demonstrated claim 3 to hold only for 50 drivers. For 200 drivers they find the opposite, namely that equation (1) outperforms equation (4) in terms of fairness as well as profitability metrics. We evaluate these claims by testing whether they still hold under a variety of modifica‐ tions to the experimental setup. We conduct four experiments that deviate increasingly from the exact setup of the paper: (a) the experiment of the paper is reproduced using the author’s preprocessed data, (b) the non‐myopic neural value estimator is replaced by a myopic greedy estimator, (c) the experiment of the paper is replicated using data generated with our own preprocessing method, and (d) the experiment is applied to a different dataset (New York Green Taxi dataset), using our own preprocessing method. Note that all experiments except for (b) use the neural value estimators also used in the original paper.
3 Methodology
This section explains the methodology used for the four experiments we carried out. An overview of the used code is provided, followed by descriptions of the model, the datasets and the hyperparameters. Finally, we outline the experimental setup and state the computational resources needed to perform the experiments.
3.1 Code The code provided by the authors, which is largely based on the code by [4], was used as a base for our re‐implementation in PyTorch. The provided code was sufficient to re‐ produce the experiments performed in the original paper, after the authors emailed the preprocessed data that they used in the paper. This data consists of the graph of Man‐ hattan, travel times, routes, and rider requests from the New York Yellow Taxi dataset mapped to nodes on the graph. Neither the code to generate this data nor the data itself are publicly available. To solve the integer linear problem that determines which set of actions is assigned to which driver, the original code uses the callable library CPLEX 12.8. However, at the time of this replication study, the free edition of CPLEX does not suffice to train the required models, since the problem size limits were exceeded. Therefore, the no‐cost academic edition of CPLEX 20.11 was used instead.
1https://pypi.org/project/cplex/
ReScience C 8.2 (#29) – Neplenbroek, Perdijk and Prins 2022 4
In addition to an exact reproduction, we examine the paper’s claims’ robustness against a different method of preprocessing the same raw data. The paper uses the method described in [5] to preprocess the raw trip data. However, this method is computation‐ ally demanding and complex to implement. We developed an algorithm that generates routes and travel times on a graph, but that differs in two ways from [5]. First, we use travel time estimates from OpenStreetMap (OSM), corrected by a multiplication con‐ stant, equal to the mean ratio between the actual travel time and the OSM estimate of the travel time, computed over all trips in the dataset. Second, unlike the method used in the paper, we do not compute the Dijkstra algorithm for each pair of nodes, which is an O(n2) approach, where n is the number of nodes in the graph. For the street network of Manhattan (n ≈ 4000), this can take days on a typical laptopwithoutGPUacceleration. Instead, our routing algorithm invokesDijkstra on a total of ≈ 500, 000 pairs of randomly sampled nodes, which yields a coverage of ≈ 60% of all n2 = 16M routes, because all subroutes of each route are also optimal routes. The optimal routes between the remaining 40% of node pairs are approximated by setting each remaining route (n,m) equal to the concatenation of subroutes (n, p) and (p,m), for a predecessor p selected from a set of predecessors of nodem, for which routes (n, p) and (p,m) are known and yield the lowest total travel time. Lastly, to test the generalizability of the methods used in the paper, we performed addi‐ tional simulations using trips in Brooklyn from the New York Green Taxi dataset. The algorithm described above is used to generate routes and travel times between all nodes, given the graph of Brooklyn’s street network.
3.2 Model descriptions The original paper has adapted the model that incorporates an MDP to assign a set of actions to each vehicle from [4]. An overview of this algorithm is provided in Appendix A. Themodel makes use of a neural value estimator that assigns a value to each possible set of actions. In the original paper, the objective functions (equations 1, 2, 3, 4) that this model aims tomaximize are varied, alongwith the number of drivers (50 and 200 drivers are used). The input to the neural value estimator [4] is composed of the current location and path of the vehicle, the permissible delay, the current epoch, the number of other vehicles in the vicinity and the number of requests that were placed in the current epoch. By using an LSTM, this value estimator can take into account non‐myopic considerations like the possibility that a future rider request will appear along the route of a current rider request, therefore increasing the value of the current request. The location and path features are embedded using pretrained embeddings, which were computed by a separate network that was trained to predict travel times between any two nodes in the graph.
3.3 Datasets
The original experiments are conducted on the New York Taxi dataset [6], available at 2, consisting of pickup and drop‐off locations and times for Yellow Taxi passengers from March 23rd to April 1st and from April 4th to April 8th, 2016. The generalization experiments are conducted on the New York Green Taxi dataset 3, consisting of pickup and drop‐off locations and corresponding times for Green Taxi pas‐ sengers in the months February, March and June. We take the subset of trips in Brook‐ lyn, to keep the size of the graphmanageable and similar to the graph ofManhattan used in the original paper. Whereas Yellow taxis in practice only serve the business district of downtownManhattan, the Green taxis serve all of New York. This makes the Green Taxi
2https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page 3https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page
ReScience C 8.2 (#29) – Neplenbroek, Perdijk and Prins 2022 5
dataset a good choice to test the generalization of results concerning rider‐side metrics, because of differences in affluence between various districts of New York. In addition, Brooklyn is a different geographical area and the Green Taxi dataset contains a different distribution of requests, compared to the Yellow Taxi dataset.
3.4 Hyperparameters Nohyperparameter searchwas done for this replication study. Instead, the hyperparam‐ eters provided by [1] were used to adhere to the original experimental setup as much as possible. This meant that for the driver‐side fairness objective function we set λ to be 4 6 , and for the rider‐side fairness objective function, λ was set to be 10
9. Additionally, we set the constant costs of a ride to $5, the capacity of a car to 4 riders, the number of neighborhoods to 10, and we batch rider requests per minute.
3.5 Experimental setup For each experiment containing a neural value estimator (section 2), themodel is trained for each combination of objective function (equations 1, 2, 3, 4) and number of drivers (∈ {50, 200}). For the specific packages and their versions that were used to obtain our results, we refer to our codebase 4. Reproducing the experiments by [1] means that we trained allmodels on 3 days of data, except for the rider‐side fairness objective (equation 3) models, which were trained on 2 days of data. All models were evaluated on one day of data. In order to evaluate the claims, the followingmetrics are of interest: the overall success rate, the success rate in the worst‐served neighborhood (also calledminimum request success rate), and the income per driver. To compare the objective functions, three plots are generated per experiment, in line with the reporting of the original paper: 1) the min‐ imum request success rate as a function of the overall success rate for the simulation with 50 drivers, 2) the same plot for the simulation with 200 drivers, and 3) the distri‐ bution of income across drivers for each objective function for the simulation with 200 drivers. During the exact reproduction of the paper’s experiments, we observed that the neural model is not trained (seemingly inadvertently) in the experiment with 50 drivers. The number of training examples for the neural net grows in the number of drivers and the number of days of training data. The authors included a minimum threshold of training examples, which is not met by the experiment with 50 drivers. However, the algorithm silently executes, therefore using an untrained randomly‐initialized neural network. Importantly, the value assigned to each action is a linear combination of a deterministic term and the output of the (untrained) neural net. Therefore, even though the network’s outputs are random in the case of 50 drivers, the computed values are not. This finding motivated the experiment where the neural value estimator is replaced by a greedy value estimator. To test the claims under a different data preprocessing method, we run an experiment using the same rawdata as the original paper, but with our self‐developed preprocessing method (i.e. a graph of Manhattan with routes and travel times computed as outlined in section 3.1). Apart from the data preprocessing, this experiment is identical to the experiment in the paper. With this, we aim to investigate the sensitivity of the claims and the method used by [1] to different data preprocessing methods and in particular to a different travel time computation, which is inherently noisy. Our final experiment uses the Green Taxi dataset and our own preprocessing method in order to study the generalizability of the work by [1]. The models for the Green Taxi dataset were trained on 6 days of data, except for the rider‐side fairness objective (equa‐ tion 3) models, which were trained on 4 days of data. All these models were evaluated
4https://github.com/Veranep/rideshare-replication
ReScience C 8.2 (#29) – Neplenbroek, Perdijk and Prins 2022 6
on two days of data. For all experiments using our preprocessing method, two new sets of pretrained embeddings were trained for the corresponding graphs of Manhattan and Brooklyn.
3.6 Computational requirements All experiments were run on one Nvidia GeForce 1080Ti GPU, using three CPU nodes. Training and evaluating a model on the Yellow Taxi dataset for 50 drivers took roughly 2.5 hours, whereas training and evaluating one for 200 drivers took 6‐7.5 hours. For the rider‐fairness objective function models, which were only trained on two days of data, runtimes were two‐thirds of this. The experiments that use a greedy non‐neural value estimator took an hour less for 200 drivers and roughly the same amount of time for 50 drivers. For the Green Taxi dataset, more days of data were used to train on, since this dataset contains fewer requests per day. Here, the model took roughly 1 hour to train and evaluate for 50 drivers and 10 hours for 200 drivers. Computing embeddings of size 100 for all ≈ 4000 locations took approximately 10 hours. Finding shortest paths and computing travel times between all pairs of locations took 1.5 hours on a laptop with an Intel i5 processor 5.
4 Results
In this section, we present the results of the reproduction of the original paper, the re‐ placement of the neural value estimator by the greedy non‐neural value estimator, the replication using our data preprocessingmethod, and the generalization experiment us‐ ing the Green Taxi dataset. For each experiment, we evaluate whether the claims listed in Section 2 are supported by the presented results.
4.1 Reproduction of the original experiment The first claim states that objective functions which improve the overall success rate for riders also improve the success rate in the worst‐served neighborhood. The figures that the authors use to support this are displayed in Appendix B and our reproduced results in Figures 1a and 1b. If objective functions that improve the overall success rate also improve the success rate in the worst‐served neighborhood, we should see the success rate in theworst‐servedneighborhoodmonotonically increase as the overall success rate increases. This is indeed a pattern that we see in the figures from the original paper, as well as in our figures. Second, the authors claim that no objective function raises wages for the lowest‐earning drivers or raises the total income, compared to the requests objective function (equation 1). In the original paper, results related to the income distribution used to support this claim are only obtained for 200 drivers, as can be seen in Appendix B. In our reproduc‐ tion the function thatmaximizes total income at 200 drivers is also the requests objective function. However, the maximum income for the least‐earning drivers is obtained with the driver‐side fairness objective function, as displayed in Figure 1c. The final claim states that the driver‐side fairness objective function (equation 4) outper‐ forms the requests objective function (equation 1) in terms of overall success rate, suc‐ cess rate in the worst‐served neighborhood, and reducing the spread of income. These first two results are only obtained for 50 drivers, as seen in the figures in Appendix B, and the last result only for 200 drivers. We reproduce all three of these results. In Fig‐ ure 1a, we see that both the highest overall success rate and the highest success rate in the worst‐served neighborhood are obtained with equation (4). Finally, we find that
5Specifically, a MacBook Pro (13‐inch, 2020) with 1.4 GHz Quad‐Core Intel Core i5 CPU
ReScience C 8.2 (#29) – Neplenbroek, Perdijk and Prins 2022 7
equation (4) reduces the spread of income compared to (1), as can be seen from Figure 1c.
4.2 Results beyond original paper In addition to reproducing the results in the original paper, we performed supplemen‐ tary experiments to test the generalizability of the methods used in the original paper. First we discuss the results of replacing the neural value estimator with a greedy value estimator. Further, we examine the results of using our preprocessing method. Lastly, we discuss the results obtained using the Green Taxi dataset.
ReScience C 8.2 (#29) – Neplenbroek, Perdijk and Prins 2022 8
Results using a greedy non-neural value estimator — These results are obtained by replacing the neural non‐myopic value estimator with a myopic greedy value estimator. This serves both to test the added value of the neural estimator, and to test the sensitivity of the claims to a different estimation method. Interestingly, the results obtained with the greedy estimator (Figure 2) closely resemble the results obtained with the neural es‐ timator (Figure 1), even in the case of 200 drivers where the neural estimator does train (as opposed to the case with 50 drivers). This suggests that, given the limited training examples for 200 drivers and 3 days of taxi data, the neural model provides little added benefit over amyopic greedy estimator. By extension, this experiment reaches the same conclusions: claims 1 and 3 are replicated, but claim 2 is not.
Results using our preprocessing method — To examine the sensitivity to changes in the pre‐ processing method, we compare the results of this experiment to the results of the re‐
ReScience C 8.2 (#29) – Neplenbroek, Perdijk and Prins 2022 9
production. The obtained results, as displayed in Figure 3, are similar to the reproduced results. We see the same monotonic increase in Figures 3a and 3b as we saw in Figure 1 for the reproduction. Similarly, the income distribution (Figure 3c) shows that objec‐ tive (4) obtains the highest income for the lowest‐earning drivers and reduces the spread of income. Therefore, we can conclude that these results support claim 1 and claim 3, but do not support claim 2, and that the method proposed by the authors is robust to changes in the preprocessing method.
Results on Green Taxi dataset — In order to analyze the generalizability of the original paper, we use the results obtained on the Green Taxi dataset to see if the claims described in Section 2 hold for a different dataset. These results (Figure 4) are similar to the ones ob‐ tained on the Yellow Taxi dataset in both the reproduction experiment (Figure 1) and the experiment using our preprocessing (Figure 3). This experiment again supports claims
ReScience C 8.2 (#29) – Neplenbroek, Perdijk and Prins 2022 10
1 and 3, but does not support claim 2. Important to note is that the success rates are much higher compared to those obtained on the Yellow Taxi dataset. This is because the Green Taxi demand in Brooklyn is signif‐ icantly less than the Yellow Taxi demand in Manhattan. Hence, with an equal number of taxis a greater share of requests can be met. The fact that the findings of this ex‐ periment are consistent with the previous experiments, all of which have much lower success rates, provides confidence that the claims also generalize to realistic success rates (i.e. success rates approaching 100%, as is expected from real taxi companies).
ReScience C 8.2 (#29) – Neplenbroek, Perdijk and Prins 2022 11
5 Discussion
To conclude, our results support the first claim, since we find that the success rate in the worst‐served neighborhood increases monotonically with respect to the overall success rate for both 50 and 200 drivers. Unlike the original paper, wedonot find that the request‐ maximizing objective function (equation 1) maximizes income for the lowest‐earning drivers, so we do not support the second claim. Instead, we find that at 200 drivers the driver‐side fairness objective function (equation 4) obtains the highest income for the lowest‐earning drivers. We support the third claim since our results show that the driver‐side fairness objective function yields the greatest overall success rate, the highest success rate in the worst‐ served neighborhood, and reduces the spread of driver income. Indeed, our results provide even stronger support for this claim than the original paper. Unlike the paper, we have found the driver‐side objective to provide the best success rates in both cases of 50 and 200 drivers. Furthermore, this objective lifts the income of the least‐earning drivers above what they make under the request‐maximizing objective. This makes the driver‐fairness objective attractive in all respects, and an interesting subject for further research. One avenue to explore is why the driver‐fairness objective produces greater success rates than the request‐maximizing objective, even though the latter’s sole pur‐ pose is to maximize the success rate. The obtained results are generally consistent across the four conducted experiments, showing that the claims which are supported by our results (claims 1 and 3) are robust and relatively insensitive to a range of reasonable changes to the experimental setup. This provides confidence that these claims and the corresponding objective functions generalize well beyond the precise setups in which we and [1] tested them. One limitation of ourwork, which is also shared by the original paper, is that the success rates across all experiments are unrealistically low, because the number of drivers (50 or 200) is insufficient to meet demand (there are more than 10,000 Yellow taxis in Manhat‐ tan). This creates an abundance of possible actions for each driver that is not represen‐ tative of the competition that exists for real‐world taxi services. Running experiments in a setup where success rates are more realistic would be a worthwhile additional gen‐ eralization experiment. Such experiments may require more computational resources than some researchers, ourselves included, have access to. However, our results for the Green Taxi dataset already mitigate concerns that the claims would not generalize to greater success rates; the claims were upheld in this setup with success rates of over 50%.
5.1 What was easy The paper is written engagingly and the theoretical sections in particular give a clear description of the problem setup and objectives. The paper is also accompanied by an open‐source codebase with their implementation, which is extremely helpful to obtain‐ ing accurate reproductions.
5.2 What was difficult Even though the code was sufficient to reproduce the experiments done in the original paper, it was cluttered at times. It contains functions that are never used, as well as print statements solely used to check if a certain point in the code is reached without errors. Additionally, the code used to create the location embeddings creates embeddings of size 10, when embeddings of size 100 are expected by the model. When reimplement‐ ing the code in PyTorch, most difficulty was experienced when having to feed masked data into an LSTM backwards, as a result of how masking is implemented in PyTorch. Further, various important details could only be found in the code, such as which days
ReScience C 8.2 (#29) – Neplenbroek, Perdijk and Prins 2022 12
they used to train the model on and the used epoch duration. One of the most impor‐ tant details that was missing is the notion that the model does not train for 50 drivers and three days of Yellow Taxi data, as it will not train without enough examples. Fur‐ ther, the data to perform the original experiments and the script to preprocess the raw data were not publicly available. After contacting the authors, they provided us with the missing data. Despite what is stated in the paper, approximately 1% of the routes in this data were not computed. These omitted routes, however, were not present in any of the rider requests and therefore did not pose a problem to this research.
5.3 Communication with original authors We contacted the authors because the data and the embeddings used to perform the original experiments are not publicly available. The authors provided the missing data quickly and expressed willingness to help with further queries."
"['Alessio Galatolo', 'Alfred Nilsson']",[Re] Replicating and Improving GAN2Shape Through Novel Shape Priors and Training Steps,10.5281/zenodo.6574685,Replication,Python,https://zenodo.org/record/6574685/files/article.pdf,rescience c machine learning deep learning python pytorch gan2shape 3d,https://openreview.net/forum?id=B8mxkTzX2RY,https://github.com/alessioGalatolo/GAN-2D-to-3D,8,2,2022,"We re‐implement the method proposed by Pan et al. [1] with regards to 3D shape re‐ construction, and extend their work. Our extensions include novel prior shapes and two new training techniques. While the code‐base relating to GAN2Shape was largely rewritten, many external dependencies, which the original authors relied on, had to be imported. The project used 189 GPU hours in total, mostly on a single Nvidia K80, T4 or P100 GPU, and a negligible number of runs on a Nvidia V100 GPU.",The original code is easily runnable on the correct machine type (Linux operating sys‐ tem and CUDA 9.2 compatible GPU) for the specific datasets used by the authors.,"Porting the model to a new dataset, problem setting or a different machine type is far from trivial. The poor cohesion of the original code makes interpretation very difficult,
Copyright © 2022 A. Galatolo and A. Nilsson, released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Alessio Galatolo (galatolo@kth.se) The authors have declared that no competing interests exist. Code is available at https://github.com/alessioGalatolo/GAN-2D-to-3D. – SWH swh:1:dir:531d1456baa3bb553ce549785158be7005c682c7. Open peer review is available at https://openreview.net/forum?id=B8mxkTzX2RY.
ReScience C 8.2 (#30) – Galatolo and Nilsson 2022 1
and that is why we took care to re‐implement many parts of the code using the decou‐ pling principle. The code depends on many external implementations which had to be made runnable, which caused a significant development bottleneck as we developed on Windows machines (contrary to the authors). The exact loss functions and the number of training steps were not properly reported in the original paper, whichmeant it had to be deduced from their code. Certain calculations required advanced knowledge of light‐ transport theory, which had no familiarity to us, and had to be mimicked and could not be verified.
Communication with original authors We did not communicate with the original authors.
ReScience C 8.2 (#30) – Galatolo and Nilsson 2022 2
1 Introduction
Image generation has been a hot topic within generative models as they represent an intuitive problem whose results are easily accessible by the public. One of the models that has received a lot of public attention is StyleGAN (Karras, Laine, and Aila [4]). The network’s architecture has been refined through multiple iterations in StyleGAN2 [5], StyleGAN2‐ADA [6] and StyleGAN3 [7]. StyleGAN2 improves on thefirst versionby, among other things, adding a projection method onto the latent space, which allows the inver‐ sion of an image into its latent representation.
Methods like GAN2Shape [1] aim at exploiting the information that is already stored in the generator of a pre‐trained StyleGAN2 model to go beyond generating synthetic 2D images. In particular, thismethod aims to extract the 3D shape of the preeminent object in any image. This is intuitively possible due to the size of the training dataset of the StyleGAN2model, and its ability to generate images of an object frommultiple views and lighting directions by varying w. The authors of GAN2Shape use StyleGAN2 networks pre‐trained on different dataset categories andfive different feature extractionmodels to derive the shape information for images belonging to the same dataset categories. This method, compared to many others [8, 9, 10, 11], has the advantage of being completely unsupervised, and not requiring a change in the training process of the classical 2D GAN.
In this article, we describe our replication of GAN2Shape [1] and report mixed results. We perform several experiments and we illustrate the successes and shortcomings of the method. Further, we extend the method improving the original results in several cases.
2 Scope of reproducibility
The authors of GAN2Shape make the following claims:
1. Their framework does not require any kind of annotation, keypoints or assump‐ tion about the images
2. Their framework recovers 3D shapewith high precision onhuman faces, cats, cars, buildings, etc.
3. GAN2Shape utilizes the intrinsic knowledge of 2D GANs
4. The 3D shape generated immediately allows for re‐lighting and rotation of the im‐ age.
3 Methodology
Our initial intent of re‐implementing the source code from the description of the paper had to be abandoned due to the lack of detailed information of some key points in the method. We, therefore, decided to follow a different approach integrating both the de‐ tails from the authors’ code and the paper’s description. While trying to always base our implementation on the paper’s description we found some parts (particularly the loss functions) that differed from the actual code and decided to follow the latter instead.
The resources we used were mainly the authors’ code, the code and documentation of all the out‐sourced methods the authors borrowed: StyleGAN2 [5] (code), Unsup3D [12] (code), Semseg [13] (code) and BiSeNet [14, 15] (code). The GPUs used weremultiple and varied depending on availability: Nvidia Tesla K80, T4, V100 and P100.
ReScience C 8.2 (#30) – Galatolo and Nilsson 2022 3
3.1 Model descriptions To extract the implicit 3D knowledge of pre‐trained StyleGAN network, Pan et al. [1] pro‐ pose an elaborate scheme involving five different neural networks. Each network mod‐ els a particular quantity corresponding to the view and lighting directions, the depth of the image, and the albedo. The View and Light (V and L, resp.) networks operate in a encoder type manner, trying to obtain a low‐dimensional vector representation of the camera view direction v and the direction of light l illuminating the object in the picture. The Depth and Albedo (D and A, resp.) networks utilize auto-encoder architectures1 to obtain image‐resolution depth maps d and diffuse reflections (albedo) a off the object’s presumed surface.
The real GAN knowledge extraction happens in the final network, the Offset encoder E, combinedwith the pre‐trained StyleGAN2 generator,G. The offset encoder aims to learn a latent representation w of images with randomly sampled view and light directions, pseudo-samples. Paired with G, this allows the creation of new realistic samples Ĩi = G(w′i) with new view and lighting directions, denoted projected samples. The projected samples then serve as extended training data, providing multiple view‐light direction variations of the original image.
To use the components v, l, d and a to obtain a reconstructed image, the authors utilize a pre‐trained neural renderer developed by Kato, Ushiku, and Harada [16], which we denote by Φ.
Training Procedure — The training process of this method can be divided into 3 different steps, where the different networks involved are trained separately. In the original paper, these steps are done sequentially and for one image at a time, as shown in Figure 1, and each step is repeated multiple times before moving into the following one. The result is a model that can predict the depth map for only one image. All of the networks are trained using the Adam optimization algorithm.
Prior pre‐training. Before attempting to learn the true shape of an object, the depth network is initialized by pre‐training it on a fixed prior shape. For this purpose Pan et al. [1] propose to use an ellipsoid shape as the shape prior. We utilized this ellipsoid prior to reproduce the results of Pan et al. [1], and we extended their work by also evaluating two new different priors.
Step 1 optimizes only the A network according to Equation 1. Given an input I, the first four networks predict their components v, l, d, a, and we obtain a reconstructed image Î = Φ(v, l,d, a)2.
Lstep1(I, Î) = ∥I− Î∥1 + λsLs(D(I)) + λpLp(I, Î) (1)
Step 2 optimizes the E network according to Equation 2. Using the d and a compo‐ nents given in the last step 1 iteration, and random directions v′i, l ′
i, we generate Np new pseudo‐images I ′ i. For each I ′ i we predict∆wi = E(I ′
i), which serves as input to the StyleGAN generator network G and obtain the projected images Ĩi.
Lstep2(I) = 1
Np Np∑ i=1 ∥I ′ i −G(w+ E(I ′ i))∥1 + λ1∥E(I ′ i)∥2 (2)
Step 3 optimizes the L, V ,D andA networks according to Equation 3. It consists in part of Lstep1. The second part utilizes the projected samples from the last iteration of step
1We refer to tables 5‐7 of the original paper ([1]) for the exact architectures. 2Lp is a neural network trained to predict similarities between images [17] andLs is a term that encourages
smoothness of the resulting depth maps (as described in [18]). We refer to our code for the weights λi.
ReScience C 8.2 (#30) – Galatolo and Nilsson 2022 4
2. For each projected sample ṽi = V (̃Ii), l̃i = L(̃Ii) is calculated. Combined with d and a from the original image, they can be used to reconstruct each projected sample from the components Ī = Φ(ṽi, l̃i,d, a)).
Lstep3(I, Ī) = 1
Np Np∑ i=1 [Lp(I, Īi) + ||I− Īi||1] + Lstep1(I, Î) + λ2Ls(D(I)) (3)
Stages. The steps are repeated for a number of stages. In each, the steps are trained for a different number of iterations (see Table 1 in subsection 5.5 in the appendix for details).
Novel Shape Priors — The first novel prior we consider is a masked box. Using the mask returned by the parsing model developed by Zhao et al. [19] we extrude the relevant object from the background, in a step‐like manner. Improving on this idea, we also smooth the transition from the object to the background. This is done by using three 2D convolutions, where we convolve the masked box shape with a 11× 11 filter of ones. Renormalizing the convolved shape, we obtain Figure 2c denoted as ‘smoothed box’.
The last prior we tested is obtained by normalizing the score (or “confidence”) that the parsing model gives to each pixel. We use this confidence to project the object, i.e. a pixel that is within the category with more confidence will be farther projected. This prior is similarly smoothed by convolutions and is denoted as ‘confidence based’.
Figure 2 shows a visual representation of the prior shapes used for an example image taken from the CelebA dataset.
3.2 Generalized Training Procedure Given the single‐use nature of the model obtainable with the original training proce‐ dure, we decided to develop an alternative training procedure to favor a general model M∗ usable for all images belonging to the same distribution as the training dataset D. We propose to pre‐train the depth netD on all images first, instead of repeating the pro‐ cess for each image. We also modify Step 1, 2 and 3 by greatly lessening the number of iterations given to a single image and breaking up the sequential training of the original method into a few iterations per example, and instead introducingNe epochs and batch training to compensate, increasing resource utilization and training speed. To facilitate
ReScience C 8.2 (#30) – Galatolo and Nilsson 2022 5
understanding of our modifications to the training procedure, we provide a schematic in Figure 3. It can be compared to the original shown in Figure 1. Let us note that the
original authors also briefly mention a ‘joint training’ that should improve the general‐ ization ability of the model, however, its performance is not properly reported and it only represents a mini‐batch extension of the pre‐training step.
3.3 Datasets Weaimed to reproduce the authors’ results on the LSUNCar, LSUNCat [2] and CelebA [3]. From these datasets, the authors selected a subset consisting of 10 images of cars, 216 images of cat faces, and 399 celebrity faces. Like the authors, we used RGB images of three color channels, resized to 128 × 128 pixel resolution. No further preprocessing was applied.
3.4 Hyperparameters For replication purposes, the original hyperparameters by Pan et al. [1] were used, but we also tried tuning some parameters that we believe are key to the method: the num‐ ber of projected samples,Np, for each image and the number of epochs for pre‐training the depth network. Np was varied within {2, 4, 8, 16, 32}. In our tests we found the val‐ ues 4, 8 and 8, respectively for the LSUN Car, LSUN Cat and CelebA dataset, to be the threshold after which the improvements in image quality start greatly decreasing (see subsection 5.11 in Appendix for more details).
The number of epochs for the depth network pre‐training was varied within {100, 500, 1000, 2000}. This pre‐training affects how irregular the depth map predictions are. We believe that using a threshold for the loss to check the convergence would be preferable as the number of epochs selected by the authors (1000) is enough in most cases but not in all. We attribute irregularity in some of our results to this issue.
3.5 Experimental setup and code For each dataset we run our implementation of the framework from Pan et al. [1] on the images that were selected by the authors, the procedure saves a checkpoint for each network. These checkpoints are later fed the original image to get the generated result. The evaluation of the results was only qualitative as all the datasets we explored do not have a ground truth for comparison. We instead relied on a manual evaluation.
ReScience C 8.2 (#30) – Galatolo and Nilsson 2022 6
Our code is available at https://github.com/alessioGalatolo/GAN-2D-to-3D. Our results are avail‐ able interactively under the docs folder and at alessiogalatolo.github.io/GAN‐2D‐to‐3D/.
3.6 Computational requirements Most of the experiments we ran were on a Intel(R) Xeon(R) CPU @ 2.20GHz with 2 cores available and a Nvidia Tesla P100‐PCIE‐16GB. Since the framework described by Pan et al. [1] is instance‐specific, we report the average time for completing the projection of a single image: 96m and 28s for an image in the CelebA dataset, 95m and 43s for a LSUN Cat image and 74m and 32s for a LSUN Car image.
4 Results
The model correctly learned the shape and the texture of many images, although some examples were less successful than others. For example, the model converged to be‐ lievable shapes for two of the cars in Figure 4, but the shape of the right‐most car is debatable.
In the following sections we show the reconstructed depth map and 3D projection of some images chosen as representative of the dataset. All of the images that follow have the background cut from the actual object, this was only done for ease of illustration and was not done for the actual training process since the original authors do not mask the background in all cases. It is also difficult to illustrate the results fairly in 2D images, so we invite the reader to visit our website with interactive 3D plots3.
4.1 Results reproducing the original paper
LSUN Car —We present the results on LSUN Car dataset in Figure 4. Most features are projected in the correct direction and show details that are correctly outward projected from themain object. This result supports all the claimsmade in section 2 as we did not use any annotation or assumption for the images, many details were retrieved with high precision using the StyleGAN knowledge and we were able to easily make a rotation of the image (see interactive web‐page).
LSUN Cat — The second experiment was conducted on the LSUN Cat dataset. The results were slightly poorer compared to the LSUNCar dataset. The face of the cats gets properly recognized, but some details like the nose are not protruded from the rest of the face and are generally on the same plane, see Figure 4. Some images present some irregularities in the form of spikes and hills (d). The rotation (f) does not result in a completely natural
3alessiogalatolo.github.io/GAN‐2D‐to‐3D/
ReScience C 8.2 (#30) – Galatolo and Nilsson 2022 7
image as part of the face of the cat appears on the same plane. This experiment does not support claims 2 and 4 in some cases (e.g. figures 4 (d) and (f) negate claims 2 and 4 respectively) while it does for claims 1 and 3 (section 2).
CelebA — The third experiment conducted on the CelebA dataset shows that most of the face are correctly portrayed with the only exception of the border of the face e.g. chin and forehead that sometimes is not included in the projection, see Figure 5 (b). Also we found out that themethod does not behave well with faces that are viewed from the side, see Figure 5 (c), where the face still gets a projection as it was viewed from the front. As a consequence of this, the rotation of side faces does not result in a good image. This experiment supports claims 1‐4 (section 2) only for some faces and claims 1 and 3 for those viewed from the side.
4.2 Results beyond the original paper
The effects of shape priors — The original paper did not specify the exact reasons for choos‐ ing an ellipsoid prior for the pre‐training of the depth net, therefore we decided to ex‐ periment with multiple prior shapes as well as no prior shape.
No prior. With the goal of assessing the results of this method when no prior shape is given, we ran a test on one image from the LSUN Car dataset without any prior pre‐ training, and with random initialization. The reconstruction objective is still satisfied very well, but it has converged to an extremely noisy depth map (see Figure 9 in subsec‐ tion 5.6 in the appendix). This briefly shows that this method would not work without a strong shape prior to guide it towards a reasonable shape.
Smoothed Box Prior. The first extention experiment was done by testing the first of the prior shapes we proposed, the smoothed box prior. Figure 6 shows the smoothed box prior tested on the LSUN Cat and CelebA dataset where it can be seen how it is better at understanding the structure of the nose and face in general.
Confidence‐BasedPrior. Another experimentweperformed focusedon theperformance of the second prior we presented, the confidence based prior. Figure 7 shows some re‐ sults on the datasets considered in this paper. The results are most promising in the CelebA dataset where the image of a face is correctly projected even if viewed from the side.
ReScience C 8.2 (#30) – Galatolo and Nilsson 2022 8
Generalized Training Procedure —We demonstrate the results of our new training loop on LSUN Cat. We note again that the difference to the previous demonstration on LSUN Cat, is that a single network D∗ was used to predict all of the images, as opposed to a different network Di for each image Ii. The general model was trained on a limited subset of 30 images from LSUN Cat. It was trained for a modest 60 epochs which results in approximately 60% of the weight updates per image of the original method. Figure 8 shows the projection of some images from the LSUN Cat dataset. One can observe that the method recognizes the general structure of the cat’s face but also presents some artefacts in some specific parts of the face e.g. the second cat’s cheek is further projected than where it should and similarly for the third cat’s chin.
Improved initialization — Our final experiment is inspired by the observation of the depen‐ dency of the method to the number of pseudo‐samples Np, and the variability that fol‐ lows in the results depending on their quality, as discussed in subsubsection 5.3.1. We experimentwith drastically increasing this number from16 to 128 for 10 short epochs, in which each training step is performed only once. We observemarginal improvements in the predicted shape (Figure 8) and larger improvements in the smaller details/features. See the subsection 5.10 in the appendix for further detail.
Training step 1 was not changed and it is allowed to converge in the first stage, as it does not involve the projected samples. See Table 2 in the appendix for an exact description of the number of iterations. All other parameters were left as in subsubsection 4.2.1, with the smoothed box prior. We experimented with two of the worst performers from the LSUN Cat dataset to evaluate whether this method could improve the results, see Figure 16. We applied the same idea to the general model described in sections 3.2, 4.2.2 and saw improvements, see Figure 8. The results can be compared to Figure 14.
ReScience C 8.2 (#30) – Galatolo and Nilsson 2022 9
5 Discussion
5.1 What was easy The authors provide a clear specification of the Python package dependencies, as well as other dependencies. Additionally, they provide scripts for easy downloading of a select few datasets and pre‐trained model weights. They precisely state how to execute the training script and how to run themodel for evaluation. Note that this refers to running the original code and that modifying and extending the code brought many difficulties, as explained in the next section.
5.2 What was difficult The paper by Pan et al. [1] did not contain enough information for a successful reimple‐ mentation. Many details had to be discerned or guessed from their code. Furthermore, the quality of said code does not allow for a quick interpretation. For example, deduc‐ ing the training loop and the number of iterations for each stepwas further complicated by the poor cohesion of the original code: the trainer script was heavily mingled with model class, using class members of the model object to increment training steps and nested function calls back and forth between the trainer and model classes.
The components v, l, d and a were not enough to pass in to the neural renderer to re‐ construct an image. In reality, several calculations of quantities such as diffuse shading and texture were needed to be fed into the neural renderer, using concepts from light transport theory that were not mentioned in the paper.
Another difficulty was the heavy reliance on external pre‐trained neural networks. The neural renderer [16], in particular, posed several problems. The major one was incom‐ patibility withWindows machines. To be able to develop on our personal machines, we had to make manual edits of the neural renderer script and different CUDA files.
Another challenge with this method is the lack of objective quantitative metrics to eval‐ uate the success of the models. One instead has to rely almost entirely on qualitatively gauging the shape reconstructions by eye.
ReScience C 8.2 (#30) – Galatolo and Nilsson 2022 10
5.3 Conclusions
Variability of the results —We observed that themethod is very sensitive to various random factors and identical runs may yield different results, see Figure 12. One factor may be the random initialization of the networks, but we do not believe it is the dominating factor, since the depth network is pre‐trained on a fixed prior shape each run. Rather, as mentioned by the authors [1], the quality of the projected samples varies. Additionally, we only sample 8 − 16 different view‐light directions in each step 2 iteration, which may be too few projected samples for a robust model. Since this sampling is random, increasing the number of samples should assure the inclusion of meaningful view and light projections (experimental backing in subsection 5.7 in the appendix).
Catastrophic forgetting —We have observed that the instance‐specific model forgets the previous training images (see subsection 5.8 in the appendix, Figure 13), and thus has no generalization capability. This is not necessarily a problem if one has time and com‐ putational resources. It can also be argued that this is exactly what is intended with this model, and that generalization is up to the training dataset of the StyleGAN model. It does, however, limit the usefulness of the model. As an example, the training time for one 128× 128 pixel RGB image using a Tesla K80 GPU was about 2.5 hours, which seems exceedingly costly for just one low‐resolution depth map. We argue that a generalmodel would have more use. The ideal scenario would be a modelD∗ trained onD that is able to accurately predict di = D∗(Ii) ∀ Ii ∈ D, and even extend to unseen testing data be‐ longing to the same distribution as D. This discussion is what urged us to explore the altered training procedure of sections 3.2 and 4.2.2.
Final conclusions —We were able to replicate some of the results of Pan et al. [1] on the datasets LSUN Car, LSUN Cat and CelebA. We identified several failure modes and lim‐ itations of the model, and back it up with experimental evidence. Examples are the variability and sensitivity to the projected samples, the heavy dependence on shape pri‐ ors and the computational costliness of the single‐use model ‐ all of which were not adequately accounted for in the original paper.
We propose a new prior shape, the smoothed box prior, that has shown very promising results especially for fine details and complex object structures. We propose a second prior shape, confidence‐based, that has shown best results in the face dataset. We fi‐ nally suggest two new training procedures that produce better results and are better at generalizing than the original model by Pan et al. [1].
We recognize the limitations of this work as we were only able (due to the restricted computational power) to test the method on part of the dataset. For example, the Cat’s dataset used by the authors contains more than 200 images but we were able to only test few of them. We speculate that some images in the dataset could yield better results than those reported here. However, we believe that few bad projected images should be enough to claim the uneffectiveness of the method at least in some particular cases.
Another limitation of our work is the lack of quantitative evaluation methods. The orig‐ inal authors propose their results also on the BFM benchmark [20] where it is possible to use some metrics to accurately evaluate the results.
5.4 Future work We speculate that it would be interesting to adapt the same method to StyleGAN3 [7] where the network has been modified to support training with fewer samples, leaving the question if thenetwork still retains enough information that is needed forGAN2Shape to work. Future work could also explore the use of our priors on datasets where the orig‐ inal method failed (e.g. the LSUN Horse dataset). We speculate that, since our prior
ReScience C 8.2 (#30) – Galatolo and Nilsson 2022 11
captures the boundaries of the object very well (compared to the ellipsoid where the boundaries are only used to position the origin), it could achieve better results in com‐ plex 3D objects where the shape cannot be simplified into an ellipse. A limitation of this method is that it does not use voxels, but learns a height map. This disallows realistic shape reconstructions and more complex geometries with multiple x and y values for each z value etc. Future work should investigate whether this model could be extended to predict voxels instead of height maps. Given our promising results with the general‐ izing trainer, which was obtained through only a few epochs of training, we believe that it should be further explored with increased epochs and training set size."
"['Siba Smarak Panigrahi', 'Sohan Patnaik']",[Re] Value Alignment Verification,10.5281/zenodo.6574687,Replication,Python,https://zenodo.org/record/6574687/files/article.pdf,rescience c value alignment verification reinforcement learning machine learning python,https://openreview.net/forum?id=BFLM3nMmhCt,https://github.com/AIExL/vav_rc2021,8,2,2022,"The main goal of the paper ”Value Alignment Verification” [1] is to test the alignment of a robot’s behavior efficiently with human expectations by constructing a minimal set of questions. To accomplish this, the authors propose algorithms and heuristics to create the above questionnaire. They choose a wide range of gridworld environments and a continuous autonomous driving domain to validate their put forth claims. We explore value alignment verification for gridworlds incorporating a non‐linear feature reward mapping as well as an extended action space.","The problem statement, as well as the implementation of algorithms and heuristics, were straightforward. We also took aid from the original repository published with the paper. However, we implemented the entire pipeline from scratch and incorporated several variations to our code to perform additional designed experiments.
Copyright © 2022 S.S. Panigrahi and S. Patnaik, released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Siba Smarak Panigrahi (sibasmarak.p@gmail.com) The authors have declared that no competing interests exist. Code is available at https://github.com/AIExL/vav_rc2021. – SWH swh:1:dir:4d43ea96458cc573dd2b57208fae0b12f8da896f. Open peer review is available at https://openreview.net/forum?id=BFLM3nMmhCt.
ReScience C 8.2 (#31) – Panigrahi and Patnaik 2022 1","Comprehending different algorithms and heuristics proposed in prior works along with their mathematical formulation and reasoning for their success in the given task was considerably difficult. Additionally, the original code base had several redundant files, which created initial confusion. We iterated and discussed the arguments in the paper and prior work several times to thoroughly understand the pipeline. Nevertheless, once the basics were clear, the implementation was comparatively simple.
Communication with original authors We reached out to the authors numerous times via email to seek clarifications and addi‐ tional implementation details. The authors were incredibly receptive to our inquiries, and we appreciate their thorough and prompt responses.
ReScience C 8.2 (#31) – Panigrahi and Patnaik 2022 2
1 Introduction
Autonomous agents are used for complex, challenging, riskier, and dangerous tasks which brings up the need of verifyingwhether the agents act in away that is both optimal and safe w.r.t another agent that has already been performing the said task (example, a human agent). This problem of verifying the alignment of one agent’s behavior w.r.t an‐ other agent is known as Value Alignment Verification. The original paper [1] proposes a framework for efficient value alignment verification. They discuss three different set‐ tings of increasing difficulty in terms of verification:
1. explicit human, explicit robot: where both the agents are completely aware of their reward functions.
2. explicit human, implicit robot: where the human agent is aware of its reward func‐ tion but the robot agent can only be queried about its action preferences on differ‐ ent states.
3. implicit human, implicit robot: where the only basis of value alignment is through preferences over trajectories.
Depending on the setting, value alignment can be either exact or approximate. We try to reproduce and validate the results for the proposed framework on the first and second setting, i.e., (explicit human, explicit robot) and (explicit human, implicit robot). The exper‐ iments involve gridworld environments with a deterministic action space. The aim of value alignment verification is to create a questionnaire using the human agent’s knowl‐ edge (reward function or trajectory preferences) that can be given to any agent in order to verify alignment. Efficient verification aims to minimize the number of queries in the questionnaire. While few works on value alignment discuss qualitative evaluation of trust [2] or asymptotic alignment of an agent’s performance via interactions and ac‐ tive learning [3] [4] [5], [1] solely focuses on verifying value alignment for two or more agents with a learned policy. The objective is to efficiently test compatibility of different robots with human agents. In the following sections, we reiterate the formal definition of value alignment as stated by the original authors (Value Alignment Verification in Sec‐ tion 3 and Exact Value Alignment Verification in Section 4), followed by our experiment settings in Section 7 and subsequent observations in Section 8.
2 Notation
We use the notation proposed in [6], where a Markov Decision Process (MDP) M is de‐ fined by an environmentE and a reward functionR. An environmentE = (S,A, P, S0, γ) where S is a set of states,A is a set of actions, P is a transition function, P : S×A×S → [0, 1], γ ∈ [0, 1) is discount factor and a distribution over initial states S0. The reward function R : S → R. A policy π : S × A → [0, 1] from states to a distribution over ac‐ tions. The state and state‐action values of a policy π are V πR (s) = Eπ[ ∑∞ t=0 γ
tR(st)|s0 = s] and QπR(s, a) = Eπ[ ∑∞ t=0 γ
tR(st)|s0 = s, a0 = a] for s ∈ S and a ∈ A. The op‐ timal value functions are, V ∗R(s) = maxπ V πR (s) and Q∗R(s, a) = maxπ QπR(s, a). Let AR(s) = argmaxa′∈AQ ∗ R(s, a
′) denote the set of optimal actions at a state s under the reward function R. Then AR(s) = {a ∈ A|π∗R(a|s) > 0}. It is assumed that reward func‐ tion is linear under state features ([7], [8], [9]) ϕ : S → Rk, such that R(s) = wTϕ(s), where w ∈ Rk. Note that there is no restriction on the features ϕ, therefore these features could be complex non‐linear functions of the state as well. The state‐action value function can be written in terms of features ([10]) as QπR(s, a) = wTΦ (s,a) π where Φ (s,a) π = Eπ[ ∑∞ t=0 γ tϕ(st)|s0 = s, a0 = a].
ReScience C 8.2 (#31) – Panigrahi and Patnaik 2022 3
3 Value Alignment Verification
Consider two agents (for instance, a human and a robot) where the first agent’s (human) reward function provides the ground truth for the value alignment verification of the second agent (robot). The definition is as follows:
Definition 1 Given reward function R, a policy π′ is ϵ-value aligned in environment E if and only if
V ∗R(s)− V π ′ R (s) ≤ ϵ, ∀s ∈ S (1)
The aim of the study [1] is efficient value alignment verification which, formally, is a solution for the following:
min T⊆T
|T |, s.t. ∀π ′ ∈ Π, ∀s ∈ S
V ∗R(s)− V π ′ R (s) > ϵ ⇒ Pr[π ′ passes test T ] ≤ δfpr
V ∗R(s)− V π ′ R (s) ≤ ϵ ⇒ Pr[π′ fails test T ] ≤ δfnr
(2)
where T is the set of all possible queries, Π is set of all policies for which the test is designed, δfnr, δfpr ∈ [0, 1] are the false negative and false positive rates, and |T | is the size of test T . When ϵ = δfpr = 0, the authors call this setting exact value alignment verification.
4 Exact Value Alignment Verification
Exact value alignment verification is not possible, even for finite MDPs, when we can only query the robot agent for its action preferences. Therefore, it is possible only in the most idealized setting, i.e., explicit human, explicit robot.
Definition 2 Define an agent π′ to be rational ([11]) if:
∀a ∈ A, π′(a|s) > 0 ⇒ a ∈ argmax a Q∗R′(s, a) (3)
where argmaxaQ ∗ R′(s, a) is the optimal state-action value function for the reward functionR ′.
As there exist infinitely many reward functions which can return the same optimal pol‐ icy ([12]), determining that ∃s ∈ S,R(s) ̸= R′(s) does not necessarily imply that agents with the reward functions R,R′ are not aligned. We provide an example of this in Fig‐ ure 1, where the optimal policy for human and robot is the same; thus, they are aligned. However, the rewards are different, as mentioned in Table 1.
Definition 3 Define the set of all the optimal policies under the reward function R as OPT(R).
OPT (R) = {π|π(a|s) > 0 ⇒ a ∈ argmax a Q∗R(s, a)}
ReScience C 8.2 (#31) – Panigrahi and Patnaik 2022 4
Looking at Definition 1 and Equation 3 simultaneously makes it evident that for a ra‐ tional robot, if all of its optimal policies are also optimal under ground truth reward function R; the robot is exactly aligned with the human.
Corollary 1 We have exact value alignment in environment E between a rational robot with reward functionR ′ and a human with reward functionR ifOPT (R ′ ) ⊆ OPT (R).
Revisiting the inspiration ([12]) of the original author’s proposed approach for efficient exact value alignment ‐
Definition 4 Given an environmentE, the consistent reward set (CRS) of a policy π in environment E is defined as the set of reward functions under which π is optimal
CRS(π) = {R|π ∈ OPT (R)} (4)
When R(s) = wTϕ, the CRS is of the form ([12], [13]):
Corollary 2 Given an environment E, the CRS(π) is given by the following intersection of half-spaces:
{w ∈ Rk|wT (Φ(s,a)π − Φ(s,b)π ) ≥ 0, ∀a ∈ argmax a′∈A QπR(s, a ′), b ∈ A, s ∈ S}
Since the boundaries of the CRS polytope is consistent with a policy that may not be aligned with optimal policy (e.g. zero reward), we remove all such boundary cases to obtain a modified set called aligned reward polytope (ARP).
5 Reproducing Exact Value Alignment
In this section, we explain the procedure in order to verify the claims made in the pa‐ per regarding sufficient conditions for provable verification of exact value alignment (explained in Section 4). We verify exact value alignment in disparate settings proposed by the authors for explicit human - explicit robot setting. If we have access to the value or reward function of a human, we term it as explicit human. A similar notion is applicable for the robot as well.
Theorem 1 Under the assumption of a rational robot (defined in Section 4) that shares linear reward features with the human, efficient exact value alignment verification is possible in the following query settings: (1) Query access to reward function weights w ′ , (2) Query access to samples of the reward functionR ′ (s), (3) Query access to V ∗
R′ (s) andQ∗ R′ (s, a), and (4) Query
access to preferences over trajectories.
Case 1 Reward Weight Queries
A brute‐force paradigm can be implemented to evaluate an explicit robot optimal policy under the human reward function. However, there exists another succinct verification test. We need to query the weight vectorw ′ of the robot (here,R ′ (s) = (w ′ )Tϕ(s), ϕ(s) is the feature vector of state s). The paper asserts that it is possible to form a test (defined later as ∆) that uses the obtained w ′ to verify alignment. Additionally, this query to the weight vector w ′ is done in constant time, and the test is linear in the number of questions.
ReScience C 8.2 (#31) – Panigrahi and Patnaik 2022 5
Definition 5 Given anMDPMcomposed of environmentE and reward functionR, the aligned reward set (ARS) is defined as the following set of reward functions:
ARS(R) = {R ′ |OPT (R ′ ) ⊆ OPT (R)}
We state the lemmawhich proves the sufficient condition for exact value alignment and direct the interested readers for the proof of the lemma to refer the paper.
Lemma 1 Given an MDP M = (E, R), the human’s and robot’s reward function R and R′ respectively can be represented as linear combinations of features ϕ(s) ∈ Rk, i.e., R(s) = wTϕ(s), R ′ (s) = (w
′ )Tϕ(s), and given an optimal policy π∗R under R, we have
w ′ ∈ ∩(s,a,b)∈OHRs,a,b ⇒ R ′ ∈ ARS(R)
where
HRs,a,b = {w|wT (Φ(s,a)π )− Φ(s,b)π ) > 0} andO = {(s, a, b)|s ∈ S, a ∈ AR(s), b ̸= AR(s)}
Definition 6 The intersection of half-spaces ( ∩(s,a,b)∈O HRs,a,b ) is defined as the Aligned Reward Polytope (ARP). The design of ARP in the form of∆matrix is defined as follows:
∆ =
[ Φ (s,a) π )− Φ(s,b)π
...
]
In the above equation, a is an optimal action at state s, and b is a non‐optimal action. The actions in the trajectory following a and b are optimal. Each row of∆ represents the nor‐ mal vector for a strict half‐space constraint based on feature count differences between an optimal and sub‐optimal action. Therefore, for a robot weight vector w ′ , if∆w ′ > 0, the robot is aligned. We follow the stepsmentioned in the original paper to include only non‐redundant half‐space normal vectors in ∆. We enumerate all possible half‐space normal vectors corresponding to each state s, optimal action a, and non‐optimal action b. We accumulate only non‐redundant half‐space normal vectors:
1. Removal of Duplicate Vectors: To remove duplicate vectors, we compute the cosine distance between the half‐space normal vectors. One vector in each of the pairs of vectors with cosine distance within a small precision value (we select 0.0001) is retained in∆, others being discarded. All zero vectors are also removed.
2. Removal of Redundant Vectors: According to the paper, the set of redundant vectors can be found efficiently using the Linear Programming approach. To check if a constraint aTx ≤ b is necessary, wefirst remove that constraint and solve the linear programming problem. If the optimal solution is still constrained to be less than or equal to b, that constraint can be safely discarded. After removing all such redundant vectors, we get only a set of non‐redundant half‐space normal vectors.
Case 2 Reward Queries
In this case, the tester seeks for the rewards of the robot. Here, a tester is same as a user (human) who wishes to verify the alignment of a robot. Since it is assumed that both human and robot have access to their state feature vectors, and from the equation R(s) = wTϕ(s), we obtain theweight vector for the robot, and this case reduces to Case 1. LetΦM be defined as thematrix where each row corresponds to the feature vector ϕ(s)T for a distinct state s ∈ S. In order to solve the system of linear equation for obtaining the weight vector, the number of queries needed is rank(ΦM ).
Case 3 Value Function Queries
ReScience C 8.2 (#31) – Panigrahi and Patnaik 2022 6
The tester seeks the action value function and the value function for each state in this case setting. Subsequently, the reward weights for the robot are obtained with the aid of the following equations:
R ′ (s) = (w ′ )Tx and R ′ (s) = Q∗
R′ (s, a)− γEs′ [V ∗ R′ (s ′ )]
This case also boils down to Case 1 as we obtain the weight vector for the robot. Ac‐ cording to the paper, if we define the maximum degree of the MDP transition function as
dmax = max s∈S,a∈A
|{s ′ ∈ S|P (s, a, s ′ ) > 0}|,
then at most dmax possible next state queries are needed to evaluate the expectation. Therefore, atmost rank(ΦM )(dmax+1) queries are required to recover the robot’s weight vector.
Case 4 Preference Queries
We obtain preference over trajectories ξ as judged by the human. Each preference ξA > ξB, induces a constraint (w ′ )T (Φ(ξA)− Φ(ξB)) > 0, where Φ(ξ) = ∑n i=1 γ
iϕ(si) is the cumulative discounted reward features (linear combination of state features) along a trajectory. Therefore, we construct ∆ where each row corresponds to a half‐space normal resulting from preference over individual trajectories. In this case, only a log‐ arithmic number of trajectories are needed from all possible trajectory space to obtain ∆matrix and proceed to verify alignment of robot. We obtain all valid trajectories, per‐ form preprocessing (remove duplicate & redundant vectors), and observe that the total number of queries is bounded by logarithmic number of trajectories we started with ([14]).
6 Value Alignment Verification Heuristics
When the robot acts as a black box and can provide state action preferences instead of a policy, the authors propose three heuristics; Critical States, Machine Teaching and ARP Heuristic. Each heuristic consists of a method for selecting the states at which the robot is tested and queries for an action, subsequently checking if the action is optimal under human’s reward function. It is important to note that for these heuristics, δfpr > 0, as there is no guarantee for the robot to always take the same action at a given state.
1. Critical States Heuristic: Inspired by the notion of critical states (CS) [2], the heuris‐ tic test consists of states for which Q∗R(s, π∗R(s)) − 1|A| ∑ a∈A Q ∗ R(s, a) > t, where
t is a threshold value. This intuitively states the importance of a particular state and tends to make the verification efficient.
2. Machine Teaching Heuristic: This heuristic is based on Set Cover Optimal Teach‐ ing (SCOT) [13], which approximates the minimal set of state‐action trajectories necessary to teach a specific reward function to an IRL agent. [13] show that in the intersection of half‐spaces that define the CRS (Corollary 2), the learner recov‐ ers a reward function. The authors use SCOT to create informative trajectories and create alignment tests by seeking a robot action at each state along the trajec‐ tory. Producing a test with SCOT takes longer than CS heuristic, but unlike CS, SCOT prevents repetitive inquiries by reasoning about reward features over a set of trajectories.
3. ARP Heuristic: This heuristic is a black‐box alignment heuristic (ARP‐bb) based on the ARP definition. ARP‐bb first computes∆, then uses linear programming to remove duplicate half‐space constraints, subsequently asks for robot actions from
ReScience C 8.2 (#31) – Panigrahi and Patnaik 2022 7
the states corresponding to the non‐redundant constraints (rows) in∆. Intuitively, the states probed by ARP‐bb are significant because different actions disclose vital information about the reward function. ARP‐bb approximates testing each half‐ space constraint by using single‐state action queries. As a result, ARP‐bb trades off increased approximation error in exchange for a lower query and computational complexity.
7 Experiments
In this section, we describe several experiments carried out in order to investigate the following:
1. Algorithms and Heuristics: Comparison of different algorithms and heuristics in different gridworlds. We tabulate the performance of testers (accuracy, false posi‐ tive rate, false negative rate, and the number of queries presented to the robot for verification) w.r.t different gridworld widths ranging from 4 to 8 and feature size from 3 to 8. The dimension of feature for a state is termed as number of features or feature size. Our experiments confine these state features ϕ to be one‐hot vectors only.
2. Diagonal Actions: Comparison of algorithms and heuristics in gridworlds with an extended action space. We allow diagonal movement between standard move‐ ments. This increases the standard 4 actions (left, up, right, and down) to 8 ac‐ tions (left‐up‐diag, up‐right‐diag, right‐down‐diag, and down‐left‐diag). Here, diag refers to diagonal movement. Again, we tabulate the performance of testers w.r.t different gridworld widths.
3. Non‐linear reward and state‐feature relationships: Comparison of different algo‐ rithms and heuristics with non‐linear (cubic and exponential) reward R and state‐ feature ϕ(s) relationships. In cubic, we approximate the linear behavior when wTϕ(s) ≈ 0, else not. The exact relationship we consider is R = x3 + 10x where x = wTϕ(s). In exponential, we completely remove the linear relationship between R and ϕ(s) and considerR = ew
Tϕ(s). We tabulate the performance of testers w.r.t different gridworld widths in both cases.
4. Critical States Tester for different thresholds: Comparison of Critical States Tester performance with different threshold values (0.0001, 0.2 and, 0.8) for a state to be critical.
Section 8 provides the results for one algorithm (Reward Weight Tester) and one heuris‐ tic (Critical State Tester) and plots relevant to their accuracy and number of test queries. We redirect readers to Section 2 of Supplementary Material for the detailed tabulated performance of all algorithms, heuristics, and the plots related to false positive and false negative rates. Also, note that the default gridworld rows are 4, gridworld width is 8, number of actions is 4, feature size is 5, reward and state‐feature relationship is linear (R = wTϕ(s)), and threshold value of Critical States Tester is 0.2. We created 100 different human agents for each experiment, and for each human agent, we created 100 different robots to check their alignment. Each human agent corre‐ sponds to a different human weight vector whose each element is sampled from a nor‐ mal distribution with mean 0 and variance 1. Different robot agents correspond to dif‐ ferent robot weights that are obtained by adding a random normal noise vector to the corresponding humanweight vector. The elements of the noise vector are sampled from the same normal distribution. Further, we normalize the robot and human weight vec‐ tor to have a unit norm. In total, we run 1.32 million experiments to address the points mentioned above.
ReScience C 8.2 (#31) – Panigrahi and Patnaik 2022 8
8 Results
In the plots and following discussion, rwt indicates Reward Weight Queries Tester, rt indicates Reward Queries Tester, vft indicates Value Function Queries Tester, ptt indi‐ cates Preference Trajectory Queries Tester, cst indicates Critical States Tester, scott indicates SCOT Tester, and arpbbt indicates ARP Black Box Tester."
"['Roxana Petcu', 'Pim Praat', 'Jeroen Wijnen', 'Manolis Rerres']","[Re] Replication Study of ""Fairness and Bias in Online Selection""",10.5281/zenodo.6574689,Replication,Python,https://zenodo.org/record/6574689/files/article.pdf,rescience c machine learning online selection prophet problem secretary problem fairness bias Python,https://openreview.net/forum?id=S9gs3MmhAY,https://github.com/pimpraat/FACT-Ai,8,2,2022,"This report aims to reproduce the results in the paper Fairness and Bias in Online Selection [1]. The paper presents optimal and fair alternatives for existing Secretary and Prophet algorithms. Reproducing the paper involves validating three claims made by the au‐ thors [1]: (1) The presented baselines are either unfair or have low performance, (2) The proposed algorithms are perfectly fair, and (3) The proposed algorithms perform comparably to or even better than the presented baselines.","The paper provides pseudocode for the proposed algorithms, making the implementa‐ tion straightforward. More than that, recreating their synthetic data experiments was
Copyright © 2022 R. Petcu et al., released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Jeroen Wijnen (j.wijnen@outlook.com) The authors have declared that no competing interests exist. Code is available at https://github.com/pimpraat/FACT-Ai. – SWH swh:1:dir:da9cb18759db5ecf30608639d8b35a4b247a483d. Open peer review is available at https://openreview.net/forum?id=S9gs3MmhAY.
ReScience C 8.2 (#32) – Petcu et al. 2022 1
easy due to providing clear instructions.","However, we did run into several difficulties: 1) There were a number of inconsistencies between the paper and the code, 2) Several parts of the implementation were missing in the code base, and 3) The secretary experiments required running the algorithm over one billion iterations, whichmakes verifying its results within a timelymanner difficult.
Communication with original authors The authors of the original paper were swift in their response with regard to our find‐ ings. Our main allegations regarding inconsistencies in both the Secretary and Prophet problems were confirmed by the authors.
1 Introduction
Online selection is challenging, as candidates arrive sequentially and decisions need to bemadewith incomplete information. Such problems affect our lives in a profoundway. Algorithmic credit scores determinewho receives amortgage orwho can start a business. Automatic systems even decide who receives an organ transplant or who has priority in being admitted to an Intensive Care Unit. The growing importance of algorithms has prompted concerns about fairness alongside efficiency. Addressing these issues is essential. Research has long focused on the performance of such algorithms, but fairness was not a consideration until recently [2, 3]. The paper ”Fairness and Bias in Online selection” [1] aims to fill this gap. The authors propose three fair selection algorithms for the domain of online selection. In particular, they focus on two well‐known problems from the literature: the Secretary and the Prophet problems. The aim of this study is to validate the claims made in the paper and see if their results can be reproduced. Furthermore, we propose an adjusted version of their prophet al‐ gorithms, in order to reduce the number of occurrences where the algorithm does not pick any candidate.
2 Scope of reproducibility
The focus of our study is to empirically verify the claims of the paper. Themathematical proofs and theorems lie outside our scope. The authors of the original paper propose three online algorithms, namely oneMulti‐Color Secretary and twoMulti‐Color Prophet approaches that are both fair and efficient. They also present several existing baseline algorithms. The main empirical claims of the paper are:
• The used baselines are either unfair or have low performance.
• The proposed algorithms are perfectly fair.
• The proposed algorithms perform comparably or even better than the presented baselines.
These claims are supported by experiments where all algorithms select a candidate based on a variety of datasets. The original authors consider an algorithm fair when ”the solution obtained is balanced with respect to some sensitive attribute (e.g. nation‐ ality, race, gender)” [1]. This notion is consistent with previous work [4, 5]. More pre‐ cisely, algorithms are considered fair when they respect the prior probability p that the
ReScience C 8.2 (#32) – Petcu et al. 2022 2
best candidate belongs to a certain group. Performance is defined as the probability of selecting the optimal candidate (in the Secretary setting) and the average value of the selected candidate (in the Prophet setting). We validate their claims by recreating the algorithms and experiments from scratch in Python. We use the description in the paper as a guideline, referring to the original code only when necessary.
3 Methodology
3.1 The Secretary Algorithm
Algorithm 1 describes the original au‐ thors’ fair secretary algorithm. Candi‐ dates appear in increasing order of their arrival time τ . The algorithm calculates one threshold t ∈ [0, 1]k per group c, us‐ ing Formula 1.
t∗k = (1− (k − 1)pk) 1 k−1
t∗j = t ∗ j+1
( ∑j r=1
pr j−1 − pj∑j
r=1 pr j−1 − pj+1
) 1 j−1
for 2 ≤ j ≤ k − 1
t∗1 = t ∗ 2 · e
p2 p1 −1
(1)
Algorithm 1 Fair Secretary
Input: t ∈ [0, 1]k, a time threshold per group n candidates scores Output: i ∈ [n], index of chosen candi‐ date for i← 1 to n do
if τi′ > tc(i) then if i≻ max {i′ | τi′ ≤ τi, c (i′ |) = c(i)}
then return i
end end
end This threshold determines fromwhich point the algorithm could pick a candidate. Once the thresholds are computed, they are used as input to Algorithm 1 along with the data. The algorithm will return its best candidate.
3.2 Prophet algorithm In contrast to the secretary setting, the prophet algorithm knows the distribution that the scores are drawn from. Furthermore, all prophet experiments occur in a setting where each candidate is in a unique group, meaning each group has a size of one. This constraint aims to create an algorithm that gives candidates in each arrival position the same probability of being picked. Each group represents a position in the queue and arrival order of the candidates in this problem is not random. The original authors consider two settings in their paper: one where each candidate is drawn from a separate distribution, and one where the scores are i.i.d.. Pseudocode for both models is illustrated in Algorithms1 2 and 3.
1Since the original authors refer to Algorithm 2 as the Fair General Prophet and FairPA interchangeably, it makes sense for us to do the same.
ReScience C 8.2 (#32) – Petcu et al. 2022 3
Algorithm 2 Fair General Prophet Input: F1...Fn, distributions
q1...qn, fair optimal pick proba‐ bility n candidates scores Output: i ∈ [n], index of chosen can‐ didate for i← 1 to n do
if vi ≥ F−1i ( 1− qi/21−s/2 ) then
return i end s← s+ qi
end
Algorithm 3 Fair IID Prophet Input: F1...Fn, distributions
q1...qn, fair optimal pick proba‐ bility n candidates scores Output: i ∈ [n], index of chosen can‐ didate for i← 1 to n do
if vi ≥ F−1 ( 1− 2/3n1−2(i−1)/3n ) then
return i end
end
3.3 Evaluation metrics For evaluating the experiments, the authors set several metrics that reflect both the fair‐ ness and efficacy of their study. For the Secretary algorithm they report the number of candidates picked by each model, the number of times the chosen candidates corre‐ spond to themaximumvaluemax Cj within their group, and the probability of choosing the maximummax C from the data. Meanwhile, the Prophet algorithms are compared based on the balance in selection rates across arrival order and the average value of the picked candidates.
4 Code implementation
Implementation of the experiments was done in Python, making use of the descriptions in the paper and the published code base 2. The original authors conducted their exper‐ iments in C++. The code was factorized neatly into different files for retrieving the data, implementation of algorithms and experiments. We were largely able to reproduce all of the code. However, three important elements of the code were lacking:
• the experiments on the prophet algorithms
• the production of plots and summary statistics of both experiments
• the data preprocessing for real datasets
Due to these issues, wewere unable to review the exact settings of the experiments. This made it difficult to determine the reason behind different results in our reimplementa‐ tion. Details are expanded on in the following section. As a consequence, we contacted the authors for further specifications of their approach. Moreover, the naming of the baselines and proposed algorithms in the original imple‐ mentation is inconsistent with the naming in the paper. The original papers of the base‐ lines were needed to figure out the used naming conventions. Lastly, it is important to note that our implementation does not utilise GPUs or paralleli‐ sation because we have sequential process. Therefore the results could not be sped up using high performance clusters. As a result, one of our experiments could not be run in a timely manner as it took over 40 hours for 1/5 of the data.
2Original code: https://github.com/google-research/google-research/tree/master/fairness_and_bias_in_online_ selection. Our full implementation is open‐sourced and can be found on: https://github.com/pimpraat/FACT-Ai
ReScience C 8.2 (#32) – Petcu et al. 2022 4
5 Experimental setup
5.1 Secretary problem Data: The paper uses four different datasets for the Secretary problem, out of which two are synthetic. For each dataset, the algorithm runs 20,000 times. For the first dataset we divide candidates into four groups with 10, 100, 1000, and 10, 000 occurrences. The probability p of the best candidate coming from this group is the same for all colors, namely (p = .25). In the second setting, this condition is changed and group probabilities differ: p = (.3, .25, .25, .2). Thirdly, the authors use a dataset of phone calls made by a Portuguese banking institution [6]. For the purpose of this exper‐ iment, the score is the length of the phone call. The group probabilities are set to be equal (p = .2). Lastly, the algorithm is tested on a dataset of influencers of the social network ‘Pokec’[7]. The influencers’ score is their number of followers and they are di‐ vided into five groups with equal probability: (p = .2) for each group.
Baselines: The authors test their fair Secretary algorithm by contrasting it to two base‐ lines. Secretary algorithm (SA) computes themaximum score value assigned in the first 1/e part of the arrival sequence of the candidates. After that, it compares the rest of the values with the aforementioned picked one and returns the maximum value across the whole streamline. It does not consider a candidate’s group. The Single‐color secretary algorithm (SCSA) selects a color with a probability proportional to the provided values of p, and then considers only candidates of that color.
5.2 Prophet problem Data: The prophet algorithms are tested on two synthetic datasets. In the original paper, each algorithm runs 50, 000 times. In the first experiment, 50 samples are drawn from a uniform distribution [0, 1]. In the second experiment, 1000 samples are drawn from a binomial distribution with 1000 trials and probability of success of 1/2.
Baselines: The authors compare their devised algorithmswith four baseline algorithms: First, the SC algorithm [8], which places a single threshold such that it finds a candidate 50 % of the time. Second, the EHKS algorithm [9] where each candidate is selected with probability 1n . Thirdly, the CFHOV algorithm [10], which uses a succession of thresh‐ olds derived from the probabilities that candidates are accepted. Lastly, the DP algo‐ rithm [11] that uses a differential equation to create thresholds. This last algorithm is excluded from their plots, as it is so unbalanced that it distorts the readability of the graph. During implementation we noticed that both the SC and EHKS algorithms were signif‐ icantly quicker. This is due to their property of using a constant calculated threshold for each run of the algorithm, instead of recalculating the threshold after seeing each candidate.
6 Replication of results
6.1 Secretary problem Figure 1 shows the results of the Secretary experiments from our implementation. Our algorithm is equally fair and appears to pick the optimal candidate with roughly the same frequency in three out of four experiments. The results from the original paper can be found in the Appendix (Figure 4). Table 1 shows the evaluationmetrics (as described in section 3.3) for all experiments. Our scores are generally comparable to those in the original paper, with a margin of just 3‐4%.
ReScience C 8.2 (#32) – Petcu et al. 2022 5
The only algorithm in which our results differ is the SA, illustrated as U‐Pick and U‐ Max. The SA algorithm showed inconsistencies in two respects. To begin with, the authors’ experiments show that in setting (a) (synthetic dataset with equal p), SA almost exclusively returns candidates from group 4. However, in setting (b) (when p differs per group) it selects from multiple groups. This change is striking, as the SA algorithm should not take into account the probabilities of different groups. We raised these observations in a chain of discussionswith the authors. They confirmed our suspicions that the results of the SA algorithm are not intuitive, but did not know the reason for the discrepancies. They indicated that one possible reason would be the manner of sampling synthetic data. Given their explanation, we chose to further analyze their C++ implementation and figure out whether our results are incorrect or if there are other reasons for these differences. We found out that there are several inconsistencies in their original implementation as compared to the paper:
• New synthetic data are generated for each of the 20,000 iterations of the experi‐ ment instead of using the same dataset for all iterations
• When testing whether the returned candidate at index i is the maximum from its group Cj , the authors apply a margin of 10. They verify whether score(i) ∈ [max Cj − 10], wheremax Cj represents the maximum score of color j.
• Even though the original paper states that the probabilities p are not taken into account by algorithm SA, the original implementation does take into account the probabilitieswhen creating the synthetic data. It adds bias towards a certain group by assigning one candidate from that group theupper limit value of aunsigned int 64 data type in C++ ( 264 − 1). This happens only in the second experiment.
ReScience C 8.2 (#32) – Petcu et al. 2022 6
Because of these implementation inconsistencies, parts of the experiments were not easily reproducible. We claim that they cause a difference in results for experiment (b). We test our claim by running the original code, but without the three inconsistencies mentioned above. The modified implementation outputs results that are much closer to our findings. They are illustrated in the Appendix in Figure 6. Furthermore, the SA algorithm also returned different results for dataset (d) on Influ‐ enceMaximization. Thepaper illustrates thatU‐pick selects candidates from twogroups, namely Under and Normal. However, our algorithm picks candidates only from the Normal group. To understandwhy this happened, we ran this experiment using the original code. The authors included neither the data nor the preprocessing steps, so we used our own preprocessed data. The results can be found in the Appendix in Figure 73. When using the same input data, the original code yields exactly the same results as our im‐ plementation. Therefore, the found inconsistencies originate from the data itself, and correcting the BMI formula from the original code should result in identical outcomes.4 We can thus conclude that the Influence Maximization experiment would be exactly re‐ produced if we were to have access to the originally prepossessed data.
6.2 Prophet problem Figure 2 shows the experiment outcomes of our replicatedFairPAandFairIID algorithms. Even though the general trends in the plots match, our overall number of picks is far lower for each of the algorithms. The original authors appear to pick a candidate every single time.5 In some cases, the number of picks even exceeds the number of experi‐ ments run, which should not be possible.6 By contrast, our reproduced FairPA algorithm returns a None result 50% of the time, and FairIID 30%. This makes sense, as the algorithm was designed to pick each candidate with probability of q/2.7 We also ran the original code, after making minor adjustments to get it running and to deal with None picks. Running on this code shows identical results to our own reproduced implementation. The most probable explanation for both discrepancies in the reproduced results is that the original authors ran 100, 000 experiments, instead of 50, 000. Figures 2c and 2d show
3The authors ran approximately 1 billion iterations over the Pokec dataset. Due to time constraints we had to restrict our experiment to 20,000 iterations. For a clearer comparison between the groups frequency and the experiment results, we downsampled the size of the input
4For our experiment, we used the formula BMI = weight/height2 and defined the health groups as described by the WHO.
5For instance the number of picked candidates per position for their FairPA algorithm in the uniform distribution is 1000. This corresponds to 50 positions x 1000 picks = 50,000 total picks, the same as the number of iterations used.
6The number of picks of the original FairIID algorithm in the uniform distribution dataset hovers around 1200, which wouldmean 1200 picks x 50 positions = 60,000 total picks, far more than the 50,000 iterations. The same is true for the FairIID algorithm under the binomial setting. The line is somewhat obscured by other algorithms, but appears to be consistently higher based on the reported number of experiments.
7q is the probability of an optimal offline algorithm choosing a certain candidate. This offline algorithm has a None rate of zero.
ReScience C 8.2 (#32) – Petcu et al. 2022 7
that when running our algorithms with this number of experiments, the results are strongly comparable to those of the original authors. We also contacted the authors about this discrepancy. They confirmed that their reported number of picks was too high. Similarly to us, they assumed to have run the experiments twice as often as re‐ ported. However, they were not able to confirm this at the time. Since the implementa‐ tion of the Prophet experiments themselves are not included in the code base, we were not able to definitively diagnose the reason for the discrepancy. Table 2 shows the originally reported mean values, as well as our replication results. As is clear, we were able to closely approximate the original authors’ results. However, we were only able to do this after assigning None results a value of zero. Neither the ICML‐ version nor the full version of the paper mentions how their metrics deals with None picks. Nevertheless, as taking None picks as values of zero generated the same results, we assumed they used this approach.
Additionally, the original FairPA and FairIID algorithms selected candidates with an av‐ erage value of ”66.71% and 88.01% (for the uniform case), and 58.12% and 75.82% (for
ReScience C 8.2 (#32) – Petcu et al. 2022 8
the binomial case), of the ”optimal, but unfair, online algorithm” average. 8 9 Here, we again found found the same results (deviation < 1%).
7 Fair online decision making with higher pick-rates
As mentioned in section 6.2 the paper’s proposed prophet algorithms pick a candidate in only 50% of cases. This is often not useful in practice. For this reason, we extended on the original paper by adjusting the (mathematical) parameters used for the FairPA and FairIID algorithms. We contacted the authors to ask about their reasoning for us‐ ing their parameters. They replied that their parameters achieved: ”the best possible approximation ratio guarantee of a 1/2. However, they added: ”It is possible that other algorithms also achieve the 1/2 guarantee, or something close to it, while having other interesting properties, for instance being less wasteful.” Both algorithms 2 and 3 depend on calculating a top percentile that the candidate’s value needs to be in. Each formula includes a constant of 1. We change this constant to pa‐ rameter ϵ:
• The FairProphet algorithm depends essentially on 1− qi/21−s/2 . We change this frac‐ tion to 1− qi/2ϵ−s/2
• TheFairIID algorithmdepends on 1− 2/3n1−2(i−1)/3n , whichwe change to 1− 2/3n ϵ−2(i−1)/3n .
and perform a grid search to approximately find the optimal values. For this parameter search, we used values slightly above and below the original parameters. We hypoth‐ esise that choosing a lower ϵ should decrease the top percentile a candidate needs to belong to in order to get selected. This should decrease the probability of finishing without picking any candidate, with the downside of achieving possibly a lower mean value. Figure 3 shows the results from our grid search, for the FairPA setting. The experiments for the FairIID setting show similar trends, as can be seen in Appendix section 8.3. As ϵ decreases, the number of picks goes up significantly. The algorithm remains approxi‐ mately equally fair10. However, when ϵ becomes too low, fairness starts to suffer. This is because the algorithm always chooses a candidate before getting to the end, meaning it never sees the last candidates in line. Our updated version of both the FairPA and FairIID increases performance on almost all originally used metrics in the paper for both distributions (see Appendix section 8.3). For the best found epsilon values, the None rate is close to zero. When excluding None results from the mean value of candidates, our optimal version performs slightly worse than the original authors’ algorithm. This makes sense, as our algorithm is less picky and will also accept candidates with slightly lower scores. On the other hand, when including None results as a 0 value in the average, our algorithm outperforms that of the original authors.
8During communication with the authors it was brought to our attention that the results for the DP differ in the ICML version and the full version of the original paper, ”due to a small issue in the calculation of the DP in the ICML version.”. This results in the DP achieving an average score of 0.964 and 548.94 for the uniform and binomial distribution respectively. This then also changes the value of the optimal, but unfair algorithm to the following: ” 51.97% and 68.57% (for the uniform case), and 54.35% and 70.91% (for the binomial case)” [12]. However, we focus on the ICML paper and thus focus on the presented results in this version. Partly due to the issue that no sufficient documentation could be found in order to solve this addressed issue in the DP algorithm.
9While the paper does not specify explicitly which unfair algorithm they mean in the paper, this seemed to refer to the DP algorithm.
10We would like to mention that we have not mathematically proven that our version is indeed ’fully’ fair as the original authors did
ReScience C 8.2 (#32) – Petcu et al. 2022 9
8 Conclusion
To summarise this study: for both the Secretary and the Prophet problems we found that the results are largely reproducible. We did however find some inconsistencies in one of the baselines of the secretary problem, and on the scale of the prophet results. After further investigation, these discrepancies could be attributed to inconsistencies in the original authors’ code. After this reproducibility study we conclude that the main claims made in the paper still hold. The paper and the provided code base provided a good resource for reproducing the code. However, due to the absence of several parts of their code and the mentioned inconsistencies, the replication of the (exact) results took longer than expected. Fortu‐ nately, the authors showed to be very helpful and willing to answer our questions and concerns. A drawback of the proposed prophet algorithms is that they only select a candidate in 50% (FairPA) and 30% (IID) of cases. Having such a None result is often undesirable, so we introduced two adjusted prophet algorithmswhich have a pick rate of (close to) 100%. Our results suggest that these algorithms maintain similar levels of fairness. As a point of discussion, we would like to note that knowing the group probabilities p beforehand is, in some cases, quite counter intuitive. This fell outside of the scope of this reproducibility study, but it would be an interesting approach for further research to handle this critique."
"['Nils Peters', 'Joy Crosbie', ""Rachel van\\'t Hull"", 'Marius Strampel']",[¬Re] Reproducing 'Fair Selective Classification via Sufficiency',10.5281/zenodo.6574691,Replication,Python 3,https://zenodo.org/record/6574691/files/article.pdf,rescience c classification selective classification sufficiency machine learning Python 3,https://openreview.net/forum?id=r9Leh2M7hCt,https://github.com/MLRC2022FSCS/FSCS,8,2,2022,"In this reproducibility study we focus on the paper ”Fair Selective Classification via Suf‐ ficiency”. Our experiments focus on the following claims: 1. Sufficiency is able to miti‐ gate disparities in precision across the entire coverage scale and inmargin distributions, and will not increase these disparities compared to a baseline selective classification model in any case. 2. Using sufficiency may decrease overall accuracy in some cases, but still mitigates the disparity between groupswhen looking at individual classification scores. 3. The sufficiency‐regularised classifier exhibits better fairness performance on traditional fairness datasets.","The authors made the importance of implementing fair selective classification with suf‐ ficiency very clear. Moreover, the authors provided an in‐depth mathematical back‐ ground to sufficiency and selective classification, making their reasoning explicit. Fi‐
Copyright © 2022 N. Peters et al., released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Nils Peters (nils.peters@kpnmail.nl) The authors have declared that no competing interests exist. Code is available at https://github.com/MLRC2022FSCS/FSCS – DOI 10.5281/zenodo.6479342. – SWH swh:1:dir:effcbb5800e91db9053cb59c68bbc097a10da7cf. Open peer review is available at https://openreview.net/forum?id=r9Leh2M7hCt.
None 8.2 (#33) – Peters et al. 2022 1
nally, the authors presented their results in such a manner that allowed for straightfor‐ ward comparison once we had trained the model.","Many technical details and model parameters were not specified in the original paper, and as no code was provided by the authors, these initially had to be determined by experimentation. Furthermore, someof the figures in the paper caused confusion about the exact implementation of the model.
Communication with original authors As soon as we noticed we needed clarification on the hyperparameters, datasets and models, we contacted the authors via email. Initially we did not receive a reply, and eventually the authors were only able to answer some of our questions on the Tuesday before the deadline. While we re‐implemented our model based on the newly supplied information, timewas too short to fix the new issues that became apparent with the new model.
None 8.2 (#33) – Peters et al. 2022 2
1 Introduction
Fair classification problems emerge when one wishes to ensure that underprivileged groups sharing some sensitive attribute, such as race or gender, are not disadvantaged against any other group with the same sensitive attribute [1]. A variant of the fair clas‐ sification problem is selective classification, where a model is allowed to abstain from making a decision. This is usually implemented via confidence thresholding. When the confidence threshold is higher, one should expect to see better performance on the remaining samples, as the system is only making decisions when it is very confident with regards to some confidence measure [2]. However, it has been shown that while decreasing the coverage can increase overall performance, it can additionally magnify disparities between groups [2]. The paper by Lee et al.1 that is central to this reproducibility study proposes a method for enforcing fairness during selective classification, consisting of a sufficiency criterion and a regulariser based on mutual information. The authors claim that the method en‐ sures that a classifier is fair, even if it abstains from classifying on a large number of samples. They demonstrate their method on four datasets, each consisting of a differ‐ ent type of data.
2 Scope of reproducibility
In this reproducibility study we focus on several claims. The first claim is that suffi‐ ciency is able to mitigate disparities in precision across the entire coverage scale and in margin distributions, and will not increase these disparities compared to a base‐ line selective classification model in any case. The second claim is that using suffi‐ ciency may decrease overall accuracy in some cases, but still mitigates the disparity between groups when looking at individual classification scores. Finally, the authors claim that sufficiency‐regularised classifier exhibits better fairness performance on tra‐ ditional fairness datasets. Our study consists of two components:
• Code reconstruction: Since the author’s code is not publicly available, all code was written from scratch in Python 3, using the instructions and pseudocode as described in the paper. Models, code and datasets are described in Section 3. Our code can be found on GitHub1.
• Replication: The main part of our study is focused on reproducing the results in Lee et al.1, and to validate their observations and conclusions. Our replication results are presented in Section 4.
3 Methodology
First, an overview of the general sufficiency model is given, after which we discuss how the model was adapted to each of the datasets. This is followed by a discussion on how we evaluated our implementation, and finally we discuss the computational require‐ ments.
3.1 Model descriptions As mentioned before, the original paper uses a selective classification model to which the sufficiency criterion has been applied during training. The sufficiency criterion en‐ sures that the predictive accuracy is the same for each group at each confidence level,
1https://github.com/MLRC2022FSCS/FSCS, accessed 04‐02‐22
None 8.2 (#33) – Peters et al. 2022 3
that precision increases for each group when using selective classification and helps prevent disparities between groups when decreasing coverage. For a binary target Y and sensitive attribute D, the sufficiency criterion imposes a con‐ ditional independence between Y and D conditioned on the learned features Φ, thus requiring:
P (Y = 1|Φ(x), D = a) = P (Y = 1|Φ(x), D = b), ∀a, b ∈ D.
An overview of the general sufficiency model is given in Figure 1. When training the model, depending on which data set is used, the data is first passed through either or both a pre‐trained deep neural network and a two‐layer neural network. The first layer serves as a feature extractor and the second one serves as a classifier. From these fea‐ tures, in addition to training a joint classifier, a group‐specific classifier is trained for each d ∈ D. For each data point, a group‐specific loss and a group‐agnostic loss are computed. To obtain the first, the datapoint is assigned to the correct group‐specific classifier, that is the one corresponding to the input’s sensitive attribute D = d, while for the second the input is assigned to either of the classifiers based on the marginal distribution PD. A combination of these losses is then used as a sufficiency regulariser:
LR ≜ 1
n n∑ i=1 ( log q(yi|Φ(xi); θdi)− log q(yi|Φ(xi); θ∼di) ) The overall loss function then becomes:
min 1
n n∑ i=1 ( L(T (Φ(xi)), yi) + λ log q(yi|Φ(xi); θdi)− λ log q(yi|Φ(xi); θ∼di) ) and is used to update the feature extractor and joint classifier. By minimising the difference between the group‐specific and group‐agnostic loss, Φ(x) will be such that the group‐specific models trained on it will decrease their individual biases and converge towards the samemodel. In binary selective classification, an input
X is classified as belonging to a certain class when the confidence exceeds some thresh‐ old. The softmax response s(x) is monotonically mapped to the confindence score k(x) with the following formula, which maps [0.5, 1] to [0, inf] and provides much higher resolution on the values close to 1 [1]:
κ(x) = 1
2 log
( s(x)
1− s(x) ) When ŷ = y, the margin M(x) is κ(x) and −κ(x) otherwise. Given a threshold τ , the classifier makes a correct prediction whenM(x) ≥ τ and an incorrect prediction when M(x) ≤ −τ .
None 8.2 (#33) – Peters et al. 2022 4
3.2 Code reconstruction
Following the paper, our code was implemented in PyTorch2. This was achieved by cre‐ ating the featuriser for each dataset, a joint classifier and two fully connected layers: one for the privileged and one for the unprivileged protected group. No activation lay‐ ers were added to the joint classifier and group‐layers, since cross‐entropy loss requires logits as input. However, for evaluation of the model a softmax layer was applied to the predictions of the joint classifier as this was required for selective classification. Three separate Adam optimisers were used: one for the featuriser, one for the joint clas‐ sifier and one for both layers in the group classifiers. The loss regulariser λ was set to 0.7 for all datasets as was stated in the paper. The learning rate was not provided in the paper, but later clarified by the authors to be 0.001 for each of the three featurisers. Moreover, there was no mention of what range was used for the confidence threshold, which determines the coverage. As such, testing starts with a threshold τ of 0 (i.e. with a coverage of 100%), and increaseswith some threshold step size until we reach a coverage of under 0.19. The cut‐off point for coverage at 0.19was chosen somewhat arbitrarily, as it lies a little past 0.20, which seems to be roughly the point beyondwhich neither the ac‐ curacy, nor the precision change much at all. This is in line with both our observations, as well as the data presented by Lee et al.1.
3.3 Dataset-specific models We ran the experiments on three of the four binary classification datasets used in the paper. For each of the datasets, we used the predetermined train/test splits if available.
Adult dataset — The Adult3 dataset [3] consists of 48.842 entries containing tabular cen‐ sus data, such as age, sex and education. The first step in preprocessing the dataset was removing all entries with missing values. The data was then split into 29092 training examples and 15060 test examples. Categorical variables within the data were one‐hot encoded, and the continuous variables were normalised to be between 0 and 1, the lat‐ ter of which was done to remove the outliers that could incorrectly skew the gradient learning of the parameters. Following the original paper, we only kept the first 50 sam‐ ples for women with a high income, that is D = 0 and Y = 1, to stimulate disparities between groups. The resulting data, X, was used to predict the target label Y , which in this case is an individual’s income. Classification is binary: an income of over 50k is viewed as high income and assigned label 1, and every other income was assigned label 0. Sex was designated as the sensitive attributeD. For this dataset, we followed the original paper and used a two‐layer neural network with a hidden layer consisting of 80 nodes. The first layer is a feature extractor using a Scaled Exponential Linear Unit (SELU) activation function, and the second layer serves as the joint classifier. The network is trained for 20 epochs.
CelebA dataset — The CelebA4 dataset [4] consists of 202.599 images of 10.177 different celebrities, alongwith a list of attributes depicted in the images. Itwas not clear from the original paperwhether the aligneddataset or the original onewasused. Moreover, it was only specified that the images were resized to 224x224, but it was not explained how this was done and whether there were any other preprocessing steps, such as normalisation. After communicationwith the authors it became clear that the aligned dataset was used, and that the images were to be normalised with 0.5 mean and 0.5 standard deviation. Because the Pytorch dataloader loaded in 38 extra columns that were unnecessary in our research, wemanually resized the images to 224x224 with a Pytorch transformation.
2https://pytorch.org/docs/stable/index.html, accessed 04‐02‐22 3https://archive.ics.uci.edu/ml/datasets/adult, accessed 04‐02‐22 4http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html, accessed 04‐02‐22
None 8.2 (#33) – Peters et al. 2022 5
In order to be able to use the cross‐entropy function in a later stage, all ‐1 values of the binary ’blond’ and ’male’ variables were mapped to 0. The resulting images were used as data X, the hair colour (blond or not) was used as the target variable Y and the sex variable was used as the sensitive attribute D. To obtain features from the images, we trained a ResNet‐50 model [5], initialised with the pre‐trained ImageNet weights, for 10 epochs. The features were then extracted from the second to last layer. The last layer was removed and replaced with a layer consisting of two output nodes to form the classifier.
Civil Comments dataset — TheCivil Comments dataset5 [6] is a text‐based dataset consisting of 1.999.514 online comments on various news articles, along with metadata about the commenter and a label indicating whether the comment displays toxicity or not. The Kaggle repository does not provide a test set with labels nor a validation set. This meant that exclusively datapoints from the training set were used in our study. Following Lee et al.1, we let X be the comment text, Y be the binary toxicity label, and D be whether Christianity is mentioned. The dataset does not include mention‐of‐Christianity values for each data point and therefore all data points without one were dropped. A total of 235.087 comments remained. These were subsequently split into a training, validation and test set using ratios of 0.8, 0.1, 0.1 respectively. Additionally, the targets Y and men‐ tions of ChristianityD were converted to binary values, where values above or equal to 0.5 were mapped to 1 and values below 0.5 were mapped to 0. Lastly, the comments X were tokenised using the BERT tokeniser6, with max length set to 512, truncation set to true, and padding set to the max length. To obtain features from the texts, the tokenised data was passed through a BERT model [7] using the pretrained parameters. The exact BERT model was not specified in the original paper. Due to time constraints, the Tiny BERT model from Hugging Face7 [8, 9] was used, which had previously been adapted to Pytorch. Similarly to the Adult dataset, we then applied a two‐layer neural network to the BERT output with 80 nodes in the hidden layer. The first layer was treated as a feature extractor and the second layer as the classifier. Following the original paper, we trained the model for 20 epochs.
3.4 Evaluation Tomake sure our implementation is correct, we also implement a standard classification baseline where we only optimise the cross‐entropy loss function. This can be observed in the lower part of Figure 1. Moreover, we plot the margin distributions of our suffi‐ ciency implementation and compare them to that of the original paper. To measure the effectiveness of our selective classification implementation, we follow the evaluation method of the authors and plot the accuracy‐coverage and precision‐ coverage curves, and then compute the area under the curves to summarise the per‐ formance across coverage values.
3.5 Computational requirements The experiments were run using a Nvidia RTX 3090 with 24 GB VRAM at 1785 MHz. The batch sizes were not provided in the original paper, and so they were chosen based on memory constraints. As the Adult dataset consists of relatively little data, the batch size was set to 32 in order to perform enough gradient steps to fit the parameters. This resulted in a total training runtime of about 10 seconds for the baseline and 5 minutes for the sufficiency implementation across all 20 epochs. For the CelebA dataset, the largest batch size that fit in memory was 96, which resulted in a total training runtime
5https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/data, accessed 04‐02‐22 6https://huggingface.co/docs/transformers/model_doc/bert, accessed 04‐02‐22 7https://huggingface.co/prajjwal1/bert-tiny, accessed 04‐02‐22
None 8.2 (#33) – Peters et al. 2022 6
of 1 hour and 30 minutes for the baseline and 3 hours and 30 minutes for sufficiency for 10 epochs. For the Civil Comments model, a batch size of 48 was used, resulting in a total of 30 minutes of training time for the baseline model and 1 hour and 38 minutes for the sufficiency implementation when running for 20 epochs.
4 Results
4.1 Overall accuracy-coverage graphs Figure 2 displays the overall accuracy plotted against the coverage for different datasets and for both the baseline and the sufficiency‐regularisedmodel. From the Adult dataset graph, we can infer that accuracies are the same for both models across all coverages. For the CelebA dataset, the sufficiency model increases the accuracy for most of the coverage scale, only converging with the baseline at a coverage of around 0.25. In the Civil Comments dataset graph, the baseline model outperforms the sufficiency model across the entire coverage scale. In the original paper, the authors claim that sufficiency may decrease accuracy in some cases. Specifically, they show that the baselinemodel outperforms the sufficiencymodel on overall accuracy for the Adult dataset. Our results do support this specific result on the CelebA dataset, though for the Adult dataset the baseline and sufficiency models perform equally. For the Civil dataset, however, it is the case that sufficiency decreases accuracy, which thus confirms the general claim that sufficiency does not necessarily improve accuracy.
4.2 Group-specific precision-coverage curves Figure 3 shows the group‐specific precisions across the entire coverage scale. When comparing the baseline model to the sufficiency model, Figure 3a shows that, from a coverage of below about 0.7, sufficiency leads to a smaller gap between the female and male precisions on the Adult dataset. Theworst‐group precision, i.e. themale precision, improves most. For the CelebA dataset in Figure 3b, we observe both groups’ precisions increasingwhen using sufficiency. The precisions increase equally however, causing the gap between the genders to remain the same. As was to be expected from Figure 2c, both precisions decrease when using sufficiency on the Civil Comments dataset. However, the gap between the two groups very slightly decreases for coverages between 0.7 and 1.0. These findings are mostly in line with the findings in the original paper: while for the Adult dataset and the Civil Comments dataset the gaps between the two group do de‐ crease when including sufficiency, and while for the CelebA dataset this is not the case, sufficiency does not increase the gap but does significantly improve accuracy. These
None 8.2 (#33) – Peters et al. 2022 7
results neither confirm nor deny the authors’ claim that the sufficiency criterion intro‐ duces a method for mitigating the disparity in precision, though we do note that the differences in precision in our results are much less significant than those as reported in the original paper.
4.3 Margin distributions In Figure 4, themargindistributions for both groups are displayed for eachof the datasets. For the Adult dataset, the margins do not appear to be affected much by sufficiency.
Conversely, in the CelebA dataset, both margin distributions become more positively centred, causing the distributions to bemore similar. Especially themale groupmargin shifts more towards the positive side, obtaining a smaller range in the negative region and a wider peak in the positive region. The number of samples in the female group with a negative margin has decreased. We also observe an increase in the number of outliers in the positive region. Finally, the Civil Comments dataset shows the Non‐Christian group’s margin becoming more normally centred around a margin of around 1, and also shows the two groups’ distributions becoming more aligned. Our results show sufficiency mitigating and in any case not worsening disparities be‐ tween the two groups, with the Adult dataset distributions staying the same and the other two datasets confirming that sufficiency causes a slight reduction of the gap be‐ tween the margin distributions of different groups. This thus confirms the claim that sufficiency helps mitigate disparities in margin distributions, however, again, the dif‐ ferences between the models’ distributions are not as clear as in the original paper.
4.4 Numerical evaluations In Table 1, the areas under the accuracy curves and the areas between the precision curves are presented for each of the datasets. For the Adult dataset, the area under the accuracy curve virtually remains the samewhen using sufficiency, in linewith Figure 2a. The area between the precision curves slightly increases. While this seems to contradict
None 8.2 (#33) – Peters et al. 2022 8
Figure 4a, note that we only observed a decrease in the precision gap for coverages of below 0.7, and the numbers in Table 1 concern the entire coverage scare. For the CelebA dataset, the area under the accuracy curve increases, resulting in an increase in overall accuracy as previously observed in Figure 2b. However, as already suggested by Figure 4b, the area between the precision curves stays virtually the same when using the sufficiency method. Once again confirming the results observed in Figure 3, when using sufficiency, the area under the Civil Comments dataset’s accuracy curve decreases. The area between the precision curves effectively stays the same. As mentioned before, in the original paper sufficiency causes the Adult dataset accu‐ racy to diminish, while in our results both models achieve the same performance. In contrast, while for the Civil Comments dataset the original paper’s accuracy increases, our results show a decrease in accuracy. The CelebA results both exhibit an increase in accuracy, though this increase is more prominent in the original paper. The area between the precision curves significantly decreases for theAdult dataset in the original paper, which is not the case for our results. The same holds for the precision curves of the the CelebA and Civil Comments dataset: although less so than for the Adult dataset, the original paper’s result show that disparities are decreased when using sufficiency, while our results do not show any significant change. The Civil Comments results show that accuracy can reduce when using sufficiency, but disparities will not increase. Furthermore, although the claim about disparity in pre‐ cision mitigating is not directly confirmed by our results as the areas stay the same, it does show that sufficiency will not (significantly) worsen disparities in any case.
5 Discussion
To summarise, the numbers (accuracies, precisions, margin distributions etc.) obtained in our experiments differ significantly from those reported in the original paper. How‐ ever, although differences between the baseline model and the sufficiency model are not as significant as in the original paper, our results do support the main claims about sufficiency being able to increase theworst‐group precision and thus causing disparities between groups to decrease. It is worth mentioning that the Figures 4b and 4c show the largest increase inmargin alignment, and these are also the datasets that either improve in overall accuracy, or decrease in disparities between groups. Moreover, the authors claimed that the sufficiency‐regularised classifier exhibited better fairness performance on traditional fairness datasets. Though we were not able to reproduce their results in
None 8.2 (#33) – Peters et al. 2022 9
this study, we do believe we can validate this claim, as sufficiency is either able to de‐ crease the disparities in precision between groups (Figures 3a and 3c), or increase the precision for both groups in an equalmanner aswe traverse the coverage scale,meaning that no group is penalised for the sake of improving the other group’s precision. The fact that we were not able to precisely reproduce the results from the original pa‐ per is likely due to the fact that not all technical details required to fully replicate the original paper were provided by the authors in the paper. Specifically the learning rate, selective classification threshold and optimiser algorithms had to be decided upon our‐ selves. While a well‐informed guess of what parameters to use was made possible due to experimentation, it could well be possible that the authors’ implementation differs on these fronts, and that this caused our results to differ from the ones in the paper. We also did not have time to run all the experiments we would have liked to. For ex‐ ample, testing on the CheXpert8 dataset, or experiments beyond replication, such as applying the sufficiency method to a new dataset. This was due to the fact that we spent a large amount of time trying to improve our original results, because we wanted to make sure these were stable before attempting to generalise further.
5.1 Reproducibility of the paper
What was easy — The authors provided a strong and logically structured theoretical back‐ ground that made the importance of implementing fair selective classification with suf‐ ficiency very clear. Moreover, the authors provided an in‐depth mathematical back‐ ground to sufficiency and selective classification, making their reasoning explicit. Fi‐ nally, the authors provided clear explanations of the evaluation method and presented their results in such amanner that allowed for straightforward comparison once we had trained the model.
What was difficult — As mentioned previously, many crucial technical details (e.g. pre‐ trained models and hyperparameters) required to replicate the original paper were not provided by the authors. Furthermore, we found the overview of the model shown in Figure 1 (Figure 2 in the original paper) difficult to interpret. This caused the implemen‐ tation of the model to take more time than we had anticipated. The first issue was the use of ”ex” in the deep network and joint loss depictions, which is generally short for ”excluding”. In section 4.1 of the original paper, it appears that the ResNet‐50 model is modified in place, leading to the features being extracted and classifiedwithinResNet‐50 itself. This would indeed indicate ’ex’ meaning ’excluding’, as there is no separate fea‐ turiser in this case. However, this interpretation means that cross‐entropy is excluded from the joint loss, though it is explicitly mentioned in section 4.1. This would indicate ”ex” is short for ’exemplum’, which is a contradiction. Moreover, the image does not make immediately clear that the fully connected layers FC0 and FC1 are the same for both the group‐specific and the group‐agnostic classifier. There was also no mention of the loss functions or activation functions used for the fully connected layers in the group‐specific classifiers. Finally, it was not explicitly mentioned whether the featuris‐ ers were the same for the Adult and Civil datasets.
5.2 Communication with original authors As soon as we noticed we were missing crucial information about the hyperparameters and the CelebA dataset and we needed some clarifications on the workings of themodel, we contacted the authors via email. Initially we did not receive a reply, and so we sent a follow‐up email. We received an answer from the authors that they needed more time to verify the information we asked for and were currently working towards a deadline
8The fourth dataset from the original paper: https://stanfordmlgroup.github.io/competitions/chexpert/, accessed 04‐02‐22
None 8.2 (#33) – Peters et al. 2022 10
themselves andwe eventually received an email on 01‐02‐2022. In this email, the authors were only able to answer some of our questions. While we re‐implemented our model based on the newly supplied information, time was too short to fix the new issues that became apparent with the new model."
"['Rohit Ranjan', 'Himadri Bhakta', 'Animesh Jha', 'Parv Maheshwari']",[Re] Differentiable Spatial Planning using Transformers,10.5281/zenodo.6574693,Replication,Python,https://zenodo.org/record/6574693/files/article.pdf,rescience c machine learning deep learning python pytorch,https://openreview.net/forum?id=HFUI1pfQnCF,https://github.com/sirmisscriesalot/Differentiable-Spatial-Planning-using-Transformers,8,2,2022,"This report covers our reproduction effort of the paper ‘Differentiable Spatial Planning using Transformers’ by Chaplot et al. [1]. In this paper, the problem of spatial path planning in a differentiable way is considered. They show that their proposed method of using Spatial Planning Transformers outperforms prior data‐drivenmodels and lever‐ ages differentiable structures to learn mapping without a ground truth map simultane‐ ously. We verify these claims by reproducing their experiments and testing theirmethod on new data. We also investigate the stability of planning accuracy with maps with in‐ creased obstacle complexity. Efforts to investigate and verify the learnings of the Map‐ per module were met with failure stemming from a paucity of computational resources and unreachable authors.","Model architecture and training details were enough to easily reproduce.
Copyright © 2022 R. Ranjan et al., released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Rohit Ranjan (ranjanmail.rohit@gmail.com) The authors have declared that no competing interests exist. Code is available at https://github.com/sirmisscriesalot/Differentiable-Spatial-Planning-using-Transformers – DOI 10.5281/zenodo.6475614. – SWH swh:1:dir:6aa6080e642126b1166661d245a4f594a777889b. Open peer review is available at https://openreview.net/forum?id=HFUI1pfQnCF.
ReScience C 8.2 (#34) – Ranjan et al. 2022 1","We lost significant time in generating all synthetic datasets, especially the dataset for the Mapper module that required us to set up the Habitat Simulator and API [4]. The ImageExtractor API was broken, and workarounds had to be implemented. The final dataset approached 1.6 TB in size, and we could not arrange enough computational re‐ sources and expertise to handle the GPU training. Furthermore, the description of the action prediction accuracymetric used is vague and could be one of the possible reasons behind the non‐reproducibility of the results.
Communication with original authors The authors of the paper could not be reached even after multiple attempts.
ReScience C 8.2 (#34) – Ranjan et al. 2022 2
1 Introduction
In the original paper [1], the problem of spatial path planning in a differentiable way is considered. The authors show that their proposed method of using Spatial Planning Transformers outperforms prior data‐driven models that propagate information locally via convolutional structure in an iterative manner. Their proposed model also allows seamless generalisation to out‐of‐distributionmaps and goals and simultaneously lever‐ ages differentiable structures to learn mapping without a ground truth map.
2 Scope of reproducibility
We seek to investigate the following major claims made in the paper:
• Claim 1: Their proposed SPT planner module provides a definite improvement of 7‐19% over state‐of‐the‐art CNN based planning baselines in average action prediction accuracy.
• Claim 2: Their proposed SPT planner module maintains stability in accuracy as complexity increases and the number of obstacles increases.
• Claim 3: Their proposed SPT module outperforms classical mapping and planning base‐ lines under an end‐to‐end mapping and planning setting.
3 Methodology
The entire codebase iswritten fromscratch for the SPTmodules and the synthetic dataset generation in Python 3.6. Pytorch Lightning was used for the SPT modules. For dataset generation, similar parameters were used, as mentioned in the paper, to the maximum extent. The vagueness of parameters in terms of obstacle size allowed us to test out a range of obstacle sizes and the accuracy of the model on them. All runs were logged on the WandB platform. The training was done using NVIDIA Tesla T4 and P10 GPUs on Google Colaboratory Pro.
3.1 Model descriptions Our implementation of the model follows the description provided in the paper taking liberties where details are vague. The input map and the goal map are stacked vertically and then fed into a CNN Encoder. The Encoder has 2 fully connected layers with a kernel size=1 and ReLU activation func‐ tion. The first layer increases the number of channels from 2 to 64, while the second layer maintains the number of channels and outputs a 64 channel encoded input. As described in the original paper, Positional encoding is added to the encoded input, which is then reshaped and fed into the Encoder part. Their are five encoder layers, each with nheads = 8, dmodel = 512 and dropout = 0.1. This output is fed into a Decoder made of a fully connected layer. The Decoder gives one output for each cell. The output is then reshaped to regain its original map shape. We carry further investigations on how the number of layers in the CNNEncoder, nheads and layers in the Encoder and embedding size affect the SPT Planner Module. Improve‐ ments were gained and are detailed in the Results section.
ReScience C 8.2 (#34) – Ranjan et al. 2022 3
3.2 Datasets
The SPT Planner Module —We create 3 datasets for the SPT planner module, each with a map size = {15 30 50} and up to 5 randomly generated obstacles. The position of the goal is randomly chosen from a free‐space cell. 2 different datasets are generated at map size = 15 with up to 10 and 15 obstacles, respectively. Each of these datasets has 100,000maps for training, 5,000 for validation and 5,000 for testing.
The End-to-End Mapper and Planner Module —We further used the Habitat Simulator, and Habitat API [4] to generate 36000 maps for training the end‐to‐end model. Seventy‐two scenes from the Gibson dataset [5] from Stanford is loaded onto the simulator, and 500 maps with a grid cell dimension of 0.5 meters and map size of 15, are rendered from each scene. Ground truths for all datasets were generated using the classical Dijkstra’s algorithm. This dataset is over 1.6 TB andmade it difficult to hand‐engineer training on limited GPU resources. All datasets generated and used have been released for open‐source and can be found on the project’s github page.
3.3 Hyperparameters An extensive hyperparameter grid search led us back to the same hyperparameters cited in the paper. The model is trained for 40 epochs with a learning rate decay of 0.9 per epoch, a starting learning rate of 1.0 and a batch size of 20. The model is separately trained for each of the map distributions using mean squared error loss and stochastic gradient descent [6].
ReScience C 8.2 (#34) – Ranjan et al. 2022 4
4 Reproducibility Results
We reproduced the accuracy for the SPT planner module to within 14.7% of reported value, which, while outperforming the baselines [2] [3] in select cases, fails to support the paper’s conclusion that it outperforms the baselines. However, we achieve a similar drop‐off in accuracy in percentage points over different model settings. We suspect that the vagueness in the accuracy metric leads to the absolute difference of 14.7% despite the paper being reproducible. The Mapper module’s accuracy could not be tested.
Figure 4. Sample output for Navigation Task (left) and Manipulation Task (right) visualised. ∗ Could not be trained due to lack of enough computational resources.
5 Further Investigation Results and Discussion
The CNN Encoder — The CNN Encoder takes the map and the goal location as the input and encodes the information into an embedding of size dmodel. This is achieved by a
ReScience C 8.2 (#34) – Ranjan et al. 2022 5"
"['Nick Rucks', 'Tobias Uelwer', 'Stefan Harmeling']",[Re] Solving Phase Retrieval With a Learned Reference,10.5281/zenodo.6574695,Replication,Python,https://zenodo.org/record/6574695/files/article.pdf,rescience c phase retrieval machine learning python pytorch,https://openreview.net/forum?id=rlWzUnM72RF,https://github.com/tuelwer/machine-learning-reproducibility-challenge-2021,8,2,2022,"This report reproduces the experiments and validates the results of the ECCV 2020 paper ”Solving Phase Retrieval with a Learned Reference” by Hyder et al. [1]. The authors con‐ sider the task of recovering an unknown signal from its Fourier magnitudes, where the measurements are obtained after a reference image is added onto the signal. In order to solve this task a novel, iterative phase retrieval algorithm, presented as an unrolled network, that can train a such reference on a small amount of data is proposed. It is shown that the learned reference generalizes well to unseen data distributions and is robust to spatial data augmentation like shifting and rotation.",,
"['Roopsa Sen', 'Sidharth Sinha', 'Animesh Jha', 'Parv Maheshwari']",[Re] Reproducibility Report: Contrastive Learning of Socially-aware Motion Representations,10.5281/zenodo.6574697,Replication,Python,https://zenodo.org/record/6574697/files/article.pdf,rescience c machine learning deep learning python pytorch,https://openreview.net/forum?id=SIQEl6f7h0Y,https://github.com/RoopsaSen/social-nce-trajectron-plus-plus,8,2,2022,"The central claim of the paper is that the consideration of negative (collision) cases in trajectory predictionmodels through a socially contrastive loss function Social‐NCEwill improve the robustness of themodels. We verify their claimon variousmodels, with spe‐ cial focus on improvements in the human trajectory prediction models Social‐STGCNN and Trajectron++ and on robot navigation through an imitation learning model.","The publicly available codebases were well documented and easy to follow. The authors have also mentioned sources for the processed datasets that they have used. The simu‐ lation data generation code for the imitation learning model was also shared.
1https://github.com/vita‐epfl/social‐nce
Copyright © 2022 R. Sen et al., released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Roopsa Sen (roopsa.sen@kgpian.iitkgp.ac.in) The authors have declared that no competing interests exist. Code is available at https://github.com/RoopsaSen/social-nce-trajectron-plus-plus – DOI 10.5281/zenodo.6511007. – SWH swh:1:dir:ba72ac2acf3bac942d9b3a66e51091e6bcce6617. Open peer review is available at https://openreview.net/forum?id=SIQEl6f7h0Y.
ReScience C 8.2 (#36) – Sen et al. 2022 1","The proposed contrastive loss was implemented on different trajectory prediction mod‐ els, the understanding of which was required to reimplement the code from PyTorch to PyTorch Lightning. Experiments on the entire ETH and UCY dataset on restricted computational resources took a considerable amount of time and we had to restrict our ablation study to one model.
Communication with original authors We contacted the authors with some queries on their implementation and on the im‐ portance of some hyperparameters. They replied promptly and their input was pivotal while conducting experiments.
1 Introduction
Humans tend to develop a strong intuition towards predicting future motions of other people, while navigating in crowded spaces. This is essential for carrying out daily tasks without any discomfort and to maintain a safe distance from others while moving around. However, building neural models that can replicate similar nature of accurate predictions is often challenging, even with a large training set. Multi‐agent problems such as trajectory forecasting and robot navigation, require the model to learn socially aware motion representations. Previously, several papers have proposed neural network based models to achieve these tasks. However, these models still fail to generalize well with different scenarios, often outputting colliding trajecto‐ ries. The original authors aim to tackle this issue by feeding explicit negative examples into the network, while teaching the model to differentiate between the two using a newly proposed Social Contrastive Loss. We exhaustively carry out all the experiments done in the paper and verify all claims and tables. We then review the results and present an assessment. We further ported the code to the PyTorch Lightning framework. This allowed us to train the code flexibly over different platforms and automate the optimization process. We also expect this to help in future implementation or reproduction of the codebase. Then we proceed to present a few ablations in the original code, especially hyperparameter tuning.
2 Scope of reproducibility
Existingwork onmulti‐agent trajectory prediction problems sometimes output colliding trajectorieswhichmakes themunsuitable for deployment. The authors claim that this is due to the bias in existing datasetswhich only consist of safe trajectories andno collision scenarios, giving the models no negative cases to train on. The original paper proposes a modified contrastive loss (Social‐NCE) which incorporates ground truth knowledge to generate negative cases to reduce collision rates on several benchmarks. The details of this loss have been discussed later (in Methodology section) in the report. The key claims that we aim to verify in our reproducibility report are:
1. Addition of the Social‐NCE loss in human trajectory forecasting models signifi‐ cantly decreases collision rate while maintaining similar final displacement error.
2. Addition of the Social‐NCE loss in imitation learning models for robot navigation in crowded environments significantly decreases the collision rate.
3. Addition of the Social‐NCE loss in reinforcement learning models increases sam‐ ple efficiency, and they obtain a collision‐free policy quickly.
ReScience C 8.2 (#36) – Sen et al. 2022 2
3 Methodology
The authors have a detailed public repository2 on the addition of Social‐NCE on Tra‐ jectron++ [2], Social‐STGCNN [3], models for human trajectory prediction and on an existing imitation learning model [4] for robot navigation. Further, we contacted the authors and they gave us their implementation of Social‐NCE in reinforcement learn‐ ing using Rainbow DQN [5] as the baseline. We reproduced the findings of the paper based on these repositories. We focused primarily on the human trajectory prediction models Social‐STGCNN and Trajectron++ and attempted ablations on Social‐NCE hyper‐ parameters in the Trajectron++ model to improve its performance. Lastly we ported the codebase for Trajectron++, Social‐STGCNN and the imitation learningmodel to PyTorch Lightning [6].
3.1 Social-NCE Loss and Negative Data Augmentation
Consider M agents with index i ∈ {1...M}, the state of agent i at time t is given by sit = (xit, y i t) which are its position coordinates. State of all agents combined is given by st = {s1t , s2t ....sMt }. Given s1:t the model predicts st+1:T . Encoder f(·) : Gives vector encoding( hit) for agent i at time t given state of all agents till time t and index of agent:
hit = f(s1:t, i) (1)
Encoder has two sub‐modules: sequential fs(.) and interaction fi(.) modules to make encoding of one agent dependent on the state of other agents. Decoder g(·) : Returns predicted state from vector encoding
sit+1:T = g(h i t) (2)
Social-NCE loss — Embedding Models
• Query: Projection head that embeds the vector encoding of the agent i till time t
q = ψ(hit) (3)
• Key: Encoder that embeds the future state of agent i at time t + δt where δt is the sampling horizon in a given range
k = ϕ(sit+δt, δt) (4)
Both the query and key are 2‐layer MLPs which return 8‐dimensional encoded vectors. Loss The InfoNCE Loss [7] is given by:
LNCE = −log exp(sim(q, k+)/τ)∑N n=0 exp(sim(q, kn)/τ)
(5)
2https://github.com/YuejiangLIU/social‐nce‐trajectron‐plus‐plus
ReScience C 8.2 (#36) – Sen et al. 2022 3
In standard InfoNCE loss the similarity function sim(q, k) is the cosine similarity be‐ tween the two vectors. In the Social‐NCE variation this similarity function has been modified to the dot product of the two embedded vectors returned from the encoders. The Social‐NCE Loss is given by:
LSocial−NCE = −log exp((ψ(hit)·ϕ(si,+t+δt, δt)/τ)∑ δt∈Λ ∑N n=0 exp((ψ(h i t)·ϕ(si,nt+δt, δt)/τ)
(6)
The three encoders f(·), ψ(·) and ϕ(·) are jointly trained such that the query is encoded closer to the positive key and further from the negative keys. The keys aremade through data augmentation as discussed next. The final loss for a specific model would be given by the weighted sum of the model task loss and the Social‐NCE loss.
Data Augmentation —Negative samples: The state of the agent i at time t + δt cannot be same as the state of any of the other agents at time t + δt, so the states of the M − 1 elements other than the agent i can be used as negative keys for it. For each agent j ∈ {1, ...M}−{i}, 8 points are taken uniformly from a circle with radius of minimum distance of comfort around the agent j as negative keys for agent i
si,n−t+δt = s j t+δt +∆sp + ϵ (7)
∆sp = (ρcosθp, ρsinθp), ρ being minimum distance of comfort and θp = 0.25pπ, p ∈ {0, 1, ..., 7} ϵ is a normally distributed added noise Each agent i thus has 8(M − 1) negative keys. Positive samples: Single positive key is taken from state of agent i at time t + δt after adding normally distributed noise ϵ
si,+t+δt = s i t+δt + ϵ (8)
The data augmentation is made clearer by the following diagram given by the authors [1]. For an agent i (in blue) the areas of Collision and Discomfort as shown are used as negative samples.
3.2 Datasets The human trajectory prediction models were run on a processed version of ETH and UCY datasets. The original dataset is a collection of 5 video segments of pedestrian trajectories from which the states of each agent per frame id had been stored and the dataset had been pre‐divided into train, test and validation sets to maintain uniformity in accuracy comparison. The processed ETH and UCY datasets are are available in the repository linked3.
3https://github.com/StanfordASL/Trajectron‐plus‐plus/tree/master/experiments/pedestrians/raw
ReScience C 8.2 (#36) – Sen et al. 2022 4
The imitation and reinforcement learning models used pedestrian data from an open‐ source simulator based on OpenAI gym library The dataset consisted of 5000 simulated situations in which the position of 5 random agents are stored for each time step. A validation split of 0.3 was taken.
3.3 Hyperparameters Apart from the hyperparameters required for regular network training, the Social‐NCE included three additional hyperparameters, specific to the model. These were: the tem‐ perature hyperparameter τ , the sampling horizon δt and the contrastive weight λ. In the original paper, there values were set by default. We improvised upon previous work by performing a thorough random search for these hyperparameters using WandB [8]. We further do a sensitivity analysis, and check whether hyperparameter tuning offers any significant benefit. The details of the search can be summarised as follows:
Details on the loss hyperparameters:
• Temperature(τ ): Part of the Social‐NCE losswhich controls theweight of the penalty and reward for negative and postive samples respectively.
• Sampling Horizon(δt): The future time step till which the negative samples are considered for data augmentation
• Contrastive Weight(λ): The weight between the main loss of the model and the Social‐NCE Loss
A similar search was performed separately for the hyperparameters pertaining to data augmentation, with the default values for the hyperparameters discussed in the previ‐ ous section. These hyperparameters were: Minimum Separation, MaximumSeparation and the weight between maximum separation and noise. The details of this search can be summarised as follows:
Details on the augmentation hyperparmeters:
• Minimum Separation: Minimum admissible value of ρ in negative augmentation which is the minimum comfortable distance between two agents
• Maximum Separation: Maximum admissible value of ρ in negative augmentation which is the maximum distance after which agents can pass each other with colli‐ sion.
• Weight between maximum separation and noise: The weight between the added normal noise and the position of the augmented sample.
ReScience C 8.2 (#36) – Sen et al. 2022 5
3.4 Experimental setup and code The encoder models were trained with Adam Optimizer. For the training of the Tra‐ jectron++, Social‐STGCNN and imitation learning models 300, 500 and 200 epochs were used respectively. There were two runs of the reinforcement learning model on 2000 and 5000 episodes respectively. As mentioned in the original paper, the models were evaluated on the following metrics:
• Final displacement error (FDE): the Euclidean distance between the predicted out‐ put and the ground truth at the last time step.
• Collision rate (COL): the percentage of test cases where the predicted trajectories of agents run into collisions.
A lower FDE is preferred, however the current reproduction mainly aims to see the de‐ crease in collision rate. The code was also integrated with WandB to conduct further experiments. This process involved constructing a config dictionary, which included the list of all possible hyperparameters and the values it could potentially take. The main function was modified with WandB initialisation and the logging function to log the value of the Loss after training is complete. The function was then passed to the WandB agent to carry out sweeps. The code can be found in this link 4.
3.5 Computational requirements The training code for Trajectron++ and Social‐STGCNN was run on Kaggle with GPU (Tesla P100‐PCIE‐16GB) and CPU (13GB RAM + 2‐core of Intel Xeon).The average training runtimes are listed in the tables below. It can be seen clearly that porting to lightning has not caused any increase in training time.
The following experiments support the claims made by the authors. We compared the results from training the model from scratch(Reproduced) and reimplementing the model in PyTorch Lightning (Ported Code)with the results given by the authors (Original Paper).
4.1 Results reproducing original paper A comparison of the FDE (Final Displacement Error) and COL (Collision Rate) for the addition of Social‐NCE to Trajectron++ and Social‐STGCNN models in original paper, reproduced and ported code.
4https://anonymous.4open.science/r/social‐nce‐stgcnn‐62D5/README.md
ReScience C 8.2 (#36) – Sen et al. 2022 6
A comparison of the collision rate and time taken for the robot to reach destination for the addition of Social‐NCE in the imitation learningmodel in original paper, reproduced and ported code.
A table of reward vs number of episodes trained for the implementation of Social‐NCE on the reinforcement learning model.
A similar search was performed separately for the hyperparameters pertaining to Data Augmentation:
The FDE and collision rate after training the Social‐STGCNN model for 400 epochs on the original (Original Parameters) and tuned hyperparameters(Tuned Parameters) are:
Our results support the authors’ claim that modelling of social knowledge through the addition of negative test cases reduce the collision rate of trajectory prediction models. In both training from scratch in the original code and in the ported code, the results have remained consistent with that of the original paper.
1. In human trajectory forecasting, the addition of Social‐NCE to the models Trajec‐ tron++ and social‐STGCNN showed a 35.7% and 35.1% decrease in collision rate on average respectively(Table 4 and Table 5) in our reproduced results. The Final Displacement Error(FDE) showed deviation of less than 1%, showing that addition of Social‐NCE adds to the robustness of the models without affecting it’s accuracy.
2. In the imitation learning model the collision rate decreased by 68.9% on average in our reproduced results with the time taken showing little deviation (Table 6).
3. The Social‐NCEaddition to theRainbow‐DQNbased reinforcement learningmodel, as in the original paper, achieves a reward of 0.6 in 2000 episodes in comparison to 4000 episodes of the original Reinforcement Learning model(Table 7).
The hyperparameter tuning conducted was also vastly helpful and lead to an increase of accuracy by 0.91 %. The loss hyperparameters, determined the sensitivity of the model. The contrastive weight, determined emphasis of the Social‐NCE loss. The more the em‐ phasis, the better the model learnt to differentiate between a positive and negative sam‐ ple, but at the expense of loss of proximity to the actual training examples. It remains
ReScience C 8.2 (#36) – Sen et al. 2022 8
difficult to analytically understand the effect of change in the temperature hyperparam‐ eter. Hyperparameter search, even though tedious, can lead to a great increase in accuracy. The tuning of hyperparameters involved in the model, lead to an overall increase in ac‐ curacy. In task like trajectory prediction and motion forecasting, it might be crucial to try and increase the accuracy as much as possible. However, one thing to be noted is that the Social‐STGCNN had a huge running time, and one sweep took a huge amount of time. The effect of the Data Augmentation hyperparameters, seem to be highly variable. It is natural that results are likely to vary greatly with the choice of dataset, and the nature of the problem statement. This is because these hyperparameters are physical constraints put on the model, and hence might lead to different results for different datasets. Further, it was found that best results were found when the value of the contrastive weight to be 16, while the default value was 2. The values might differ distinctly, but this reinforces confidence in the proposed Social‐NCE loss.
5.1 What was easy The authors have provided a detailed public codebase on the implementation of Social‐ NCEonTrajectron++, Social‐STGCNNand imitation learningmodel. Further, they shared the codebase for the reinforcement learningmodel. All the codebases have instructions on how to set up the environment and logs the important metrics, which proved to be helpful in reproduction.
5.2 What was difficult Theporting of the implementationof Social‐NCE in theTrajectron++ andSocial‐STGCNN models from PyTorch to PyTorch Lightning required an understanding of those models and their original codebase which required additional time. Training of the models from scratch required large computation power. All the training was done over cloud GPUs with limited runtimes which often fell short of the time required for training.
5.3 Communication with original authors We mailed the authors listing down some of the queries we had on their code imple‐ mentation. We also had some queries regarding the important hyperparameters that we could tune to improvemodel performance. The authors gave a prompt reply to our ques‐ tions. They shared the codebase for the reinforcement learning model as well. Their contribution has helped us with some crucial points in the report.
6 Future Work
Weoriginally planned to perform the following additional experimentswhichwe couldn’t finish due to lack of time. They have been listed down below and we believe that future work on this paper can be done in this direction.
• A best hyperparameter search on Social‐NCE in Trajectron++, the imitation learn‐ ing model and the Rainbow‐DQN based Reinforcement Learning model as well and comparison of the variation in results for different models.
• Implementation of Social‐NCE on the Social‐LSTM and Directional‐LSTM models on the Trajnet++ benchmark, the results for which have been given in the original paper.
ReScience C 8.2 (#36) – Sen et al. 2022 9
• Implementation of Social‐NCE on state of the art models in other benchmarks such as on the PGP model [9] for the nuScences dataset."
"['Abhishek Shukla', 'Sourya Roy', 'Yogesh Chawla', 'Avi Amalanshu', 'Shubhendu Pandey', 'Rudransh Agrawal', 'Aditya Uppal', 'Viswesh N', 'Pradipto Mondal', 'Anubhab Dasgupta', 'Debashis Chakravarty']","[Re] From goals, waypoints and paths to longterm human trajectory forecasting",10.5281/zenodo.6574699,Replication,Python,https://zenodo.org/record/6574699/files/article.pdf,rescience c trajectory prediction machine learning deep learning python pytorch,https://openreview.net/forum?id=HV2zgpM7n0F,https://github.com/Viswesh-N/MLRC-2021,8,2,2022,"The following paper is a reproducibility report for From Goals, Waypoints & Paths To Long Term Human Trajectory Forecasting [1]. The basic code was made available by the author at this https url. We have verified all claims and results from the experiments mentioned in the paper to support the claims. The central claim of YNet is that it sets state‐of‐the‐art short and long‐term prediction standards by a multi‐modal network em‐ ploying both segmentation matrices and past trajectory heat‐maps together.","Obtaining the proposed results on the SDD and InD datasets was easy. Well‐documented interactive notebooks for training and testing along with the requisite data for SDDwere provided with the codebase. The code could be run with minimal changes overall.
Copyright © 2022 A. Shukla et al., released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Abhishek Shukla (shuklaabhishek@iitkgp.ac.in) The authors have declared that no competing interests exist. Code is available at https://github.com/Viswesh-N/MLRC-2021. – SWH swh:1:dir:3ddeeb8325dbac3f85d05e49621a9adef5f44ebb. Open peer review is available at https://openreview.net/forum?id=HV2zgpM7n0F.
ReScience C 8.2 (#37) – Shukla et al. 2022 1","The codebase and data provided by the authors were incomplete, and contained various redundancies and unused methods, making it difficult to follow. The requisite code and data required to reproduce the experiments on the ETH and UCY datasets were completelymissing. These factors were compounded by stringent computational power requirements, which were difficult to fulfill for students without access to server‐grade computation.
Communication with original authors Attempts were made to contact the authors regarding some doubts, which went without response. Running the experiments thereafter were done based on our understanding of the paper and code.
ReScience C 8.2 (#37) – Shukla et al. 2022 2
1 Introduction
The paper reproduced in this report aims to tackle multiple pedestrian trajectory pre‐ dictions using rich multi‐modal predictions for the use of autonomous vehicles, social robots, etc. Earlier approaches to this problem have been auto‐regressive in nature [3][4][5], i.e., using n points (or, analogically, data from the last t seconds) from the dataset to produce the next immediate point, and recurring this process. In this paper, the trajectory distribution, viz. the path taken by a pedestrian is conceived to have been influenced majorly by two factors:
• Epistemic: The conscious will of the pedestrian to reach a particular goal.
• Aleatoric: The unknown and unexpected changes in the environment influencing the path they take to reach the goal.
The proposed architecture incorporates this multi‐modality. An explicit probability dis‐ tribution of the many possible broad future trajectories is predicted first (modelling the where of the agent). Then, random future points of the trajectory are taken in conjunc‐ tion with the sampled way‐points to obtain probability maps over the remaining pre‐ dicted points (modelling the how of the agent). To formulate this report, we have experimented on the author’s code by adding/remov‐ ing social pooling layers and employing visualisation tools. We have tried the unique idea ofmulti‐dataset trainingwhereinwe train themodel for long on aparticular dataset, and then immediately introduce it to a completely new dataset. We also performed some experiments such as shifting the prediction origin to different previously predicted points instead of the one closest in time to the present. These experiments are explained in detail in the following sections.
2 Scope of reproducibility
The problem of multi‐modal trajectory prediction is key to unlocking vehicular intelli‐ gence and autonomous navigation. The problem this particular paper aims to address is finding pedestrian trajectories in an environment crowded with similar and/ or dif‐ ferent interacting agents. By extension, the scope of using such architecture is beyond pedestrians, as virtually any human or non‐human agent navigating crowded terrains that may benefit from segmentation may employ such mechanics of trajectory predic‐ tion. The central claims of the paper can be summarized as follows:
• Conditionedway‐point predictions: Themodel performsbetter thanpreviousworks as trajectories are conditioned in a two‐stage manner, with aleatoric predictions conditioned upon epistemic ones. This provides stricter constraints on the final set of predictions by modelling them explicitly, as opposed to SGAN [6], SoPhie [7] and other attention based mechanisms that produce a diverse set of trajectories.
• Scene Segmentation: The model performs better than contemporary models as semantic information about the scene is accounted for. The paper considers as in‐ put, both the segmentation map and trajectory heatmap of probabilities. The seg‐ mentation step is a novel addition that classifies the possible trajectory avenues of the pedestrian. Intuitively, this can be thought of as follows: Given a predicted valid goal of the pedestrian, he is highly unlikely to climb a wall to achieve it. Rather, he shall traverse his current course (say, a park track). The segmentation steps performs better than previous non‐segmented attention mechanisms.
• Long Term Prediction: The model uses these techniques to achieve significantly improved results on long horizon trajectory prediction as well as short horizon.
ReScience C 8.2 (#37) – Shukla et al. 2022 3
3 Methodology
We used the GitHub repository provided by the author as the base. However, it only contained the base model for results on the different data sets. In order to reproduce the rest of the experiments, we had to make changes accordingly.
3.1 Model descriptions The problem of multi‐modal trajectory prediction can be formulated as prediction of future trajectory given past positions of pedestrians in the scene. This section has been referenced from the original paper [1] (Section 3). The scene image is first processed by a segmentation network, producing segmentation map S (dividing the image in various classes) of the same spatial size as image. In a par‐ allel branch the past trajectories are embedded in a trajectory heatmap. Concatenation of both produces the heatmap tensorHs. For each frame n in the input, the heatmap is calculated as
H(n, i, j) = 2 ||(i, j)− un||
max(x,y)ϵI ||(x, y)− un|| (1)
The heatmap and semantic maps are concatenated and fed into the encoder branch Ue of the network. The subsequent architecture consists of 3 sub‐networks Ue , Ug and Ut. Ue which is an encoder like U‐Net [2] is used in the model architecture to process the tensorHs. It has a total ofNUe blocks, it reduces the dimensions of the H × W toHU ×WU and increases the channel depth. The final representation is termed as HUe which is then passed in the goal decoder Ug and the trajectory decoder Ut. The next step is termed as the ”Goal &Waypoint Heatmap Decoder” in which the output maps of Ue at various spatial resolutions are passed in Ug which is modelled fromU‐Net. The output is passed through a deconvolution layer, which involves the application of a transpose convolution, effectively expanding the previous feature map, spatially dou‐ bling the resolution in every block. The encoder map from the respectively sized input layer is concatenated. To attain the final resolution of the goal, heatmap feature merg‐ ing is done. Therefore, it can be said a U‐Net block consists of deconvolution, feature merging and convolution layers. The final branch Ut is termed as the ”Trajectory Heatmap Decoder”. The waypoint dis‐ tributions from Ug are sampled using the softargmax operation
softargmax(X) = ∑ i i ∑ j e Xij∑ i,j e Xij , ∑ j j ∑ i e Xij∑ i,j e Xij  Aheatmap tensorHUg is generated using these samples. Each heatmap is downsampled to its corresponding size from the architecture. These heatmaps are concatenated with the respective blocks from HUe which goes through Ut for a decoding phase.
3.2 Datasets All annotationswere preprocessed tomatch the format[’trackId’, ’frame’, ’x’, ’y’, ’sceneId’, ’metaId’]. For experiments based on varying thepredictionwin‐ dow, the data was preprocessed with different trajectory lengths.
Stanford DroneDataset (SDD): [8] The dataset by default contains annotations for 10,300 unique agents across 6 classes, of which 5232 belong to the class of pedestrians. Trajec‐ tories are sampled at FPS = 30 in 2D image coordinates. We use the pre‐processed data
ReScience C 8.2 (#37) – Shukla et al. 2022 4
provided by the authors, which has been downsampled to FPS = 2.5 for short term train‐ ing and FPS = 1 for long term. The lengths of the input sequences np are 8 and 5 respec‐ tively, while the those of the output nf are 12 and 60 respectively. All trajectories not belonging to the pedestrian class or of insufficient length (< nf + np) are dropped. The midpoints of the bounding boxes are considered to be the ground truth positions. Tra‐ jectories are split at temporal discontinuities and a staggered sliding window is used to split long trajectories. The resultant is a set of 1502 trajectories. A semantic map with 5 classes is generated. There is a train/test split of 30 scenes for training and 17 for testing.
Intersection Drone Dataset (InD): [9] The dataset by default contains 11,500 trajectories across 3 classes, in 32 scenes at 4 distinct locations. Trajectories are sampled at FPS = 25 in 2D world coordinates. We perform the preprocessing described in the paper, which involves downsampling the data to FPS = 1 for np = 5 and nf = 30, filtering out non‐ pedestrians, filtering out short (< nf + np) trajectories, splitting long (using the sliding window technique) and discontinuous trajectories. The coordinates are brought into image coordinates by using the scale factors and cropping parameters provided in the paper as cited. The resultant is a set of 1396 trajectories. The scenes of one location (ID 4) are used for testing while those of the remaining 3 are used for training.
ETH and UCY datasets (ETH/UCY): Combined, the dataset contains trajectories for 1536 pedestrians, in 9 scenes at 5 distinct locations. Trajectories are sampled at FPS = 2.5 in 2D world coordinates. The authors claim to use preprocessed data from [6], however this is not usable on account of being normalized with unknown parameters and being in the incorrect format. We instead use preprocessed data provided by the authors in response to an issue raised on the GitHub repository. We take np = 8 and nf = 12 as per the paper. We use the homographymatrices providedwith the datasets to transform the pixels into world coordinates. A leave‐one‐out cross‐validation strategy is employed.
3.3 Hyperparameters Several hyperparameters were experimented with in this paper. Those of particular im‐ portance are the following:
• Ke: Themodel aims to produceKe possible future trajectories due to the epistemic uncertainty of final goal. This is a hyperparameter that can be tuned to find the
ReScience C 8.2 (#37) – Shukla et al. 2022 5
optimal value for any given probability map as input.
• Ka: After the end‐point prediction distribution, the path(s) taken to reach themost likely of them constitutes absolute randomness when not conditioned on aleatory factors and environmental interactions. Thus, given the goal, the model produces Ka separate predictions for path.
• T : The temperature parameter T during sampling can be visualised as a scaling factor for the generated heat‐map. It is used to control the trade‐off between di‐ versity and precision; a lower value meaning the predictions are condensed in a smaller spatial density and vice versa. Intuitively, a higher value of T should be used for long‐term predictions, but this parameter can still be tuned to gauge the power of the model.
All hyper parameters were tuned by random searches and heuristic guesses instead of brute/ grid searches or Bayesian techniques, mainly due to constraints posed by very high computational resource requirements. However, the trends in accuracy could still be predicted and reasoned as the effects of changing the values were both experimen‐ tally visible and logically explainable. These points have further been discussed in the Results and Discussions sections.
3.4 Experimental setup and code The code for this experiment is set‐up mainly in the train.py, evaluate.py and test.py Python files that import helper methods defined in python files in the utils folder. Python notebooks are given to facilitate running different parts of the code. De‐ tailed instructions about each, the presence of pre‐trainedweights and/ or pre‐processed files and other relevant information is given in the ReadMe section of the repository. The main metrics of interest are the ADE (mean L2‐norm distance between all future ground truth and predicted points) and FDE (mean L2‐norm distance between final fu‐ ture ground truth and predicted points). The accuracy of all experiments are validated with these metrics, where a lower value means a more accurate result.
3.5 Computational requirements All experimentswere run usingGoogle Colaboratory, whose back‐end has the Tesla P100 GPU. The technical specification of the GPU is that it has 3584 CUDA cores, 16GB CRAM and a 4096‐bit memory interface. The run‐times we faced on such a setup for the different experiments is quite long. For example, running the code without any ablations on the SDD dataset took roughly 10 minutes for a single epoch. Of course, this value is dependant on other hyperparameters such as batch size.
ReScience C 8.2 (#37) – Shukla et al. 2022 6
4 Results
The results we obtained are listed below. Upon comparison, we are confident that the results resemble those in the paper. However, due to the lack of extensive computational capabilities, we were forced to limit our training to a fraction of what was done in the original paper. Despite this, we have deeply analysed fitting and convergence trends and are confident that the model does at least as well as claimed, and even better in some experiments. All results were logged with ease with the WandB solution [10]. In general, extensive overview of error trends could be gauged from auto‐generated graphs, which cemented our beliefs of convergence and correctness.
4.1 Results reproducing original paper
Performance of model as compared to baselines — Our reproduced model functions better than all previous baselines, and satisfactorily close to the reults of YNet as cited in the paper.
Performance of model for different datasets of ETH/UCY: Importance of social masking — This ta‐ ble is produced separately because it addresses the importance of social masking. The paper results are with masking, while ours are without.
Turning TTST and CWS on and off — TTST and CWS are heuristics designed to improve sam‐ pling. TTST encourages clustering samples in high‐density regions by roughly thresh‐ olding and clustering the probability distribution. CWS discourages sampling erratic trajectories by assuming points to be sampled between two known points roughly divide the line segment joining them. The roughness is modelled using Gaussian distributions. We experiment with various possible state to verify their effect on error.
ReScience C 8.2 (#37) – Shukla et al. 2022 7
Hyperparameter tuning -Ka,Ke and T —
4.2 Results beyond original paper
Generalization — One of our main findings beyond the paper was the generalizing power of the model, abstracted by its potential to be used as a transfer learning model. Given that the data can be processed in a similar manner outside the domain of the actual model, we observed much‐improved results when trained for a very short time on a completely new dataset. To explore this further the idea of Fine‐tuning was explored in which once the Y‐net model was trained on Dataset A, the final weights were consid‐ ered as the pretrained weights for a new training and the model was further trained on Dataset B for very few epochs. In this way the model not only remembered the previous training features but also adapted the conditions for the new dataset. This method proved to improve the per‐ formance of the model and is computationally very inexpensive.
ReScience C 8.2 (#37) – Shukla et al. 2022 8
5 Visualisations
Some real world trajectories on actual reference images are provided below. The lines are enlarged for clarity. It can clearly be seen that the model works fantastically well in real‐life scenarios to predict trajectories. Segmentation has worked well in these cases, with no class overlap except cases when the trajectory itself goes across two different semantic classes like in figure (b).
6 Discussion
Many obstacles were faced in the reproduction of the results, particularly for students with limited access to server grade computational resources. The codebase and data had many redundancies and omissions, requiring some experiments to be recreated from scratch. Despite these challenges, our experiments achieve a satisfactory repro‐ duction of the paper. However, some discrepancies were observed. Our results on the InD dataset were significantly better than those cited in the paper. This may be due to model optimizaitons in PyTorch Lightning or fortunate random initialization of weights. The experiments on the SDD and ETH/UCY datasets were found to be consistent with the paper. The predicted trajectories represented state‐of‐the‐art accuracy, evenmore so with the TTST and CWS sampling techniques enabled. We observed enhanced accuracy with dataset dilution and marginal training on a new dataset. The long‐term prediction results were viable, viz. significantly better than contemporary models, enabling this model to be used in a real‐time prediction stack for trajectory prediction.
6.1 Further discussion on the results Table 4 confirms that the usage of TTST and CWS markedly improves the accuracy of the final results by increasing the tendency to draw samples from relevant points in the probability distribution. However, this comes at the cost of increased computational complexity.
ReScience C 8.2 (#37) – Shukla et al. 2022 9
Themodel is robust towards changes in context and hence can be extended to a wide va‐ riety of applications, as evidenced by Table 5. Good transfer performance indicates the architecture is the dominant factor in our results as opposed to extraneous factors such as sampling techniques, demonstrating its strength. This experiment also highlights the potential of transfer learning in improving neural network performance, especially for complex models like this, which reap the benefit of carrying over a dense field of features. The crux of the paper, the predictive power of the chosen multi‐modality, is succinctly demonstrated by Figure 2. We see a marked improvement in inference as we increase both Ka and Ke independently of each other. This direct relationship indicates that the approach of sequentially predicting epistemic and aleatoric distributions is signifi‐ cant, and verifies this paper’s contribution to the state‐of‐the‐art of pedestrian trajectory prediction. There are significant increases in all errors upon removing social masking and pooling as seen in table 3. This is a central claim of a paper, i.e. aleatory interactions from the surroundings are a crucial factor in determining the best path taken. Modelling themusing the segmentationResNet‐101 [15] is evidently better thanusing deterministic criteria to model these interactions.
6.2 What was easy The experiments on the SDDand InDdatasets requiredminimal effort to reproduce. The authors provide interactive Python notebooks for training and testing, along with all the requisite scripts and most of the data to run them. Due to the modularity of the code, performing the ablation study was also easy.
6.3 What was difficult There were significant challenges faced in this reproduction. Due to limited computa‐ tional resources, training the extensive CNN was problematic (mainly owing to a per‐ epoch training time of 30‐60 minutes, despite a small batch size of 4). Further, the code, data, pre‐trained weights, semantic maps, semantic models for the experiments on the ETH/UCY datasets were missing from the repository, rendering it impossible to exactly reproduce the authors’ experiments. The paper suggests preprocessed data from [6] be used, however we found it was unusable as that data had been normalized with un‐ known parameters. The preprocessing functions provided by the authors for ETH/UCY could not be used as it was not possible to fulfill some arguments. There was an error in the pre‐trained weights provided for the long term SDD experiment, which caused a tensor dimension mismatch during testing. The codebase contained some unused methods. There were some redundant parame‐ ters, for example batch_size = 4 in the yaml configuration file and BATCH_SIZE = 8 declared in the training notebooks. Some lines of code were commented‐out without documentation. These factors made it difficult to follow and debug the code.
6.4 Communication with original authors Multiple attempts to contact the authorsweremade over a 2month period. Some doubts with the paper and the absence of ETH/UCY experiments from the codebasewere raised. However, there was no response from the authors."
"['Vid Stropnik', 'Maruša Oražem']",[Re] Graph Edit Networks,10.5281/zenodo.6574701,Replication,Python,https://zenodo.org/record/6574701/files/article.pdf,machine learning network analysis graph machine learning pytorch python rescience c,https://openreview.net/forum?id=H5lOnzXhAY,https://github.com/MarusaOrazem/reproducibility_challenge,8,2,2022,"The studied paper proposes a novel output layer for graph neural networks (the graph edit network ‐ GEN). The objective of this reproduction is to assess the possibility of its re‐implementation in the Python programming language and the adherence of the provided code to the methodology, described in the source material. Additionally, we rigorously evaluate the functions used to create the synthetic data sets, on which the models are evaluated. Finally, we also pay attention to the claim that the proposed ar‐ chitecture scales well to larger graphs.","All the provided code has extensive documentationwhichmade the paper’s experiments easy to reproduce. The entire code base is readable, modular and adheres to established practices on code readability. The authors also provide some unit tests for all of their models and have pre‐implemented several useful diagnostic measures.
Copyright © 2022 V. Stropnik and M. Oražem, released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Vid Stropnik (vs2658@student.uni-lj.si) The authors have declared that no competing interests exist. Code is available at https://github.com/MarusaOrazem/reproducibility_challenge – DOI 10.5281/zenodo.6505384. – SWH swh:1:dir:a48bde44f1ef0b6f060687ea7b8b164a97b0931e. Open peer review is available at https://openreview.net/forum?id=H5lOnzXhAY.
ReScience C 8.2 (#38) – Stropnik and Oražem 2022 1","Running some of the provided code on a consumer‐grade laptop (as reported in the original work) was prohibitively expensive. The lack of transparency about the code base’s runtimes made our work here much more difficult. Another time‐consuming task was the debugging of a section of author‐provided code. We’ve helped the authors identify the problem, which has now been resolved.
Communication with original authors The authors were prompt with their responses, welcomed our efforts in reproducing their work and made themselves available for any questions. Upon our request, they happily provided additional implementations, not originally available in their reposi‐ tory, and offered their counter‐arguments to some methodological concerns that we expressed to them.
1 Introduction
The studied paper proposes a novel output layer for graph neural networks (GNNs), the graph edit network (GEN). This layer yields a sequence of graph edits δ . Particularly, the graph edit schema considered in the work is the one initially proposed in [1], describing notions of node insertions (insx), deletions (delx) and replacements (repli,x), as well as edge insertions (einsi,j) and deletions (edeli,j). Note that the subscripts x in node edits refer to the attributes of the edited node (in repli,x, the additional subscript i denotes the to‐be replaced attributes), and i, j in the edge edits refer to the indices of nodes between which the edited edge can be found. These finite sequences of edits, also referred to as edit scripts δ̄t = [δ1t , δ2t , . . . , δnt ], are general enough to describe any graph‐to‐graph transformation and are not only very interpretable for humans, but also computationally efficient. Both of these properties establish GENs as a useful tool for work in the domain of graph time series prediction. More particularly, GENs perform time series prediction under the Markovian assump‐ tion, which states that knowing the graphGt and themapping functionψt, derived from the edit script δ̄t, is sufficient for predicting the graph found in the next step of the time series as
Gt+1 = ψt(Gt); ψt := δ 1 t ◦ δ2t ◦ · · · ◦ δnt ; ∀δit ∈ δ̄t,
where the subscript t denotes the time‐dependant index in the time series.
2 Scope of Reproducibility
The authors of the reproduced work formally prove theorems, stating that finding a mapping ψ between pairs of time‐adjacent graphs is sufficient for constructing train‐ ing data for GENs. They propose that their GNN architecture be trained to reproduce specific teaching signals for this function ψ, which may be derived from any gathered training time series of graphs. This is done by first finding reference pair mappings ψt : Gt → δ̄t(Gt) ≡ Gt → Gt+1 from the training series via graph edit distance approxi‐ mators1, and then computing teaching signals via an algorithm, provided in the paper’s supplementary material. The authors empirically underpin this corollary by showing that the GEN performs well in a series of graph time‐series prediction tests. They define several data generating
1Approximation is used due to the NP‐hard nature of the graph edit distance in general, as shown in [2]. In practice, exploiting domain knowledge may also lead to sensible mappings ψt. As an example of domain knowledge exploitation, the authors cite [3].
ReScience C 8.2 (#38) – Stropnik and Oražem 2022 2
processes (DGPs), from which the GEN attempts to learn the user‐defined functions ψ, which remain hidden to the algorithm. The tests can be roughly split into three classes, which have corresponding experiments in section 4. The explicit conclusions of the experimental subsection of the original paper are that the GENoutperforms the selected baselines in all of the observed tasks. In our work, we compare the GEN to one of the baselines ‐ themodified version of Varia‐ tional graph autoencoders (VGAE). As in the original work, we observe amodification of the method, suggested by [4], where the method attempts to directly infer the the graph in the next step of the time series. In the other experiments, we interpret claims about GEN’s performance on different datasets directly. Since the graphs, generated by the author‐defined DGPs, are of a completely synthetic nature and very limited in scale, the authors also attempt to establish that GENs scale well to real‐world networks. In their experimentation, they only pay attention to the scaling efficiency of the architecture and not to the quality of the predictions themselves. From the described conclusions, we identify the following claims, made in the experi‐ mental section of the paper, that we will be exploring:
Claim (i): GENs, trained with either hinge or crossentropy loss, outperform the mod‐ ified VGAE on all three dynamical graph system DGPs.
Claim (ii): GENs, trainedwith user defined losses, achieve a perfect accuracy score on both dynamical tree DGPs.
Claim (iii): The runtime of forward passes of a GEN, trained on the social network dataset (with orwithout edgefiltering), scales sub‐quadratically as thenum‐ ber of nodes in a graph increases.
Claim (iv): The runtime of backward passes of a GEN, trained on the social network dataset with edge filtering, scales approximately linearly, as the number of nodes in a graph increases.
An additional contribution of our work is the thorough study and description of the synthetic datasets, used to evaluate the GENs performance. We pay special attention to this part of the paper, as they were not exhaustively described in the original work. This examination helps us shed light on the performance of the GEN in the discussion section and evaluate the suitability of the used exprimental approachs. It also provides a more in‐depth descriptive resource to other researchers in the field, that might find these DGPs useful for their own work.
3 Methodology
Throughout our reproduction attempt, we have made great use of the code, provided in a supplementary repository to the original paper [5]. To replicate the author’s ex‐ perimental environment, we try to make the same assumptions and hyperparameter choices than those provided either in the original paper, or the documentation of the supplementary repository. A fork of this repository with our changes and additions is available at [6].
3.1 Model descriptions In the first class of experiments, we train 2 GEN models, one using the adapted cross‐ entropy loss (GEN‐XE) and the other using the adapted hinge loss (GEN), described in the paper. Both models are parametrized by their input, output and hidden dimension‐ alities, as well as their used nonlinearities. Given the short edit scripts expected in these scenarios, no edge filtering is used in these models.
ReScience C 8.2 (#38) – Stropnik and Oražem 2022 3
We also train the Variational Graph autoencoder model, as described in [7]. Apart from its input, output and hidden dimensionalities, it is also parametrized by the size of its encoding space, the regularization strength β and a scaling factor for the noise on the last layer node features σ. It also takes a hyperparametric definition of the used nonlin‐ earity. The GENmodels used in the experiments, governed by the Peano addition and Boolean formulae DGPs, are similar to those in the Dynamical graph systems class. The models here, however, use an author‐defined loss function, with respect to a custom teaching protocol, with only a single predictive step between graphs. Similarly to before, no edge filtering is used. In the experiments on the social network dataset, we train two variations of the GEN model. The first sets up two binary classifiers for each node to decide whether to con‐ sider changing outgoing/incoming edges or not. This approach is denoted in the results as flexible edge filtering. The secondmodel limits the number of permitted edge editswith a fixed upper bound ‐ this is denoted as fixed edge filtering. The models use a simplified single‐step teaching protocol, over which its loss function is defined. In the protocol, all edits, except for node insertion, are processed as expected. For insertion, however, the protocol lets a given node n insert a neighbor n′ when there is at least one edge (n, n’) found in Gt+1, where n′ is not a node found in Gt. The authors acknowledge potential shortcomings of this method, but cite the desire of using a single‐step protocol as the reason for choosing it.
3.2 Data The paper contains three classes of experiments. The first two use user created DGPs, whereas the last one works with an external, well established social network. We de‐ scribe the dataset and DGPs in accordance to the class of experiments they correspond to, in the following subsections.
Dynamical graph systems — The Dynamical graph systems class of DGPs governs the train and test set generation in Experiments 4.1.1, 4.2.1 and 4.2.2. The class contains three discrete processes, provided in the supplementary repository in the form of scripts for the python programming language. During training/testing time, the time series gen‐ erator function is called, always returning a sequence of graphs based on DGP‐specific function arguments. The Edit Cycles DGP always yields one of three author specified cyclical time series, the outputs only differing in length and the starting time index. The edit script δ̄t between two graphs is always of cardinality |δ̄| ≤ 2 and all possible generated graphs consist of between two and four nodes. The cyclical series that the DGP yields are visualized in Figure 1. The Degree Rules data generating function generates a series of a determined length using the edit rules, described in Algorithm 1. The generator function accepts param‐ eters, corresponding to the series length and the number of nodes in the initial graph G0. G0’s adjacency matrix is then randomly initialized. Consequentially, given a fixed time series length, the returned series is fully dependant on the random initialization of G0, as the rules are deterministic. In the examples in section 4.1, as per the author’s
ReScience C 8.2 (#38) – Stropnik and Oražem 2022 4
source code, the randomization fromNumPy’s random.rand is used, and all series’ ini‐ tial graphs G0 start with exactly 8 nodes. We comment on this choice of randomization and provide our alternative in Section 4.2. The third and final DGP in this class is inspired by Conway’s Game of Life [8]. Similarly to Degree Rules, it takes an input graph and applies a graph‐to‐graph mapping function. This one is specified by Algorithm 2 and is used to create a time‐series of a specified length. This function is also deterministic. In the resulting graphs, the nodes consid‐ ered alive in the Game of Life rule set are denoted with the feature value xn = 1. In contrast to degree rules, Game of Life graphs retain their number of nodes throughout evolution, as the graph will always denote theD ×D grid with the neighborhood struc‐ turemodeling a nodes’ 8‐neighborhood, and only the nodes’ alive/dead state will change. In each time series, a number of random Game of Life oscilators (randomly chosen be‐ tween 5 candidates) is chosen and made alive. Afterwards, each still dead cell will be made alive with a probability Pr(repl0,1(n)) = p. In the experiments in section 4.1, we report results using the parameters p = 0.1, D = 10, and always placing a single oscillator on the grid at initialization.
Tree dynamical systems — The Tree dynamical systems class of DGPs governs the train and test set generation in Experiments 4.1.2 and 4.2.3. It contains two distinct processes. They are distinguished from the DGP class in the previous section because they both generate strictly tree‐structured graphs, with no loops. Furthermore, they both include more complex node attribute encodings in the form of one‐hot vectors. The initial graph in a series, generated by the Boolean Formulae generator function, corresponds to a random Boolean formula. The time series following such a G0 rep‐ resents gradual simplifications of the formula, ending with a logic graph that can not be simplified any longer. An example evolution is given in Figure 2 for the formula (x ∨ (y ∧ ¬y)) ∨ x. The initial trees are generated via a stochastic regular tree grammar with a Pr(∧) = Pr(∨) = 0.3 and Pr(x) = Pr(¬x) = Pr(y) = Pr(¬y) = 0.1. The generator functions also offer a hyperparametric maximal number of applied rules p, where the authors use p = 3 in the original experiments.
Algorithm 1 The Gt → Gt+1 mapping for the Degree rules DGP. The function shareN returns true if the nodes share at least one neighbor. Input: Graph Gt, containing nodes n. 1: for each component C ∈ Gt do 2: for each n ∈ C do 3: d← degree(n) 4: if d ≥ 3 then del(n) 5: else if ∃n′ ∈ C : shareN(n, n′) then 6: for each n′ ∈ C : shareN(n, n′) do 7: eins(n, n′) 8: else ins1(n∗), eins(n, n∗)
ReScience C 8.2 (#38) – Stropnik and Oražem 2022 5
Algorithm 2 The Gt → Gt+1 mapping for the Game of Life DGP. The AliveDegree function returns the number of neighboring nodes n′ with the attribute xn′ = 1. Input: Graph Gt, containing nodes n. 1: for each n ∈ Gt do 2: d← AliveDegree(n) 3: if (xn == 1) and (d < 2 or 4 ≤ d) then 4: repl1,0(n) 5: else if (xn == 0) and (d == 3) then 6: repl0,1(n)
ThePeano additionDGPmodels Peano’s recursive definition of addition. The operations are encoded similarly as in the Boolean formulae DGP, where both the operands and the arguments are represented as nodes in the dynamical tree graph.The initial graph gen‐ erator function receives an argument, specifying the maximal number n of additions. The authors use n = 3 in their experiments. Peano’s addition rules simplify into four edit rules, the edit scripts of which are all upper bound as |δ̄| ≤ 3. The node attributes appearing in the set are the 10 digit values, the summation operation +(m,n) = m+ n and the successor operation succ(m) = m+ 1. The author‐reported numbers of possible graphs, appearing in the time series, resultant from the five described DGPs, is tabulated in Table 1. Note, however, that not all of these graphs can be sampled as the initial graphs G0 in a given series and that the mappings ψ : Gt → Gt+1 are deterministic in all DGPs. Hence, the actual number of unique pairs (Gt, Gt+1) is much lower.
Real-world social network — For the final class of experiments, the arXiv HEP‐Th citation network data set, first described in [9], is used. It describes a graph, parsed from the e‐print arXiv and covers all mutual citations within a set of 27,700 papers. In it, a pa‐ per x, that cites paper y is connected with it with an outgoing edge. From this network, the authors parse sub‐graphs with a rolling window approach ‐ considering only papers published within τ months of a given time point between January 1993 to April 2003. The number of nodes naturally grows with τ, so the result is a collection of graphs with different orders of node‐count magnitude. In the presented experiment, these 1554 dis‐ covered sub‐graphs of node count NG ∈ [100, 2786] are assumed as undirected.
3.3 Hyperparameters For all the GNN‐based models in the first two classes of experiments, the authors use two hidden layers with 64 neurons each. As far as the architecture specification is con‐ cerned, the GENs use summation as the aggregation function and concatenation as the merge function. All networks are trained with the Adam optimizer using the learning rate of 10−3. The weight decay is set to 10−5 in the graph dynamical systems class of experiments and to 10−3 in the dynamical tree class of experiments. The results for the VGAE model are reported using β = 10−3, γ = 10−3. The dimen‐ sionality of its embedding space is always equal to the size of the last hidden layer, so 64. As per the provided code by the authors, all models use the sigmoid nonlinearity
ReScience C 8.2 (#38) – Stropnik and Oražem 2022 6
in the experiment on the Game of Life dataset, whereas we employ ReLU for all other experiments on synthetic data. In the experiments reported in section 4.1, both the training and the testing time series are sampled independently from their corresponding DGP, without special assertions of training and testing set discrepancy. All models train on 30,000 series, whereas the testing results are reported for 10 samples. We comment on the authors’ methods of risk estimation and provide alternatives for these parameters in section 4.2. For the experiments on the social network dataset, a 3‐hidden layer architecture with the tanh nonlinearity, and PyTorch’s default learning rate and weight decay are used.
3.4 Experimental setup and code In our experiments, we use the metrics of precision and recall to evaluate the perfor‐ mance on insertion and deletion tasks. The experiments done on Tree dynamical systems use the notion of accuracy, which is an indicator function, defined at the value 1 when the nodes in the two input graphs match in all their features, and their adjacency matri‐ ces are identical. The reported accuracy is the average value of these indicator functions across all graph pairs in all time‐series in the test set. The experiments in section 4.1 were run in a loop across an entire class of DGPs, with 5 repetitions being ran for each consideredmodel. In the training phase, a time serieswas independently generated on each epoch using its corresponding generator function. As per the original paper, the considered stopping criterion was a rolling 10‐epoch average stop loss. Upon finishing training, the model was evaluated on time series, generated by the same generator functions as during training. We recognized this method of risk estimation as potentially problematic, given that there is no special care taken to ensure the discrepancy of the tranining and testing sets. It is for this reason that we change the used approach in some experiments, reported in section 4.2. In them, we sample our test set of graphs GTest0 ahead of time, and ensure that at each sampled training time series, the function ψ : GTest0 → GTest1 , ∀ GTest0 ∈ T remains hidden from the algorithm.
3.5 Computational requirements All experimentation was done on a desktop machine, running Windows 11, powered by an AMD Ryzen 7 2700X processor and 32 GB of RAM. The code was evaluated locally, in an environment, based on Python 3.8. The code base provided by the authors is depen‐ dant on the NumPy, PyTorch, PyTorch Geometric, Edist [10] and MatPlotLib packages. One repetition of running all three considered models on all three Graph dynamical systems (together) takes 90 minutes on average, with the VGAE taking the bulk of time to train, as the hinge‐loss GEN usually hits the stop loss threshold and stops training earlier. A single repetition of the experiment on the Peano addition DGP takes approxi‐ mately 15 minutes, whereas one over the Boolean formulae experiment takes 1 minute. On average, 60 minutes required to compute a full pass over all 12 months on the So‐ cial network experiment, for both edit schemas together. Working only with the largest graphs, i.e. τ = 12, takes 8 minutes on average.
4 Experiments
Our results confirm the authors’ findings from claims (i) ‐ (iii) when considering the results of the strict reproduction. We find that the scaling of the backward passes from claim (iv) is not linear, but remains sub‐quadratic. However, we show that these results are achieved by an architecture that is not able to optimize its loss function successfully. Our additional experiments in Subsection 4.2 show that the experimental results are stable for different choices of the initial graphG0. The results also stand formore robust
ReScience C 8.2 (#38) – Stropnik and Oražem 2022 7
method of risk estimation. From these additional experiments, we derive important insights about the testing scenarios, presented in Section 5.
4.1 Experiments reproducing original paper
Precision/Recall on Dynamical Graph System DGPs — In this task, we aimed to reproduce the results, stated in Claim (i) in Section 2. For almost all the metrics, we were able to repro‐ duce the values originally reported in the paper, with the difference δ := (our results− reported results) within a standard deviation of 0. The only major discrepancy we no‐ ticedwas an increase inmeandeletionprecision and insertion recall for theVGAEmodel in the edit cycle task, when comparing to the results, reported in the original paper. However, both GEN models still outperformed the VGAE, which supports Claim (i).
Accuracy on Tree dynamical system DGPs — In this task, we address Claim (ii) from Section 2. In the original paper, the authors reported a 100% accuracy for both Tree dynamical system scenarios. While our results returned an accuracy of 0.98 ± 0.02 in the Boolean Formulae task (and a perfect score for Peano addition), we can conclude that these re‐ sults are convincing enough to support Claim (ii).
Scaling of GENs on bigger graphs — This experiment addresss claims (iii) and (iv) from Sec‐ tion 2. In the original paper, the authors claim thatGENswere able to scale sub‐quadratically in their forward passes and approximately linearly in their backward passes, whenusing appropriate edge filtering approaches. Figure 3 shows scatter plots of the runtime‐graph scale dependency on a log‐log scale. Notice, that the runtime duration of the backward passes with constant edge filtering is very unstable, when compared to other scenar‐ ios. This is likely due to a higher difference in the fraction of considered edges, when compared to the flexible filtering approach. The scaling coefficients of the fitted linear models are further tabulated in Table 2. These results support Claim (iii) in that the for‐ ward passes scale sub‐quadratically. However, the lower of the two average coefficients for computing the gradient (the flexible approach) is still substantially larger than one. This indicates an exponential, albeit sub‐quadratic scaling of the backward passes. We conclude that these results do not support Claim (iv).
4.2 Experiments beyond original paper
Established methods of random graph generation — It is a common practice in the social net‐ work analysis (SNA) community to, when initializing random graphs, use specific meth‐
ReScience C 8.2 (#38) – Stropnik and Oražem 2022 8
ods of graph generation. Namely, if we want to make general statements about SNA methods, inferred fromexperiments on randomgraphs, these should be similar to those that tend to appear in nature. At the very least, it is considered a good practice to use established randomization methods, to more easily compare to results in other publica‐ tions. In this experiment, we repeat the methods from experiment 4.1.1 on the Degree rules DGP. However, instead of randomly initializing the adjecency matrix, we use two established methods of random graph generation: the Erdős–Rényi model [11] and the Configuration graph model [12]. In our experiment, graphs G0 were always initialized with 36 nodes in both models. We set the edge creation probability in the Erdős‐Renyi model p = 0.5 and the degree sequence of the Configuration model follows a random power‐law sequence with the exponent γ = 3. Allmetrics on thesenewly generated randomgraphs remained in the 0.05‐neighborhood of the originally reported results. We conclude that the performed experiments are ro‐ bust to different methods of random graph generation, and that the change in graph generation does not disprove Claim (i).
Alternative methods of risk estimation - Dynamical graph systems — As established above, no special care is taken to ensure the discrepancy between the training and testing set of time‐series in the original results. In this experiment, we re‐run experiments 4.1.1 and 4.1.2 with our changed method of risk assessment, described in Section 3.4. We also raise the cardinality of testing set to 100, attempting to achieve stable results. We analyze our results by comparing several repetitions of the new experiment with the reported values. As a diagnostic tool, we employed the automatic plotting of δ‐boxplots. An exam‐ ple of such a plot ‐ describing the testing scenario where the discrepancy between the reported results and our experiments was the largest, is provided in 4. Notice that, while our change in the experimental setup did contribute to slightly worse metric scores, these changes are still minimal (δ ∈ [−0.1, 0.05] for all observed testing scenarios). Con‐ sequentially, we conclude that the experimental results are robust for ourmethod of risk estimation. Other diagnostic boxplots are available in the supplementary repository [6]. The insights of Figure 4 should not be interpreted as solely positive, as we discuss in Section 5.
Alternative methods of risk estimation - Dynamical tree systems — For the Peano addition and Boolean Formulae DGPs, we attempted to employ a similar sampling restriction for training series generation, as described above. During sampling, however, we noticed that our described methodology failed to sample a sufficient amount of training exam‐ ples. Our troubleshooting lead us towards the realization, that these DGPs were very
ReScience C 8.2 (#38) – Stropnik and Oražem 2022 9
prone to generating trees that could not be simplified any further, which meant that no mapping pairs (G0, G1) could be generated from such a sample. Our diagnostic results in Figure 5 show the overwhelming majority of samples being part of this group, which casts doubt on the claims,made in 1. We evaluated the empirical probability of a unique, simplifyable tree G0, being sampled from a DGP. Our results show that the Boolean ad‐ dition DGP sampled such a treewith probability PrBoolean = 0.13±0.003, while the Peano addition DGP performed at PrPeano = 0.26±0.002. These results are derived over 300,000 DGP samples with uniformly distributed hyperparametric values of maximal permited operations p ∈ [3, 5], with 3 repetitions. In an attempt to evaluate the performance of the GEN on this family of data, we loosen our restrictions, set in Subsection 3.4. Instead, we run 5 repetitions of training, with holdout estimation (|Test set| = 100) on the time series, generated by the unique graphs G0, described in the previous paragraph. In this setup, the results were not perfect, but remained in the ±0.05 standard‐deviation‐neighborhood of the reported results.
Performance on the social network dataset — The authors use the social network data set only to evaluate the scaling capabili‐ ties of the GEN, but do not offer any in‐ formation on themodel’s performance on the set.2 Since the model’s scaling may be dependant on specific model param‐ eters (specifically, the used user‐defined loss function), we examine if the model is capable of training using gradient de‐ scent in this experiment. We visualize the loss curves of training the model over 1554 iterations (one pass of each available graph in Figure 6, with all hyper parameters similar to the origi‐ nal experiment, and using the Adam op‐ timizer. We see that the model, imple‐ mented in the scenario, does not optimize its loss function successfully.
5 Discussion
Our experimental results conclusively show that most of the claims in the original work hold. It is imperative, however, to discuss the choice of DGPs on which the model was evaluated to achieve these results. Consider, for example, the Game of Life DGP, used for evaluating the precision and recall of the test set. While at first glance, a perfect re‐ sult on a relatively involved system might be impressive, we must recall that node/edge edits and insertions should never appear in an edit script δ̄ between two Game of life graphs, as the only changes in the systems correspond to replication edits. Consequen‐ tially, the system in the scenario is only asked to output without any addition or inser‐ tion edits. Since experiment 4.2.1 showed that this output does not always appear, this casts a doubt over the model’s expressive power. Another example of a somewhat poor test setup is the Edit Cycles DGP, in which the network will always test on transitions ψ, to which it was already introduce during training, given that the series are cyclical and Markovian. Adding to this, it is very likely that, due to the nature of the problem
2This concern was also raised to the authors during the paper’s submis‐ sion and review process by AnonReviewer4. See the section Weak points in: https://openreview.net/forum?id=dlEJsyHGeaL&noteId=Sg922s85khx
ReScience C 8.2 (#38) – Stropnik and Oražem 2022 10
they describe, the mappings ψ, inferred from the Peano addition and Degree formulae DGPs, are often seen during training. We support this claim with our description of the sampling problems we encountered in Experiment 4.2.2. Our experimental results on the arXiv citation network show that the network’s runtimes are subquadratically dependant on the number of nodes in the given graph. This par‐ tially corroborates the authors’ claims. However, we note that these results are achieved by an architecture, that is not able to optimize its loss function correctly. Given that the loss cumulative loss increases with τ (as one would expect), we hypothesize that this performance is not a result of a simple syntactical error in the author‐defined loss func‐ tion. While this additional insight does not disprove Claim (iii), we note that a different, better performing loss function, might. We propose that th weakneseses we higlighted here be considered in future work, We believe that a more in‐depth and practical experimental evaluation of an otherwise ele‐ gant and interpretable solution could greatly benefit the machine learning community in the years to come.
5.1 What was easy All the provided code has extensive and clear documentationwhichmade the paper’s ex‐ periments easy to reproduce. The entire code base is readable, verymodular, adheres to established practices on code readability, and goes hand‐in‐handwith the nomenclature of the paper. While the presented implementations do require intermediate familiarity with common PyTorch constructs, the authors do admirable work in explaining every‐ thing else as‐they‐go, almost always without using unnecessary dependencies or need‐ lessly referencing the reader elsewhere. The authors also provide amoderate amount of clearly written unit tests for all of their models and have already pre‐implemented sev‐ eral diagnostic measures, such as execution runtime logging, repetition handling and plotting of training curves, which made our work a lot easier.
5.2 What was difficult Even with the extensive supplementary material, we believe that it would have been very difficult to reproduce the exact implementation of GEN and the presented DGPs by reading the paper alone, as we’ve discovered many important details from the supple‐ mentary documentation. In the paper, the authors state that all experimentswere run on a consumer‐grade laptop. While this may be the case, running some of the provided code is prohibitively time consuming to run on such a machine. For example, we were not able to finish a single pairwise distance calculation in a day’s worth of computing time (and have thus not reported on the results of that method here) on the kernel‐based baseline from [13]. The lack of transparency about the code base’s runtimes made our work here much more difficult. The original paper also uses a direct implementation of the [4] as a baseline for exper‐ iments, relating to Claim (i). This model was not provided in the repository at the be‐ ginning of our work. The authors later provided us with the implementation, which encountered runtime errors. Even though the model now works, the trouble‐shooting of this part of the code was especially time‐consuming. The author’s repository also lacks a hierarchical structure of related items. While the purpose of every file is clearly explained, our reproduction would have been easier with some reorganization.
5.3 Communication with original authors We contacted Mr. Paaßen, along with his colleagues to inform them about our efforts to reproduce their work inmid‐January. He was prompt with his responses, welcomed our
ReScience C 8.2 (#38) – Stropnik and Oražem 2022 11
work and made himself available for any questions. Upon our request, he forwarded the code with which the authors evaluated a baseline, reported in the paper, but not available in the repository. Upon our discovering of its aforementioned problems, he was prompt to offer solutions and sent us an adapted file in a couple of days. He let us know that the authors plan to update the repository with this working file shortly, which we see as an aditional benefit of our effort reproducing this article. When asked about their method of risk estimation, the author argued that the combi‐ natorial explosion of possible starting states makes it unlikely that GEN just memorizes the training data without generalization. For the case of the Edit Cycles dataset, where this obviously has to happen, since there is no underlying ground‐truth function ψ, he offered the insight that generalization was not the main aim of the inclusion of this dataset. Rather, it was intended to test the expresiveness of the edits, as memoriztation alone does not suffice to solve the task of mapping Gt → Gt+1. Summing up, we greatly appreciate the authors’ responses and their general attitude towards their work being reproduced as a part of this challenge."
"['Maša Kljun', 'Matija Teršek', 'Domen Vreš']",[Re] Learning to count everything,10.5281/zenodo.6574703,Replication,Python,https://zenodo.org/record/6574703/files/article.pdf,few-shot learning few-shot counting CNN counting data set rescience c machine learning python,https://openreview.net/forum?id=HKbgd3zmh0t,https://github.com/tersekmatija/re-LearningToCountEverything,8,2,2022,"The core finding of the paper is a novel architecture FamNet for handling the few‐shot counting task. We examine its implementation in the provided code on GitHub and compare it to the theory in the original paper. The authors also introduce a data set with 147 visual categories FSC‐147, which we analyze. We try to reproduce the authors’ results on it and on CARPK data set. Additionally, we test FamNet on a category specific data set JHU‐CROWD++. Furthermore, we try to reproduce the ground truth density maps, the code for which is not provided by the authors.","Running the pretrained models and the demo app was quite easy, as the authors pro‐ vided instructions. It was also easy to reproduce the results on a given data set with a pretrained model.
Copyright © 2022 M. Kljun, M. Teršek and D. Vreš, released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Domen Vreš (dv6968@student.uni-lj.si) The authors have declared that no competing interests exist. Code is available at https://github.com/tersekmatija/re-LearningToCountEverything – DOI 10.5281/zenodo.6508260. – SWH swh:1:dir:cf19f5a717c777cd1097e938ef4e6bdb735f71c7. Data is available at https://drive.google.com/file/d/1ymDYrGs9DSRicfZbSCDiOu0ikGDh5k6S/view?usp=sharing. Open peer review is available at https://openreview.net/forum?id=HKbgd3zmh0t.
ReScience C 8.2 (#39) – Kljun, Teršek and Vreš 2022 1","It was difficult to verify the ground truth density map generation as the code was not provided and the process was incorrectly described. Obtaining a performant GPU was also quite a challenge and it took quite many emails to finally get one. This also meant that we were unable to reproduce the training of the model.
Communication with original authors We contacted the authors three times through issues on GitHub. They were helpful and responsive, but we have not resolved all of the issues.
ReScience C 8.2 (#39) – Kljun, Teršek and Vreš 2022 2
2 Introduction
Counting objects in a scene is a task that is very simple and intuitive for humans, how‐ ever, the problem arises when there are hundreds, thousands, or even more objects in one scene as the counting becomes difficult or impossible. Yet, sometimes it is bene‐ ficial to have a count estimation of such big amounts of objects and that is why many approaches for counting objects have been proposed. These methods can easily outper‐ form humans, especially when there are many objects in a scene. Still, the advantage of humans is that we are able to count objects from the majority of visual categories with ease, which is not the case with the current object counting methods. In fact, the counting approaches that have been proposed until now can usually handle only one visual category at the time, and even those categories are mostly limited to a few, most frequently humans [1, 2, 3, 4, 5], vehicles [6, 7, 8, 9, 10], and animals [11, 12]. The reason behind these limitations in the currently proposed approaches is twofold. The major‐ ity of counting approaches requires dot annotations for thousands of objects on few thousands of training images. The second reason is that there exists no large enough unconstrained data set, which would allow the development of a method for counting any visual category. Both of these limitations exist as dot annotation and development of a large enough data is a laborious and a costly task. In this reportwe try to reproduce the paper Learning toCount Everything [13], inwhich the authors try to overcome both of the abovementioned limitations. Instead of mimicking the previousworks and treating counting as a fully supervised regression task, they pose counting as a few shot regression task. This approach is generalizable as only an input image with a few exemplars from the same image (that represent the object of interest) is required to achieve generalization to a completely novel visual category class. Second, the authors of this paper also address the lack of data sets with many visual categories as they introduce a data set including more than 6000 images from 147 visual categories.
3 Scope of reproducibility
The authors are interested in counting everything and they achieve that by posing count‐ ing as a few‐shot regression task. The core finding of the paper is a novel architecture called FamNet that handles a few‐shot counting task together with a novel adaptation strategy that adapts the network to any novel visual category at test time, by using only a few exemplar objects from the novel category. Furthermore, the authors introduce a data set containing 147 different visual categories and they show that their method out‐ performs other state‐of‐the‐art approaches – object detectors as well as few‐shot count‐ ing approaches. We test these key findings from the paper:
• FamNet outperforms other few‐shot approaches when it comes to object counting.
• FamNet performs well even on a category‐specific data set.
• Increasing the number of exemplars decreases FamNet’s error.
4 Methodology
Where available, we use the authors’ code from GitHub. We modify it so that we can evaluate the model on different data sets. Additionally, we prepare our scripts for gen‐ erating ground truth density maps, ablation study, and preprocessing of CARPK data set, as the authors do not provide it.
ReScience C 8.2 (#39) – Kljun, Teršek and Vreš 2022 3
4.1 Model descriptions FamNet is composed of two main modules – a multi‐scale feature extraction module and a density prediction module. The multi‐scale feature extraction module is based on the ImageNet pretrained network, more specifically on the first four blocks from a pretrained ResNet‐50 backbone. From the code, we find out that the authors use the pre‐ trained ResNet‐50 model from TorchVision. The density prediction module is designed in a way to be agnostic to the visual categories. They achieve this by not feeding the features obtained from the feature extraction module directly. Contrary, they rather use the correlation map between the exemplar features and image features as the in‐ put to the density prediction module. We show a visualization of inputs to the density prediction module in Appendix 7. As mentioned, the proposed FamNet can adapt to a new visual category once trained, using only a few exemplars. To understand the novel adaptation loss that is used during test time we first quickly describe the Min‐Count and Perturbation losses. Let B denote the set of provided exemplar bounding boxes (bounding boxes denoting examples of the object, that we are counting, given to the network). For each bounding box b ∈ B, let Zb represent the crop from the density map Z at location b.
Min-Count Loss —Min‐Count Loss is defined as
LMinCount = ∑ b∈B max(0, 1− ||Zb||1). (1)
The idea behind this loss is that the sumof density valueswithinZb should be at least 1 as the predicted count is a sum of predicted density values, and there is at least one object at the location b. Meaning that if the total value of the density map in the exemplar box is equal to or greater than 1, the loss will not increase for this location, but if the total value of the density map in the exemplar box is smaller than 1, we increase the loss. By inspecting the authors’ code, however, we find out that Min‐Count loss is incorrectly implemented. Instead of using the difference between 1 and ||Zb||1, the authors use the squared difference. In notation, the implementation of Min‐Count loss in the original implementation is
L implemented MinCount = ∑ b∈B max(0, (1− ||Zb||1)2). (2)
We address the issue and test the performance of the model for both implementations in Section 5.
Perturbation Loss — Perturbation Loss is defined as
LPer = ∑ b∈B ||Zb −Gh×w||22, (3)
whereGh×w is a 2D Gaussian window of size h×w and standard deviation σG = 8. The authors do not provide the reasoning for the chosen value, so we try different options to investigate its influence. We report our findings in Section 5.2.1. This loss is inspired by the success of tracking algorithms based on correlation filter, where algorithms learn a filter that has the highest response at the location of the bounding box and lower re‐ sponse at all perturbed locations. We can look at the density map Z as the correlation response between the exemplars and the image.
Adaptation loss — The final loss, called adaptation loss, is defined as a weighted combina‐ tion
LAdapt = λ1LMinCount + λ2LPer, (4)
ReScience C 8.2 (#39) – Kljun, Teršek and Vreš 2022 4
whereLMinCount is theMin‐Count Loss, LPer is Perturbation Loss and λ1 and λ2 are scalar hyper‐parameters. The authors fine‐tuned them on validation set, and we use the same values λ1 = 10−9 and λ2 = 10−4. Note that adaptation loss is only used at test time, and MSE between predicted and ground truth density map over all pixels is used as a loss during training.
4.2 Data sets
FSC-147 — As the majority of the data sets are dedicated to a specific visual category, the authors collected and annotated 6135 images across 147 different visual categories. The average image height is 774 and the average image width is 938 pixels. In each image, all objects are dot‐annotated in an approximate center of the object. Furthermore, in a majority of cases (96.26%) three object instances are randomly selected and are addition‐ ally annotatedwith axis‐aligned bounding boxes denoting exemplar bounding boxes. In some cases four (3.45%), five (0.27%), or six (0.02%) object instances are additionally an‐ notated. The data set is divided into train, validation, and test sets in a way that each of these sets does not share any object categories. The train, validation, and test sets consist of 3659, 1286, and 1190 images, respectively. The authors provide two sets of ground truth density maps which are the same in all but two cases (3417.npy and 3477.npy). In the second set of ground truth density maps, the first image appears more blurred, while different objects are counted on the latter image (see Figure 1).
In the original paper, the authors compare FamNet to some common object detectors ‐ Faster R‐CNN [14], RetinaNet [15], and Mask R‐CNN [16], which were pretrained on COCO data set [17]. Thus they select a subset of FSC‐147, which contains categories that also appear in COCO. We manually try to find the intersecting categories and find that 17 categories appear under the same (or similar) name in both data sets. The authors in‐ clude all images from FSC‐147 from those categories in COCO‐Val and COCO‐Test splits that they provide, and do not leave out any categories that might appear in FSC‐147 and COCO.
Resizing of FSC-147 images before using FamNet — The authors provide a link to FSC‐147 data set in their GitHub repository. However, the images there are already resized as a part of preprocessing before using FamNet. The authors decided to resize all images to a fixed height of 384 pixels. They claim that they adjusted the width of the images in the way that the aspect ratio is preserved. As the authors provide the information about the original dimensions of each image, we checked, whether all processed images are correctly resized to have a height of 384 pixel and if their aspect ratio is truly preserved. We found some cases where the aspect ratio was not preserved. We showed such cases
ReScience C 8.2 (#39) – Kljun, Teršek and Vreš 2022 5
to the authors, who replied that they did not preserve the aspect ratio for images with original width of less than 384 pixels. However, the provided example with a corrupted aspect ratio did not have a width smaller than 384.
FSC-147 ground truth density map generation — The authors do not provide the code for the generation of ground truth density maps, but rather provide the already pre‐computed density maps and only describe the process. While this is beneficial, as it saves com‐ putation time, it is somewhat questionable, as we do not get a full insight into how the data set was generated, and cannot verify their claims. An issue has been opened on the authors’ GitHub, but they did not provide the code. We implemented our own code as described in the paper. We used Gaussian smoothing with adaptive window size and estimated the size of the objects from distances between dot annotations and their nearest neighbor. We averaged those distances to obtain the size of the Gaussian window sG. The authors claim that they use the sG4 as the standard deviation, however, we could not reproduce the results using this value. We obtained the closest results with sG8 (see Figure 2 for illustrative example). When we asked the authors about the issue, they suggested that large discrepancies might be due to them computing ground truth deviations on larger images, and then downscaling them to the sizes in the data set. However, we still could not reproduce the same results with the suggested approach. This question still remains open and the issue has not been resolved. Our code produces results most similar to the ground truth density maps, though displacement for some points is visible.
CARPK — The authors want to check the performance of FamNet on category specific counting task. TheyuseCARPKdata set [18], which contains around 90,000 cars recorded in various parking lots, taken with drones. The data set is already split into train and test set, and for each image ground truths in a form of bounding boxes are provided. In order to convert the data set into a form suitable for the evaluation of FamNet, we had to create the density maps that represent the ground truths, select the bounding boxes that represent the exemplars, and resize the images to have a height of 384 pixels. The authors do not provide any information about the preprocessing of that data set. We first obtained the distribution for a number of exemplars in FSC‐147 data set. We then sampled a number of exemplars n from this distribution for each image and ran‐ domly chose n bounding boxes that represent exemplars. To obtain the density maps, we represented each car by a Gaussian filter of the size of the provided bounding box. We set the σ of the filter to h+w16 in order to follow the setting of σ for FSC‐147 data set. However, we did not set the σ based on the authors’ description in the paper but based on our findings, described in Section 4.2.3.
ReScience C 8.2 (#39) – Kljun, Teršek and Vreš 2022 6
JHU-CROWD++ — Aswewant to check how the FamNet performs on a typical crowd count‐ ing data set, we extend the authors’ research and test the pretrained model on JHU‐ CROWD++ data set [19, 20]. This includes 4327 images collected under a diverse set of conditions (adverse weather, various illumination, varying densities, etc.) and 1.51mil‐ lion annotations (dots, approximate bounding boxes, etc.). We again had to do some preprocessing in order to get the data set in the format for evaluation of FamNet. We used the same preprocessing as we did for CARPK data set (see Section 4.2.4).
4.3 Hyperparameters There are several FamNet hyperparameters that have to be set. The authors set σG = 8 used in perturbation loss (see Section 4.1.2) without any explanation why. We therefore decided to check how different values of σG impact the error of the model. To select the best value of σG we used grid search. We tested every even integer value between 2 and 20 and report our findings in Section 5.2.1. We did not test λ1 and λ2 from adaptation loss (see Section 4.1.3). The authors set their values to 10−9 and 10−4, respectively. They say that setting them to such small values is necessary, so the adaptation loss has a similar magnitude to the training loss. We also did not test the number of gradient descent steps and the learning rate during the test time adaptation. The authors said that these two values were tuned along with λ1 and λ2 on the validation set.
4.4 Experimental setup and code To perform our experiments, we used the authors’ and our code. Authors’ code is avail‐ able on theirGitHub repository1. Weperformedour experiments by runningfiletest_extended.py, which is an extended version of the authors’ file test.py, with some flags formanipula‐ tion of different options. To evaluate different values ofσG, weused scriptchoose_sigma.py, which is run in a similar way as the scripts mentioned before. We also did some prepro‐ cessing and testing in our Jupyter notebooks that are self‐explanatory to run. Model is evaluated with absolute error (MAE) and root mean squared error (RMSE), de‐ fined as:
MAE = 1
n n∑ i=1 |ci − ĉi|, RMSE = √√√√ 1 n n∑ i=1 (ci − ĉi)2, (5)
where n denotes the number of instances in test/val set, ci denotes the number of se‐ lected objects on i‐th image from that set, and ĉi denotes the predicted count for that image.
4.5 Computational requirements All experiments were ran on GPU only (hence we do not report used CPU and RAM). We ran our experiments on a server with Nvidia Quadro RTX 5000 GPU. Each evaluation of FamNet on test or validation set (FSC‐147) takes around 2 minutes without the test time adaptation and around 1 hour and 40 minutes with it. The ablation study with number of exemplars takes around 3 hours (the execution times are shorter when the number of exemplars is decreased). Evaluation of FamNet on subset of categories from COCO data set takes around 40 minutes with adaptation. Evaluation of FamNet on CARPK data set (with adaptation) takes around 1 hour and 20 minutes. We spent around 50 GPU hours to run all of our experiments.
1https://github.com/cvlab-stonybrook/LearningToCountEverything
ReScience C 8.2 (#39) – Kljun, Teršek and Vreš 2022 7
5 Results
Our results support the claims of the authors about the quality of their proposed FamNet structure. We managed to reproduce their results exactly (where the code is provided) or up to the point that we can confirm that their model performs as they claim in com‐ parison with the other methods
5.1 Results reproducing original paper Wereproducedmost of the results obtainedwithFamNet onFSC‐147 andCARPKdatasets. The only exception is the ablation study with number of exemplars, where our results do not entirely support the authors’ claim.
Evaluation of FamNet on FSC-147 dataset —We managed to get the same results as the au‐ thors when testing FamNet on FSC‐147 validation and test set, which supports the claim that FamNet outperforms other tested few‐shot approaches. The results are given in Ta‐ ble 1 of the original paper. However, we did not test the few‐shot methods that FamNet is compared to.
Comparison with object detectors —We tried to reproduce the comparison of FamNet with object detectors, trained on COCO data set. The authors compare FamNet with the de‐ tectors on images from FSC‐147 data set from categories that overlap in FSC‐147 and COCO. We did not manage to reproduce the exact results obtained by the authors (Ta‐ ble 2 in their paper), but we get the results that are within the standard error of theirs or, in case of RetinaNet worse than theirs, and still support the claim that FamNet beats listed object detectors. Our results are shown in Table 1. Additionally to the authors, we report the standard error of MAE estimate, which was calculated from standard devia‐ tion. We obtained those results using TorchVision models. The authors use Detectron2 models instead, which perform worse in our experiments.
Number of exemplars ablation study —We reproduced the experiment, that tested the impact of the number of exemplars on the performance of FamNet. However, our results (see Table 2) do not entirely support the claim of the authors that increasing the number of exemplars improves the performance of the FamNet. We can see that by increasing the number of exemplars from 2 to 3, RMSE increased on both test and val set, while the MAE increased on val set and decreased on train set.
ReScience C 8.2 (#39) – Kljun, Teršek and Vreš 2022 8
Table 2. The performance of FamNet on FSC‐147 data set with respect to the number of exemplars. Columns SE show standard errors of MAE estimates.
MAE SE RMSE
MCNN 188.9 / 483.4 CSR‐Net 85.9 / 309.2
FamNet (our results) 256.9 15.0 652.5
Evaluation on a category-specific data set — The authors evaluate FamNet on a CARPK data set. We reproduced their results of FamNet trained on FSC‐147, but we did not try to reproduce the results for FamNet trained on CARPK. As the authors do not describe the used preprocessing, we did not get exactly the same results as they did. However, our results are close to theirs and still support their claim that FamNet performs well on this category‐specific data set. We got MAE 27.9 (with standard error 1.1) and RMSE 36.4, while the authors got MAE 28.8 and RMSE 44.4.
5.2 Results beyond original paper Additionally, we tested how σG (Section 4.1.2) and correction of the Min‐Count Loss affect the model’s performance, evaluated the model on another category‐specific data set, visually inspected the errors of the model and effects of test time adaptation.
Impact of σG on the error of the model — Since the authors do not provide any justification for setting σG = 8, we test how theMAE of FamNet changeswith different σG (see Figure 3). We can see that σG has practically no impact on MAE of FamNet.
Min-Count Loss correction — Sincewehavenoticed that the authors’ definition ofMin‐Count Loss differs from their implementation (see Section 4.1.1), we tested how it affects the error of the model. Our results did not show any significant difference in MAE and RMSE.
Evaluation on JHU-CROWD++ — To test the performance of FamNet on category‐specific data set even further, we evaluated it on the JHU‐CROWD++ data set (see Section 4.2.5). We use a model trained on FSC‐147. The results are shown in Table 3. We can see that FamNet performs worse than baselines. However, this data set is challenging (large number of objects, small bounding boxes) and training the model on that data set with a higher number of exemplars would likely boost the performance.
ReScience C 8.2 (#39) – Kljun, Teršek and Vreš 2022 9
Performance of the model without adaptation — Additionally, we visually inspect the images, where absolute error, normalized by the ground truth count, is the highest or the lowest. Our observations and visualisations are described in Appendix 8.
Effect of adaptation on model’s predictions — To inspect the effect of adaptation, we analysed the most positive and negative effects of adaptation on model’s performance. We de‐ scribe the results in Appendix 9.
6 Discussion
We tried to reproduce the results from the paper Learning to count everything. We ob‐ tained the same results as in the paper for some experiments. For others, our results are still close enough to the papers’. We confirmed that FamNet outperforms other few‐shot approaches when it comes to object counting and that FamNet performs well even on a category‐specific data set. Our experiments disprove the authors’ claim that increasing the number of exemplars decreases FamNet’s error. We assume that this is due to the fact that we discarded different exemplars than the authors. This might suggest that choosing correct exemplars is more important than choosing more of them.
6.1 What was easy A demo app with clear instructions helped with the understanding of the model. The model’s architecture was understandable from the code and the paper. It was easy to reproduce the results on FSC‐147 with a pretrained model.
6.2 What was difficult Reproducing the ground truth densitymapswas difficult, as the process in the paper did not lead to the paper’s results, and the code for it was not provided. We did our best to mimic the ground truth density maps. Evaluating other models for which the code was not providedwas challenging, as no parameters were given (e.g., confidence or intersect over union thresholds for object detectors). We struggled obtaining a good enough GPU. Due to lack of time, we were unable to train the model ourselves, and we delegate this to future work.
6.3 Communication with original authors We contacted the authors three times through issues on GitHub. They were helpful and responsive, but we have not resolved all of the issues."
"['Jille van der Togt', 'Lea Tiyavorabun', 'Matteo Rosati', 'Giulio Starace']",[Re] Badder Seeds: Reproducing the Evaluation of Lexical Methods for Bias Measurement,10.5281/zenodo.6574705,Replication,Python,https://zenodo.org/record/6574705/files/article.pdf,rescience c machine learning deep learning python pytorch nlp bias seeds,https://openreview.net/forum?id=HcIxA3Mm2CF,https://github.com/thesofakillers/badder-seeds,8,2,2022,"Combating bias in NLP requires bias measurement. Bias measurement is almost always achievedbyusing lexicons of seed terms, i.e. sets ofwords specifying stereotypes or dimen‐ sions of interest. This reproducibility study focuses on Antoniak and Mimno1’s main claim that the rationale for the construction of these lexicons needs thorough checking before usage, as the seeds used for bias measurement can themselves exhibit biases. The study aims to evaluate the reproducibility of the quantitative and qualitative results presented in the paper and the conclusions drawn thereof.","Once understood, the methods proposed by the authors were relatively easy to imple‐ ment. The mathematics involved is quite straightforward. Communication was also reasonably accessible. The authors’ emails were readily available, and the responses came quickly and were always helpful.
Communication with original authors Wemaintained a lengthy email correspondence throughout the replication of the paper with one author, Maria Antoniak. We contacted her to clarify extensive aspects of the paper’s methodology. Specifically, this concerned summarizing the data processing ap‐ proach, explaining missing hyperparameters, and outlining the aggregation of metrics across different bootstrapped models. None of the original code was disclosed.
ReScience C 8.2 (#40) – Togt et al. 2022 2
2 Introduction
The emergence of bias quantification in Natural Language Processing (NLP) methods has given rise to two use cases, referred to as downstream and upstream. In the former, biasmeasurements are used to debias or correct biases in word representations to avoid encoded biases trickling downwhen applying these NLPmodels [2, 3]. In the latter, bias measurements are used onmodels trained on small corpora to quantify the bias present and compare them. This use case has endowed social scientists with the quantitative foundation to answer political and social questions about bias across corpora in an em‐ pirical manner [4, 5]. Crucially, most bias quantification methods depend on lexicons of seed terms that specify the bias dimensions of interest. The selection of seed terms varies considerably across the literature, and seed sets themselves may exhibit social and cognitive biases [1]. It is not clear whether it is possible to re‐use seed set across corpora (thereby interfering with upstream use cases), and elements such as seed term frequency have been shown to affect bias measurements, and thus downstream uses [6]. We seek to replicate the Antoniak and Mimno1 paper, hereafter referred to as ”the orig‐ inal paper/work”. In it, the authors seek to 1) qualitatively explore seed selection and their sources, 2) demonstrate that features of seed sets such as pairing order, set simi‐ larity, and frequency can cause instability in bias measurements, and 3) make recom‐ mendations for the testing and justifying of seed sets in future work. We have replicated the experiments showing the fragility of seed sets, thus verifying the claims of a need for better justification and analysis of them in future literature. We have also built a public toolkit to reproduce these measures on arbitrary seed sets and trained embeddings.
3 Scope of reproducibility
This reproducibility study focuses on the authors’ main claim that seed lexicons need thorough checking before usage to measure bias, as seeds themselves can be biased and induce instabilities in measurement. The authors conducted a literature review on prior works to gather many seed sets. They subsequently evaluated the gathered seed sets with a series of bias measurement metrics proposed by Bolukbasi et al., Caliskan, Bryson, and Narayanan2,3, and themselves. Our work consists of two interconnected efforts: code replication, given the absence of pre‐existing code for the original paper, and reproducing the main results. The latter goal is the main focus of our work and entails reproducing the outcomes that support the paper’s central claims, which can be summarized as follows:
1. Bias subspaces generated from common bias subspace metrics (e.g., WEAT, PCA) can help capture the difference represented by the seed set pairs.
2. Bias subspaces suffer from instability due to the following factors:
(a) The ordering and pairing of the seed sets. (b) The selection of seeds that are members of the seed sets. (c) The degree of semantic similarity between seeds.
3. Methods of sourcing seed sets are inconsistent, with disparate strategies being used across NLP literature.
4 Methodology
The code from the original paper was not made publicly available. We, therefore, re‐ implemented the entire approach from the description in the original paper. The fol‐
ReScience C 8.2 (#40) – Togt et al. 2022 3
lowing section will summarize the resources and methodology used to reproduce the original paper accurately.
4.1 Code As mentioned above, the code from the original paper is not publicly available. We fully re‐implement all the code, which can be found on GitHub1. We closely follow the original paper’s methodology to achieve accurate reproduction. The reproduction is performed step by step, from downloading and preprocessing the data to training the models and visualizing the results.
4.2 Documentation Unfortunately, there was little to no documentation in the original work besides the content of the original paper. This occasionally lacked crucial information to reproduce the results or was vague on implementation details. In addition to the original paper, Antoniak and Mimno1 published a Github repository that contained a JSON with the metadata on seed sets gathered from prior works2.
4.3 Model descriptions We train several bootstrapped skip‐gram word2vec models with negative sampling on unigrams on each dataset. This model attempts to predict whether a particular word is a valid context (where the context window size is a hyperparameter) for a given other word using a single fully connected hidden layer. The first step in training this model is creating a vocabulary of the entire training dataset. With this vocabulary, each word can be represented as a one‐hot vector. The network output is then a measure of the probability that the word is a valid context. The trained weights from this hidden layer are then used to obtain word embedding vectors for each term in the training set vocab‐ ulary.
4.4 Datasets The original paper used four datasets and one pretrained model: New York Times ar‐ ticles from April 15th‐June 30th, 20163; high‐quality WikiText articles, using the com‐ pleteWikiText‐103 training set [7]; Goodreads book reviews for the romance and history and biography genres sampled from the UCSD book Graph [8, 9]; and the pretrained word2vec GoogleNewsmodel4. We use these same corpora for our research, preprocess‐ ing them as closely as possible to the original paper. This consists of grouping the text into documents, filtering relevant documents, lowercasing and removing special char‐ acters. We then use spaCy [10] for tokenization and POS‐tagging. Because the work is not concerned with model performance, this study makes no use of train/dev/test splits. The WikiText‐103 dataset, however, is pre‐split, so like in the original work, we work with the training split. Links to all these datasets can be found in our Github repository. Preprocessing statistics of our work and the original paper can be found in Table A.1. We find general agreement in our numbers regarding the total number of documents per dataset. There are minor discrepancies in the Goodreads datasets, most likely due to implementation differences. We also count slightly fewer total words than the origi‐ nal paper in all cases, but the orders of magnitude generally match. We are, however, unable to reproduce vocabulary size accurately. We tried many strategies in the replica‐ tion process to obtain these numbers, but none were successful. Furthermore, looking
1https://github.com/thesofakillers/badder‐seeds 2https://github.com/maria‐antoniak/bad‐seeds 3https://www.kaggle.com/nzalake52/new‐york‐times‐articles 4https://github.com/mmihaltz/word2vec‐GoogleNews‐vectors
ReScience C 8.2 (#40) – Togt et al. 2022 4
at the official dataset statistics, for example for WikiText [7], it is clear that our repro‐ duced vocabulary size is a lot closer to the ground truth than the one by Antoniak and Mimno1. Lastly, mean document length values of each dataset are accurately repro‐ duced, with the WikiText values suffering the most. The subsections below will discuss each dataset in more detail.
NewYork Times This dataset contains 165,900 paragraphs from 8,888 articles from the New York Times published between April 15th and June 30th 2016. The articles cover a broad range of sections, including but not limited to movies, sports, technology, busi‐ ness, books, science, and fashion.
WikiText‐103 This dataset contains 28,472manually verified articles fromWikipedia.org. The entire training dataset is used, in which lists, HTML errors, math, and code have already been removed. Furthermore, we removed all formulas still present in the text.
Goodreads The entire Goodreads dataset containsmillions of reviews. This study uses just the Romance and the History/Biography genres. Five hundred book reviews per book are sampled for each genrewhile filtering out all bookswith fewer than 500 reviews and all reviews containing fewer than 20 characters.
GoogleNews Google’s pretrained word2vec model is trained on ca.100 billion words from the GoogleNews dataset (4). Our use of this model was limited to replicating the results outlined below for additional robustness.
Seed Set Dataset Part of the contributions of the original workwas creating a catalogue of 178 seed sets gathered from eighteen highly‐cited prior works on bias measurements. We refer to this catalogue as the gathered seeds. Each element of the catalogue comprises a seed set, the category it represents, a justification, the source categorization, a link, and a unique ID. It is readily available on the original author’s GitHub2. A brief statistical overview can be found in Fig. A.1. We process the catalogue by lower‐casing the seeds and removing bigrams to use them with our models. We also filter seed sets containing less than two seeds as we argue that a single seed would not be sufficient to form a set.
4.5 Experimental setup and code An environment containing all necessary packages is included in the publicly available repository and can be quickly set up. To mirror the original paper’s setup, we used the gensim [11] implementation of skip‐gram with negative sampling [12] to train the vector embeddings for all datasets. We used this library to train ourmodels as that is the frame‐ work used by the original paper and to avoid noise due to different implementations (the investigation of which would be outside the scope of this paper). Several PyTorch [13] implementations are also available on GitHub if that is preferred5,6. We reproduce the original paper’s results by focusing on two popular seed‐based bias metrics to measure bias in corpus‐derived embeddings: WEAT and PCA. These met‐ rics are used to produce a bias subspace vector given a pair of seed sets that specifies a bias dimension of interest. The WEAT method, introduced in Caliskan, Bryson, and Narayanan3, produces a vector based on the difference between themean vectors of the two target sets. The PCA method, described in Bolukbasi et al.2, instead requires that each seed term in one of the seed sets be paired with one seed term from the other seed set. The subspace vector is then the first principal component resulting from the PCA
5https://github.com/theeluwin/pytorch‐sgns 6https://github.com/ddehueck/skip‐gram‐negative‐sampling
ReScience C 8.2 (#40) – Togt et al. 2022 5
of a matrix constructed by, for each pair of seeds, taking the two half vectors from the pair’s mean to the two pair members and using them as two columns of the matrix. We also reproduce the original paper’s coherence metric, which aims to quantify the robustness of the bias subspace. This metric is calculated as the absolute value of the difference in mean ranks of the terms in two seed sets when all the model’s vocabulary is ranked by cosine similarity to the bias subspace. Anothermetric used is set similarity, the cosine similarity between the average vectors of two seed sets. Finally, when aggregating embeddings of a specific word across bootstrapped models, we take the average of the embedding vectors in each model that includes the word. Given a particular pair of seed sets for coherence aggregation, we only average coher‐ ence scores for models containing every seed term in the two sets to avoid aggregating coherence based on different seed sets.
4.6 Hyperparameters 100‐dimensional embeddings were trained for five epochs on all four datasets, with a five‐word negative context sampling rate and a window size of five. We trained embed‐ dings with aminimumword count of 0, 10, and 100 due to variation in the original paper. This process was repeated for 20 bootstrapped samples of each dataset (with the sample size equal to the number of documents in the dataset), resulting in 20 separate models. The bootstrapping provided the stochasticity required for robustness. To ensure this reproducibility, we use a random seed of 42 throughout.
4.7 Computational requirements The execution of the reproduced code does not take excessive computing power. This study used no GPUs or computing clusters. We ran the experiments on an Intel I9 9900k and 32GB of 3200MHz RAM running Ubuntu 20.04.3 LTS. Table A.3 shows peak RAM usage and time in seconds to completion for every subprocess of the replication.
5 Results
5.1 Quantitative Results We started by confirming that the bias subspace does capture the difference or bias that the seed pairs are intended to represent. For this, we reproduced an experiment by An‐ toniak andMimno1 ranking the cosine similarity between the first Principal Component (PC) of the bias subspace and all words in the corpus. The top and bottom ten words for each bias subspace are shown in Fig. 1a. In the shown words of the gender pair subspace and the shuffled gender pair subspace gender‐related words are found, whereas none are present in the randompair subspace. However, only the gender pair subspace divides nicely betweenmale and female terms. We extended this by calculating the cosine similarity of the top and bottom ten words from the ordered bias subspace for the shuffled bias subspace. The results in Fig. A.2 show she and his as the two highest‐ranked words, which are not split along the intended bias subspace. Fig. 2 shows that the first PC has almost always a very high explained variance ratio for the bias subspace of ordered pairs, which drops off quickly for the subsequent PCs. Instead, the explained variance ratio per PC drops more smoothly for the shuffled pairs. Fig. A.2 shows this behavior by computing the top and bottom ten words by cosine similarity against the second PC of the gender subspace. We can observe that the bias subspace of the ordered pairs does not contain gender words anymore. In contrast, the shuffled subspace does have gender words such as her, thereby replicating the trend ob‐ served in Fig. 2. It is also important to note that in Fig. 2 there are exceptional cases where shuffled seed sets produce the first PC with a higher explained variance than the
ReScience C 8.2 (#40) – Togt et al. 2022 6
ordered seed sets. In general, these results replicate the trends of the original experi‐ ments.
Fig 3 shows that bias measurement is highly inconsistent across seed sets with the same seed category sourced from different papers. We used the cosine similarity between female seed sets and the word unpleasantness as a biasmeasurement. The cosine similarity varies greatly between seed sets, replicating the same trends as the original paper.
0.6 0.4 0.2 0.0 0.2 0.4 0.6 cosine similairty to unpleasentness
female-Kozlowski_et_al_2019
female_1-Caliskan_et_al_2017
definitional_female-Bolukbasi_et_al_2016
female_singular-Hoyle_et_al_2019
female_definition_words_2-Zhao_et_al_2018
female_stereotype_words-Zhao_et_al_2018
se ed
s et
romance history and biography
Figure 3. Reproduction of Fig. 2. Displaying the cosine similarity between the averaged vector of unpleasantness across all 20 boot‐ strapped models and different seeds sets of the category female.
Fig. 4 explores the rela‐ tionship between set sim‐ ilarity and the robust‐ ness of the bias subspace. The relationshipbetween set similarity and the ex‐ plained variance of the PCA‐derivedbias subspace vector is plotted for each dataset and frequency thresh‐ olds. The original pa‐
per shows this relation‐ ship only for the Wiki‐ Text dataset, and we find a similar negative corre‐
lation between set similarity and explained variance for that dataset. Table A.2 qualitatively explores this relationship, ranking both gathered and generated
ReScience C 8.2 (#40) – Togt et al. 2022 7
sets by coherence. More semantically dissimilar seed sets score higher in coherence than more similar sets. In the gathered sets, seed sets related to names have extremely low coherence due to their semantics being very similar and the set pairs containing duplicate terms (see ”names black” and ”names white”). In the generated sets, we see that very different terms (such as those relating to careers and those related to lower body clothing/parts) have high coherence. In contrast, sets such as food terms score much lower. We observe a similar pattern when using the PCA algorithm as a basis for coherence. These results show the replicability of the original paper, as they are almost identical.
5.2 Qualitative Results The original paper gathered 178 seed sets of eighteen highly‐cited prior work on bias measurement. These seeds are both embedding‐based and non‐embedding‐based bias detection methods, often overlapping. The seeds are chosen in a multitude of ways. Only unigram seeds are selected, and words that do not appear in the training corpus are omitted. We have validated the accuracy of Table 3 in the original paper by review‐ ing each of the eighteen papers and determining which methods the authors used. We briefly summarize them below:
Borrowed from social sciences Select seed sets are borrowed from prior psychology and other social sciences work.
Crowd‐Sourced Crowd‐based annotation can create custom seed sets. This method can aid in gathering contemporary associations and stereotypes. However, controlling crowd demographics often poses a problem. This can lead to stereotypes being hard‐ coded into the seeds.
Population‐Derived Seeds can also be derived from government‐collected population datasets. These datasets are usually names and occupations common to specific demo‐
ReScience C 8.2 (#40) – Togt et al. 2022 8
graphic groups. A significant problemwith thismethod is that the data tends to be often US‐centric and thus gives a distorted view of the rest of the world.
Adapted from Lexical Resources Researchers can also draw seeds from existing dic‐ tionaries, lexicons and other public resources. The advantage is that these seeds have already undergone a round of validation.
Corpus‐Derived This quantitativemethod is used to extract seeds terms from a corpus. It has the advantage of ensuring high‐frequency words are selected but suffers from similar risks as crowd‐sourced seeds.
Curated Seed hand‐selection by authors often yields high precision seeds but is slow and relies on unbiased authors.
Re‐used The last method relies on prior bias measurement research for seed terms. The advantage is that the seeds have already been used, but researchers should not use them without validation.
5.3 Results beyond original paper Set Similarity and Bias Subspace in Additional Datasets We extended the original pa‐ per’s set similarity versus bias subspace explained variance analysis to cover all datasets (beyondWikiText) in Fig. 4. The negative trend is still present with the NYT corpus, but not in the Goodreads corpora, where the trend is almost absent or slightly positive. In addition, the positions of the highlighted seed set pairs are variable across corpora. We also extended this work to examine the relationship between seed pair coherence versus set similarity, where the inverse relationship is present in all datasets. Notice that the requirement that coherence is calculated only for models that contain all seed terms (as described in Section 4.5) makes specific pairs of seed sets be ignored, as seen from the lack of the two highlighted set pairs for select datasets.
Testing Minimum Frequency Filter Due to inconsistencies both in the paper and in communication with the author in the reported minimum frequency filter for the skip‐ gram models, we experimented with minimum frequencies µ ∈ {0, 10, 100}. These en‐ abled us to see results across the whole vocabulary in the case of µ = 0 and reduce noise from rare words in the case of µ = 10. We also used µ = 100 to generate Fig. 1 as the original paper.
Seed Toolkit and Pairing Seed Set Data. Other than extending the experiments of the original paper, we have two additional contributions. For the sake of reproducibility, we make our code publicly available and design our repository as an open Python package that can be used to obtain bias subspace vectors and assess seed set robustness. This toolkit can help future researcherswho aim to evaluate their seeds carefully. Our second contribution is an augmentation of the seed dataset provided by Antoniak and Mimno1. We provided additional annotations regarding pairing, i.e. we identify which seeds to pair together along standard bias dimensions in a queriable .csv format.
6 Discussion
Overall, our results replicate the data reported in the original paper. This replication lends strong support to the general claim of the original paper that seed sets incorporate
ReScience C 8.2 (#40) – Togt et al. 2022 9
strong inductive biases that affect their performance as grounding for bias metrics and that researchers should be more cognizant of these limitations. Instability in bias subspaces can be introduced by selecting seeds in seed sets, as stated in claim 2b. Our results in Fig. 3 support this as they reproduce the original work. The same bias measurement varies across seed sets selected by different authors who as‐ signed it to the same category. In addition, the dependence of the bias subspace on seed set selection is further supported by Fig. 4. The two highlighted seed sets (black vs white roles/names) are generally distinct in position for each corpus, despite theoret‐ ically attempting to define similar bias dimensions. Another source of instability claimed by Antoniak and Mimno1 is the ordering and pair‐ ing of seed sets. In Fig. 2 we show that the explained variance ratio for the ordered bias subspaces can behave very differently from the shuffled bias subspaces, supporting claim 2a. Our work in Fig. 1a also supports this claim. While the ordered subspace success‐ fully splits the top words along the intended subspace of male and female, the first PC of the shuffled bias subspace has words such as mother and boyfriend both ranked on the same end. This shows that while the subspace still picks up on gender words, it does not represent the intended subspace. Supporting claim 2a that bias subspaces can become less meaningful with a shuffled seed pairing. We could further confirm this behavior by calculating the cosine similarity of the top words of the ordered subspace for the shuffled subspace in Fig. 1b. These results show that she and his are ranked next to each other at the top and not split along the intended bias subspace. These experiments lend strong support to claim 2a that the order of seed pairs can substantially influence the meaningfulness of the bias subspace and, consequently, the bias metrics. Finally, bias subspaces suffer instability due to semantically overlapping seeds being less distinguishable in the bias subspace, as stated in claim 2c. Our results in Table A.2 and Fig. 4 demonstrate that bias subspace vectors are less robust when the seed sets are semantically similar or overlapping. This relationship lends strong credence to claim 2c. However, our results did show that this inverse relationship is not conserved across a minority of corpora (e.g., the Goodreads datasets) for the explained variance metric. More broadly, however, this still shows that the reliability of seed selection is quite variable. While similar seed sets may generate robust bias subspaces for more semantically equivalent seed pairs for some corpora, that is not guaranteed. Therefore, while this inverse relationshipmay beminimized for specific corpora, extensive corpus‐ specific seed set investigations are still required.
What was easy. The original paper clearly described the algorithms used to obtain bias metrics. Additionally, it carefully cited the papers that first proposed them, which specified further details. This aided our understanding of the underlying concepts and accelerated the implementation of the frameworks. Model training and embedding generation was also facilitated by the pre‐existing gensim framework. This permitted greater focus on reproducing the details of the experiments than choosing between al‐ ternative implementations of skip‐gram word2vec. In addition, responsive authors per‐ mitted quick clarifications through email communication when important details were not clear.
Whatwas difficult. The original paper did notmake code publicly available and largely lacked documentation. Only the gathered seeds were provided via GitHub (2). This made it necessary to reproduce all the code from scratch. In select instances, the paper crucially omitted important information, making us re‐ liant on communicationwith the authors. This wasmost pronouncedwhen aggregating embeddings or other metrics across the bootstrapped model sampling, where vocabu‐ lary sizes were different. This meant that not all models had good embeddings for all seed terms. We had to consider several different approaches before settling on the av‐ eraging criteria described in Section 4.5.
ReScience C 8.2 (#40) – Togt et al. 2022 10
Finally, preprocessing the data was more difficult than initially imagined. The tokeniza‐ tion pipeline in the original paper was vaguely specified, and differences in our imple‐ mentation caused the slight discrepancies in Table A.3. The POS taggingwith spaCywas imperfect, resulting in the incorrect tagging of several proper nouns as common nouns, making it hard to control for POS in random seed generation.
Communication with original authors. While the authors did not disclose any code, we maintained a lengthy email correspondence with them. One author, Maria Anto‐ niak, was contacted to clarify hyperparameters of the word2vec model, the methodol‐ ogy for generating random seeds across bootstrapped models, and which bias metrics (PCA orWEAT)were used for different results. She also described her dataset processing pipeline, as there were many alternate ways to process the corpora before training.
7 Conclusion
Overall, our results replicate the ones reported in the original paper. This lends strong support to the general claim of the original paper that seed sets incorporate significant inductive biases that affect their performance as grounding for bias metrics and that researchers should be more cognizant of these limitations. Aside from confirming the danger of blindly using seed sets, we also provide additional contributions. First of all, all code used to replicate the original paper is publicly available. This code can obtain bias subspace vectors and assess seed set robustness. Secondly, we extended the original paper’s set similarity versus bias subspace explained variance analysis to cover all datasets. Furthermore, we implement multiple numbers of minimum frequencies that further enable results across the entire vocabulary. Lastly, we provide an additional annotation pairing of the original seed dataset. We have highlighted a need for carefully justifying the use of particular sets through em‐ pirical means, but a theoretically sound and systematic method for doing so is still in its infancy. Further workmay explore what criteria seed sets should satisfy to demonstrate robustness. In addition, future researchersmaywant to extend this work to bigram seed terms and embeddings to explore the limitations of more expressive seeds and bias di‐ mensions.","The significant difficulties encounteredwere due to a lack of publicly available code and documentation to clarify missing information in the paper. For this reason, many algo‐ rithms that ultimately turned out to be quite simple required lengthy clarifications with authors or trial and error. Lastly, the research was quite data‐intensive, which caused some implementations to be non‐trivial to account for memory management.
Copyright © 2022 J.V.D. Togt et al., released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Giulio Starace (giulio.starace@gmail.com) The authors have declared that no competing interests exist. Code is available at https://github.com/thesofakillers/badder-seeds – DOI 10.5281/zenodo.6480966. – SWH swh:1:dir:13ff45fd249e765a221d49f701c32d45b64ee675. Open peer review is available at https://openreview.net/forum?id=HcIxA3Mm2CF.
ReScience C 8.2 (#40) – Togt et al. 2022 1"
['Žiga Trojer'],[Re] Transparent Object Tracking Benchmark,10.5281/zenodo.6574707,Replication,Python Matlab,https://zenodo.org/record/6574707/files/article.pdf,rescience c machine learning deep learning tracking computer vision python pytorch matlab,https://openreview.net/forum?id=HxZZV3MQ20Y,https://github.com/trojerz/TOTB-reproducability,8,2,2022,"In the article, the authors of the Transparent Object Tracking Benchmark compare the performance of 25 state‐of‐the‐art tracking algorithms, evaluated on the TOTB dataset, with a new proposed algorithm for tracking transparent objects called TransATOM. Au‐ thors claim that it outperforms all other state‐of‐the‐art algorithms. They highlight the effectiveness and advantage of transparency feature for transparent object track‐ ing. They also do a qualitative evaluation of each tracking algorithm on various typical challenges such as rotation, scale variation etc.","The evaluation of the tracking results and comparison of different trackers with each other was a simple part of the reproduction because the implementation in Matlab is
Copyright © 2022 Ž. Trojer, released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Žiga Trojer (ziga.trojer20@gmail.com) The authors have declared that no competing interests exist. Code is available at https://github.com/trojerz/TOTB-reproducability – DOI 10.5281/zenodo.6475970. – SWH swh:1:dir:b80fa866c01389a46dde8b6f419d893d127f1025. Open peer review is available at https://openreview.net/forum?id=HxZZV3MQ20Y.
ReScience C 8.2 (#41) – Trojer 2022 1
very robust and works for different formats of tracker results.","The most difficult aspect of the replication was integrating the TOTB dataset into vari‐ ous standard evaluation tools and running all trackers on this dataset. The reason for this is that each tool requires its own dataset format, and it was also difficult to set up so many different tracker environments. It also took a long time to run all of the trackers because some of them are quite slow and the TOTB dataset is quite large. The depreca‐ tion of different packages was also a problem for some trackers, necessitating extensive debugging.
Communication with original authors We communicated with the author via email. The author provided us with feedback that helped us reproduce the results more accurately.
2 Introduction
In recent years, the tracking community has made amazing progress. Many new track‐ ingmethods, particularly neural network trackers, have substantially improved the track‐ ing of opaque objects. Existing research in the topic mostly focuses on tracking of opaque objects, with very little attention dedicated to tracking of transparent objects. However, transparency brings additional challenges not well tackled by the state‐of‐the‐ art in opaque object tracking. Tracking of such objects may be very relevant to robotic vision, human‐machine inter‐ action and security surveillance. A vessel collecting plastic from the sea, for example, could so effectively track plastic in the sea and remove it from the water. Another po‐ tential application is the grabbing of produced light bulbs with a robotic arm. That is why it is important to reproduce and verify the results of this article, as it pro‐ poses a new state‐of‐the‐art tracker TransAtom, which is currently thought to be the best performing when tracking transparent objects compared to other trackers.
3 Scope of reproducibility
In our work, we focused on reproducing and comparing the results of various trackers on TOTB. The proposed TOTB ‐ transparent object tracking benchmark, which is the first benchmark dedicated to transparent object tracking, was the original paper’s main contribution. In our opinion, this is a significant contribution because it is the first step toward the development of trackers for transparent objects. We intended to evaluate and compare the proposed TransATOM tracker to other state‐ of‐the‐art trackers on the aforementioned dataset. With this, we hoped to validate the claim that TransATOMsignificantly outperformsother state‐of‐the‐art trackers designed primarily for tracking opaque objects. We hoped to verify the claim that including a transparency feature in the tracker improves performance when tracking transparent objects. Finally, we conducted a qualitative evaluation on various types of recordings to see where different trackers excel and where they fail. Claims that we tested are the following:
• TransATOM assessed on TOTB significantly outperforms other evaluated state‐of‐ the‐art algorithms by a large margin.
• Including a transparency feature in the tracker improves performancewhen track‐ ing transparent objects.
ReScience C 8.2 (#41) – Trojer 2022 2
• TransATOM well handles all challenges for robust target localization owing to the transparency features.
4 Methodology
We used the author’s TransATOM code to reproduce the results, which is available here. Code for evaluation tools and other trackers was obtained from GitHub:
• PyTracking tool, which includes code for ATOM, PrDiMP‐18, PrDiMP‐50, DiMP‐18 and DiMP‐50.
• PySOT tool, which includes code for SiamMask, SiamRPN and SiamRPN++.
• py‐MDNet tool, which includes code for MDNet.
• STARK tracker with it’s own evaluation tool.
We used an internal server with an Ubuntu 18.04 operating system and a TITAN X graph‐ ics card with 12GB VRAM to reproduce the results.
4.1 Model descriptions Here we list hyperlinks to the models’ descriptions and all of the parameters we used: TransATOM, ATOM, PrDiMP‐18, PrDiMP‐50, DiMP‐18, DiMP‐50, SiamMask, SiamRPN, SiamRPN++, MDNet and Stark. All models have been pre‐trained.
4.2 Datasets An important part of tracker analysis is to know in which cases the tracker excels and in which cases fails. To this end, the authors have assigned several attributes to each recording. A twelve‐dimensional binary vector was provided for each sequence to indi‐ cate the presence of an attribute (1 denotes the presence of a certain attribute). From Table 1, which summarizes TOTB dataset, we can observe number of sequences with a certain attribute (bold diagonal) and number of sequences with combination of dif‐ ferent attributes. Table 2 shows the distribution of the following attributes on TOTB dataset: illumination variation (IV), partial occlusion (PC), deformation (DEF), motion blur (MB), rotation (ROT), background clutter (BC), scale variation (SV), full occlusion (FOC), fast motion (FM), out-of-view (OV), low resolution (LR) and aspect ratio change (ARC). The most frequent challenges in TOTBdataset are rotation, partial occlusion and scale variation. The TOTB dataset is available for download at the following link.
result), with the value varying depending on the threshold (which may be different for each tracker). Normalized precision is used to eliminate the influence of different scales by performing normalization with target areas. Success compares the intersection over union (IoU) of tracking results and groundtruth boxes, and success score is calculated as the percentage of tracking results with IoU greater than 0.5. All the code we needed is available on GitHub.
Tracker TransATOM ATOM PrDiMP‐18 PrDiMP‐50 DiMP‐18 DiMP‐50 SiamMask SiamRPN SiamRPN++ MDNet Stark
average FPS 12 25 7 5 7 6 55 42 40 3 70 maximum FPS 21 32 13 11 9 8 78 64 59 5 98 average OPE 1 h 59 min 57 min 3 h 25 min 4 h 45 min 3 h 25 min 3 h 58 min 26 min 35 min 35 min 7 h 57 min 20 min maximum OPE 2 h 2 min 59 min 3 h 29 min 4 h 50 min 3 h 29 min 4 h 04 min 28 min 36 min 37 min 8 h 13 min 21 min
5 Results
There are two parts to this section. In section 5.1, we examine tracker performance in terms of precision, normalized precision and success and compare it with each other. The results presented there are to support the first two claims in Section 3. The results of the qualitative evaluation are presented in section 5.2, where the results contradicts the claim that TransATOM effectively handles all challenges for robust target localization.
ReScience C 8.2 (#41) – Trojer 2022 4
Tracker Precision Normalized Precision Success
TransATOM 65.3± 0.4 73.5± 0.5 73.8± 0.4 ATOM 63.9± 0.3 71.2± 0.4 71.8± 0.4 DiMP18 55.9± 0.6 64.4± 0.8 65.1± 0.7 DiMP50 60.1± 0.5 67.9± 0.8 68.5± 0.7 prDiMP18 58.9± 0.3 66.3± 0.4 67.8± 0.3 prDiMP50 64.3± 0.3 72.3± 0.4 73.7± 0.4 SiamRPN 62.9± 0.2 70.1± 0.4 72.2± 0.4 SiamMASK 64.1± 0.3 72.4± 0.4 73.0± 0.3 SiamRPN++ 64.7± 0.2 71.9± 0.5 72.8± 0.5 Stark 76.2± 0.4 81.7± 0.5 83.5± 0.4 MDNet 59.6± 1.8 69.3± 2.9 69.7± 2.2
TransATOM and ATOM tracker performance can now be compared. The only distinc‐ tion between these two trackers is that TransATOM includes a transparency feature.
ReScience C 8.2 (#41) – Trojer 2022 5
We can confirm the second claim, that including a transparency feature in the tracker improves performance when tracking transparent objects, because TransATOM outper‐ forms ATOM by 1.4 percent in precision, 2.3 percent in normalized precision, and 2.0 percent in success, while confidence intervals do not overlap (see Table 4 and Figure 1).
We evaluated the current state‐of‐the‐art tracker Stark in addition to the best trackers from the original article. We can see from the above results that it outperforms all other
ReScience C 8.2 (#41) – Trojer 2022 6
tracking algorithms and handles all challenges for robust target localization much bet‐ ter.
6 Conclusion
Wewere able to confirm two of the three main claims from the original article, as stated in the results. The claim which states that TransATOM outperforms other evaluated state‐of‐the‐art algorithms by a large margin on TOTB was confirmed, as we demon‐ strated that TransATOM outperforms other trackers that the authors evaluated in their original paper. The second claim was also confirmed, because we showed that the dif‐ ference in performance of TransATOM and ATOM tracker, which differentiate only on the transparency feature, was significant enough. However, we were unable to confirm the the last claim, which states that TransATOM effectively handles all challenges for robust target localization due to transparency fea‐ tures. We evidenced multiple cases where the TransATOM tracker fails to handle trans‐ parent object tracking adequately. We believe that this is the most audacious claim, be‐ causeweknow that theTOTBdataset containsmanydifficult challenges that no currently‐ developed tracker can handle well. The strength of our strategy was that we attempted to follow the steps outlined in the article. We also chose only the top 10 trackers based on their performance on the TOTB dataset, allowing us to focus more on implementation and evaluation quality. In addi‐ tion, we compared the current state‐of‐the‐art Stark tracker. We wanted to show that there is still a lot of room for improvement in the field of tracking transparent objects. Because we didn’t know which parameters were used in the original article, we used only the default choice of parameters for all trackers. This was a flaw in our approach. We could also do more in‐depth qualitative analysis because we could compare three results for each tracker and pick the best one, but we took the best one in the whole TOTB dataset.
6.1 Recommendations for reproducibility We recommend using the code from GitHub to reproduce the results of the original ar‐ ticle or our work. We recommend to look at which evaluation tool the original code is written in for each tracker and use that evaluation tool. We do not recommend repro‐ ducing the results for all trackers, but rather selecting the trackers with the best results, because evaluating the trackers takes a lot of time. We have adapted the TOTB dataset for PySOT, py‐MDNet, STARK, and VOT21 evaluation tool, and we recommend to down‐ load it from here."
"['Noah van der Vleuten', 'Tadija Radusinović', 'Rick Akkerman', 'Meilina Reksoprodjo']",[Re] Explaining in Style: Training a GAN to explain a classifier in StyleSpace,10.5281/zenodo.6574709,Replication,Python,https://zenodo.org/record/6574709/files/article.pdf,rescience c machine learning deep learning python pytorch explainable ai xai gan stylegan2 stylex,https://openreview.net/forum?id=SYUxyazQh0Y,https://github.com/NoahVl/Explaining-In-Style-Reproducibility-Study,8,2,2022,"StylEx is an approach for classifier‐conditioned training of a StyleGAN2 model [1], in‐ tending to capture classifier‐specific attributes in its disentangled StyleSpace [2]. At‐ tributes can be adjusted to generate counterfactual explanations of the classifier deci‐ sions. StylEx is domain and classifier‐agnostic, while its explanations are claimed to be human‐interpretable, distinct, coherent and sufficient to produce flipped classifier decisions. We verify these claims by reproducing a selection of the experiments in the paper.","Itwas easy to run the provided JupyterNotebook, and verify the results of the pre‐trained models on the FFHQ dataset. Extending an existing StyleGAN2 model implementation to fit this study was relatively easy.","Reproducing the experiments on the same scale as the authors, as well as the develop‐ ment of the full training procedure, model architecture and hyperparameters, partic‐ ularly due to underspecification in the original paper. Additionally, the conversion of code from TensorFlow to PyTorch.
Communication with original authors We correspondedwith the first author of the paper through several emails. Through our mail contact, additional details were released on the network architecture, the training procedure and the hyperparameter configurations.
None 8.2 (#42) – Vleuten et al. 2022 2
2 Introduction
Existing post hoc visual explainability measures, such as heatmaps[3], can highlight regions that influence model decisions. However, they do not visualize non‐spatially localized attributes, nor do they indicate how these areas may be changed to influence the classification. Counterfactual explanations, which are statements of the form ”Had the input x been x′, the classifier output would have been y′ instead of y”, has been pro‐ posed as an alternative which both allows for the visualization of salient features and directly explains how they can be altered to achieve an alternative classification. As such, these explanations are promising as they can provide a suggestive recourse to non‐domain experts in a machine learning‐based decision system. The effectiveness of visual methods strongly depends on the intuitive difference that humans observe; there‐ fore one of the primary objectives is to find interpretable, salient attributes. Secondary objectives involve the visualization and control of the impact of these attributes on the classifier output. In thiswork, we reproduce thepaper ‘Explaining in Style: Explaining aGAN in StyleSpace’ [4]. The paper proposes a novelmethod for explaining the classification of a given image, by altering discovered human‐interpretable features discovered to affect the classifica‐ tion output. We re‐implemented the model in PyTorch together with the unreleased training procedure, as the original TensorFlow implementation lacked the training pro‐ cedure code. We performed training on the FFHQ and PlantVillage dataset using a lower resolution. Using our implementation, we check whether the results are consistent with the descriptions provided in the paper. We substantiate this with the addition of a human‐grounded evaluation of the generated images. Additionally, we used the FID measure to evaluate the image quality of the counterfactual generated images.
3 Scope of Reproducibility
The StylEx model, in addition to the AttFind algorithm defined in the paper, is pre‐ sented as a viable option for generating counterfactual explanations of black‐box classi‐ fiers. The StylEx procedure aims tomake individual style coordinates classifier‐relevant, through a novel training procedure which is outlined in 4. As no benchmark metrics exist to evaluate and assess attribute‐based counterfactual explanations, the authors propose three evaluation criteria themselves: 1) visual coherence, 2) distinctness and 3)
None 8.2 (#42) – Vleuten et al. 2022 3
‘effect of attributes on classification’ (sufficiency). We reformulate these criteria as the main claims of the paper in the following manner:
1. Visual Coherence: Attributes detected by StylEx should be clearly identifiable by humans.
2. Distinctness: The attributes extracted by StylEx should be distinct.
3. Sufficiency: Changing attributes should result in a change of classifier output, where changing multiple attributes has a cumulative effect.
4 Methodology
To evaluate claim 1 and 2, the authors conduct a user study in two parts. To evaluate claim 3, they study the percentage of flipped classifications when modifying top‐k (in their case k = 10) attributes. To reproduce these claims, we conduct the same experi‐ ments, albeit at a lower dimensionality of 642px. The complex network architecture of StyleGAN, as well as the encoder, requires a significant number of training epochs un‐ til its convergence and thus, training these at the full resolution of 2562px is extremely computationally expensive. We verify the sufficiency scores of the released model, by making use of the supplied Jupyter Notebook. However, several elements crucial for reproduction were missing, including the training procedure, the omission of hyperparameter configurations and the details on the optimization procedure. As such, we ported the available TensorFlow code to PyTorch, and implemented the missing parts, to enable a more comprehensive reproducibility of StylEx. We reimplemented the StylEx procedure in PyTorch, using an open‐source StyleGAN2 model implementation as a starting point1. For running our code, we havemade use of an NVIDIA GTX 1080 Ti, RTX 2070 Super and a laptop RTX 3060 graphics card, running on different machines. In the conduction of the user study, we have made use of the online survey tool Qualtrics [5].
4.1 Model descriptions In addition to a pre‐trained classifierC, StylEx is comprised of three trainable elements, which are a 1) generatorG, 2) a discriminatorD and 3) an encoderE. TheD andG follow the StyleGAN2 model architecture, with minor alterations toD which will be explained below. Figure 2 provides an overview of the network architecture. Some design details were unspecified or omitted in the original paper. We contacted the authors to provide clarification on these details, which are stated as follows:
1. StylEx is trained using both encoder input and noise input transformed through StyleGAN2’s mapping network, using alternating steps;
2. The output of D is a weighted sum of the 2‐dimensional output of its last layer with the classifier probabilities of the 1) original image if using the encoder, 2) randomly sampled image if using noise input;
3. Lrec and Lcls are only calculated during the generator training steps.
The GAN is trained jointly with the encoder, which embeds an image into the W latent space of StyleGAN2, forming a latent vector w. A recent observation by [7] highlighted the disentanglement of this space (called StyleSpace) that is used in StylEx to extract classifier‐specific attributes. Logits of the original image C(x) are then appended to
1https://github.com/lucidrains/stylegan2‐pytorch
None 8.2 (#42) – Vleuten et al. 2022 4
w, to condition the training on classifier inputs. The current architecture includes a StyleVectorizer that obtains the latent vector w from z, which is sampled from a normal distribution. In alternating steps, the generator was fed input from the encoder and in‐ put from the StyleVectorizer mapping network [6]. The original authors noticed a slight improvement in image quality using alternating training, compared to only using the encoder input. Note that we used two slightly different implementation choices for training our mod‐ els. The first implementation does not include the discriminator change mentioned in 2, while the second implementation does and uses probabilities instead of logits for con‐ catenation to w. We call these two choices ‘Model 1’ and ‘Model 2’ in results on datasets where we have trained both. We additionally noted that the MobileNet classifier ‘Model 1’ was trained with did not performwell on the faces. This is why, for both faces models, a ResNet classifier was used to perform the AttFind algorithm. Additionally, we skipped discriminator filtering for ‘Model 2’. Discriminator filtering skips encoded images the discriminator deems unrealistic. We did this because the discriminator was too unsta‐ ble to give reliable estimates. This might explain the poor performance of this model. We are unsure if this was caused by the changes to the architecture, training time or just bad luck. This expanded latent vector w, either obtained by the encoder or StyleVectorizer, is passed on to the StyleGAN2 model, where it is transformed into the StyleSpace by a set of concurrent affine transformations to style vectors s0, ..., sn. These style vectors are used to generate novel images, that aim to reconstruct the original image as closely as possible. Several losses are used to aid the training procedure. The cumulative training loss for the algorithm is a sum of losses, denoted as follows:
StylExLoss = Ladv + Lreg + Lrec + Lcls. (1)
A logistic adversarial loss [8] Ladv is used as in standard GAN training, followed by the regularization lossLreg, as described in the original StyleGAN [1] paper. The reconstruc‐ tion loss Lrec is given by the sum of Lxrec + Lwrec + LLPIPS, where the first two terms are the L1 distance between original and reconstructed input image, and the original and reconstructed w latent vector, respectively. The LLPIPS term is the LPIPS distance
None 8.2 (#42) – Vleuten et al. 2022 5
between original and reconstructed input, as described in [9]. This loss ensures that re‐ constructed images resemble the original input as close as possible, to serve as an input for generating counterfactual examples. The classifier loss is defined as the Kullback‐ Leibler divergence between the original input imageX and the newly generated image G(E(X), C(X)) , defined as follows: Lcls = DKL[|C(x′)||C(x)]. This loss ensures that the generator does not disregard image attributes that are important for the classifica‐ tion. To extract classifier‐specific attributes, the AttFind algorithm is proposed in the paper. As input, it takes the trainedmodelD and a set ofN images of which the predicted labels do not match the target label y. For each class label, AttFind encodes the images and iteratively tries to find a set Sy ofM style coordinates that represent the largest possible shift to the opposing class. Next to this, it finds the set of directions Dy ∈ {±1}M in which the attribute needs to be adjusted to flip the classifier decision. In each iteration, it considers all style coordinatesK and determines the coordinate with the largest effect. All images in which changing this coordinate results in a large effect on their probability are removed from the iteration. The process is repeated until no images are left, or until M attributes are found.
4.2 Datasets We reproduce a selection of the findings of the authors on two of the given datasets in our PyTorch implementation:
1. CelebA [10] The original Large‐scale CelebFaces Attributes (CelebA) dataset2 con‐ tains 200000 image entries, each containing 40 attribute annotations. We have trained classifiers on the ‘perceived gender’ attribute.
2. FFHQ [11]The original Flickr‐Faces‐HQdataset containing 70000 images of human faces. This datasetwas used for StylEx training, while the pre‐trained classifierwas trained on the CelebA dataset, following the procedure of the original paper.3
3. Plant‐Village: This dataset contains 54303 entries of plant images, with 38 cate‐ gories. This dataset was used to train the classifier to differentiate between sick and healthy leaves.
For the classification tasks, the FFHQ dataset was split into train/validation/test sets of 70/15/15, while the Plant‐Village retained a proportion of 70/20/10.
4.3 Hyperparameters Original research: For the partial reproduction of Table 3 of the original paper, we lim‐ ited ourselves to a sample of n = 250 images, rather than the n = 1000 randomly sam‐ pled images, as denoted in the Jupyter Notebook. Reimplementation: The computational costs of training StylEx precluded an in‐depth hyperparameter search. For all modules except the encoder, we found a learning rate of 2e − 4 for the Adam optimizer, with β1 = 0.5 and β2 = 0.9. We found the training to diverge unless the encoder learning rate was lowered significantly to 1e− 5. We ascribe this difference to the significantly smaller input size in our models or subtle implemen‐ tation differences from the original paper that are unknown to us. The classifier used in the paper was MobileNetV1 [12], but we opted for a MobileNetV2 [13] or ResNet‐18 models[14]. The authors asserted that the use of advanced networks identified more subtle cues from the datasets on the classification problems at hand, and for this purpose, we opted for ResNet‐18. Additionally, we observed that the Mo‐ bileNet model did not perform well on the CelebA dataset for gender classification on
2https://www.kaggle.com/jessicali9530/celeba‐dataset 3This is a detail that was revealed through contact with the authors.
None 8.2 (#42) – Vleuten et al. 2022 6
this image resolution. The components of the Lrec loss were scaled according to au‐ thors’ suggestion in our correspondence: 0.1 for Lxrec and LLPIPS, 1 for Lwrec. Other loss components were not scaled. On the local GPUs, weused a batch size of 4with 8 gradient accumulation steps, whilewe use a batch size of 16 with 4 gradient accumulation steps on the computer cluster. For the training of the MobileNet V2 classifier and the ResNet‐18 classifier, we finetuned the pretrained models by slowly unfreezing the top layers, we have set the learning rate to lr = 1e − 4, used a batch size of 128 and used the Adam [15] with default PyTorch parameters.
4.4 Experimental setup and code We aimed to follow the experimental setup as close as possible for our experiments. Our PyTorch implementation is available on GitHub4 to further support and advance reproducibility in machine learning research. The repository provides explanations to run the described experiments.
4.5 Computational requirements Locally, ourmodels were trained on two differentmachines, which contained a 1) laptop NVIDIA RTX 3060, 2) an NVIDIA RTX 2070 Super. A computer cluster containing GTX 1080 Ti GPUs was also used to train some of our models. The first machine makes use of the Windows operating system, while the latter two are Linux‐based. For both the FFHQ dataset as well as the Plant‐Village dataset, training was done until convergence, which was reached in 150K training steps for the FFHQ dataset and 260K training steps on the Plant‐Village dataset. On the local GPUs, a batch size of 4 (RTX 3060) and 8 (RTX 2070 Super) was used along‐ side gradient accumulation for 8 (RTX 3060) and 2 (RTX 2070 Super) steps. On the com‐ puter cluster, a batch size of 16 was used, with a gradient accumulation parameter of 4. Depending on the hyperparameters of the batch size and gradient accumulation, the computational time to run the experiments ranged between 20‐50 GPU hours. Training for 150000 steps took 20 hours on an RTX 2070 Super.
5 Results
5.1 Results reproducing original paper
Sufficiency —Wecalculate the percentage of flipped classifications after changing the top‐ 10 most influential attributes found by the AttFind procedure. The results can be seen in table 1. Our results using the author’s model are within 1% of the accuracy reported in the paper. Our models show significantly worse performance on both perceived gen‐ der (51% vs 83.2%) and plant healthiness (30% vs 91.2%), showing that the attributes discovered are not very relevant for classification.
Coherency and Distinctness — Similar to the original paper, we have conducted a user study (n = 54) to evaluate the distinctiveness of the found attributes and the coherence of the generated images. The user study was divided into two parts ‐ 1) a classification study and 2) a verbal description study, following a similar setup as presented in [16]. For the classification study, users are shown one animation of four images in a grid format. The two images on the left switch between their original image and have the same transformation applied. The two images on the right swap between their original image and one of two transformations. The user then has to find the transformation on
4https://github.com/NoahVl/Explaining‐In‐Style‐Reproducibility‐Study
None 8.2 (#42) – Vleuten et al. 2022 7
the right that matches with those on the left. In the verbal description study, the users were asked to look at an animation of four images, and consequently describe in 1‐4 words the changing attribute. We have done this for the plant dataset as well as the FFHQ datasets. The order of the datasets was randomized to avoid biases and learning effects. All participants are under‐ graduate and graduate students who have some affinity with and knowledge ofmachine learning. None of them reported having color blindness. In Appendix 7, a few examples can be found on the posed questions (without animations) and the type of provided an‐ swers. The full user evaluation data and questions from the questionnaire can be found on our GitHub repository, under the folder all_user_studies.
Although our results seem to slightly outperform the results by Wu et al. (2021) on the perceived gender classifier, it does not seem to outperform the method posed by Lang et al. (2021).
5.2 Results beyond original paper
FID scores — To investigate the impact of attribute per‐ turbation on the quality of the generated images, we compute the Fréchet Inception Distance (FID) [17] between the original images and the generated im‐ ages, as described by Seitzer18. We perturbed the im‐ ages with increasingly more attributes in a cumula‐ tive fashion, starting from zero perturbed attributes, which corresponds to only encoding and decoding the image. For the pre‐trained model from the orig‐ inal authors, we used the provided subset of 250 la‐ tent vectors and their corresponding original images that were found in FFHQ. For our models, we used subsets of 100 images (500 images for model 2) due to computational constraints with regard to running the AttFind algorithm. Our results, seen in 3, show that the FID increases with the number of stacked perturbed attributes.
None 8.2 (#42) – Vleuten et al. 2022 8
This result is not surprising for three reasons. Firstly, making an image to be classi‐ fied as another class might introduce perturbations for a certain class that are out‐of‐ distribution for that particular class. For example, a man with lipstick does not appear often in the male class. Therefore, counterfactuals are more likely to be out of distribu‐ tion to a particular degree. Secondly, a combination of perturbations seems to be more likely to produce an image that ismore out of distribution thanwhen one perturbation is applied individually. For example, a womanwith thicker eyebrows in combination with more facial hair might be more out of distribution than one of those perturbations indi‐ vidually. Moreover, we noticed that perturbing several attributes leads to an increasing number of image artefacts, which could be an additional cause for the increasing FID score. This holds both for the original authors’ models and our implementation.
6 Discussion
Our experimental results support the claims made in the original paper ‐ the attributes detected by StylEx are identifiable by humans to a certain degree, distinct and sufficient. However, due to the significantly lower resolution and poorer image quality of the mod‐ els, these results are not comparable to the ones displayed in the original paper. Reflection on our reproducibility study An important insight obtained during the con‐ duction of the study is that the provided code did not cover the entire scope of the paper. Through a thorough study of both the code aswell as the paper, we quickly noted discrep‐ ancies and missing elements that were fundamental ‐ such as the network architecture, scaling of the losses and the hyperparameter configurations ‐ to the original research. We believe that researchers could enhance transparency and reproducibility inmachine learning research by the addition of a reproducibility statement within their research, including the used hardware, releasing written software and adding details relevant to the paper (e.g. such as clarifications on the exact network architecture). Moreover, it is important to detail hyperparameter search spaces and final parameter settings for all the used architectures and baselines. We believe that transparency is fundamental to stimulating the large‐scale deployment of machine learning algorithms.
6.1 What was easy It was relatively easy to run the code as the provided Jupyter Notebook by the authors. The provided notebook was thoroughly documented and written in a consistent coding style, making the interpretation of the notebook easier. However, the provided note‐ book lacked the elements to fully reproduce the research; the training procedure of the network was missing, only one pre‐trained model was provided and four datasets were missing that we were required to add. As such, we had to implement the framework in PyTorch, while porting the limited released code from TensorFlow. Adding a dataset not used in the original notebook to accommodate the experiments was a relatively easy task.
6.2 What was difficult Given the limited computational resources that were available to us, reproducing the ex‐ periments at the same computational scale as the authors were deemed to be the largest challenge. For the training of the model, the original authors made use of 8 NVIDIA V100s, which took the original authors a week to train at the full resolution of 2562px, whereas we were restricted to the use of the computer cluster, Colab/Kaggle, and our lo‐ cal GPUs. Due to this limitation, we had to scale down the resolution of the new images across the different datasets significantly. We scaled down the resolution of the gen‐ erated images across the different datasets to a resolution of 642px, which reduced the
None 8.2 (#42) – Vleuten et al. 2022 9
fidelity of the reconstructed images. Additionally, we experienced the following issues with the original paper:
1. Little to no hyperparameters were given in the paper, e.g. on the scaling of the losses, the learning rates etc;
2. Ambiguities about the trainingprocedure: the classifier in thenotebookwas trained on CelebA, instead of the FFHQ dataset, which we did not expect. This appeared to be a design choice by the authors, as the CelebA dataset contained labels, which the network could leverage information from. Additionally, softmax logits ap‐ peared to be added to the discriminator – which was not mentioned explicitly in the paper – but appeared to follow the cGAN [19] training procedure;
3. Ambiguities on the network architecture: It was not entirely clear what the di‐ mensionality and the function were of the z vector, as the paper did not explicitly mention this;
4. Ambiguities about the preprocessing pipeline of the images before it enters the encoder/classifier ‐ in contact with the authors, they appeared to scale the RGB values from [−1, 1].
The original authors did provide the hyperparameter configurations early on, which slightly reduced the time to explore the different possibilities, but the provided learning rate for example was too high for us. Additionally, the conversion of the AttFind algo‐ rithm from TensorFlow to PyTorch also proved to be a somewhat difficult exercise. The challenge predominantly concerned the integration of this algorithm within the new PyTorch codebase, which required a thorough understanding of the internal workings of the algorithm.
6.3 Communication with original authors Three emails were sent to the first author of the paper. In these emails, we have asked for additional details on the proposed network architecture, hyperparameter configura‐ tions and the training procedure of the networks. These details were not noted in the paper, nor in the provided code. Answers to these questions were provided promptly. Unfortunately, they were not able to share their code for the training procedure, as it contained too many internal dependencies from their perspective.
None 8.2 (#42) – Vleuten et al. 2022 10"
"['Velizar Shulev', 'Paul Verhagen', 'Shuai Wang', 'Jennifer Zhuge']",[Re] Replication Study of DECAF: Generating Fair Synthetic Data Using Causally-Aware Generative Networks,10.5281/zenodo.6574711,Replication,Python,https://zenodo.org/record/6574711/files/article.pdf,rescience c machine learning deep learning python pytorch reproducibility causal graphs debiasing,https://openreview.net/forum?id=SVx46hzmhRK,https://github.com/ShuaiWang97/UvA_FACT2022,8,2,2022,In this paper we attempt to reproduce the results found in ”DECAF: Generating Fair Syn‐ thetic Data Using Causally‐Aware Generative Networks” by Breugel et al [1]. The goal of the original paper is to create a model that takes as input a biased dataset and out‐ puts a debiased synthetic dataset that can be used to train downstreammodels to make unbiased predictions both on synthetic and real data.,,
"['Alfonso Taboada Warmerdam', 'Lodewijk Loerakker', 'Lucas Meijer', 'Ole Nissen']",[Re] Privacy-preserving collaborative learning with automatic transformation search,10.5281/zenodo.6574713,Replication,Python,https://zenodo.org/record/6574713/files/article.pdf,rescience c machine learning deep learning python pytorch,https://openreview.net/forum?id=S9Iepnz7hRY,https://github.com/Linkerbrain/fact-ai-2021-project,8,2,2022,Gao et al. [1] propose to leverage policies consisting of a series of data augmentations for preventing the possibility of reconstruction attacks on the training data of gradients. The goal of this study is to: (1) Verify the findings of the authors about the performance of the found policies and the correlation between the reconstruction metric and pro‐ vided protection. (2) Explore if the defence generalizes to an attacker that has knowl‐ edge about the policy used.,,
"['Romana Isabelle Wilschut', 'Thomas Paul Alexandre Wiggers', 'Roman Sebastiaan Oort', 'Thomas Arthur van Orden']",[Re] Robust Counterfactual Explanations on Graph Neural Networks,10.5281/zenodo.6574715,Replication,Python,https://zenodo.org/record/6574715/files/article.pdf,counterfactual explanations GNN robust graph neural networks interpretation explainable AI decision logic reproducibility python rescience c machine learning,https://openreview.net/forum?id=HWNgihGX20Y,https://github.com/RomanOort/FACTAI,8,2,2022,"The original author’s code contained the code necessary to train both GNNs and ex‐ plainer models from scratch. However, some alterations made by us were necessary to be able to use it. To validate the authors’ claims, the trained RCExplainer model is compared with other explainer models in terms of fidelity, robustness and efficiency. We extended the work by investigating the generalisation to the image domain and ver‐ ified the authors’ implementation.","The original paper described their metrics for comparing multiple explainer models clearly, which made it easier to reproduce. Moreover, a codebase was available which included a pre‐trained explainer model and files for training the other models. Because
Copyright © 2022 R.I. Wilschut et al., released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Romana Isabelle Wilschut (romana.wilschut@student.uva.nl) The authors have declared that no competing interests exist. Code is available at https://github.com/RomanOort/FACTAI. – SWH swh:1:dir:5744faf1da0fd9b520c8aa72a0608b78f0a91e7a. Open peer review is available at https://openreview.net/forum?id=HWNgihGX20Y.
ReScience C 8.2 (#45) – Wilschut et al. 2022 1
of this, we could easily find the reason for differences between our results and those of the paper.","The most difficult part of the reproduction study was determining the functionality of the provided codebase. The original authors did provide a general README file that in‐ cluded instructions for all code parts. However, using these provided instructions, we were not able to run this code without changes. As the provided codebase was very ex‐ tensive, it was difficult to understand and determine how the different modules worked together.
Communication with original authors We found it not necessary to contact the original authors for this reproduction study.
ReScience C 8.2 (#45) – Wilschut et al. 2022 2
2 Introduction
GraphNeural Networks (GNNs) [2] are a recent development in the field of deep learning, aiming to exploit structural information by representing the input data as graphs. By passingmessages along the nodes of the input graphs, these networks can use the struc‐ tured nature of these graphs to reason on them. This allows GNNs to achieve ground‐ breaking results in a variety of fields such as the modelling of physics systems or molec‐ ular analysis [3]. However, GNNs are similar to conventional neural networks (NNs) and can therefore similarly be considered a black box. Hence, they do not always provide a sufficient explanation for their outcome. Nevertheless, such an explanation might be useful in some applications. An explanation, as presented in [1], is simply a subset of edges of the input graph. The authors of [1], to whom we will refer as the original authors from this point on, consider an explanation to be counterfactual if the prediction on the input graph changes significantly when the edges in the explanation are removed from the input graph. Several methods to explain the reasoning of GNNs have already been proposed [4, 5, 6, 7]. However, these models fall short in that their generated explanations are neither counterfactualnor robust to noise. These features are important for amodel because they make the explanations concise, easy to understand for humans and more trustworthy [1]. The original authors propose the RCExplainer model [1], which meets both criteria, and claim it is capable of outperforming existing explainer models, on the task of graph classification, while also being at least as time‐efficient.
3 Scope of reproducibility
With this paper, we aim to validate the original authors’ claims, their experimental setup, and investigate the application of theirmethod to another domain. Our code1 is publicly available and builds upon the code2 of [1]. The original authors tested the RCExplainer model on three different datasets, however, due to long training times, we employed only one of these three. This reproduction paper aims to validate the following claims as made by the original authors:
• The RCExplainer model produces superior counterfactual explanations in com‐ parison to previous methods based on fidelity scores for all levels of sparsity.
• The RCExplainer model is more robust to noise than competitive methods based on ROC AUC score.
• The RCExplainermodel is at least as efficient in terms of inference time as existing explainer models.
Moreover, we conduct a set of additional experiments to inspect the following exten‐ sions to the original paper:
• Split the dataset into a proper train test split, that is no overlap between those sets, for training the explainer model and validating the effect on its performance in terms of fidelity and ROC AUC scores.
• Apply the RCExplainermethod to the task of image classification using theMNIST‐ Superpixels dataset.
• Calculate the ROC AUC scores in two additional ways. 1Our source code is located at https://github.com/RomanOort/FACTAI. 2Theoriginal authors’ code is available at https://marketplace.huaweicloud.com/markets/aihub/notebook/detail/?id=e41f63d3‐
e346‐4891‐bf6a‐40e64b4a3278.
ReScience C 8.2 (#45) – Wilschut et al. 2022 3
The next section will discuss the method of [1] in more detail and introduce our addi‐ tional experiments. Section 5 reports the results to validate the original authors’ claims as well as the results of our extensions. Finally, Section 6 reflects on our work and con‐ cludes that we were able to partly reproduce the original paper.
4 Methodology
4.1 Model description The original authors propose a method consisting of two steps. First, the common de‐ cision logic of a GNN is extracted based on a set of linear decision boundaries (LDBs). This set comes from aGNN that is trained for graph classification. Second, the explainer model, based on the set of LDBs, which is a simple neural network, is trained to generate counterfactual explanations.
Graph neural network The graph neural network, denoted by ϕ, is trained to classify input graphs. This model consists of an arbitrary number of graph convolutional layers, which produce an embedding vector, and a fully connected head. This head predicts the class probabilities from the embeddings.
Explanation network The explanation model, denoted by ϕθ, is trained using the em‐ bedding vectors as produced by the GNN. The network consists of two linear layers with ReLU activations.
Linear Decision Boundaries — The architecture of the classification GNN, ϕ, can be divided into two distinct parts: the graph convolutional layers, denoted by ϕgc, and the fully connected layers, denoted by ϕfc. The RCExplainer model proposed by the original authors works by partitioning the output space of the graph convolutional layers into a set of decision regions, one for each class of the dataset. Given that the GNN uses piecewise linear activations on the neurons [8], its decision regions can be modelled by a set of linear decision boundaries (LDBs), the combination of which forms a convex polytope. As the total number of LDBs of a GNN grows exponentially with respect to the number of neurons [9], it is intractable to compute all the LDBs of a model. However, an LDB can be written as a linear equation of the form wT x + b = 0, where the basis w and the bias b can be computed with the following equations:
w = ∂ (max1(ϕfc(α))−max2(ϕfc(α)))
∂α , (1)
b = max1(ϕfc(α))−max2(ϕfc(α))−wTα, (2)
where α = ϕgc(G), so the embedding of the graph G in the output space of the graph convolutional layers, and the max1 and max2 operations take the highest and second‐ highest value of the input respectively. The original authors, therefore, propose to uni‐ formly sample a random subset of input graphs and extract their respective LDB, in order to circumvent the complexity of computing all LDBs, giving a subset of decision boundaries H̃ ⊂ H. The set of LDBs forming a decision region for a specific class is then chosen to cover the maximum amount of graphs belonging to that class while ensuring that this region covers as few graphs of other classes as possible. The set of LDBs H̃c that forms the decision regions of a class c is determined by iteratively applying the following rule:
h = min h∈H̃\H̃c g(H̃c, c)− g(H̃c ∪ {h}, c) + ε k(H̃c, c)− k(H̃c ∪ {h}, c) , (3)
ReScience C 8.2 (#45) – Wilschut et al. 2022 4
where g(H̃c, c) is the total number of graphs belonging to class c that are covered by the LDBs in H̃c, k(H̃c, c) is the total number of graphs not belonging to class c that are covered by H̃c, and ε is a small noise term that ensures the best LDB is chosen, even when the numerator equals zero. This rule is applied until H̃c covers all graphs of class c, and then repeat this process for every class.
Explanations —Having extracted a decision region for each class, the original authors use this to generate an explanation S for each graph G, where S consists of a subset of the edges in G. This explanation is generated through the fully connected neural network ϕθ, parameterized by θ. This model takes the node embeddings of nodes i and j gener‐ ated by ϕgc, and returns the probability that an edge between these two nodes is part of G’s explanation. Over all node pairs, this forms the matrix M, where each entry is the probability of the corresponding edge in the adjacency matrix belonging to S, which is then chosen to be the set of all edges with a value greater than 0.5 inM. The goal during training is to train a model such that the prediction of the GNN on the explanation is consistent with the prediction on the original graph, such that ϕ(S) = ϕ(G). Furthermore, the original authors want to ensure that removing the edges in S from G changes the prediction on G significantly, such that ϕ(G\S) ̸= ϕ(G). In order to satisfy these goals, the original authors define the following loss function:
L(θ) = ∑ G∈D (λLsame(θ,G) + (1− λ)Lopp(θ,G) + βRsparse(θ,G) + µRdiscrete(θ,G)) (4)
whereLsame is a term ensuring that the explanation ofGhas the same classification asG itself, Lopp ensures that removing S fromG changesG’s classification, the combination of these terms ensuring that the explanations are counterfactual. Furthermore,Rsparse is a simple L1‐regularization overM, ensuring only a small amount of edges is selected to be part of the explanation byminimizing this term, andRdiscrete is a term that pushed the values in M closer to either 0 or 1 to more closely resemble an actual adjacency matrix.
4.2 Datasets The original paper evaluates the model on three different datasets: Mutagenicity [10], BA‐2motifs [7], and NCl1 [11]. Due to time constraints, our reproducibility paper only at‐ tempts to reproduce the results on theMutagenicity dataset. TheMutagenicity dataset is a binary dataset containing over 4000molecules of different sizes represented as graphs (see Table 1), with a target stating whether these molecules are mutagenic or not. Be‐ sides the Mutagenicity dataset, we also employed the MNISTSuperpixels dataset [12], containing 60, 000 graphs, in order to evaluate the RCExplainer model on a task in a dif‐ ferent field. These graphs are obtained from the MNISTSuperpixels dataset [13], which contains images of handwritten digits, and are based on the images that are segmented using a superpixel segmentation [14]. This decreases the size of the graphs, by reducing the image from 28×28 pixels to 75 superpixels. Furthermore, where the graph represen‐ tation of a standard image would be a regular grid, where each pixel is only connected to its direct neighbours, which is identical for each image, the superpixel representa‐ tion introduces irregularity between the different images, as the segmentation of each image is different ensuring each image has a different graph.
4.3 Experimental setup and code This section is split into two parts: the experiments concerning the validation of the claims made by the original paper’s authors, and the experiments which validate our aforementioned extensions.
ReScience C 8.2 (#45) – Wilschut et al. 2022 5
Reproducibility — First, the original authors train a GNN from scratch on the classifica‐ tion task. This GNN is then used to obtain the predictions and node embeddings of the input graphs. These embeddings and predictions are used to train the RCExplainer model as described in Section 4.1. Subsequently, the trained RCExplainer model is com‐ pared with other explainer models in terms of fidelity, robustness and efficiency (see Section 5.1). Due to long training times, we chose to compare the RCExplainer only to the RCExp‐NoLDB [1] and PGExplainer models [7], all trained from scratch on 10 differ‐ ent seeds using the hyperparameters mentioned in the original paper. The GNN used as the prediction model is the pre‐trained GNN provided alongside the codebase, with 3 graph convolutional layers. Moreover, the original paper uses the entirety of the Mutagenicity dataset for training the GNN, but for training the explainer network only 1742 samples are used. We follow this same setup in our experiments. However, the original authors only mention an 80/10/10% train‐val‐test split for training the GNN, but no specific split for training the explanation networks. After inspecting the codebase, we observed that the training set is always a subset of the test set and, therefore, it appears that the data used for the evaluation of the RCExplainer is not entirely unseen by the model. Consequently, we decided to also evaluate all models using a train‐test split of 80/20%, which is a more common split used in artificial intelligence. The results of the comparison between both splits are discussed in Section 5.2. Furthermore, for evaluating the model based on robustness, the area under the curve (AUC) of a computed receiver operating characteristic curve (ROC) is calculated. In the provided codebase there were some unclear aspects of the AUC computation, which are addressed in Section 5.3.2.
Extension — In addition to reproducing the results of the original codebase and the orig‐ inal datasets, we applied the method in a different domain to evaluate the method’s ability to generalise to a new domain. Where the original authors employed the Muta‐ genicity dataset, which requires a certain level of chemical knowledge in order to inter‐ pret the qualitative results. Therefore, we applied the RCExplainer model on the image domain as we expect these qualitative results to be easier to interpret intuitively (see 5). For this purpose, the MNISTSuperpixels dataset [12] is used. This dataset was chosen because of its relative simplicity compared to other vision datasets. In order to apply the RCExplainer model to the MNISTSuperpixels dataset, a GNN was trained from scratch, using 4 graph convolutional layers, with 100 hidden units, fol‐ lowed by an embedding layer consisting of 30 units. This increase in model size is nec‐ essary to obtain results comparable to state‐of‐the‐art [15]. More details are presented in Appendix 9. We used the hyperparameters as specified in the original paper and trained the model for 600 epochs. For comparison, both an RCExplainer and PGExplainer model have been trained to ex‐ plain this GNN. The training uses the default hyperparameters for both models, similar to the comparison in the original paper. Again, following the original paper, we do not make use of a test train split, and evaluation is performed on part of the training set.
ReScience C 8.2 (#45) – Wilschut et al. 2022 6
4.4 Computational requirements To run all experiments, that is to say, both the reproduction study and the extension, we made use of 6 computers with varying specifications, but that contain at least one NVIDIA 2080TI GPU. The exact specifications can be found in Appendix 8. Table 2 states the training time in GPU hours per model. The total training time for all models adds up to ±454 hours of GPU runtime.
Fidelity The original authors use fidelity to compare which model produces explana‐ tions with the strongest counterfactual characteristics. Fidelity is the amount the pre‐ diction confidence decreases when the explanation is removed from the input graph. A higher value indicates stronger counterfactual characteristics. This metric can be sen‐ sitive to the sparsity of explanations, which is the percentage of the remaining edges of the input graph after deleting the explanation. The results for this metric can be seen on the right‐hand side in Figure 1. Note that the sparsity values are shown from 50% instead of 75%, because of a lack of datapoints for the PGExplainer on the 75‐80% interval. Figure 1 shows that the RCExplainer has the highest performance of the models, corresponding to the findings of the original authors. However, the performance of the RCExp‐NoLDB and PGExplainer in Figure 1 is significantly lower than in the original authors’ paper. As mentioned in Section 4.3.1, we use the hyperparameters as specified in the origi‐ nal paper. For comparison, the model was also evaluated using the hyperparameters mentioned in the README file of the codebase, changing the parameters µ, λ and β in the loss function. The corresponding results are reported in Appendix 11 and show that changing the hyperparameters significantly affects performance. Therefore, we hy‐ pothesise that the hyperparameters are the reason for the performance discrepancies as seen in Figure 1.
Robustness The robustness of amodel ismeasuredbyhowmuchan explanation changes after noise is added to the input graphs. The graphs are modified by adding random
ReScience C 8.2 (#45) – Wilschut et al. 2022 7
noise to the node features and randomly adding or deleting edges. The produced expla‐ nation of each noisy input graph is compared to the ground truth, the k best (top-k) edges of the explanation of the unmodified graph, by computing a ROC curve and computing the AUC of this ROC curve. The higher the AUC score of the model, the more robust it is. Each model is evaluated for different levels of noise, measured in the percentage of nodes and edges that are modified, ranging from 0% to 30%. The results are shown on the right‐hand side of Figure 2. It shows that the re‐trained RCExplainer performs the best for almost all noise values. This corresponds with the findings in the original paper. However, similar to the fidelity results, the results of the RCExp‐NoLDB and PGExplainer are much lower than shown in the original author’s paper. We again hypothesise that this is explained by the hyperparameter tuning, following the same reasoning as in the previous paragraph.
Efficiency The original authors claim their method is at least as efficient as previous methods, and report a 0.01s± 0.02 execution time to produce a single explanation. Our experiments show a 0.007s ± 0.0006 execution time. This slight difference is likely due to differences in hardware platform and library versions. So, while unable to compare the performance of the RCExplainer model to other explainers, regarding their time efficiency, wewere able to achieve results in linewith the findings of the original authors on the run time of the RCExplainer model.
ReScience C 8.2 (#45) – Wilschut et al. 2022 8
5.2 Results beyond original paper As mentioned in section 4.3.1, the RCExplainer is evaluated using data that has already been encountered during training. Therefore, all models have also been evaluated on fidelity and robustness with a train‐test split to see the effect of this experimental setup. Figure 1 and 2 show the results of these evaluations, where the 80/20% split is shown on the left side and the 100/100% on the right side. For both metrics, the figures show no significant differences. This lack of difference is likely because the explainer model is trained to explain the GNN, not the data, and therefore a train‐test split does not seem to have a significant influence on the performance for training the explainer models.
5.3 Extension This section discusses the results of our extensions to the original method. First, the results of the extension to a newdomain are presented in Section 5.3.1. Then, the results of two additional AUC computations are reported in Section 3.
MNISTSuperpixels — In order to determine whether the claims of the original authors also extend to other domains, we measured the fidelity performance and noise robustness of the RCExplainer on the MNISTSuperpixels dataset (see Figure 3). To compare these curves, the same evaluation is also performed using the PGExplainer.
Fidelity Figure 3 show that both models achieve high fidelity, especially for sparsity lower than 90%, indicating that both methods saturate the task, achieving near‐optimal performance. The explainers have been trained using a 100/100% train‐test split following the original paper. While this makes it significantly easier to saturate performance on the test set, as the samples are seen during training, results on other datasets in Section 5.1 show no clear difference between a more conventional train‐test split and evaluating on the full set. Therefore, we hypothesise that the explainers still generalise well to this domain. Performing this evaluation with a split of 80/20% is still preferred, but not feasible in this reproduction study due to the long training time of the models. We speculate that the decrease in fidelity for higher sparsity levels is likely not due to the model’s ability to select explanations, but rather because the explanations are smaller as the sparsity level increases. As they become smaller, the counterfactual graph is more similar to the original graph retaining the same prediction. While unable to verify the performance advantage of the RCExplainer over the PGExplainer in this domain, we can verify its ability to generalise to new domains.
ReScience C 8.2 (#45) – Wilschut et al. 2022 9
Robustness In contrast to the fidelity performance, the noise robustness shows a clear difference according to Figure 3. This difference could be caused due to an inherent difference in robustness threshold in the MNISTSuperpixel dataset compared to Muta‐ genicity. As not every pixel in an image is essential, and even with large parts missing, it is still possible to correctly classify an image. The PGExplainer is more robust to noise, remaining close to the original explanation, evenwith noisy input graphs. However, the performance of the RCExplainer falls short, and the method appears to be less robust to noise in this domain.
AUC computation —When examining the implementation of the AUC computation we found this was adjusted when compared to the standard definition of the AUC‐score, without motivation, leaving us unsure of these adjustments. The AUC‐score is used to compare the accuracy of S′ to S, where S′ is produced from noisy input graphs to evalu‐ ate robustness to this noise. The explanation problem is formulated as a binary classifi‐ cation problem. For this classification, the original authors only consider true positives and false positives when measuring the AUC, discarding the false negatives and giving the metric a positive bias. A false negative could occur when an edge in S is no longer in S′, for example, when S′ covers a different part of the original graph. If the explainer producingS′ is not robust to noise, its AUC score could be incorrectly high if it only produces a subset of the ground truth explanation S. This means, under noisy circumstances, an explainer only has to predict a single correct edge to attain a perfect AUC score, instead of predicting the full ground truth. Therefore, false negatives appear to provide important information. True negatives are also discarded, but while their inclusion is standard practice, they only add information about the size of the graph compared to the explanation. When evaluating robustness, this is not as relevant and mostly reduces the difference between the scores. Hence, we compared the originalmethod and the inclusion of the false negatives, shown in Appendix 7. For the highest noise percentage, this yields an 0.895% AUC score de‐ crease. While this means the original method includes a slight positive bias, a bias is also present in the other explanation methods as the same evaluation code is used. Our foremost concern would be the comparison to other papers, where the metric might be implemented differently. We, therefore, chose to retain the original AUC computation method, as the bias is small and we prefer to retain the ability to compare our results to the original paper.
6 Discussion
This paper is a reproduction study of Robust Counterfactual Explanations on Graph Neural Networks [1]. We were partly able to reproduce the original authors’ claims that their model produces more counterfactual explanations, is more robust to noise and is at least as time‐efficient. The RCExplainer showed equal results, while the RCExp‐NoLDB and PGExplainer differed, which we hypothesise is because of the hyperparameters. For our reproduction paper, we only employed the experiments on the Mutagenicity dataset, and compared it solely to the RCExp‐NoLDB and the PGExplainer, due to time constraints. Moreover, the results of the experiments have been obtained for 10 different seeds. Additionally, multiple extensions were performed to validate the experimental setup of the original paper and apply the model to the image domain."
"['Doğa Yılmaz', 'Furkan Kınlı', 'Barış Özcan', 'Furkan Kıraç']",[Re] Lifting 2D StyleGAN for 3D-Aware Face Generation,10.5281/zenodo.6574719,Replication,Python,https://zenodo.org/record/6574719/files/article.pdf,face generation generative networks machine learning rescience c,https://openreview.net/forum?id=BcNonfQ3RY,https://github.com/yilmazdoga/lifting-2d-stylegan-for-3d-aware-face-generation,8,2,2022,"In this study, we present our results and experience during replicating the paper titled ”Lifting 2D StyleGAN for 3D-Aware Face Generation” [1]. Thiswork proposes amodel, called LiftedGAN, that disentangles the latent space of StyleGAN2 [2] into texture, shape, viewpoint, lighting components and utilizes those components to render novel synthetic images. This approach claims to enable the ability of manipulating viewpoint and lighting components separately without altering other features of the image. We have trained the proposed model in PyTorch [3], and have conducted all experiments presented in the original work. Thereafter, we have written the evaluation code from scratch. Our re-implementation enables us to better compare different models inferring on the same latent vector input. Wewere able to reproducemost of the results presented in the original paper both qualitatively and quantitatively.","The paper is well‐written. The main components of the LiftedGAN was open‐source, and implemented in PyTorch, which facilitated our reproduction study.","3D evaluation and reconstruction scripts were not available in the official repository. Also, there were some missing implementation details to reproduce some results in the original work.
Communication with original authors Wewere in contact with the authors since the beginning of the challenge. We could not achieve to reproduce 3D evaluation and reconstruction parts, fortunately, the authors swiftly answered our questions regarding the topic.
1 Introduction
The paper [1] proposes a framework that disentangles the latent space of a pre‐trained StyleGAN2 [2] for 3D‐aware face generation. The previous approaches are trained to generate random faces, thus they do not offer direct manipulation over the semantic attributes such as lighting or pose in the generated image. A number of studies exists that aims to manipulate the semantic attributes of the generated images directly [7, 8, 9, 10, 11]. Although these feature manipulation methods have shown ability to generate faces with high visual quality under assigned poses, it is unclear whether other features such as identity are preserved when we change the pose parameters. In the paper [1], to overcome this problem, a pre‐trained StyleGAN2 is distilled into a 3D‐aware generator, which outputs the generated image with its viewpoints, light direction and 3D informa‐ tion. The framework proposed in the original paper [1], namely LiftedGAN, is composed of five sub‐networks that are responsible for light direction, viewpoint, foreground/back‐ ground map, depth, and texture components. These sub‐networks are than utilized to render a 2D face image. As the main claim of the paper, this method achieves to change the light direction and viewpoint without affecting the other important features such as texture and shape. In this reproducibility report, we studied LiftedGAN for generating and manipulating human and cat faces. During this work, we have implemented the testing loops for running the experiments on the same randomly generated latent vectors. We have also trained both the StyleGAN2 and LiftedGANmodels with different datasets from scratch. Furthermore, we present the results of the original work on different domains and com‐ pare the obtained results with the ones reported in the original paper. Finally, we report the important details about certain issues encountered during reproduction.
2 Scope of reproducibility
Themain idea of the paper is to train a 3D generative network by distilling the knowledge in StyleGAN2 for building a 3D generator that disentangles the generation process into different 3D modules. Afterwards, those modules are utilized to render a 2D face image. The proposed framework, namely LiftedGAN, claims to provide on‐par performance to the state‐of‐the‐art face generationmethods in termsof Fréchet InceptionDistance (FID) [12] score while providing the ability to change the viewpoint and light direction. To validate these claims, we try to investigate the following questions:
ReScience C 8.2 (#46) – Yılmaz et al. 2022 2
• Is the implementation details described in the paper and the provided code suffi‐ cient for replicating the quantitative results reported in the paper?
• Are the qualitative results visually‐plausible?
• Could our replication obtain similar qualitative results compared to the reported qualitative results in the original paper?
• Could our replication obtain similar FID scores compared to the reported results in the original paper?
• How does the architecture perform when trained on other datasets (e.g., CelebA)?
3 Methodology
We have adopted the code for the architecture and the training loop from the official repository of the paper. Due to the nature of both StyleGAN2 and LiftedGAN, the frame‐ work samples a random latent vector from the latent space and uses that vector to gener‐ ate a new face. This makes comparing the original and reproduced results not possible by using the original code, since the generated face is changed for each trial as we run the original test loop. To overcome this issue, we have written a modified version of the original testing loop that stores the randomly generated latent vector and provides it to different versions of the LiftedGAN model. At this point, we found that the paper is well‐written, and contains the details required to reproduce the most of the qualitative and some of the quantitative results. Since the official repository of the paper is publicly available, we mainly focused on reproduc‐ ing the original experiments in a controlled manner and extending the experiments on different datasets to further validate the claims made by the original paper. In this section, we introduce the implementation details of LiftedGAN, the points in the paper which were important for reproduction, hyperparameters we used, and our experimental setup.
3.1 Model descriptions The main idea of LiftedGAN is to train a 3D generative network by leveraging the knowl‐ edge in pre‐trained StyleGAN2. The StyleGAN2 network is composed of two parts: a multi‐layer perceptron (MLP) that maps a latent code z ∈ Z to a style codew ∈ W , and a
ReScience C 8.2 (#46) – Yılmaz et al. 2022 3
2D generator G2D that synthesizes a face image from the style code w. LiftedGAN aims to build a 3D generator that disentangles the generation process ofG2D into different 3D modules, including texture, shape, lighting and pose, which are then utilized to render a 2D face image. As shown in the Figure 1, the framework involves two pathways, which are the reconstruction pathway and style manipulation (i.e.. perturbation) pathway.
3D Generator — As shown in Figure 1, the 3D generator, denoted as G3D, is composed of five trainable sub‐networks: DV , DL, DS, DT , M , a pre‐trained StyleGAN2 G2D and a differentiable renderer R. M is used as style manipulation network that transfers a style code Ŵ to a new style code with a specified lighting and viewpoint. This approach creates w0 = M(ŵ, L0, V0) thus, G2D(w0) outputs a lighting and viewpoint neutralized face image. The rest of the sub‐networks DV , DL, DS, DT are responsible from the viewpoint, lighting, depth and shape representation, respectively. Finally, R is used to output a rendered image Iw = R(A,S, T, V, L) where A is the face image with neutral viewpoint and lighting, S, T , V , L are the depth, shape representation, desired view‐ point and desired lighting, respectively.
Loss Functions — As mentioned in Section 3.1, the framework has two pathways for face reconstruction and style manipulation. As shown in Figure 1, the reconstruction path‐ way uses L1 loss whereas the style manipulation pathway uses the perturbation loss. The overall reconstruction loss function consists of five objective functions, which are reconstruction loss Lrec, photometric flip loss Lflip, perturbation loss Lperturb, identity variance loss, Lidt and albedo map loss LregA . Overall loss function and its each compo‐ nent are defined below. Reconstruction loss is defined as following:
Lrec = ||Iw − Îw||1 + λpercLperc(Iw, Îw) (1)
where Lperc refers to the perceptual loss [13] using a pre‐trained VGG‐16 network [14], Îw is the proxy image output by StyleGAN2 and Iw is the image rendered byR. Lflip has the same formulation as Lrec except that it uses flipped albedo and shape maps during the rendering. Perturbation loss is defined as following:
LLVcyc = ||Ṽ ′ − V ′||2 + ||L̃′ − L′||2 (2)
L (a) perturb = d(I ′ w, G2D(w
′)) + β ||w′ − µw||2
2σ2w (3)
L (b) perturb = d(R(A,S, T, V ′, L′), Î ′w) + λLVcycLLVcyc (4)
Lperturb = L (a) perturb + L (a) perturb (5)
where ŵ is a randomly sampled style code, w′ is the manipulated style code, Îw′ rep‐ resents the proxy image generated by the manipulated style code, V ′ and L′ are the randomly sampled viewpoint and lighting vectors, Ṽ ′ = DV (w′) and L̃′ = DL(w′). Also, µw is the empirical mean and σw is the standard deviation of randomly generated style codes. I ′w is the rotated and relighted face image output generated by R(A,S, T, V ′, L′). Identity variance loss component is defined as following:
Lidt = ||f(Iw0)− f(I ′w)||2 (6)
where Iw0 is the texture map and f is a pre‐trained face recognition network. Albedo map loss component LregA is also defined as following:
LregA = ||KA||∗ (7)
ReScience C 8.2 (#46) – Yılmaz et al. 2022 4
where K is the albedo matrix that is composed of filtered and vectorized albedo maps and ||.||∗ denotes the nuclear norm. The overall loss function for the 3D generator used in the reconstruction pathway is as following:
LG3D = λrecLrec + λflipLflip + λperturbLperturb + λidtLidt + λregALregA (8)
3.2 Hyper-parameters The hyper‐parameters used in the original work are mostly the objective function co‐ efficients, and the default values mentioned in their paper are presented in Table 1. During our additional experiments on CelebA, we have followed the same settings that the authors used for FFHQ. We have also considered the batch size and learning rate as hyper‐parameters, and they are set to 8 and 1e−4, respectively for all of our experiments.
3.3 Datasets Following the paper, we have conducted our experiments on two well‐known datasets: FFHQ, AFHQ Cat. The original paper uses FFHQ for training the StyleGAN2, and the original LiftedGAN framework uses the generated data from the pre‐trained StyleGAN2. Moreover, in the original work, AFHQ Cat is used to validate the performance of the architecture on a different domain. In addition to FFHQ, we have also conducted ad‐ ditional experiments on CelebA dataset to further validate the generalization ability of LiftedGAN. The details are provided in Table 1.
Quadro RTX 6000. The second one has Intel 3770K CPU, 8 GB RAM and 2x Nvidia GTX 1080. StyleGAN2 trainings for our custom datasets have been conducted in our second ma‐ chine, and take approximately 2‐3 days to be completed, whereas LiftedGAN trainings have been conducted on our first machine, and completed in ∼1 day. The experiments we conducted for reproducing this work do not require any other significant resources, but GPU memory.
4 Results
Wehave conducted all experiments by following the descriptions given in the paper. We re‐implemented the test scripts that enables us to run two different models on a single latent vector. In general, we were able to reproduce the quantitative and qualitative re‐ sults on FFHQ and AFHQ Cat datasets. We extend the results of AFHQ Cat presented in the original work by conducting the lighting and viewpoint (i.e. pitch) manipulation. Moreover, we extend the experiments given in the original work by training the Lift‐ edGAN from scratch and testing it on CelebA.
4.1 Results reproducing the original work
Qualitative results — As shown in Figure 2, we have achieved visually on‐par face gener‐ ation performance on FFHQ. Although there are slight differences in our results com‐ pared to the results presented in the original work (e.g., the absence of glasses in the second column and the first row), they do not reduce the face generation quality and the identical features for all samples are mostly preserved. We provide more face gener‐ ation examples for more extensive comparison in our supplementary materials and the reproduction repository. Figure 3 demonstrates the comparison of the viewpoint rotation between the outputs obtained by using the weights given by the authors and the outputs reproduced by our work. At this point, we validate that LiftedGAN achieves to change the viewpoints in the generated images without affecting the other visual features. Moreover, in Figure 4, we show both qualitative results of the original work and our reproduction study on chang‐ ing the direction of the light source task on FFHQ dataset. We can state that LiftedGAN also achieves to change the direction of the light source in generated images. In our study, we were able to reproduce these results. In the originalwork, the examples of face generation results between interpolated latent codes are demonstrated. The main claim in the paper is that LiftedGAN can achieve a smooth change between two disparate samples. To validate this claim, we have gener‐ ated the face images by using the interpolated latent codes, and observed the effect of the viewpoint rotation strategy, as in the original work. Our reproduced weights can
ReScience C 8.2 (#46) – Yılmaz et al. 2022 6
generate similar faces to the ones produced by the original weights with the same view‐ point rotations, as presented in Figure 6. Qualitative results of the ablation study for our reproduction are shown in Figure 5. We also provide more visual examples for all these additional experiments in our supple‐ mentary materials and the reproduction repository.
Quantitative results — In this section, we present our quantitative results of this reproduc‐ tion study in Table 3, and compare with the ones reported in the original work. The authors have conducted several ablation studies on FFHQ. Particularly, they remove symmetric reconstruction loss (i.e., wo_flip), perturbation loss (i.e., wo_perturb), identity regularization loss (i.e., wo_idt) and albedo consistency loss (i.e., wo_rega), respectively, to re‐train their proposed architecture for further comparison. Our reproduced results have lower FID scores than the ones reported in the paper, as well as all ablation studies. As claimed in the original work, the model cannot produce visually‐plausible and logi‐ cally reasonable shapes for the generated faces, and this can be observedmore dramati‐ cally in our reproduced results. Moreover, we additionally measure the performance of the proposed architecture and its variants on AFHQ, which is not reported in the orig‐ inal work. We obtain more similar quantitative results for the reproduction on AFHQ Cat dataset.
4.2 Results beyond the original work
Extended experiments on AFHQ — In the original work, a controlled generation strategy on cat headshas been followed in order to demonstrate that the framework is object‐agnostic. However, this experiment is limited, and conducted on only the viewpointmanipulation on yaw axis. We present the visual results of our controlled generation on cat heads in Figure 7 (for the viewpoint manipulation in yaw and pitch axes) and in Figure 8 (for changing the light direction). At this point, we can validate that the framework is able to work well on different objects, not only human faces.
The performance on CelebA — To extend the scope of the experiments in the original work, and validate the generalization ability of the architecture, we have re‐trained the frame‐ work from scratch on CelebA. The visual results of this experiment can be seen in Figure 9. Themain observations for this experiment are as follows: (1) the overall performance is similar to the one for FFHQ, (2) the outputs for the face generation is visually‐plausible, (3) the viewpointmanipulation can be achieved on this dataset, (4) there are some visual artifacts in the outputs for the task of changing the light direction.
ReScience C 8.2 (#46) – Yılmaz et al. 2022 8
5 Discussion
We can clearly say that the paper reproduced was well‐written. Although there are a few missing implementation details in the paper and a few missing evaluation scripts in the official repository, we were able to reproduce the results reported in the original work on a large scale. Overall, we were able to obtain similar qualitative results when compared to the original work. Our results are visually‐plausible. The quantitative re‐ sults do not exactly match with the reported results, but eventually not very far from them. In addition to these results, we demonstrate the reproduced results of the view‐ point rotation on yaw and pitch axes and changing the light direction tasks, the visual results of the ablation study and the task of generating interpolated and rotated faces. We extend the experiments on AFHQ Cat dataset, and also observe the performance of the proposed methodology on an additional dataset (i.e., CelebA).
5.1 What was easy The code was open‐source, and implemented in PyTorch, hence adopting the training loop and model implementation facilitated our reproduction study. The provided pre‐ trained StyleGAN2 weights significantly reduced our required GPU hours for FFHQ ex‐ periments.
5.2 What was difficult Since the 3D evaluation and reconstruction scripts are not available in the official reposi‐ tory and not describedwith enough detail in the original paper to reproduce it, we could not achieve to reproduce the results related to 3D reconstruction metric.
ReScience C 8.2 (#46) – Yılmaz et al. 2022 9
5.3 Communication with original authors Wewere in contact with the authors since the beginning of the challenge. We could not succeed to reproduce the 3D reconstruction task, fortunately, they swiftly answered our questions, and provided more information for reproducing the task."
['Urša Zrimšek'],[Re] Learning Unknown from Correlations: Graph Neural Network for Inter-novel-protein Interaction Prediction,10.5281/zenodo.6574721,Replication,Python,https://zenodo.org/record/6574721/files/article.pdf,multi-type inter-novel-protein interaction graph neural networks fair evaluation python rescience c replication machine learning,https://openreview.net/forum?id=Hc8GOhfmhRF,https://github.com/zrimseku/Reproducibility-Challenge,8,2,2022,"In the paper the authors propose a new evaluation that respects inter‐novel‐protein in‐ teractions, and also a new method, that significantly outperforms previous PPI meth‐ ods, especially under this new evaluation. Therefore we will first inspect if this kind of evaluation is objectively better, and secondly, we will try to reproduce the results of the proposed model in comparison with previous state‐of‐the‐art, PIPR [2].","It was easy to run GNN‐PPI code on different datasets and with different parameters, as their repository is nicely organized and the code is clearly structured. It was also easy to understand their idea of the problem, the reasons for new evaluation and the framework of their proposed model.","In both models used in this reproduction, the environment setup was harder than ex‐ pected. There was no documentation or comments in the code, which made it hard at first to understand it. Some debugging was needed for GNN‐PPI and a lot of code changes for PIPR to train well.
Communication with original authors We communicated with authors through email. They provided some useful clarifica‐ tions of the method and pipeline.
ReScience C 8.2 (#47) – Zrimšek 2022 2
2 Introduction
The study ofmulti‐type Protein‐Protein Interaction (PPI) is fundamental for understand‐ ing biological processes from a systematic perspective and revealing disease mecha‐ nisms. Existing methods suffer from significant performance degradation when tested on different dataset, that was not used for training (in comparison to only dividing one dataset into train and test set). In this paper, authors investigate the problem and find that it is mainly attributed to the poor performance for inter‐novel‐protein interaction prediction. However, current evaluations overlook the inter‐novel‐protein interactions, and thus fail to give an instructive assessment. As a result, theypropose to address theproblem fromboth the evaluation and themethod‐ ology. Firstly, they design a new evaluation framework that fully respects the inter‐ novel‐protein interactions and gives consistent assessment across datasets. Secondly, they propose a graph neural network based method (GNN‐PPI), that uses correlations between proteins for better inter‐novel‐protein interaction prediction. Experimental re‐ sults on real‐world datasets of different scales demonstrate that GNN‐PPI significantly outperforms state‐of‐the‐art PPI predictionmethods, especially for the inter‐novel‐protein interaction prediction.
3 Scope of reproducibility
Since authors propose a new evaluation framework, our first task will be to critically inspect their methodology, that is based on different construction of train and test sets. We need to confirm that this kind of dataset splitting is objectively better and mimics the real world problem that they are trying to solve. Secondly, we will try to reproduce experimental results on real‐world datasets of differ‐ ent scales, that were shown in the paper. The authors compare their model to a series of baseline algorithms, some Machine Learning based models (Support Vector Machines, Random Forest and Linear Regression) and some Deep Learning basedmodels (PIPR [2], DNN‐PPI [3] and DPPI [4]). Since most of the author claims were made on comparisons of GNN‐PPI with PIPR, we will try to reproduce those. The main claims of the original paper, that we will test are the following:
1. GNN‐PPI has higher micro‐F1 score than PIPR on SHS27k, SHS148k and STRING datasets, using random, BFS or DFS testset construction strategies.
2. GNN‐PPI predicts inter‐novel‐protein interaction better than PIPR on the same datasets and testset construction strategies as in claim above.
3. Test performance on trainset‐homologous testset (trained and tested on same set: SHS27k or SHS148k) underBFS andDFSpartition schemes reflects theperformance of generalizing knowledge to unseen testset (trained on SHS27k or SHS148k and tested on STRING) better than using random partition scheme – micro‐F1 scores are more similar, when training and testing GNN‐PPI on data split in such way.
4. If we construct the PPI network in GNN‐PPI only from the trainset, the micro‐F1 score is still better than the one of PIPR. This shows that the trained model is robust to newly discovered proteins and their interactions.
4 Methodology
For the reproduction we used authors code, slightly changing the pipeline for automa‐ tization of multiple runs with different seeds. We also used PIPR code, where we com‐ pletely changed the pipeline, to be able to use it on the same datasets as GNN‐PPI. We
ReScience C 8.2 (#47) – Zrimšek 2022 3
only used their function build_model, in which we changed last layer activation func‐ tion from softmax to sigmoid, because otherwise the model failed in predicting multiple interaction types.
4.1 Model descriptions In our experiments we used the author’s model, GNN‐PPI and the previous state‐of‐the‐ art for multi‐type protein interaction prediction, PIPR.
GNN-PPI — GNN‐PPI is a graph neural network based method that uses correlation be‐ tween two protein features to predict multiple types of their interaction. Pairwise inter‐ action data are firstly assembled to build the graph, where proteins serve as the nodes and interactions as the edges. The model is developed by constructing an embedding for each protein to obtain predefined features, then processed by Convolution, Pooling, BiGRU and FCmodules (it is called GIN network) to extract protein‐independent encod‐ ing (PIE) features, which are aggregated by graph convolutions and arrive at protein‐ graph encoding (PGE) features. Embeddings are pretrained for each amino‐acid and combined for the proteins by their amino‐acid sequences. The last is Multi‐label PPI prediction. For unknown PPIs, we combine their protein feature encoded by the pre‐ vious process with a dot product, and then use a fully connected layer as classifier for multi‐label PPI prediction. For optimization the authors use Adam optimizer.
PIPR — PIPR employs a Siamese architecture of residual RCNN encoder to better appre‐ hend and utilize the mutual influence of two sequences. It uses the same pretrained embeddings as GNN‐PPI, which are then send through the RCNN, fromwhich we get se‐ quence embedding vectors. This are multiplied with a dot product to form a sequence pair vector. Finally, this sequence pair vector is fed into a multi layer fully connected network with categorical cross‐entropy loss function, to predict the multi‐label PPI pre‐ diction.
4.2 Datasets We trained and tested this two models on three different databases (and their combina‐ tions):
1. STRING: this database collected, scored, and integrated most publicly available sources of protein‐protein interaction information and built a comprehensive and objective global PPI network, including direct (physical) and indirect (functional) interactions. In this paper, we focus on the multi‐type classification of PPI by STRING. It divides PPI into 7 types: reaction, binding, post‐translational modifi‐ cations (ptmod), activation, inhibition, catalysis, and expression. Each pair of in‐ teracting proteins contains at least one of them. We use all PPIs of Homo sapiens, which contains 15,335 proteins and 593,397 PPIs.
2. SHS27k: randomly selected 1690 proteins of Homo sapiens subset of STRING, that have 7624 PPIs between them.
3. SHS148k: randomly selected 5189 proteins ofHomo sapiens subset of STRING, that have 44488 PPIs between them.
The interactions from the datasets were combined into labels, so thatmultiple lines that represent different types of interactions between two proteins are combined into one datapoint, where label is a vector of length 7 (number of interaction types) with ones on the indices of interactions that are present and zeros elsewhere.
ReScience C 8.2 (#47) – Zrimšek 2022 4
The authors split datasets so that the test set contained 20%of the interactions. Splitting schemes will be described in the experimental setup more thoroughly, as their evalua‐ tion approach was one of their main contributions to the field. Whole datasets are avail‐ able on the authors GitHub repository, and the combined ones, used for PIPR training can be found on our repository.
4.3 Hyperparameters For GNN‐PPI we used the hyperparameters that authors described in Table 10 in the paper. The only change was setting batch size to 2048 when training on STRING dataset, as that was much faster, and the authors also used that in the code on their repository. For PIPR we did a manual hyperparameter search, to find the parameters where the model works best. We tried different batch sizes, 64, 128, 256, 512, 1024 and 2048; differ‐ ent learning rates, 0.1, 0.01, 0.001 and 0.0001; numbers of epochs, 100, 200 and 300; and RMSprop and Adam optimizers. As the training takes a lot of time, we didn’t train the model until the end for all options. With batch sizes, we fully trained it only on smaller datasets and compare the results. We saw that smaller batch size slows the training time a lot, so when using it, we needed to lower the number of epochs. For SHS27k, we saw that it is better to train for 200 epochs with batch size 128, than to do less epochs with batch size 64 (or more with bigger batch size), so we chose this combination. For SHS148k batch size 256 gave better results than 128, and with bigger performance fell. On STRING, the only option was to take batch size 1024, as others were too slow, and with 2048 training also slowed, because we ran out of memory on GPU. Here we only did 100 epochs, because after that, we couldn’t use the GPU anymore. We set optimizer to Adam after it proved better on couple runs on the smallest dataset. Learning rate was set just based on first couple epochs (10‐20), as we quickly saw that with 0.0001 the train‐ ing loss hardly even falls, and that with 0.01 and 0.1 it only falls at the beginning, and after couple of epochs, the model stops learning. So we set it to 0.001 for all datasets.
4.4 Experimental setup and code One of the main authors claims is that the usual evaluation scheme (randomly spliting the interactions into train and test set) is not correct from the protein interaction point of view. The result of such split is, that the majority of the proteins were already seen during training, and it is much easier to predict the interactions for such proteins, then for some completely new. To show this, they separate the test set into three subsets: XBS denotes interactions where both proteins were already seen during training, XES denotes those where one protein was seen, and XNS those interactions, where both proteins are first seen in test phase. In the random testset construction, the XNS set is almost empty (which can be also seen in Table 3), meaning that the testing is not representative for new proteins. To solve this, authors propose two new strategies, Breath‐First Search (BFS) and Depth‐ First Search (DFS), where the testset is constructed by firstly selecting the root node and then performing the proposed BFS or DFS strategy to select other nodes for the test set (0.2 of the whole dataset in our experiments). As they more thoroughly explained in the paper, these strategies seem to mimic the real world case, where some new cluster of proteins, that tightly interact with each other, is found (BFS) or we just have some new proteins distributed around the previously known network (DFS). As the authors did in the paper, we then compared the models based on their micro‐ averaged F1 score (which is the same as the accuracy giving each sample the same im‐ portance). We repeated the experiments 5 times where it wasn’t too computationally expensive, to get the uncertainty and see how reliable our results are. We were not able to do multiple runs on STRING dataset for each setting, as each run was very expen‐ sive, but we believe that the uncertainty here would be very small, as we have a very big dataset. The code for all our experiments is available on this repository.
ReScience C 8.2 (#47) – Zrimšek 2022 5
Training time [min] Testing time [s]
SHS27k SHS148k STRING SHS27k SHS148k STRING
GNN‐PPI 11 63 1064 0.2 1.2 44 PIPR 36 135 602 5 23 291
5 Results
In this section we will present the results of the experiments that we did to support the claims above. Our results were in some parts far from the authors results, but even so, they support the main claims of the original paper.
5.1 Comparison of GNN-PPI and PIPR Results in this subsection refer to our first two claims. In Table 3 we can see the com‐ parison of the models in question on all three datasets, trained and tested with all three partition schemes. For first two datasets we ran the experiments 5 times, with 5 differ‐ ent random seeds, to see how the performance changes on different sets. We can see that especially for SHS27k the standard deviation for bfs and dfs splits is very big, which also explain why our results are at some points quite far from the authors. For STRING, multiple runs were too expensive, so we only trained and tested once. But this should be enough to asses the authors claims, because the dataset is so much larger, that the randomness of the split effects the performance less. The comparison of general performance, that refers to the first claim, can be seen if we look at the micro‐F1 score averaged across whole dataset (column average). Except for BFS mode on the smallest dataset, where uncertainty is too big, we can confirm that in all other cases GNN‐PPI performs better. The second claim is that GNN‐PPI predicts inter‐novel‐protein interactions better. The subsets we are observing are denoted with bs, standing for both proteins being seen
ReScience C 8.2 (#47) – Zrimšek 2022 6
during training, es, either of the proteins seen during training and ns, neither of the proteins seen before. So for the second claim, we need to compare the performance on subsets es and ns. The results in the table are in bold where uncertainty is small enough that we can confirm it. We can also observe that even where it is not, mean is never bigger for PIPR.
5.2 Generalization performance In this subsectionwewill inspect the third claim, that says that with the newly proposed evaluation protocol, we are better assessing the models generalization abilities. To test that, authors trained both models (we will reproduce results for GNN‐PPI) on SHS27k and SHS148k datasets and tested them on the bigger STRING dataset. The test sets of both smaller datasets were now used as validation sets during training, to determine themodel fromwhich epoch should be taken as best. The authors then compared these to the results on trainset‐homologous testset (here authors don’t use validation during training, as they use that set for testing). The results in Table 4 confirm claim 3. As we can see generalizing accuracy severely drops when using random partition scheme (∼ 0.2). With newly proposed schemes we get similar, sometimes even better performance when testing on STRING set.
5.3 Robustness for unknown proteins In Table 5 we have the comparison of different PPI graph construction methods ‐ GCA means that the PPI graph was constructed from all proteins in the dataset, and GCT means that PPI graph was constructed only form the proteins in the train set. This re‐ sults confirm claim 4, but in a different way as those in the original paper. It is true that the performance with GCT construction method is still better than PIPR method, but contrary to authors results, we get even better performance from the GCT construction method than with GCA.
6 Discussion
New evaluation protocol which proves superiority of a newly proposed model could be questionable, because the authors would only select a new evaluation that speaks for their model. But in this case, they also compared themodels by random strategy, which is the previously used evaluation method. The new evaluation also has empirical stud‐ ies to support it and is based on the domain knowledge, so we think that the authors proposed a good framework that can be very useful in future research in this field as such performance prediction is more on par with real world situation. When comparing GNN‐PPI and PIPR model, we confirm that GNN‐PPI has better aver‐ age performance than PIPR. We should also observe, that the standard deviation for new partiton scheme BFS on the small dataset is too big for us to make certain claims. But we see that on the bigger dataset, it becomes smaller, so we can rely more on this evaluations. There is a bit less certainty when assessing second claim – comparing re‐ sults in columns XES and XNS from Table 3. First let’s observe that the size of XNS is to small in random partition scheme for all datasets, so we won’t compare models on it. Next, we see that with BFS split scheme, training useful models is much harder than for other two. We need a lot more data for models to perform well, and if we have it, then we can claim that GNN‐PPI performs better at least when one of the proteins in the pair is seen in training. For both unseen before, we can’t claim with enough certainty. So let’s say that we partially proved the second claim ‐ it holds for random and DFS scheme, and for BFS on bigger datasets. There is onemore shortcoming of our approach. We ran out of time to run 200 epochs of training PIPR on STRING dataset. If we had the time,
ReScience C 8.2 (#47) – Zrimšek 2022 7
the result could be better, and could potentially beat GNN‐PPI. We propose this to be checked in further reproduction. Ifwe compare absolute scores ofGNN‐PPIwith those that authors described in the paper, they vary quite a bit. This happens because the standard deviations are so big, and the authors might (could be unintentionally) chose the better results of their runs. Their in‐depth analysis on test subsets also didn’t include uncertainty, which is a problem, as we can see from our results that show that uncertainty is very big and so their results are not reliable. We confirmed that the new evaluation protocol is much better in assessing the models generalization abilities, which was the main problem of the field that the authors were trying to solve. An important thing to observe here is also that when using any model for prediction of PPI, we can use this evaluation protocol and predict its performance in much more detail. We know how many of the proteins that we are interested in are completely new, and how many were already known when training the model, so we can predict the performance separately for any new set, based on performances on test subsets BS, ES and NS. When comparing the robustness of predictions for unknown proteins, we need to ask ourselves why can we even use the GCA method, that actually uses test data in network construction during training. In most cases that would be a big mistake, but if we look from a protein perspective, this has a practical explanation. We could know which pro‐ tein exist, what amino‐acids they are built of, so we could put them into the network, but we wouldn’t know anything about their interactions yet. If we are interested into such proteins, than GCA evaluation will tell us more about our models performance. If we want to know how our model will perform for some newly discovered proteins, we need to inspect evaluation using GCT. In Table 5 we can see a big discrepancy with authors results. They were showing that with GCT the performance falls, which would be expected because we have less information, but in our case, the mean results are better with GCT construction. If we look at the standard deviations, we again see that the differences between results of multiple runs are big, so we can’t say with certainty that this results show that GCT is better than GCA. The reason for this could also just be different root node at splitting schemes, and therefore different clusters of unknown proteins. But in any case, it shows that the performance of GNN‐PPI with graph con‐ struction only from the trainset is much better than the performance of PIPR, which confirms the fourth claim and further proves the usefulness of GNN‐PPI. In this reproduction, we left out some parts of the paper that we think should be fur‐ ther verified. We only took PIPR model, and didn’t inspect the others for the same tasks. Except for overall performance, also authors didn’t compare themselves with other methods, but we believe that for saying that their model is state‐of‐the‐art in inter‐ novel‐protein interaction prediction, they should also inspect other models more thor‐ oughly. With a lot of trouble with setting up PIPR and long training times, we ran out of time for this additional experimentation. We also just superficially grasped the hy‐ perparameter selection for PIPR, and with proper grid search (that would require a lot of computing resources), we could also find better settings for it, or in other case, we could more confidently say that GNN‐PPI is better. We also left out the separate results for labels, and ablation study, for which there was no code, but since it could be easily implemented, we suggest it to be done in future. We didn’t do it because of time re‐ strictions, and because the authors said in our communications, that it was not the part of original paper, only an addition for requirements of the reviewer, included in arXiv version.
6.1 What was easy The easiest part of this reproduction was to understand the paper and it’s ideas. The authors motivate and describe the problem in an easy to understand way, supported by expressive graphics. They support the ideas with domain knowledge, which makes
ReScience C 8.2 (#47) – Zrimšek 2022 8
the paper much more insightful. The algorithm for GNN‐PPI is clearly described in the paper, so we believe that it would be possible to put it in code without major problems. But their code is also nicely structured and easy to run with various parameters, so we suggest you use it when in need for their method.
6.2 What was difficult For GNN‐PPI there was also no environment file, and in the environment descriptions, versions of some libraries were left out, so it took some time to set the environment cor‐ rectly. You can load the environment file from our repository, to avoid this problem. There was also no documentation of the authors code, so when inspecting the imple‐ mentation, it was difficult to recognize use of some variables. There was some minor debugging needed before the code ran smoothly. We couldn’t use the already trained models for any of our tasks. If we are least judging from their names, they were trained only using the train set, so only useful for checking the accuracy on test part of the same dataset. But this can’t be done, because they didn’t upload the split information, so we can’t build this exact test set. If we wanted to use the models on some other dataset, they would need to upload the model with best validation accuracy, as that one would probably be better. This were all minor problems compared to the difficulty of running the PIPR model. Their environment file was not useful, and the versions they described on repository were not compatible with each other, which meant that we spent a lot of time finding out which libraries we should load to run their code. The code was not documented and it was completely unreadable, so it was hard to even know what they were doing. In the end we only used the model building part, and wrote other parts ourselves. Even the building function needed some changes, because they used wrong activation function on the last layer for themodel to be able to learnmulti‐type prediction. Even its descrip‐ tion in their paper was not very explanatory, but the reason for that was probably that it wasn’t the main part of their research."
"['Waqas Ahmed', 'Sheeba Samuel']",[Re] Nondeterminism and Instability in Neural Network Optimization,10.5281/zenodo.6574623,Replication,Python,https://zenodo.org/record/6574623/files/article.pdf,rescience c machine learning deep learning python pytorch,https://openreview.net/forum?id=BNefkaG73At,https://github.com/wi25hoy/MLRC21_Nondeterminism,8,2,2022,"The claims of the paper [1] are threefold: (1) Summers and Dinneen1 made the surpris‐ ing yet intriguing discovery that all sources of nondeterminism exhibit a similar degree of variability in themodel performance of a neural network throughout the training pro‐ cess. (2) To explain this fact, they have identified model instability during training as the key factor contributing to this phenomenon. (3) They have also proposed two ap‐ proaches (Accelerated Ensembling [2] and Test‐Time Data Augmentation [3]) to mitigate the impact on run‐to‐run variability without incurring additional training costs. In the paper [1], the experiments were performed on two types of datasets (image classification and language modelling). However, due to the intensive training and time required for each experiment, we will only consider image classification for testing all three claims.","The authors havemade the source code publicly available in theGitLab repository. Even without extensive documentation, reimplementation of the experiments was straight‐ forward and required little effort. Moreover, the paper’s clearly presented details signif‐ icantly reduced the effort required to set up the experimental configurations. The use of regular neural network training and widely used datasets was the icing on the cake to follow the implementation. This allowed us to explore other new aspects of themethod.","Although the implementation was easy to comprehend and intuitive with the resources provided, the validation of some baselines proved to be computationally intensive and time‐consuming, requiringmultiple runs. In particular, the variability analysis required training 100models each for 500 epochs to verify the role of a single source of nondeter‐ minism. Nevertheless, we managed to maintain the original settings, but we could not run multiple iterations to gain more confidence in the results.
Communication with original authors At the beginning of our reproducibility study, we contacted the original authors once. The basic questions about the experimental settings were answered and the foundation for the rest of our experiments was laid. In addition, we also referred to their post and answers available on the OpenReview portal.
ReScience C 8.2 (#1) – Ahmed and Samuel 2022 2
1 Introduction
In the pursuit of reproducibility in Deep Learning, a key criterion is the elimination of sources of nondeterminism in model optimization. Random initialization of weights is considered the main source of nondeterminism [4], but other sources such as random shuffling of training data [5], random data augmentation [6], and even GPU libraries such as cuDNN also contribute [7] . These random parameters tend to initialize with a random value every time we train the model, even if we use the same source code. On the one hand, such randomization helps to achieve sound performance, but on the other hand, it leads to run‐to‐run variability. This causes difficulties in verifying and improving baselines. To have complete experimental control, a better understanding of these random components is required, which is why each independent model is trained multiple times as a standard practice. While this can solve the problem, it is extremely costly in terms of computational resources and time. The authors’ original work focused on quantifying the independent effect of each source of nondeterminism on model training. All different sources of nondeterminism were found to have similar effects on model variability. They also created an experimental protocol that used standard evaluation measures of model diversity and variability to capturemodel behaviour better. While developing a basicmechanismof understanding, they also discovered model instability as a major cause of run‐to‐run variability. To support this finding, experiments were conducted on image classification and language modeling datasets. In the end, two solutionswere proposed to reduce variabilitywithout additional costs.
2 Scope of reproducibility
1) First, we have attempted to replicate all three of the paper’s claims:
• Claim 1: All sources of nondeterminism have similar effects on model diversity and variability.
This claim seems to be a surprising discovery, as it could pave the way for researchers to improve the algorithm as a whole to reduce the effects of model variability, rather than focusing on each source of nondeterminism separately. In this reproducibility report, all sources of nondeterminism were tested individually and also in combination with other sources for ResNet‐14 [8] on the CIFAR‐10 dataset [9].
• Claim 2: The key driver of this phenomenon “All sources of non‐determinism have similar effects on model diversity and variability” is the instability of model opti‐ mization.
Model optimization is said to have instability where small changes to the initial parame‐ ters lead to large changes to the final parameter values. Simply put, changing the initial‐ ization of a single weight by the smallest possible amount of 10−10 has the same effect as initializing all weights with completely random values. This study shows that any source of nondeterminism is susceptible to a change in weights by at least 10−10 and therefore produces the same amount of variability. This also illuminates the discovery of [4], which shows that removing a single source of nondeterminism is not sufficient to improve the stability of the training.
• Claim 3: Accelerated ensembling and TTA are two possible solutions to reduce model variability without additional training costs (e.g., time).
As mentioned earlier, the standard practice to counter model variability is to train mod‐ els multiple times, which costs additional computational resources. This claim attracts
ReScience C 8.2 (#1) – Ahmed and Samuel 2022 3
our attention because it could change current practices and facilitate the reproducibil‐ ity of experiments in the context of Deep Learning by promoting deterministic training without additional costs.
2) Although the main objective of our study is to reproduce the main claims, we did not limit ourselves to these only. We have also conducted a series of experiments that go beyond the paper and follow two lines of investigation:
• Ablation study: During the reproducibility study, one of the main difficulties we faced was the excessive amount of time required to conduct a single experiment. In Section 4.2, we attempted to address this issue by recommending changes to the default settings supported by our experimental results, while keeping the main claims intact.
• Generalization to larger architectures and datasets: Because we were able to re‐ duce the experimental time, we tested the authors’ claim on a larger architecture and dataset to verify that the claim still holds in general.
3 Methodology
3.1 Code The publicly available source code was provided by the original authors in the corre‐ sponding GitHub repository . It was written using the Pytorch [10] and NumPy libraries with Python 3.7.5. We used the same code and made some adjustments, such as setting thewidth of the output terminal and downloading the datasetsmanually. With thesemi‐ nor changes, we were able to run the code according to our experimental environment. The code provides a basic structure that allows numerous architectures to be used with few changes. However, additional code must be added for architectures larger than ResNet‐18 [8]. The code also has command line functionality that allows the user to con‐ figure seed values and hyperparameter settings for a specific task. Although the code covers the entire implementation with the exact experimental settings described in the paper, a portion of the code is missing to visualize the results.
3.2 Model descriptions We initially chose the ResNet‐14 model because it was frequently used for image clas‐ sification experiments in the original study along with the CIFAR‐10 datasets. Due to the large number of trained models required for a single experiment, we did not have time to work with other models except ResNet‐34, which we created ourselves to test the generalization of the claim over larger model architectures. Figure 1 shows the ba‐ sic residual block of a ResNet architecture, consisting of two 3x3 convolutional layers followed by batch normalization before activation. On the same basis, Figure 3 shows the modular architecture of ResNet‐14 and ResNet‐34 [8] without the first 7x7 convolu‐ tional layer and the final fully‐connected layer. The blocks are shown in parentheses along with the number of output channels, with the multiplier indicating the number of residual blocks in that module.
3.3 Datasets To investigate the effects of nondeterminism on image classification, the authors used CIFAR‐10 as the primary training dataset to train the ResNet‐14 model. Because the ar‐ chitectures used in the original study were smaller, the use of CIFAR‐100 was not seen. In comparison, we additionally used the CIFAR‐100 dataset to train and test the larger
ReScience C 8.2 (#1) – Ahmed and Samuel 2022 4
architecture (ResNet‐34) in our extended study. It is worth noting that the authors used a runtime code to download the datasets using the torchvision library. Although this would have been the preferred choice, we encountered some issues due to the external access limitations of our experimental environment. Thus, we manually downloaded the dataset and specified the path, whichworkedwell for us. We used the authors’ proto‐ col for the training and testing portions with 50k samples and 10k samples of CIFAR‐10, respectively. No validation set was used. Table 1 shows the datasets used in our experi‐ mental tests.
3.4 Hyperparameters In training the models, all standard parameters were used as given in the paper to more closely approximate the original approach. While not all values were mentioned in the paper, they could be easily found in the code itself. Allmodelswere trainedwith a cosine learning rate decay [11] with a maximum learning rate of 0.40 and 500 epochs. We also
ReScience C 8.2 (#1) – Ahmed and Samuel 2022 5
used the first three epochs for warm‐up with linear learning rate, as was the case in the original study. Throughout the training, the SGD optimizer was used with a batch size of 512, a momentum of 0.9, and a weight decay of 5.10−4.
3.5 Evaluation for the effects of nondeterminism To understand the impact of each source of nondeterminism, the original study devel‐ oped a protocol related to performance variability and model diversity representation.
Performance variability: All random sources are controlled by seeding values. To test a single source, all other sources are assigned the constant deterministic seeding value of 1, except for the source that is under observation and assumes different seeding val‐ ues from 1 to the total number of training runs. For the sources that cannot be seeded, such as cuDNN, the range is limited to 0 to 1, with 0 and 1 indicating the random and deterministic values, respectively. In the original settings, the total number of training runs is set to 100, so for each source of nondeterminism, 100 models can be trained. If we assume 4 different sources, each can be represented as S1, S2, S3, and S4, where S denotes the seed values. For example, S1 denotes the seed for random parameter ini‐ tialization, S2 for training data shuffling, S3 for data augmentation, and S4 for cuDNN. If we set (S1 = 1, S2 = 1, S3 = R,S4 = 1), whereR denotes the range from 1 to the total number of training runs, we would analyse the effect of data augmentation as a random source. If we want to analyse the effects of multiple sources simultaneously, we would also assign the R values to other sources. Finally, to work with performance variability, we consider the standard deviation of accuracy and cross entropy across all 100 trained models for each source.
Representation diversity: In addition to performance variability, the authors also con‐ sidered the representation of the trained models. This allows us to determine the differ‐ ence in the representation of the trained models even when their performance variabil‐ ity is the same. In doing so, they used four different metrics that we followed. Of these, we did not find an implementation for the Centered Kernel Alignment (CKA) evaluation metric [12], which is considered the most advanced evaluation metric for determining similarities between models. The first metric is the simplest, which uses the average disagreement between pairs of 100 models. Second, they used the average correlation between the models’ predictions. Finally, they examined the change in performance when two models are ensembled from the same source of nondeterminism.
3.6 Extended experiments With the extended experiments, we have tried to eliminate the difficulties we encoun‐ tered in replicating the experiments to verify the paper’s claim. One of our main con‐ cerns was the time required for each experiment. Therefore, we performed a series of experiments beyond the original work to satisfy the claims without being computation‐ ally intensive.
Models v/s model variability: In this experiment, we examine the actual number of models required to test the variability analysis for each source of nondeterminism,which can reflect the same conclusion as the original settings while reducing the overall com‐ putational cost. Due to time constraints, we chose to work with only two sources. We varied the number of models for each source and observed the results using the same evaluation measures.
ReScience C 8.2 (#1) – Ahmed and Samuel 2022 6
Epochs v/s model variability: Another factor contributing to the long training time is the use of a large number of epochs. In this experiment, we investigate the effects of a different number of epochs on the variability of the model, and therefore try to obtain similar results with a smaller number of epochs.
3.7 Experimental setup and computational requirements To achieve similar results as in the original study, we strictly follow the same experi‐ mental environment and use Pytorch as frameworkwith Python = 3.7.5, NumPy = 1.17.4, Torch = 1.3.1 and Torchvision = 0.4.2. All experiments were performed on the HPC clus‐ ter ARA using the SLURMworkload manager at Friedrich Schiller University Jena. This system consists of multicore nodes for high computational performance and therefore offers a variety of GPU systems that can be used. According to our needs, we chose to workwith 2NVIDIATeslaV100GPUs equippedwith 24 core Intel CPUand 128GBofRAM. Table 2 shows the number of experiments performed and the time needed for them. It is worth mentioning that the evaluation part of all experiments involves the technique of TTA, which must also be performed on a GPU, so the time needed for the evaluation part is also added. The first three experiments belong to each of the three claims and the others are part of our extended study, which is not included in the original studies.
4 Results
In this sectionwe present our experimental results by replicating all three claims and go‐ ing beyond the paper [1]. First, we start with the core replication by following exactly in the footsteps of the original authors and producing all three experiments for each claim. Second, we ran threemore experiments that help us obtain the same resultsmuch faster and generalize the first two claims across different datasets and architectures.
4.1 Core replication results Effects of nondeterminism sources: Table 3 shows the result of our replication study for claim 1 with some minor differences as reported in [1]. In addition to all sources of nondeterminism, we performed additional deterministic training to verify that we have complete control over all sources and no other effects of randomness are observed during the training process unless otherwise noted. We trained all 100 models for each source, with 100 different seed values, as in the original work. We obtained almost the same results when we analysed the effect of each source separately. However, when the combination of multiple sources was tested, we found only a few anomalies (marked with red colour in Table 3), which ultimately appear to be negligible. Therefore, we support the claim that all sources of nondeterminism have similar effects on model variability and diversity.
ReScience C 8.2 (#1) – Ahmed and Samuel 2022 7
The effect of instability: Table 4 shows the result of the second claim. Note that the second claim states that instability in neural network optimization is the key factor for similar effects of nondeterminism sources on model variability. To observe the effects of instability, deterministic training was performed with a small change of 1 bit (5 × 10−10) in a single randomweight for 100models. Our results show that this 1‐bit change generates about as much variability as any other source of nondeterminism. Therefore, this claim can be considered confirmed by our experiment.
Reduction of variability with proposedmethods: In Table 6 we show the results of our replication study for the third claim. Unlike the other two claims, our study this time shows numerous differences in the results compared to the original study. The TTA and accelerated ensembling methods were used to reduce model variability, and the values were compared to the result obtained by combining all sources of nondeterminism pre‐ sented as a ”Single Model”. First, we found a computational error in the percentage of variability reduction in the original paper itself, which was taken as the average value for all 5 metrics compared to the single model. This measure would allow us to see the effectiveness of these two probable solutions. Although the mathematical formula is not given in the study, it seems intuitive to work with average values. Therefore, we performed a calculation of the baseline averages and found differences in the overall reduction percentages. For all reduction percentages, the values on paper appear to be about 20% higher than the calculated values. This is highlighted in red, as shown in Table 5. Second, in addition to the calculation error, we found other minor anomalies that ac‐ count for more than 10% change, as shown in Table 6 (highlighted in red). Including all minor differences, we have again shown that TTA and accelerated ensembling can be used to reduce variability. However, the highest possible percent reduction was re‐ duced from 61% to 51% compared to the original study. When compared to the recal‐ culated values, a slight increase in the percentage is observed. Moreover, the different types of TTA alone seem to cause an equal reduction in performance variability, while the change is mainly visible in model diversity. Thus, the overall variability is reduced. Despite these differences, the third claim remains and we therefore support it..
4.2 Additional results not present in the original paper In replicating all three claims, we faced the major problem of the time required to pro‐ duce the results. While it is understandable that the nature of the problem requires
ReScience C 8.2 (#1) – Ahmed and Samuel 2022 8
multiple model training, it is still not clear to us why the author used 100 trained mod‐ els with 500 epochs each as default settings for each source of nondeterminism. Since these two parameters play an important role in the time required for an experiment, we decided to explore this area with the goal of reducing the training time while maintain‐ ing all the claims. This will allow the scientific community to test the claims on larger architectures and datasets with less time consumption.
No. of models v/s Variability: In this experiment, we used the original settings, except for the number of trained models considered for the variability analyses. By changing the number of trained models for nondeterminism, we observed the change in model variability. Due to lack of time, we experiment with only 3 different sources of nonde‐ terminism. We found that the result is not significantly different from the number of models, except for the error bars associated with standard deviation of accuracy and cross entropy. While all important metrics remain the same, it can be observed that these error bars decrease as the total number of models increases, as can be seen in Figure 3. All sources tested in Table 7 show the same trend.
ReScience C 8.2 (#1) – Ahmed and Samuel 2022 9
Epochs v/s Variability: Since we found that a smaller number of trained models is less likely to affect the result in terms of model variability, we kept the number of trained models constant at 25. In addition to the original settings, we changed the number of epochs from 100 to 500 to see its impact on model variability. It can be seen that chang‐ ing the epochs does not affect the performance variability, but the model diversity. The values for pairwise correlation and change in two models ensembling indicate greater model diversity as the number of epochs increases. The same trend can be observed in both sources, as shown in Table 8.
Generalization: In this section, we examine the first two claims of the paper on a larger scale in terms of architecture and dataset. So far, these claims have shown no difference in results and have only been tested with ResNet‐18 representing the largest architec‐ ture in [1]. For this reason, we went a step further and conducted experiments to test the generalization of nondeterminism and instability to CIFAR‐100 (dataset) and ResNet‐ 34 (model architecture). We conducted the experiment to obtain the 25 trained models with 200 epochs each for the sources of nondeterminism listed in Table 9. We obtained an average accuracy of 63%for the CIFAR‐100 test dataset, however the goal is to observe the changes in model variability and its metrics. We have found that the two different sources of nondeterminism produce roughly the same variability. The relative variabil‐ ity of instability with ”Random Bit Change” also shows a similar result. However, the significant change in values of thesemetrics are observed about three times higher than the experiments performed with CIFAR‐10 and ResNet‐14. Even though this difference is due to the lower accuracy of the test results, the two main claims still hold.
ReScience C 8.2 (#1) – Ahmed and Samuel 2022 10
5 Discussion
Our results in section 4 fully support the first two assertions regarding the effects of ”non‐determinism” and its identified cause ”instability”. To gain sufficient confidence in the result, we also tested these claims on larger architectures and datasets, which also confirms the results of the study. But, when conducting experiments with accel‐ erated ensembling and TTA as a solution to reduce variability, some differences were found. Our results show that both approaches can reduce variability. However, the ex‐ tent to which they reduce variability is presented higher in the original study and lacks concrete numbers. In addition, we did not find in the paper a mathematical formu‐ lation for the average percentage of variability reduction that could have avoided this discrepancy. However, this is not sufficient to refute the claim. Therefore, we also sup‐ port the third claim. Moreover, the discovery that all sources of nondeterminism have similar effects on model variability is novel in itself and opens many interesting areas of research toward reproducibility of deep neural networks.
Strengths and weaknesses: One of our strengths in the reproducibility study was that we stuck to the original implementation by using the publicly provided code and were able to create the experimental environment with exact hardware and software speci‐ fications. This allowed us to obtain similar results that confirmed the paper’s claims. Another strength of our work was to perform some additional experiments that helped us reduce the overall computation time, allowing experiments with a larger architec‐ ture and dataset to be completed on time. The weakness of our approach is that in the limited time available for the reproducibility study, we could not test the claims about different combinations of hyperparameters, since 100 of trainedmodelsmust be seeded for each experiment, whereas training a single model takes about 40minutes."
"['Rajeev Verma', 'Jim J. O. Wagemans', 'Paras Dahal', 'Auke Elfrink']",[Re] Explaining Groups of Points in Low-Dimensional Representations,10.5281/zenodo.4835602,Replication,Python,https://zenodo.org/record/4835602/files/article.pdf,rescience c rescience x,https://openreview.net/forum?id=cqAHExg2f,https://github.com/elfrink1/FACT,7,2,2021,"This report covers our reproduction of the paper ʼExplaining Low dimensional Representationʼ [1] by Plumb et al. In this paper, a method (Transitive Global Translations, TGT) is proposed for explaining different clusters in low dimensional representations of high dimensional data. They show their method outperforms the Difference Between the Means (DBM) method, is consistent in explaining differences with few features and matches real patterns in data. We verify these claims by reproducing their experiments and testing their method on new data. We also investigate the use of more complex transformations to explain differences between clusters.","The easiest part was running the existing code with the pre-trained model files. The original authors had set up their code base in an organized manner with clear instructions.
Copyright © 2021 R. Verma et al., released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Rajeev Verma (rajeev.verma@student.uva.nl) The authors have declared that no competing interests exist. Code is available at https://github.com/elfrink1/FACT. – SWH swh:1:dir:445130f59283e6dce7df5eb72dd346a5c57c9230. Open peer review is available at https://openreview.net/forum?id=cqAHExg2f.
ReScience C 7.2 (#24) – Verma et al. 2021 1","The first difficulty that we encounter was finding the right environment. The source code depends on deprecated functionality. The clustering method they used, had to be re-implemented for us to use it in our replication. Another difficulty was the selection of clusters. The authors did not prove a consistent method for selecting clusters in a latent space representation. When retraining the providedmodels, we get a latent space representation different to the original experiments. The clusters have to be manually selected. The metrics that they used to evaluate their explanations are also depend on the clustering. This means that there is some variability in the exact verification of reproducibility.
Communication with original authors We asked the original authors for clarification on how to choose the ϵ hyper-parameter. However, it became apparent that we had misread, and the procedure is indeed adequately reported in the paper.
ReScience C 7.2 (#24) – Verma et al. 2021 2
1 Introduction
The curse of dimensionality [3] is a long-standing problem in Machine Learning. Data in many domains and applications (e.g. Bioinformatics) has high-dimensional representations. Finding patterns in such high-dimensional data is a challenging task. To this end, dimensionality reduction [4] techniques have greatly helped in data-analysis, information extraction, building computational models, and in doing inference. Given an input x ∈ Rd, dimensionality reduction learns a function r : x 7→ r(x), r(x) ∈ Rm, where m << d. Such a dimensionality reduction function r naturally arises in deep learning due to the expressivity and representational power of neural networks. The goal of r is to encode useful knowledge about the input space, thus providing distinctive information in the transformed output r(x). This results in “clusters” or “groups of points” in the transformation space. The downside of this exercise, however, is that the output space is usually non-interpretable. There is usually no easy way to know what information is present in the transformed points r(x) and what sort of distinctive knowledge they contain. In this work, we reproduce the paper ʻExplaining Groups of Points in Low-Dimensional Representationsʼ by Plumb et al. [1]. This paper proposes amethod for explaining different clusters in latent space representation. They look at the problem of explaining the points in the latent space representation through the lens of Interpretability inMachine Learning. We reproduce their findings and expand upon their work with our an extension. We extend their research by applying their method to a larger class of explanation functions and testing their method on new dataset. We further investigate the efficacy of the explanations using a probing classifier [5].
2 Methodology
Counterfactual Explanations [6] have emerged as an active research area in the field of Interpretable Machine Learning. A counterfactual explanation is defined as the smallest perturbation to the input that would change the output of amachine learningmodel. As such, these explanations are promising as they can provide suggestive recourse to the beneficiary in a machine learning based decision system. As an interpretable machine learning problem, Plumb et al. [1] aim to find such counterfactual explanations in order to explain the differences between the groups in latent space. To this end, they employ the function r itself to find what perturbation δ needs to be made to the input x ∈ Rd so that r(x + δ) belongs to the different target group. The goal is to find the global explanations that apply to the whole group as opposed to the local explanations which explain only individual examples [7]. Furthermore, the explanations need to be sparse for them to be interpretable by practitioners. Finally, these explanations should be be both symmetric and transitive. To obtain these Global Counterfactual Explanations(GCE), the authors propose the algorithm called, Transitive Global Translations (TGT), explained hereafter. Following the previous notation, let r : Rd → Rm denote our dimensionality reduction function, where d is the dimensionality of the input space and m is the latent space s̓ dimensionality. Suppose Xi, Xj ⊂ Rd get mapped to the clusters Ri, Rj ⊂ Rm respectively. The goal is to define the transformation ti→j : Rd → Rd on x ∈ Xi as x ′ = ti→j(x), so that r(x ′ ) ∈ Rj , or equivalently x
′ ∈ Xj . The proposed algorithm TGT considers the transformations of the form ti→j(x) = x + δi→j . To find the optimal parameters of the transformation function, authors imply a compressed-sensing based objective function as below:
l(δi→j) = ‖r(ti→j(X̄i))− R̄j‖22 + λ‖δi→j‖1 (1)
where λ‖δi→j‖1 is a regularization term to incentivize sparser explanations, and X̄i ∈
ReScience C 7.2 (#24) – Verma et al. 2021 3
Rd and R̄j ∈ Rm denote the means of the clusters in the input space and latent space respectively. Given clusters 0, 1, . . . , n, we get a total of 12n(n + 1) transformations. To further increase sparsity, we can truncate δi→j to only the k features with the largest absolute value, for some k. An issue with this is that the translation using the truncated δi→j might no longer correctly transform inputs that get mapped to Ri into inputs that get mapped to Rj . Furthermore, the transformations ti→j have to adhere to several mathematical properties. Namely, for any clusters i, j, k these transformations should be : a) Symmetric, i.e. ti→j = tj→i
−1 and b) Transitive, i.e. tj→k ◦ ti→j = ti→k. From these properties it follows that ti→i is the identity function I as
ti→i = ti→0 ◦ t0→i = ti→0 ◦ ti→0−1 = I (2)
We define this condition as self-similarity. Furthermore, the group of translations is uniquely defined by t0→1, . . . , t0→n, because for any i, j:
ti→j = t0→j ◦ ti→0 = t0→j ◦ t0→i−1 (3)
Plumb et al. [1] compare their method against the naive baseline of Difference Between the Means (DBM). With DBM, each transformation is still a translation: ti→j(x) = x + δi→j . However, now δi→j = (X̄j − X̄i). We also use this as a baseline for comparison in this report. Since translations are a very narrow class of functions, we expanded upon the research by investigating other transformations that still satisfy the GCE requirements. We investigate the transformations of the form t0→i(x) = exp(γ0→i) x + δ0→i. These always have a well defined inverse, given by t0→i−1(x) = exp(−γ0→i) (x − δ0→i) and only have O(d) parameters. The inclusion of scaling could enhance performance, while the necessary components of GCE are maintained.
2.1 Metrics to evaluate Global Counterfactual Explanations To measure the efficacy of the transformation function ti→j , the authors propose two metrics, Coverage and Correctness.
1. The Coverage (cv(ti→j)) is the fraction of points a ∈ Rj for which there is a point b ∈ Xi such that ‖r(ti→j(b))− a‖2 < ϵ, i.e.
cv(ti→j) = 1 |Rj | ∑ a∈Rj I [∃b ∈ Xi|‖r(ti→j(b)− a‖2 < ϵ] (4)
2. The Correctness (cr(ti→j)) is the fraction of points b ∈ Xi for which there is some a ∈ Rj such that ‖r(ti→j(b))− a‖2 < ϵ, i.e.
cr(ti→j) = 1 |Xi| ∑ a∈Rj I [∃a ∈ Rj |‖r(ti→j(b)− a‖2 < ϵ] (5)
Note that both these metrics have the hyperparameter ϵ which is to be chosen carefully. When i = j we do not count the point itself, there must be some other point within distance ϵ. 1 Furthermore, the Similaritymetric measures the consistency of the explanations at different sparsity levels. Given two explanations e1, e2 where e1 is more sparse than e2, the similarity of e1 and e2 is defined as
sim(e1, e2) =
∑ i|e1[i]|1(e2[i] 6= 0)
‖e1‖1 (6)
This is equal to 1 if e1 uses a subset of the features that e2 uses. By definition, DBM always has similarity 1.
1We use this definition to set the value for epsilon, as explained in the Methodology section of the original Paper.
ReScience C 7.2 (#24) – Verma et al. 2021 4
3 Scope of Reproducibility
We investigate the following claims from the original paper:
1. In terms of the average correctness and coverage, TGT performs equally well or better than the DBM method. This remains true, especially for sparser explanations.
2. TGT explanations have similarity close to 1. It is consistent in which features it uses for explanations across different sparsities.
3. TGT correctly identifies known causal structure in data.
4. Furthermore, TGTexplanations are consistent. Whenaltering the dataset by adding a copy of a cluster with a specific feature altered, TGT recovers the modification with little change to the other explanations.
4 Methodology of Reproducibility
We make use of the code made available by the original authors 2 for our pilot investigative study. We first verify that the provided models and explanations stay true to the claims made in the paper. We further retrain their models on the provided dataset. We also made our own PyTorch [2] implementation to to further verify the claims, and to perform experiments with the proposed extension.
4.1 Model description Weassert that the scope of the original paper is to explain clusters in the low-dimensional representations. However, obtaining meaningful and discernible low-dimensional representations is an active area of research. The original authors employ a t-SNE [8] objective based Variational Autoencoder (called, henceforth, as scVIS) [9] as the r function. They make use of library3 by the original scVIS authors in their implementation. We also implement this model in Pytorch for our experiments. However, we deliberately decide not to match the model implementation exactly. This is done to study the modelagnosticism of the TGT algorithm. By design, TGT should be able to explain the clusters for any differentiable r function. However, we maintain that r should give discernible latent representations with preserved global structure in the data. In our implementation of the scVIS library, we therefore do not employ the hyperparameters and the training settings from the original library.
4.2 Dataset Description We reproduce the findings of the authors on four datasets that they used. We use two of these datasets as well as two new ones to test our PyTorch implementation.
1. Single cell RNA [10]: This dataset has 13166 features. We use the same number of clusters at the original authors, 18 in this case.
2. UCI Boston housing This dataset has 506 entries with 13 features. We use 6 clusters for both reproduction and replication.
3. UCI Heart disease This dataset has 303 entries with 13 features and 1 binary label. We used 8 clusters in the reproduction and 4 in the replication. The data was normalized to be in the range [0, 1].
2https://github.com/GDPlumb/ELDR 3https://github.com/shahcompbio/scvis
ReScience C 7.2 (#24) – Verma et al. 2021 5
4. UCI Iris This dataset has 150 entries with 4 features and 1 ternary label. Ran in the reproduction with 3 clusters. N = 150
5. Breast Cancer Wisconsin (Diagnostic) 4 This dataset has 569 entries with 30 features and 1 binary label. We use 3 clusters in the replication.
6. Pima Indians Diabetes Database 5 This dataset has 768 entries with 8 features and 1 binary label. We used 3 clusters in the replication. The data was normalized to be in the range [0, 1]. Note that the number of clusters depend on the latent-space representation, and thus, are user dependent.
4.3 Hyperparameters Tensorflow [11] Experiments For the reproduction of the original experiments, we use the same hyperparameters as the original authors.
Pytorch For our implementation of the scVIS model, we use l2 regularization of 0.001, learning rate 0.01, and perplexity of 10. Furthermore, the degree-of-freedom for the studentT distribution is set to 2.0. Perplexity and the degree-of-freedom is used same as the original scVIS implementation. We use validation set to monitor the training process of the scVIS model, and stop training when the ELBO(Evidence Lower BOund)[12] stops improving. For training the TGT explanations, we closely follow the settings from Plumb et al. [1]. We initialize the deltasδs as zero vectors. We tune the regularization parameter λ by grid search over a fixed range [0.0, 5.0] incremented by 0.5. Defining the metrics for TGT requires careful setting of the ϵ hyper-parameter. We follow the self-similarity condition (transformations of clusters to themselves should, theoretically, have correctness and coverage to be 1.0), and increase the ϵ in the range [0.0, 2.0] with increments of 0.02 until the correctness and coveragemetrics are greater than 0.95. Furthermore, we use the truncation values(TV)(refer Table 1) to evaluate on the sparsity of the explanations. For the Pima Indians Diabetes Database and Breast Cancer Wisconsin(Diagnostic) dataset, we use the same truncation values as for UCI Boston Housing dataset.
Dataset Truncation Values(TV) ϵ Single Cell RNA 50, 100, 250, 500, 1000, 15000 0.75 Heart Disease 1, 3, 5, 7, 9, 11, 13 1.0
Housing 1, 3, 5, 7, 9, 11, 13 1.5 Iris 1, 2, 3, 4 0.75
explanations on CPU (Intel i5).
5 Results
For the reproduction of the authorsʼ experiments, we achieve approximately similar results to the original paper. The TGT method does seem to outperform DBM method. The TGT explanations also have high similarity across sparsity levels. However, the TGT algorithm is unable to identify known causal structure in synthetic data with as good precision as reported in the original paper. We are also unable to match the results on the modified and corrupted data to a good precision. We describe the results in the following sections:
5.1 Results reproducing original paper
Coverage, Correctness and similarity — In figure 1, we can see a comparison between the correctness, coverage and similarity of the TGT and DBM methods. Note that the DBM always has similarity 1. The similarity of TGT stays between 1 and 0.9, which supports claim 2. We see that the coverage and correctness are similar for the UCI Heart disease dataset. On the UCI Iris dataset, the coverage is comparable but the correctness is better for TGT. In both housing and RNA, the coverage and correctness are better at less features and similar for more features. Overall, these results support claim 1, especially for a small amount of features.
5.2 Explaining Causal Structure in the Synthetic Data Weverify the claim that TGT identifies the causal structure in the data (claim 3). The synthetic dataset is generated same as the original paper, i.e. x1, x2 ∼ N (0, 0.2)+ Bern(0.5), x2 ∼ N (0, 0.05), x4 ∼ x1 +N (0, 0.05). Note that this dataset has four different clusters, caused by the first two dimensions x1 and x2, x3 is noise, and x4 is correlatedwith x1 and x2. The authors claim that for this synthetic data, TGT is able to find that x4 is not the cause for any group. However, the said claim cannot be re-verified. Interestingly, the re-run of their code doesnʼt provide the justification either to the degree as mentioned
ReScience C 7.2 (#24) – Verma et al. 2021 7
in the paper. We observe that both TGT and DBM are able to identify x3 is not causing any groups. Thus, in this scenario, both TGT and DBM are comparable. Refer table 2 for the explanations obtained. We, hereby note, that the explanations vary across multiple runs and we use the experimental setup same as the original authors. However, the values across the third dimension are consistently approximately 0.
Feature modifications — For each of the UCI datasets, the original authors add a ʻcorruptedʼ version where an extra cluster is added with artificial feature modification. With the exception of the modified features, the corrupted class is a copy of a chosen target class. They train TGT explanations using both the original scVIS model for the respective dataset and a model retrained on the corrupted dataset. We reproduce these experiments to see if TGT correctly attributes the difference between the target and corrupted class to the right features. Refer to Appendix 7.1 for the illustrated figures and description. Overall, we observe that TGT is unable to identify the modifications to as good a precision as reported in the original paper. TGT is able to identify the modification for the UCI Iris dataset. For UCI Heart Disease Dataset (figure 7), it does not identify the features modified and on the UCI Boston Housing Dataset (figure 6), it identifies noisy modifications. However, with the retrained scVIS model and new representations, TGT is consistent in identifying the modifications across all the datasets.
5.3 Results beyond original paper
PyTorch replication —We also replicate the TGT algorithm in PyTorch. Our Pytorch implementation includes the entire method along with the scVIS clustering method. In our implementation, we use the Scikit learn 8 kmeans module for our cluster selection as opposed to the manual clustering in the Tensorflow implementation. However, our number of clusters argument to the kmeans algorithm was informed by the learned low-dimensional representations for each dataset. Due to differences in the clustering model and cluster selection, we cannot directly compare the coverage and correctness metrics between our Pytorch replication and the TensorFlow reproduction. We additionally experiment with our scaling extension to the TGT algorithm. In the scaling extension of the TGT algorithm, along with the δ (δ) parameters, each cluster now has a γ (γ) parameters. The transformation from cluster 0 to i is now given by: t0→i = eγi x+δi The gammas(γs) are truncated just like the deltas and their L1 norm is added to the regularization term. Note that these transformations are strictly more expressive. If γ is the zero vector, these transformations reduce to regular TGT.
UCI Heart Disease and UCI Boston Housing Dataset — In figure 2 we see the results of our replication on the UCI Boston Housing and UCI Heart Disease dataset. For the UCI Boston Housing data, the TGT method seems to slightly outperform DBM both with and without scaling. This supports claim 1. The deltas(δs) and gammas(γs) show high similarity, supporting claim 2. For the UCI Heart Disease dataset, we do not see a difference in performance without scaling while TGT with scaling performs slightly worse.
8https://scikit-learn.org/stable/index.html
ReScience C 7.2 (#24) – Verma et al. 2021 8
Breast Cancer Wisconsin (Diagnostic) and Pima Indians Diabetes Database — In figure 3 we see the results for the Pima Indians Diabetes and Breast Cancer Wisconsin (Diagnostic) dataset. For the diabetes dataset, TGTwith and without scaling outperforms DBMwhen more than one feature is used. This supports claim 1. Since the delta (δ) similarity is close to 1, claim 2 is also supported. For the Breast Cancer dataset, we see similar performance for DBM and TGT and slightly worse performance with scaling. The deltas (δs) still have high similarity, supporting claim 2.
Scaling extension — In figure 2, we can see the difference in performance on two dataset included in the original experiments. Scaling does not seem to improve performance on the UCI Boston Housing dataset and slightly decreases performance on the UCI Heart Disease dataset. The similarity of the gammas (γs) is mostly above 0.9. In figure 3, we see the same metrics for the Breast Cancer and Pima Indians Diabetes Dataset. For theDiabetes dataset, the performance improves slightly and the gammas(γs) show high similarity. For the Breast Cancer dataset, the performance is about the same but the gammas(γs) show relatively low similarity. Altogether, these results suggest that the addition of scaling does not significantly improve the accuracy and correctness while making the transformations more complex. Based on our experiments, we do not recommend the addition of scaling in the explanation functions, and conclude that the original TGT is expressive enough.
Experiment with Modified Synthetic Data — In order to study the efficacy of the proposed scaling function, we perform experiments on the synthetic dataset. We modify one of the groups of points G by performing the operation axki + b, where i corresponds to the group number and k denotes the feature dimension which we modify. We define a ∼ U(1.0, 2.0) and b ∼ U(−0.5, 1.0). We add modified groupG′ into the original dataD to get the new data D ′ . We follow the experiment setup from the original paper as: a) r(G ′ ) should form a different group of its own. b)G ′ should bewithin the distribution of the originalD. In this study, we want to investigate whether the TGTwith scaling is able to recover themodifications, and if in doing so it affects the explanations between other groups. The sampling procedure gave a=2.0, b=0.60 and we keep k=0. We observe that the explanations with scaling are able to recover the modification to an approximate degree(scaling factor eγ ≈ 2.38, actual a=2.0), and give better correctness as compared to the regular TGT (refer figure 3). Interestingly, the translations explanations of the scaling extension are approximately equal to the deltas of the regular TGT. The exact results can be found in Table 3. Figures 8 and 9 in the appendix show the data spread and resulting translations.
Experiments with Probing Classifier — To further investigate the efficacy of TGT explanations, we use a probing-classifier [5] as a proxy to study the qualitative differences of the features selected by TGT and DBM. For each cluster, we train a binary classifier with features ranked highest by TGT and DBM at different sparsity levels K. We compute the overall accuracy at each sparsity level using the ensemble of these binary classifiers.
ReScience C 7.2 (#24) – Verma et al. 2021 9
As can be seen in Figure 4, the results demonstrate that for sparser explanations, TGT selects features that lead to higher accuracy of the ensemble classifier than those selected by DBM. This further validates the paper s̓ claim that TGT leads to better sparse explanations as compared toDBM. Furthermore, we also use the probing classifier to understand the differences between the groups. For each pair of group, we train a Binary Linear Classifier to predict the group of a test point. We, then, investigate the feature importances of the classifier towards decision making. We ascertain that the features classifier give more importance to while decision making are the defining property of the class. Interestingly, we find that the more important features according to the classifier correspond to the explanations provided by the TGT algorithm. Refer to figure 11. This provides further evidence that TGT is able to find real distinctive signals as explanations.
6 Discussion
Based on the reproduction of the original experiments, claims 1 and 2 seem to hold, the experiments for claim 4 do not all support it, but the claim does seem to hold. Claim 1 and 2 seem to hold in particular for sparse explanations. The evidence for claim 3 is inconclusive. The coverage and correctness in our reproductionwere not always the same as in the original paper. It is difficult to compare these metrics for different clustering outcomes, as they depend on the ϵ parameter which depends on the clustering. A major difficulty in reproduction is the cluster selection. When retraining the scVIS model, the latent space representation structure changes. The authors provide determine the different clusters by visual inspection. Cluster selection could be an explanation for the differences in results between the original experiments and our reproduction. To verify the results with more confidence, a robust method for cluster selection might be required."
"['Georgios Albanis', 'Nikolaos Zioulis', 'Anargyros Chatzitofis', 'Anastasios Dimou', 'Dimitrios Zarpalas', 'Petros Daras']",[Re] On end-to-end 6{DoF} object pose estimation and robustness to object scale,10.5281/zenodo.4833219,Replication,Python,https://zenodo.org/record/4833219/files/article.pdf,rescience c rescience x  python pytorch object pose estimation,https://openreview.net/forum?id=PCpGvUrwfQB,https://github.com/tzole1155/EndToEndObjectPose,7,2,2021,"This report contains a set of experiments that seek to reproduce the claims of two recent works related to keypoint estimation, one specific to 6DoF object pose estimation, and the other presenting a generic architectural improvement for keypoint estimation but demonstrated in human pose estimation. More specifically, in the backpropagatable PnP [1], the authors claim that incorporating geometric optimization in a deep-learning pipeline and predicting an object s̓ pose in an end-to-end manner yields improved performance. On the other hand, HigherHRNet [2] introduces a novel heatmap aggregation method that allows for scale-aware pose estimations, offering higher keypoint localization accuracy for small scale objects.","Both papers provided publicly available implementations. In addition, many different variations were also found online. Finally, the papers themselves were very clearly written, offering insights on various important details.","The main issue that required more effort was identifying the appropriate weights for BPnP [1] in order to balance the different optimization objectives. As expected, this varies for the context that it is applied (task, dataset) and the values presented in the paper did not work in our case. Sub-optimal selection of weights leads to convergence issues.
Communication with original authors We communicated with the authors of [1] through GitHub, and we would like to thank them as they provided a fast and detailed response. Furthermore, their responsiveness to past issues had already provided a nice knowledge base regarding reproduction.
ReScience C 7.2 (#2) – Albanis et al. 2021 2
1 Introduction
Object pose estimation seeks to determines the 3D position and orientation of an object in camera-centred coordinates. During the last years, two main directions have been emerged for data-driven 6DoF object pose estimation; direct pose regressionwhich predict pose in an end-to-end manner, and indirect that learns the surrogate task of keypoint localisation and then solves a Perspective-n-Point (PnP) problem to estimate the resulting pose. Even though it has been shown [4] that the latter methods better approach the problem, there are still open challenges that need to be solved. One issue is the splitting between the actual task at hand, and the surrogate task that they learn. The other has to do with the spatial nature of keypoint localisation and smaller scale objects. Recently, two works have been presented that seek to address these issues, BPnP [1] and HigherHRNet [2]. In this work, we seek to reproduce and verify their claims in a task that is relevant for both of these works, drone pose estimation. While BPnP s̓ relation has to dowith the task at hand, HigherHRNet is also relevant because commodity drones are usually small form objects, and when flying around the further distance themselves from the operator, effectively reducing their scale in the cameras̓ image domain.
2 Scope of reproducibility
Consequently, we opt for reproducing the claims of both of these two relevant papers addressing the aforementioned challenges. In more details, the authors of BPnP [1] propose a novel differentiable module which calculates the derivatives of a PnP solver through implicit differentiation, enabling the backpropagation of its gradients to the network parameters, and as such allowing for end-to-end optimization and learning. On the other hand, the authors of HigherHRNet [2] focus on improving the 2d landmarksʼ localization performance for smaller-scale humans by proposing a novel multi-scale supervision scheme for training and a heatmap aggregation module for inference. The main claims of both papers can be summarised below:
• BPnP: An end-to-end trainable pipeline for object pose estimation, can achieve greater accuracy by combing the reprojection losses (Table 3).
• HigherHRNet: Anovelmethod for learning scale-aware representations usinghighresolution feature pyramids, eventually achieving greater results for small scale objects1 (Table 4).
3 Methodology
We implemented our experiments by re-using the publicly available implementation for BPnP, and implementing HigherHRNet after styding the paper, the original publicly available implementation, as well as other implementations. In both cases we integrated the code base in a modular framework that facilitates reproducible experiments [5], which generally required slight modifications of the original code provided by the authors to fit its requirements. The overall methodology for our experiments is depicted in Figure 1. On the left, a traditional monocular heatmap-based keypoint localisation pipeline is presented, whereas on the right, the BPnP required components are illustrated. BPnP: BPnP focuses on the Pose Retrieval stage, and following [1] we trained our model under the 3 different schemes used in the original work as well:
1We apply the proposed module in the object pose estimation task, while authors originally demonstrated it for the human-pose estimation task, but its concept still applies in our case as well.
ReScience C 7.2 (#2) – Albanis et al. 2021 3
• heatmap loss (lh),
• mixture loss lm = lh + β ∗ lproj ,
• and pose loss lp = lreg + lproj ,
where lproj = ∥π(z|y,K)−x∗∥22 and lreg = ∥x−π(z|y,K)∥22. Also, π is the projection function employing the predicted pose(y) from the PnP solver, the corresponding object s̓ 3D points z and K the camera intrinsic matrix. Apart from these experiments presented also in the original paper, we conducted an extra set of experiments that aimed at validation the concept of end-to-end 6DoF pose estimation via differentiable PnP. We used another openly available differentiable PnP implementation, and additionally, also tested the faster counterpart of BPnP. We present results across many established object pose estimation metrics, as well as computational performance metrics for all the aforementioned experiments. HigherHRNet: On the other hand, for HigherHRNet we focused on the Heatmap regression part by using different models for the decoder part of the architecture, with details following in Section 3.1. All the code and its documentation are submitted and published along with this report.
3.1 Model descriptions The following models were used as our backbone for regressing the heatmaps and the corresponding coordinate spatial distributions (the decoder part in Figure 1):
• HRNet [6] with feature maps of width 48 and 3 stages. The 2nd, and 3rd, stages contain 1, 4 exchange blocks, respectively, and each exchange block contains 4 residual units.
• HigherHRNet [2] with feature maps of width 48 and 3 stages. The 2nd, and 3rd, stages contain 1, 4 exchange blocks, respectively, and each exchange block contains 4 residual units.
• Stacked Hourglass [7] with depth 2 and feature maps of width 128
Following the heatmap predictions, we apply a decoding operation (i.e. center of mass specifically) in order to extract the keypoints from the heatmaps, which are later driven to the PnP algorithm for retrieving the 6D pose. In addition, we integrated the EPnP [8] algorithm, using the available implementation in Pytorch3D [9] instead of BPnP to assess whether other – similar in concept – implementations can verify the claim and quantify the differences between these approaches. As
ReScience C 7.2 (#2) – Albanis et al. 2021 4
a side-note, it should be mentioned that our modelsʼ configuration slightly differs from the ones described in the original works in order to comply with the working resolution of the dataset we used.
3.2 Datasets
UAVA — As aforementioned, our experiments were conducted on a dataset that allowed for the validation of both works simultaneously. This also better helps in deducing whether the claims are reproducible as the context (task or dataset) can vary. We used theUAVAdataset2 for object pose estimation. UAVA targets human-robot cooperativeUnmanned Aerial Vehicle(UAV) applications and offers two different dronemodels, namely DJI M2ED3 and Ryze Tello4. The UAVA dataset provides the 3D models of both drones accompanied by ground-truth annotations such as 3D bounding boxes, 6D pose, and at the same time multi-modal data. More importantly, the difference in size between the two drone models allows for the validation of scale-invariant pose estimation.
Preprocessing —Weprocessed the original dataset in order to keeponly the sampleswhere all the 2D keypoints are within the image, given that BPnP relies on softly approximating the coordinate, and that would fail in the case of out of field-of-view keypoints. However, we shouldmention that we did not apply any other filtering (i.e. visibility of all the keypoints, boundary cases, etc.).
3.3 Hyperparameters We train all the models for 44 epochs and select the best performing model for testing. We used the Adam optimizer with a learning rate of 1e− 4, betas of values 0.9 and 0.999 and no weight decay, and a seed value of 1989 for ensuring reproducibility. Albeit, we experimented with different losses (i.e. KL, MSE) for lh, we found that L1 loss works the best, offering the best results and faster convergence. This could be attributed to the different resolution of the heatmaps grid (in our case is lower) as well as the different configuration of the heatmap decoder model (we used 3 stages instead of 4). It is worth mentioning that we also tried a bigger heatmap resolution (e.g. 160 × 120) although we decided to conduct our final experiments in the lower resolution for two main reasons. First, most heatmaps regression decoders used in the literaturemake their prediction in the 1/4 of the original image, and second, this higher heatmap resolution would enforce us to further reduce the depth of the decodermodel. Specifically, for BPnPwe set β value to 1e − 5 after conducting a greedy heuristic search, with values ranging from 0.001 to 1e− 9, as the proposed value for β coefficient, did not work for our case. The selection of a non-appropriate β coefficient value can lead to stability issues as noted in Section 5.2.
3.4 Experimental setup and code As mentioned above, we integrated the authorsʼ code (BPnP) or our own reimplementations (HigherHRNet) in [5] which is a PyTorch framework for modular and reproducible workflows5. Each model is implemented in a configuration file that defines the different components (optimizer, datasets, model architecture, pre-/post-processing graphs, etc.) and logs all hyperparameters. For each experiment we report the standardmetrics below:
2https://vcl3d.github.io/UAVA/ 3https://www.dji.com/gr/mavic-2-enterprise 4https://www.ryzerobotics.com/tello 5www.github.com/ai-in-motion/moai
ReScience C 7.2 (#2) – Albanis et al. 2021 5
NPE: is the magnitude (L2-norm) of difference between the ground-truth and estimated position vectors from the origin of the camera reference frame to that of the drone body frame, normalised with ground-truth vector. AD: is the angular distance between the predicted, rotationmatrix, and ground-truth,or in other words, the magnitude of the rotation that aligns the drone body frame with the camera reference frame. ACC: considers an estimated pose to be correct if its rotation error is within k◦ and the translation error is below k cm. ADD: is the average distance metric to compute the averaged distance between points transformed using the estimated pose and the ground truth pose. Eventually, a pose estimation is considered to be correct if the computed average distance is within k% of the model diagonal. Proj: is the mean distance between 2D keypoints projected with the estimated pose and those projected with ground truth pose. An estimated pose is considered correct if this distance is within a threshold k.
3.5 Computational requirements Table 1 showcases the total duration of each experiment (with a 24 batch size) as well as some other useful statistics such as the mean duration time for a forward pass, a backward pass, an optimizer step, as well as the total test duration with batch size 1. It is clear, that the introduction of the differentiable PnP modules in the training procedure increases the total training time significantly, as the backward and step operation require more time. We ran our experiments on a machine with the specifications presented in Table 2.
4 Results
Our results support the claims presented by both authors in [1] and [2] respectively. As is demonstrated in Table 3, the model trained with lp achieved better results in most of themetrics for both dronemodels. Similarly, Table 4 indicates that HigherHRNet yields better results for the small-scale drone inmost of themetrics, although its performance for the bigger M2ED drone is worse compared to the standard HRNet model.
4.1 Results reproducing original papers
BPnP —With these experiments we show that the addition of a differentiable PnP module improves the performance in object pose estimation task. We provide qualitative results in Figure 3. It is worth highlighting that training with lp does not restrict the shape of the distribution the way that it is constrained when relying on heatmap supervision (i.e. Gaussian distribution approximation). Instead, the model freely localizes the keypoints, which results in more focused predictions. This is illustrated in Figure 2 where qualitative results display the heatmaps on top of the color images."
"['Mayur Arvind', 'Mustansir Mama']",[Re] Neural Networks Fail to Learn Periodic Functions and How to Fix It,10.5281/zenodo.4833389,Replication,python,https://zenodo.org/record/4833389/files/article.pdf,periodic functions activation python,https://openreview.net/forum?id=ysFCiXtCOj,https://github.com/mayurak47/Reproducibility_Challenge,7,2,2021,"The central claims of the paper are two-fold: (1) The properties of the activation functions are carried over to the neural networks. Atanhnetworkwill be smooth and extrapolates to a constant function, while ReLU extrapolates in a linear way. Standard neural networks with conventional activation functions are insufficient for extrapolating periodic functions. (2) The proposed activation function manages to learn periodic functions while being able to optimize as well as conventional activation functions. While both experimental proof and theoretical justifications are provided for the claims, we shall only be concerned with testing the claims via experimental means.","Manyexperiments includeddescriptions of theneural network architectures and graphs showcasing performance, giving us a clear benchmark to compare our results against.
Copyright © 2021 M. Arvind and M. Mama, released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Mayur Arvind (f20160603@goa.bits-pilani.ac.in) The authors have declared that no competing interests exist. Code is available at https://github.com/mayurak47/Reproducibility_Challenge – DOI 10.5281/zenodo.4696245. – SWH swh:1:dir:8887a5d45dac9427457c6b5869728e1ba3cfd37c. Open peer review is available at https://openreview.net/forum?id=ysFCiXtCOj.
ReScience C 7.2 (#3) – Arvind and Mama 2021 1
Links to datasets for all experiments, barring one, were also included in the paper itself.","Data for the human body temperature experiment was not available. Proper implementation details were not given for initializing the weights in neural networks with snake and using snake with RNNs.
Communication with original authors Liu Ziyin, one of the authors, was contacted to provide the dataset used for the human body temperature experiment, elaborate upon the implementation of variance correction and provide the implementation of RNNs using snake. Liu provided the GitHub link to the authorsʼ original code for the human body temperature, market index, and extrapolation experiments. Liu also provided an explanation on how to implement variance correction. While the code for the RNN implementation using the snake activation was not made public, a screenshot of the same was provided. We thank the authors for their assistance.
1 Introduction
Deep neural networks are playing an increasingly prominent role in fields as diverse as computer vision [2], speech recognition [3], and language modeling [4]. However, while neural networks are excellent tools for interpolating between existing data, standard versions of these networks are not suited for extrapolation beyond the training range. This causes them to struggle at making predictions in problems with a periodic component. Previous attempts at addressing neural networksʼ inability to learn periodic functions have included using periodic activation functions [5, 6]. For example, using sin(x) as the activation function for implicit neural representations has been successful at representing complex natural signals and their derivatives [7]. However in more general cases, experimental results suggest that using sin as the non-linearity cannot compete against ReLU-based activation functions [8, 9, 10, 11] on standard tasks [12].
The original paper: (1) studies the extrapolation properties of a neural network beyond a bounded region; (2) shows that neural networkswith standard activation functions are insufficient to learn periodic functions outside the bounded region where data points are present; (3) proposes a solution for this problem in the form of a novel activation function and its variants, and showcases its performance on toy examples and realworld tasks. We have tested the claimsmade in the original paper, replicating the experiments displaying the failure of standard activation functions to learn periodic functions as well as the results of the novel activation function on toy and real-world tasks. We have also conducted experiments of our own to understand how viable the proposed activation function is at replacing existing standards such as ReLU and tanh.
2 Scope of reproducibility
The authors make two key claims:
• Standard neural networks with standard activation functions are insufficient to learn periodic functions outside the bounded region where data points are present.
• The proposed novel activation function can learn periodic functions while maintaining the favorable optimization property of the ReLU-based activations. The novel activation is referred to as “snake”:
ReScience C 7.2 (#3) – Arvind and Mama 2021 2
snakea(x) := x+ 1
a sin2(ax)
where a is treated as a fixed parameter in initial experiments, and as a learnable parameter in a few experiments. Snake is shown to outperform standard activation functions ReLU,tanh,LeakyReLU [9], as well as more recently proposed functions such as swish [8], and sin [7, 12].
Due to the broad and far-reaching consequences of the two claims, the original paper supports them via both theoretical justification and an extensive list of experiments which range from testing performance on toy datasets to real world applications. We have exhaustively replicated the original list of experiments, and have conducted a few additional experiments of our own, using the proposed activation function in a Deep Convolutional Generative Adversarial Network (DCGAN) to generate images of handwritten digits and in a Long Short TermMemory (LSTM) network for sentiment analysis.
3 Methodology
The code used by the authors had not been made public at the time we started working on re-implementing the paper. That meant we reproduced all the results in the paper from scratch relying on the descriptions of the neural network architecture and a link or description of the dataset. The descriptions were brief but sufficient such as “feedforward neural network with 2 hidden layers, both with 64 neurons” for the Body Temperature Prediction experiment and “4-layer feedforward network with 1 → 64 → 64 → 1 hidden neurons” for the Financial Data Prediction experiment. In the case of experiments that utilized large standard networks such as ResNet18, the PyTorch library implementation of the model was used, with snake substituted in place of the default activation functions. Besides the model implementations, we were also required to make a a learnable parameter in snake for a few experiments.
3.1 Model descriptions Models used in the original paper included fully-connected, feed-forward neural networks with different architectures for the various experiments. Larger standard models such as ResNet18 were also used. The authors of the original paper had initially not made their code available and we had to implement most models ourselves.
3.2 Datasets The data used in the extrapolation experiments are directly sampled from periodic functions such as sin(x). Some experiments dealt with standard datasets such MNIST and CIFAR-10. Data for the real-life datasets had to be downloaded:
• Daily data from 1995-1-1 to 2020-1-31 of Wilshire 5000 Total Market Full Cap Index: Downloaded from link provided in the original paper: https://www.wilshire.com/ indexes
• Average weekly temperature evolution in Minami-Tori-shima, an island south of Tokyo (longitude: 153.98, latitude: 24.28) after April 2008: Downloaded from link provided in the original paper: https://join.fz-juelich.de/access
• Patient body temperature: Made available by the authors upon request
• IMDBReviewsDataset used for our additional sentiment analysis experiment: Downloaded from https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews
ReScience C 7.2 (#3) – Arvind and Mama 2021 3
3.3 Hyperparameters Different experiments included varying levels of detail with respect to hyperparameters. Many experiments provided an overview of the neural network architecture (e.g. “4-layer fully connected neural network”) but not other hyperparameters and relevant details, such as batch size, loss function, or learning rate. In cases where information was missing, assumptions had to be made, with some trial-and-error required to obtain a close approximation of the original result. This trial-and-error involved a grid search over the architecture (number of layers, number of neurons in each layer), number of epochs (100 to 5000), batch size (16 to 512), optimizer (Adam, SGD, RMSProp), learning rate (0.001 to 0.1) and value of a in networks with the snake activation (1 to 30).
3.4 Experimental setup The entire codebase has been uploaded to GitHub and is publicly available: https://github. com/mayurak47/Reproducibility_Challenge. The experiments were run locally as well as on GPU enabled sessions on Google Colab. All the models and experiments were coded using the PyTorch library.
3.5 Computational requirements Many of the experiments, particularly those relating to regressing different functions and datasets, could be run locally on a MacBook Air with an Intel i5 CPU and 8 GB of RAM, not requiring more than a few minutes to train. The more demanding experiments required the use of GPUs. Training a ResNet18 on CIFAR-10 with six activation functions for 100 epochs took roughly 12 hours on a Tesla T4 GPU on Google Colab. Our additional experiments on training a GAN and an LSTM required roughly 2 hours each on the same hardware.
4 Results
Wherever possible, the claims of the original papers were tested and in each case, we were able to reproduce the original results. The list of experiments that we reproduced is listed below.
4.1 Extrapolation experiments on analytic functions
ReScience C 7.2 (#3) – Arvind and Mama 2021 4
Neural networks with a single hidden layer consisting of 512 neurons are trained on data sampled from four different analytic functions using the ReLU and tanh activation functions. The training data is obtained by sampling from [-5, 5] with a gap in [-1, 1]. It is observed in Fig. 1 that the extrapolation of neural networks depends on the activation function used. When ReLU is used, the extrapolation diverges to ±∞. When tanh is used, the extrapolation levels off. The authors formally prove these observations and conclude that neural networks using these activation functions cannot learn to extrapolate periodic functions.
4.2 Applicability of proposed method It is first demonstrated that the snake activation function is easier to optimize than other commonly used baseline periodic activation functions like sin(x) and x+sin(x). Fully-connected neural networks with 3 hidden layers (512 neurons each) are trained on the MNIST dataset. This is a 10-way classification problem, and the training crossentropy losses for the different networks can be observed in Fig. 2, with the snake network achieving the lowest training loss.
It is then shown that snake is able to regress the periodic function sin(x). While all activation functions learn the training data (Fig. 1), only snake is able to capture the periodic behavior of sin(x) (Fig. 3). The extrapolation diverges from the underlying sin function due to the limited training data used.
ReScience C 7.2 (#3) – Arvind and Mama 2021 5
4.3 Applications Multiple experiments are conducted to illustrate the performance of snake on a range of tasks.
ResNet18 [13], with 10M parameters, is trained on the CIFAR-10 dataset. This is a 10-way image classification task. The ReLU layers in the architecture are replaced with the specified activation, and the network is trained for 100 epochs. The LaProp optimizer 1 [14] is used; the learning rate is 4 × 10−4 for the first 50 epochs and 4 × 10−5 for the next 50. A test accuracy of 93-94% is achieved by the snake network (Fig. 4), in line with that of the other standard activation functions. This suggests that snake is suitable for large-scale image classification problems, and may be used as a straightforward alternative to other activation functions.
The core utility of snake is shown via two real-life problems. The two tasks are predicting the evolution of temperature in Minami-Tori-shima island
in Japan (Fig. 5), and the modeling the body temperature of a patient (Fig. 6). The architectures used are 1 → 100 → 100 → 1 and 1 → 64 → 64 → 1 respectively, as in the original paper. In the Minami-Tori-shima weather experiment, the parameters a were made learnable; in the body temperature experiment, a = 30. In both cases, snake is the only activation function that makes meaningful extrapolation and predictions. It can also be seen in Fig. 5b that snake is the only activation function that is able to learn the training data - the other non-linearities are unable to fit the training points, irrespective of the number of epochs the models are trained for.
The snake network correctly learns the periodicity of the atmospheric temperature dataset, even though the amplitude is slightly off, and correctly infers that body temperature is roughly 37°C.
1Code taken from https://github.com/Z-T-WANG/LaProp-Optimizer
ReScience C 7.2 (#3) – Arvind and Mama 2021 6
Another regression problem the authors used to demonstrate the working of snake is that of financial data prediction (Fig. 7). The data used is from the Wilshire 5000 Total Market Full Cap Index, considered representative of the worldwide economic trend. The snake network ( 1 → 64 → 64 → 1, a = 30), which was trained using data from1995 to 2020-1-31, before COVID-19 impacted the world economy, predicted an economic slowdown in 2020. This might be due to the cyclic na-
ture of world markets, which the model was able to capture. As in the previous regression experiments, snake performs better than conventional non-linearities (Table 1).
The authors, in an additional experiment described in the appendix, use this dataset to gain insights into how the snake activation function learns (Fig. 8). Observing the predictions made at various points in the training process, we notice that at first, the features learned are mostly linear, low frequency features are then learned, and high-
ReScience C 7.2 (#3) – Arvind and Mama 2021 7
frequency features are learned at the later stages of training.
The performance of a snake feedforward network (two hidden layers of 64 neurons each, a = 30) and a recurrent neural network (single recurrent layer, 64 features in hidden state), typically used for time-series prediction, are compared in Fig. 9. The task is to learn the function sin(0.1x), with Gaussian noise σ added, for T = 300 timesteps. The first 200 are used for training, while the last 100 are used for testing.
It is seen that because of the noisy training data, even the predictions of the RNN are noisy, with a high generalization loss. The feedforward network, on the other hand, almost perfectly learns the underlying function with the right frequency and amplitude. Further, RNNs learn by backpropagation through time (BPTT), which has a prohibitively high computation cost, and can result in the exploding/vanishing gradient problem [15]. As a result the time taken by the snake network to regress the function is roughly 2 orders of magnitude lower than the time taken by the RNN (Fig. 10). This suggests that snake networks may be more effective in modeling data that is known beforehand to be periodic in nature.
4.4 Effect of a In a series of experiments, the authors depict the effect the parameter a has on the learning process. We reproduce one of these experiments for brevity. Simple neural networks ( 1 → 64 → 64 → 1) are trained on the sinusoidal function sin(x) + sin(4x)/4. It is seen in Fig. 11 that larger a encourages the model to learn features with higher frequency. With a = 1, the higher frequency modulation is considered noise, while the a = 16 model learns both the signals. This tendency can be taken into account while working with data known to be periodic, with a well-chosen a speeding up training.
ReScience C 7.2 (#3) – Arvind and Mama 2021 8
4.5 Results beyond original paper The original paper demonstrated the ability of neural networks with the snake activation function to learn periodic functions and that the performance on everyday tasks like image classification is similar to that of neural networks employing conventional activation functions. We extend this study to more sub-fields of deep learning.
We train a deep convolutional generative adversarial network (DCGAN) 2 [16] to generate samples of theMNIST dataset. All the activations in the generator and discriminator sub-networks are replaced with the specified non-linearity. We see that while the initial training is slow for the snake GAN (Fig. 13a), it eventually generates realistic samples
2Code adapted from https://github.com/eriklindernoren/PyTorch-GAN
ReScience C 7.2 (#3) – Arvind and Mama 2021 9
(Fig. 12a), which are qualitatively indistinguishable from those output by a typical GAN using the LeakyReLU non-linearity (Fig. 12b). a was a learnable parameter in this experiment.
Finally, we use the snake activation function in a Long Short Term Memory (LSTM) network for sentiment analysis 3 on the IMDB movie reviews dataset. This is a binary classification problem, attempting to predict whether amovie review is positive or negative. The typical tanh activation used to output the value ht = ot ∗tanh(Ct) in an LSTM is replaced by the snake activation, so that ht = ot ∗ snake(Ct). We observed that the snake LSTM network did not perform very well on this task (Fig. 14) and convergence was much more gradual. A single epoch of training the snake LSTM took twice as long as training the tanh LSTM. Also, in many cases, the snake network got stuck in local minima, necessitating a restart of training.
A possible explanation for this is that the snake function is not bounded like tanh, causing an increase in the magnitudes of ht and leading to instability. The results of the experiment do not mean that snake cannot be used in sequence models, only that the application is not as straightforward as in the previous experiments, and further modifications in the architectures might be necessary.
5 Discussion
As the authors had not initially made their code available and only included brief descriptions of the network architectures used in their experiments, exact replication of their experimental results was not possible. However, the qualitative nature of the papermeant that only the relative performance ofsnake in comparison to other activation functions on the specified problems was of interest, as opposed to the exact architectural details or loss values achieved. For example, the losses observed in Table 1 and Fig. 5b are orders of magnitude different from those in the original paper, likely due to varying normalization techniques and hyperparameters, even though the overall results observed in Fig. 5a and Fig. 7 are similar to those observed in the original paper. We were able to uphold the claim that neural networks with standard activation functions are insufficient to learn periodic functions outside the training range. We were also able to verify that the proposed activation function performs as well as standard activation functions, ReLU,tanh,LeakyReLU, over a wide range of tasks (with the exception of the LSTM experiment), by replicating the experiments in the original paper and conducting some additional ones ourselves. Future work could focus upon providing theoretical justifications for the behavior of snake and developing more suitable optimization algorithms.
3Code adapted from https://www.kaggle.com/arunmohan003/sentiment-analysis-using-lstm-pytorch and https://github. com/piEsposito/pytorch-lstm-by-hand
ReScience C 7.2 (#3) – Arvind and Mama 2021 10
5.1 What was easy A detailed description of the neural network architectures used for experiments such as training on the MNIST dataset and human body temperature was provided, allowing us to replicate the experiments closely. Links to datasets for all experiments, barring one, were also included in the paper itself. An extensive appendix sections listed additional experiments comparing the performance of snake with different a. Every experiment was supported by graphs showcasing the performance of snake with other activation functions, giving us a clear metric against which we could compare the results of our reproductions.
5.2 What was difficult The original source codewasnot provided initially andwehad to rely on the descriptions of architectures and hyperparameters (which were absent in many cases) and educated guesswork while attempting to replicate the results. Data for the human body temperature experiment was not available. Theoretical justification for variance correction and the results of this variance correction using ResNet101 on CIFAR-10 were provided, but implementation details were not included. The section on Comparison with RNN on Regressing a Simple Periodic Function simply states that snake was deployed on a feedforward network, without any additional details of the hyperparameters used. The dataset for the experiment had to be inferred from the graphs of the results, and since white noise had been added to the data, exact replication of the experimental setup was not possible.
5.3 Communication with original authors Liu Ziyin, one of the authors, was contacted to provide the dataset used for the human body temperature experiment, elaborate upon the implementation of variance correction and provide the implementation of RNNs using snake. Liu provided the GitHub link to the authorsʼ original code4 for the human body temperature, market index, and extrapolation experiments. Liu also provided an explanation on how to implement variance correction. While the code for the RNN implementation using snake activation was not made public, a screenshot of the same was provided. The provided code was incomplete and not fully documented but was nonetheless valuable in giving us a rough idea about the hyperparameters used. The provided repository also contains the human body temperature dataset within the codebase, which is not available in the original paper. We thank the authors for their assistance."
"['Tobias Teule', 'Nienke Reints', 'Chris Al Gerges', 'Pauline Baanders']",[Re] Deep Fair Clustering for Visual Learning,10.5281/zenodo.4833547,Replication,python,https://zenodo.org/record/4833547/files/article.pdf,rescience c rescience xpython Deep clustering,https://openreview.net/forum?id=DXVAJGohUKs,https://github.com/topteulen/UVA-FACT,7,2,2021,"Deep Fair Clustering (DFC) aims to provide a clustering algorithm that is fair, clusteringfavourable, andwhich canbeused onhigh-dimensional and large-scale data. In existing frameworks there is a trade-offbetween clustering quality and fairness. In this reportwe aim to reproduce a selection of the results of DFC; using two of four datasets and all four metrics that were used in the original paper, namely accuracy, Normalized Mutual Information (NMI), balance and entropy. We use the authorsʼ implementation and check whether it is consistent with the description in the paper. As extensions to the original paper we look into the effects of 1) using no pretrained cluster centers, 2) using different divergence functions as clustering regularizers and 3) using non-binary/corrupted sensitive attributes.","The open source code of the authors was beneficial; it was well structured and ordered into multiple files. Furthermore, the code to use randomly initialized instead of pretrained cluster centers was already provided.","First of all, the main difficulty in reproducing the paper was caused by the coding style; due to the lack of comments it was difficult to get a good understanding of the code. Secondly, we were required to download the data ourselves. However, these filenames and labels did not correspond to the included txt-files by the authors. Therefore, the model did not learn and we regenerated train_mnist.txt and train_usps.txt. Finally, the authors only included pretrained models for the MNIST-USPS dataset. As a consequence, we had to pre-train some parts of the DFC algorithm for the Color Reverse MNIST dataset.
ReScience C 7.2 (#4) – Teule et al. 2021 2
1 Introduction
With the increased application of Machine Learning in automated systems, particularly in decisionmaking systems, it has become desirable that individuals are treated equally in such automated environments. However, there exists a trade-off between the fairness and the performance of machine learning algorithms in a given task [1]. In current fair clustering algorithms, fair and effective representations are learned by mainly using small-scale and low-dimensional data. In this paper, we consider representations to be ʼeffectiveʼ if they yield good performance in clustering tasks. In addition, representations are considered to be ʼfairʼ when the algorithm is able to achieve great performance without using attributes like race and gender. DeepFair Clustering (DFC) is an algorithm that aims to learn fair and clustering-favorable representations for large-scale and high-dimensional data. In this context, feature representations are considered to be fair if they are statistically independent of sensitive attributes. Whether a particular attribute is sensitive or not; that is a cultural question that lies outside the scope of the paper. The aim of the paper is to show that we can pick an arbitrary attribute of an image, e.g. whether it comes from dataset X or dataset Y , and make sure that the feature representation is independent of the specific attribute. DFC consists of an encoder that produces the representations, and a discriminator that tries to predict the value of the sensitive attribute of a representation. A minimax game is used to learn fair representations in an adversarial manner. In order to preserve the utility of the representations, clustering is performed on all datapoints with the same sensitive attribute. This component is called s̓tructural preservationʼ because it preserves the clustering structure in each sensitive attribute. Finally, The KL-divergence is used as a clustering regularizer to prevent the formation of large clusters. All code is available on Github [2].
2 Scope of reproducibility
The goal of this work is to validate the reproducibility of the DFC algorithm proposed by Li, Zhao, and Liu1 beyond the scope of the original paper. The main claims of the original paper are as follows:
Claim 1: DFC produces a fair clustering partition on high dimensional and largescale visual data.
Claim 2: DFC produces clustering-favorable representations under a fairness constraint.
To test the validity of claim 1, the balance and entropy scores will be examined and compared with the original paper. The validity of claim 2 will be tested similarly, where we instead examine the accuracy and normalized mutual information (NMI) score. Important to note is that the original paper mainly evaluated the DFC algorithm on binary sensitive attributes. As an example, in Li, Zhao, and Liu1 a sensitive attribute was defined as whether an image from the MNIST dataset has been reversed or not. Generally speaking, in the original paper the sensitive attributes could only take one out of two possible values. However, sensitive attributes in the real world, like race or gender, can take on multiple variables. To evaluate the robustness of claim 1, wewill perform the DFC algorithm for non-binary sensitive attributes. To do this, we modify one of the sensitive attributes chosen by the authors, particularly whether an image belongs to the MNIST dataset or whether it is a Color Reverse MNIST image. In the former case, all the pixels of the digit are white and the background pixels are all black; in the latter case it is the other way around. To make this attribute non-binary, images from both datasets will be corrupted; some
ReScience C 7.2 (#4) – Teule et al. 2021 3
pixel values will be flipped, and it is not the case anymore that we can distinguish the images purely on the background color. It would inspire confidence if DFC is still able to function properly. Furthermore, we will investigate the robustness of both claims by testing the DFC algorithm on different model configurations. Specifically, we will test out different clustering regularizers by replacing theKL-divergencewith other divergencemeasures, namely the Jensen-Shannondivergence (JS-divergence) and theCauchy-Schwarz divergence (CSdivergence). Finally, in the original paper it is mentioned that pretrained cluster centers were used in the DFC algorithm. However, the motivation of using pretrained cluster centers in DFC is omitted, which might suggest that pre-training cluster centers are not a necessary part of the DFC pipeline. Therefore, we will examine the influence of pretrained cluster centers in DFC.
3 Methodology
3.1 Model descriptions
Li, Zhao, and Liu1 use a pretrained convolutional variational autoencoder (VAE). The available code only contained the pretrained encoder and decoder for the MNIST-USPS dataset [3]. We implemented and pretrained a convolutional VAE for the Color Reverse MNIST dataset. The encoder is build of four convolutional layers, followed by batch normalization and a ReLU activation function. Moreover, the decoder is implemented by reversing the layers of the encoder. Both the encoder and decoder contained 610K and 58.9K parameters respectively. The VAE is trained using the Adam-optimizer and a learning rate of 1e− 3. Li, Zhao, and Liu1 also used pretrained cluster centers to start their DFC algorithm off with high accuracy clusters. They only provided pretrained cluster centers for the MNIST-USPS dataset: Therefore, in order to reproduce the results, we were required to obtain pretrained cluster centers for the Color Reverse MNIST dataset. For this task we used k-means clustering1 with k = 10. Because the original code of the authors used 64- dimensional cluster centers, we first scaled our 32×32 images downwith amax pooling layer with 4 sized filters, so that the images would go from 32× 32 to 8× 8. After dimension reduction every image becomes a 1 × 64 vector. We then fit every image in the dataset using MiniBatchKMeans from the sklearn package2. With max_iter = 1000 and batch_size = 512. This results in our pretrained cluster centers which can be trained for every dataset. To examine during clustering whether fair representations are reached, a discriminator is used; when it cannot distinguish based on the sensitive attribute the representations are fair. This discriminator is a multilayer perceptron (MLP) using three linear layers, of which the first two are followed by a ReLU activation function and a dropout of 0.5: the final layer is followed by a sigmoid activation function. The discriminator is trained jointly with the encoder for 20000 epochs. Finally, the Adam optimizer is used with an initial learning rate of lrinit = 1e − 4. The learning rate is adjusted with lr = lrinit(1 + 10t)−0.75, with t = 0 at the start of the training process; with every iteration t is linearly increased to t = 1 at the end of the training process. The objective function consists of three parts; the fairness-adversarial loss (Lf ), the structural preservation loss (Ls) and the clustering regularizer term (Lc). The task of the fairness-adversarial loss is to minimize the divergence between the cluster assignments of the different subgroups. In this way the term promotes a similar cluster distribution for all subgroups, hence, statistical independence between cluster assignments and the
1https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html 2https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MiniBatchKMeans.html
ReScience C 7.2 (#4) – Teule et al. 2021 4
particular protected subgroup that the sample belongs to. The fairness-adversarial loss can be written as:
Lf := L(D ◦ A ◦ F(X), G), (1)
where L denotes the cross-entropy loss and ◦ denotes the function composition: moreover, D, A, F denotes the discriminator, cluster assignment and encoder respectively. The fairness-adversarial loss encourages statistical independence of the cluster assignments and the sensitive attribute G, however, only optimizing Lf is not enough as it can lead to a degenerate solution, where the representations that are produced by the encoder are all constant. Of course, such a constant representation cannot lead to good clustering quality; it would hide, rather than illuminate, the fundamental structure in the data. The structural preservation loss prevents such a solution by penalizing it when the inner structure of a particular subgroup is altered in the DFC setting, as opposed to clustering the subgroup individually. The preservation loss, which was proposed by the authors [1] is given as follows:
Ls := ∑
g∈[M ] ∣∣∣∣∣∣P̂gP̂Tg − PgPTg ∣∣∣∣∣∣2 , (2) where [M ] denotes the set of sensitive attributes, P̂g andPg denote the (soft) assignments of the g−th protected subgroup when individually clustered and clustered with DFC, respectively. Following otherwork indeep clustering, DFCemploys a clustering regularizer to strengthen prediction confidence and to prevent large cluster sizes [1]. Contrary to earlier work, the clustering regularizer is chosen in such away that it encourages the members of a particular protected subgroup to be distributed equally over the clusters. To increase the confidence of the prediction an auxiliary target distribution Q is defined. This target distribution is defined in such a way that it favors current high confidence assignments and is calculated as:
qk = (pk)
2/ ∑
x∈Xg pk∑ k′∈[K]((pk′) 2/ ∑ x∈Xg pk′ , (3)
with pk the probability that sample x belongs to cluster k, and Xg the samples that belong to protected subgroup G. Then, the clustering regularizer loss is defined as the KL-divergence between soft assignment P and auxiliary target distribution Q:
Lc := KL(P ||Q) = ∑
g∈[M ] ∑ x∈Xg ∑ k∈[K] pk log pk qk . (4)
Again following the literature, the authors have chosen to use the Student t-distribution for soft cluster assignment [1]. The probability that the representation z (corresponding to a particular sample x) belongs to cluster ck is then given by:
pk = (1 + 1α ||z − ck|| 2)− α+1 2∑
k′∈[K](1 + 1 α ||z − ck′ ||2)
−α+12 , (5)
with α the degree of freedom of the Student s̓ t-distribution. In conclusion, the overall objective is defined as the following minimax strategy:
max F,A αfLf − αsLs − Lc, (6)
min D αfLf (7)
with αf and αs as trade-off hyperparameters.
ReScience C 7.2 (#4) – Teule et al. 2021 5
3.3 Extensions
Divergence Functions — Asmentioned earlier in Section 2, we examined the effect of using different divergence functions as clustering regularizers by replacing the KL-divergence with either the Jensen-Shannondivergence (JS-divergence) or the Cauchy-Schwarz divergence (CS-divergence). The JS-divergence is the smoothed and symmetric version of the KL-divergence and is calculated as follows:
JS(P ||Q) = 1 2 KL(P ||M) + 1 2 KL(Q||M) (8)
whereM = 12 (P +Q) andKL(.||.) is the KL-divergence as defined in 4. Furthermore, the CS-divergence is a divergence function that is inspired by information theory. It is given by the following ([4]):
CS(P ||Q) = − log ∫ p(x)q(x)dx√∫
p2(x)dx ∫ q2(x)dx
(9)
The CS-divergence is, like the JS-divergence, a symmetric measure. Furthermore, the CS-divergence has the range 0 ≤ CS(P ||Q) ≤ ∞, where the minimum value of 0 is obtained if p(x) = q(x).
3http://yann.lecun.com/exdb/mnist/ 4http://www.kaggle.com/bistaumanga/usps-dataset
ReScience C 7.2 (#4) – Teule et al. 2021 6
Corrupted Sensitive Attribute — Another extension mentioned in Section 2 is that we consider the influence of the corrupted sensitive attribute. In theColorReverseMNIST dataset the presence of this attribute is clear in background color, The numbers are black in the case of MNIST-USPS and white in the case of Color Reverse MNIST , The background is defined by everything that is not the colour of the number. Corrupting the sensitive attribute in this dataset implies random modifications in the background color. We compare two corruption rates (0.1 and 0.4) against the original images; for example, a rate of 0.1 implies that a random 10% of the background pixels are changed from black to white or vice versa.
Pretrained Cluster Centers — The final extension mentioned in Section 2 is that we would examine the influence of pretrained cluster centers on the performance of DFC. If no pretrained cluster centers were used, they would be randomly initialized with Xavier initialisation using a uniform distribution.
3.4 Evaluation To evaluate the models, we used the four metrics that were also used by Li, Zhao, and Liu1: accuracy and Normalized Mutual Information (NMI) were used to evaluate the cluster validity, while balance and entropy were calculated to evaluate the fairness of DFC. Equations 10-13 are used to calculate the metrics: the NMI is calculated using sklearn.
Accuracy =
∑n i=1 Iyi=map(ŷi)
n (10)
NMI =
∑ i,j nij log
n·nij ni+·n+j√ ( ∑
i ni+ log ni+ n )( ∑ j n+j log n+j n )
(11)
Balance = min i ming |Ci ∩Xg| ni+
(12)
Entropy = − ∑ i |Ci ∩Xg| ni+ log |Ci ∩Xg| ni+ + ϵ (13)
In Eq. 10, yi and ŷi represent the correct and predicted cluster label respectively: map is a function that maps the cluster label ŷi to the correct label yi. In Eq. 11, nij denotes the co-occurrence number; ni+ and n+j denote the cluster size of the i-th and j-th clusters, in the obtained partition and ground truth, respectively. n is the total data instance number. Furthermore, Ci represents the i-th cluster andXg the g-th protected subgroup. Finally, in Eq. 13, ϵ = 1e− 5, to ensure the log will always be defined. As mentioned before, accuracy and NMI are measures for the clustering quality. More specific, accuracy measures the correctness of clusters relative to a ground truth and NMI measures the similarity between the clustering obtained by DFC and the ground truth. For both metrics, a higher value indicates better clustering quality. Furthermore, balance and entropy evaluate the fairness of the obtained clustering. In particular, balance measures the homogeneity of the clustering across multiple sensitive attributes. A large value indicates that each cluster contains samples from multiple protected subgroups. If one cluster contains only instances of a particular protected subgroup, the balance has a score of 0. Entropy is a softer fairness metric than balance that measures the diversity of the clustering. Just like balance, a large entropy value indicates that samples from a protected subgroup are present in almost every cluster, which indicates a more fair clustering and thus more fair representations.
ReScience C 7.2 (#4) – Teule et al. 2021 7
3.5 Computational requirements The codewas run locally on aGPU. TheGPU in question is a GeForce GTX 970with driver version 456.71. The CPU in thismachine is an Intel Core i7-4770K. Thememory usedwas 16.0 GB DDR3. For the main training of the adversarial network with 20000 iterations at 5000 iterations per evaluation the model ran in approximately 3.5 hours. This was the same computational cost to run DFC with a different divergence function. For the corruption extension we used 5000 iterations at 500 iterations per evaluation which took about 1.5 hours. The training of the VAE for the Color ReverseMNIST dataset took roughly 1 hour. The k-means clustering to obtain the pretrained clusters took approximately 15 minutes. Taking all this into account, the reproduction of the Color Reverse MNIST results from scratch took a total of circa 6.25 hours to compute. Finally, evaluating all the results with the saved models takes about 20 minutes. In conclusion, the code is not fast but it can be run on a local machine. A GPU is heavily recommended, because without one the code is about eight times slower.
4 Results
4.1 Reproduced Results
The original results from Li, Zhao, and Liu1 as well as the reproduced results can be found in Table 2.
First of all, the reproduced accuracies on both datasets are very similar to the original values of Li, Zhao, and Liu1; differing 0.029 and 0.01 on Color Reverse MNIST and MNIST-USPS respectively. Secondly, similar to accuracy, the original and reproduced NMI values do not differ much; 0.88 on Color Reverse MNIST and 0.004 on MNIST-USPS . Thirdly, the reproduced balance on Color ReverseMNIST is close to the original; differing 0.02: however, the difference is larger on the MNIST-USPS dataset (0.049). Finally, the entropy values on Color Reverse MNIST are very similar in contrast to the original and reproduced entropy on MNIST-USPS .
4.2 Results beyond original paper
Divergence Functions — Table 3 shows the results for different divergence functions as clustering regularizers.
ReScience C 7.2 (#4) – Teule et al. 2021 8
In Table 3 it can be observed that the accuracy does not differ significantly on the Color ReverseMNIST dataset. Furthermore, using the CS-divergence seems to yield the highest accuracy. However, the NMI decreases significantly with JS- and CS-divergence as clustering regularizer. On top of that, the balance and entropy decrease significantly with CS-divergence. Using the JS-divergence also results in a decrease in balance and entropy on the Color ReverseMNIST dataset, even though that decrease is minor compared to the CS-divergence. In general, the KL-divergence outperforms the other two divergences on three of the four metrics on the Color Reverse MNIST dataset. On the MNIST-USPS dataset, it can be seen that the difference in accuracy and NMI is even less significant compared to the Color Reverse MNIST dataset. However, on the MNIST-USPS dataset all four metrics decrease when using the JS- or CS-divergence instead of the KL-divergence. Moreover, the balance and entropy seem to decrease more significantly than the accuracy andNMI. In general, on theMNIST-USPSdataset the JS- and CS-divergence perform worse than the KL-divergence.
Corrupted Sensitive Attribute — The results of the corruption extension can be found in Table 4.
As can be seen in Table 4, both the accuracy and the NMI decrease when data has been corrupted. However, the decrease in accuracy and NMI seem to be more significant when the Color Reverse MNIST dataset is corrupted. Moreover, the balance and entropy decrease when the data is corrupted. In general, a higher corruption leads to lower values on all metrics. Finally, Table 4 shows that the balance drops significantly with a higher corruption rate.
Pretrained Cluster Centers — The final extension researches the influence of the pretrained cluster centers on the utility and fairness of the clusters. The results for both datasets
ReScience C 7.2 (#4) – Teule et al. 2021 9
can be found in Table 5.
Most significantly, in Table 5, it is visible that the accuracy on theMNIST-USPS dataset is significantly higher than that on Color ReverseMNIST , both with and without pretrained cluster centers. Furthermore, for both datasets accuracy and NMI are higher when pretrained cluster centers are used. The difference in accuracy is larger on theMNIST-USPS dataset, whereas the difference in NMI is smaller on this dataset, compared to Color Reverse MNIST . Moreover, the difference in balance on MNIST-USPS is not significant (0.018) while this difference is approximately five times larger (0.089) on the Color Reverse MNIST dataset. Finally, the entropy does not change significantly on both datasets.
5 Discussion
Our experimental results support the main claims of the original paper; namely that DFC is able to produce fair and clustering-favorable representations of large-scale and high dimensional data, such as images. Furthermore, our extensions seem to add to the robustness of the model and strengthen the choices made by the original paper. First of all, the results of the different divergence functions show that both, CS- and JS-divergence, work but the default, KL-divergence, outperforms the two researched alternatives. Moreover, even though the Color ReverseMNIST dataset required the training of a new VAE and k-means clustering the results were still comparable; this speaks to the robustness of the algorithm that the original authors designed.
5.1 What was easy The open source code of the authors was conveniently arranged. For example, the divergence function was put in the utils file, which made it easy to test other divergence functions as well. Also, the code had an implementation that randomly initialises cluster centers; to discard the pretrained cluster centers only modifications in the main file were needed. Once we understood the code base, the code structure became intuitive and easy to work with.
5.2 What was difficult First of all, a difficulty while reproducing the research was caused by the coding style; due to the lack of comments it was difficult at the start to get a good understanding of the code. Secondly, we were required to download the data ourselves. However, these filenames and labels did not correspond to the included .txt-files by the authors. Therefore, the model did not learn and we were forced to produce our own train_mnist.txt and train_usps.txt. Thirdly, the algorithm uses pretrained models, a pretrained VAE, and a file with pretrained cluster centers. However, the authors solely provided these for one of the four datasets, namely MNIST-USPS . Thus, for Color Reverse MNIST we had to build our own VAE based on their structure and calculate our own cluster
ReScience C 7.2 (#4) – Teule et al. 2021 10
centers. The latter came with an extra difficulty since in the paper it is not stated how the clustering was performed. Therefore, we had to guess and chose k-means clustering. This made the reproduction of the Color Reverse MNIST dataset much harder than anticipated."
"['Prateek Garg', 'Lakshya Singhal', 'Ashish Sardana']",[Re] Training Binary Neural Networks using the Bayesian Learning Rule,10.5281/zenodo.4833681,Replication,Python,https://zenodo.org/record/4833681/files/article.pdf,rescience c machine learning deep learning binary neural network python pytorch,https://openreview.net/forum?id=bhiGno-Cxq,https://github.com/prateekstark/training-binary-neural-network,7,2,2021,"Meng, Bachmann, and Khan1 gives a mathematically principled approach to solve the discrete optimization problem that occurs in the case of BinaryNeuralNetworks and claims to give a similar performance on various classification benchmarks such as MNIST, CIFAR-10, and CIFAR100 as compared to their full-precision counterparts, as well as other recent algorithms to train BNNs like PMF and Bop. The paper also claims that the BayesBiNN method has an application in the continual learning domain as it helps in overcoming catastrophic forgetting of the past by using the posterior approximation of the previous task as a prior for the upcoming task. We try to reproduce all the results presented in the original paper by making a separate and independent codebase.","After we worked out the mathematics behind the BayesBiNN approach, we developed a pseudo-code for the optimization process which alongwith references from the author s̓ code, helped us a lot in our reproduction study.","Some of the hyperparameters were not mentioned by the authors in their paper so it was difficult to approximate the values of those parameters. The lack of resources was the next big difficulty that we faced.
Communication with original authors We had a very fruitful conversation with the authors, which helped us in better understanding the BayesBiNN approach and its extension to the segmentation domain. The detailed pointers are given at the end of this report.
1 Introduction
Deep Learning is moving towards larger and larger parameters day-by-day, which often makes it difficult to run on resource-constraint devices like mobile phones. Binary Neural Networks (BNNs) could act as a savior in such situations, helping in largely saving storage and computational costs. The problem of optimizing this binary set of weights is clearly a discrete optimization problem. Previous approaches like Straight-Through Estimator (STE) and Binary Optimizer (Bop) tend to ignore this and use gradient-based methods, which still worked in practice. The paper presents a mathematically principled approach for training BNNs which also justifies the current approaches.
2 Scope of reproducibility
The paper mentions a bayesian approach to solve the discrete optimization problem in the case of Binary Neural Networks (BNNs). The outcome of this approach was a BayesBiNN optimizer which could be used to train BNNs and achieve similar accuracy as compared to their full-precision counterparts. To verify the claims given in the paper, we target to achieve the following objectives:
• Work out and present the mathematics behind BayesBiNN in a simpler way and prepare a pseudo-code to the optimizer.
• Implement the BayesBiNN optimizer and STE optimizer to verify the accuracy on tasks of varying domains, as reported in the original paper.
• Reproduce the results for other baselines present in the paper such as proximal mean-field (PMF) according to the hyper-parameters given in the paper.
• Evaluate the performance of BayesBiNN optimizer in more complex domains like semantic segmentation.
ReScience C 7.2 (#5) – Garg, Singhal and Sardana 2021 2
3 Methodology
We have re-implemented the algorithm proposed in the paper from scratch using PyTorch and created an end-to-end model trainer with a Keras-like interface. We referred to the code given by the authors for the baselinemodel hyperparameters and the source of synthetic datasets. The algorithmpresented by the original authors in their paper can be represented as follows:
Algorithm 1: Bayesian Learning rule for BayesBiNN Input: Input: Initialize λ
for number of training epochs do for i = 1,...,number of mini-batch examples do
Sample ϵ ∼ U(0, 1) and set δ = 12 log ϵ
1−ϵ Initialize wb = tanh((λ+ δ)/τ) Compute following using gumbel-softmax trick
gi := 1
M ∇wb l(yi, fwr (xi))
si := N(1− w2b )
τ(1− tanh(λ)2)
end Update µ and λ using following equation
µ← tanh(λ)
λ← (1− α)λ− α[ M∑ i=1 (si ⊙ gi)− λ0]
end
This would make the paper easier to interpret and this implementation on code. Some of the mathematical expressions mentioned in the original paper were presented from various sources andmissed out several intermediate steps whichwe found to be very important while reproducing the paper from scratch. Here we present a step-wise derivation of some important expressions written in the original paper: Bayesian formulation of the discrete optimization problem, in which loss has to be minimized w.r.t posterior q(w), given prior p(w) can be written as:
Eq(w) [ N∑ i=1 l( yi, fw(xi) ) ] +DKL[ q(w)∥p(w)]
To solve the above optimization problem, Bayesian learning rule given in Khan and Rue2 is applied, assuming solution to be a part of minimal exponential family of distribution, given by:
q(w) = h(w)exp[λTϕ(w)−A(λ)]
where base measure h(w) is assumed to be 1. Following is the update rule used to learn λ:
λ← (1− ρ)λ− ρ[∇µEq(w)[l(yifw(xi))]− λ0]
where ρ is the learning rate, µ = Eq(w)[ϕ(w)]. Bernoulli distribution being a special case of minimal exponential family distribution, we assume prior p(w) ∼ Bern(p) with
ReScience C 7.2 (#5) – Garg, Singhal and Sardana 2021 3
p = 0.5, and posterior q(w) to be mean-field Bernoulli distribution:
q(w) = W∏ j=1 p 1+wj 2 j (1− pj) 1−wj 2
For weight j,
q(wj) = exp( 1
2 (1 + wj) log pj +
1 2 (1− wj) log(1− pj))
= exp( wj︸︷︷︸ ϕ(w) 1 2 log p 1− p )︸ ︷︷ ︸
λ
+ 1
2 log(p(1− p))
Comparing above expression with minimal exponential family distribution, we can say:
λ = 1
2 log
p
1− p andϕ(w) = w.
We defined µ = Eq(w)[ϕ(w)],
µ = ∫ wq(w)dw = E[q(w)] = ∑ wi∈{−1,1} wiq(wi) = ∑
wi∈{−1,1}
wip 1+wi 2 (1− p) 1−wi 2 = −(1− p) + p
= 2p− 1
From above derivations we can say that, p = 1/(1 + exp(−2λ)) = Sigmoid(2λ) and q(w) ∼ Bern(p). To implement the update rule, we need to compute the gradient with respect to µ. Original paper uses a reparamaterization trick called gumbel-softmax trick Maddison, Mnih, and Teh3, which is used to relax the discrete random variables of a concrete distribution (for eg, bernoulli distribution). Binary concrete relaxation Maddison, Mnih, and Teh3 of binary concrete random variableX ∈ (0, 1) with distributionX ∼ BinConcrete(α, λ) with temperature λ and location α,
X = 1
1 + exp(−(logα+ L)/λ)
where L ∼ Logistic. And its density is given by
pα,λ(x) = λαx−λ−1(1− x)−λ−1
(αx−λ + (1− x)−λ)2
Using above expressions, for binary weights wj ∈ {0, 1}, relaxed variable w ϵj ,τ r (pj) ∈ (0, 1) can be used with temperature τ and α = e2λ given by
wϵj ,τr (pj) = 1
1 + exp(− 2λj+2δjτ ) ,
where δj ∼ Logistic and its density is given by
p(wϵj ,τr (pj)) = τe2λw ϵj ,τ r (pj) −τ−1(1− wϵj ,τr (pj))−τ−1
(e2λw ϵj ,τ r (pj)−τ + (1− w ϵj ,τ r (pj))−τ )2
ReScience C 7.2 (#5) – Garg, Singhal and Sardana 2021 4
4 Experimental setup
4.1 Model descriptions We kept the model architectures the same as mentioned in the original paper to maintain uniformity and implemented them ourselves. For the MNIST classification task we used the BinaryConnect architecture and for the CIFAR classification task we used the VGGBinaryConnect architecture. The authors also compared their BayesBiNN method with the LR-Net method in Shayer, Levi, and Fetaya4. We implemented the same model architecture as in the LR-Net paper. The detailed architectures are mentioned in the supplementary material provided with this report. For the segmentation task, we used the original U-Net architecture detailed in Ronneberger, Fischer, and Brox5 with a minor difference that we introduced a BatchNorm layer after every convolution layer.
4.2 Datasets The datasets used for image classification tasks are MNIST, CIFAR-10, and CIFAR-100. For generating visualizations for the BayesBiNN and STE methods, we used small toy datasets, the Snelson dataset6 for regression problems, and TwoMoons̓ dataset Snelson and Ghahramani7 for classification problems. For the segmentation part, we used the Brain Tissue segmentation dataset from Ronneberger, Fischer, and Brox5, and for the continual learning visualizations we used the permuted MNIST dataset Goodfellow et al.8. The pre-processing of inputs has been kept the same as mentioned in the original paper and has been detailed below. Pre-processing: For the MNIST dataset we simply normalize the images and do not perform data augmentation. We keep our validation split as 0.1 uniformly across all sets of experiments except the comparison with the LR-Net method Shayer, Levi, and Fetaya4. For the CIFAR datasets also, we perform the normalization of images along with dataaugmentation where we generate images by randomly cropping a 32x32 image from a 40x40 padded image. Finally, for our semantic segmentation task, we had a very small dataset of 30 images out of which 24 were chosen for training and 6 for validation. No other pre-processing has been done.
4.3 Hyperparameters We have used the hyper-parameters given in the original paper. Table Table 1 contains the list of all the parameters we used for our experiments:
ReScience C 7.2 (#5) – Garg, Singhal and Sardana 2021 5
4.4 Computational requirements All our final experimental results were performed on a machine having 1 NVIDIA Tesla V100 GPU with 16 GB memory. Training the Binary Network with BayesBiNN optimizer for a single run, takes around 2.5 GPUhours forMNIST, 5.5 GPUhours for CIFAR-10, and around 8.5 GPU hours for the CIFAR-100 dataset, in the current experimental setup.
5 Results
In Table Table 1we report our results for various classificationbenchmarks using our implemented BayesBiNN and STE optimizer. We notice that we get a difference of less than 0.1% as compared to that in the original paper. We generated the results for baseline STE optimizer and full-precision networks by evaluating our implementation of these methods. We also generated the results of PMF, by modifying its original open-sourced code and using the hyperparameters mentioned in the original paper.
5.1 Comparison with LR-Net Authors compared their BayesBiNN approach to the LR-Netmethod presented in Shayer, Levi, and Fetaya4. We tried to reproduce the result for the same setting. In this comparison, the data pre-processing and augmentationmethods remain the same asmentioned in section 4.2, but we do not split the data in training and validation sets in this case. We
ReScience C 7.2 (#5) – Garg, Singhal and Sardana 2021 6
denote the test accuracies after 190 epochs in the case of MNIST and 290 epochs in the case of CIFAR-10, as done in the original paper to maintain uniformity. Note that, our accuracy ismatchingwith that of the original authors in the case ofMNIST but not in the case of CIFAR-10. We suspect that this is due to some difference in Batch-Norm layers used.
Optimizer MNIST CIFAR10 BayesBiNN (ours) 99.52% 84.49% BayesBiNN (orig.) 99.50% 93.97%
LR-net Shayer, Levi, and Fetaya4 99.47% 93.18%
models are intrinsically very difficult to train. For the results shown in Table Table 5 and Figure Figure 5, we have used the hyperparameters denoted in Table Table 1.
6 Discussion
We reproduced almost all the experiments given in the original paper and most of our results match with the original claims. While this BayesBiNN approach is mathematically principled, we tried to take a step forward by using that optimizer on a single segmentation task. However the results were against our expectation and the result of segmentation was a zoomed segmented image of the input with lots of noise. In addition to this, in the case of comparison with the LR-Net method, our accuracy differs from that of the original authors, which we feel might be due to some difference in architecture chosen. Themajor contribution of our work is developing a code base library
ReScience C 7.2 (#5) – Garg, Singhal and Sardana 2021 8
based on PyTorch with a Keras type interface for training BNNs with several different methods in its arsenal. This could reduce the coding efforts required for training BNNs and could help in future research as benchmarking library.
6.1 What was easy The original paper contained a very good explanation of the mathematics behind the BayesBiNN approach. After we worked that out the pseudo-code as pointed out in Algorithm algorithm 1, the basic implementation of the optimizer became easy and easily verifiable by the author s̓ original code. The appendix in the original paper contained a list of various hyper-parameters used for experiments. This helped us a lot while running the experiments and deciding the range of hyper-parameters while doing ablation studies.
6.2 What was difficult Themost difficult part here was running a large number of experiments in lack of many computational resources. This difficulty was increased since we are taking an average of 5 runs while reporting all our results. Apart from this, we also faced some difficulty in taking care of the hyper-parameters, which were not mentioned in the original paper (like momentum coefficient). To cater to that, we had to guess some possible values of the hyper-parameters and run small random searches to find a good candidate. Finally, we also faced difficultywhile reproducing the results for the baselines PMF andBop, and adapting their experimental settings tomatchwith those used in the original BayesBiNN paper. Since their code was written a long time ago and used older software stack, this task took us a lot of time.
6.3 Communication with original authors We did not understand the intent of the authors for choosing temperature as 1 in the case of experiments on synthetic datasets. We were also curious about the author s̓ view on segmentation tasks using BayesBiNN. Hence, we reached out to the authors via email along with the review of their paper, to ask for some pointers. They gave the following major pointers:
• It is reasonable that at high temperatures the learned distribution will have high variance. The mode mentioned in the paper refers to the sign(̂(w)), where (̂w) denotes the expectation of the learned posterior Bernoulli distribution. It is not appropriate to directly use the continuous (̂w) as the mode. Another way is to use
ReScience C 7.2 (#5) – Garg, Singhal and Sardana 2021 9
mean, which samples from the learned posterior Bernoulli distribution, and then make predictions using ensemble learning.
• STE is more stable and suggested by the authors to act as a baseline, in particular, Adam STE first, to make sure binary networks work. As shown in the paper, there is literally very little difference between STE and BayesBiNN but indeed the latter is difficult to train, as most Bayesian optimizers.
Broader Impact
Recent researches Strubell, Ganesh, and McCallum9 mention that training a single big transformer model could emit around 626,155 lbs CO2 which is around 5 times of average carbon emission by a car in its total lifetime. Clearly, Deep Learning takes a huge toll on the environment which is why there has been an increased focus on much more energy-efficient ”Green AI”. BNNs intrinsically have far less computational and space complexity as compared to their full-precision counterparts and as we can see above they can also achieve accuracy close to the full-precision networks, at least in the classification tasks, and also show the potential of expanding well to more complex segmentation tasks. This can help us a lot in moving towards cleaner Deep Learning. This field of research also provides a huge set of opportunities in extending AI to edge devices with much smaller and low-energy systems. We feel that its potential impact on the environment and sustainability is at par with its academic importance."
"['Rahel Habacker', 'Andrew Harrison', 'Mathias Parisot', 'Ard Snijders']",[Re] Reproducing Learning to Deceive With Attention-Based Explanations,10.5281/zenodo.4834146,Replication,Python 3,https://zenodo.org/record/4834146/files/article.pdf,rescience c rescience x Python,https://openreview.net/forum?id=-rn9m0Gt6AQ,https://github.com/MatPrst/deceptive-attention-reproduced,7,2,2021,"Based on the intuition that attention in neural networks is what themodel focuses on, attention is now being used as an explanation for a modelsʼ prediction (see Galassi, Lippi, and Torroni1 for a survey). Pruthi et al.2 challenge the usage of attention-based explanation through a series of experiments using classification and sequence-to-sequence (seq2seq) models. They examine the model s̓ use of impermissible tokens, which are user-defined tokens that can introduce bias e.g. gendered pronouns. Across multiple datasets, the authors show that with the impermissible tokens removed themodel accuracy drops, implying their usage in prediction. And then by penalising attention paid to the impermissible tokens but keeping them in, they train models that retain full accuracy hence must be using the impermissible tokens, but that does not show attention being paid to the impermissible tokens. As the paper s̓ claims have such significant implications for the use of attention-based explanations, we seek to reproduce their results.",,
"['Lars Holdijk', 'Maarten Boon', 'Stijn Henckens', 'Lysander de Jong']",[Re] Parameterized Explainer for Graph Neural Network,10.5281/zenodo.4834242,Replication,English,https://zenodo.org/record/4834242/files/article.pdf,rescience c rescience x,https://openreview.net/forum?id=8JHrucviUf,https://github.com/LarsHoldijk/RE-ParameterizedExplainerForGraphNeuralNetworks,7,2,2021,In thisworkweperforma replication study of the paperParameterizedExplainer forGraph Neural Network. The replication experiment focuses on three main claims: (1) Is it possible to reimplement the proposed method in a different framework? (2) Do the main claims with respect to the GNNExplainer hold? (3) Is the used evaluationmethod a valid method for explaining the classification decision by Graph Neural Networks?,"Themethodproposedby the authors for explaining theGraphNeuralNetworks is easy to comprehend and intuitive. Re-implementation of the method is straightforward using a modern deep learning framework. The datasets used for the experimental setup were all provided together with their codebase.
Copyright © 2021 L. Holdijk et al., released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Lars Holdijk (larsholdijk@gmail.com) The authors have declared that no competing interests exist. Code is available at https://github.com/LarsHoldijk/RE-ParameterizedExplainerForGraphNeuralNetworks. – SWH swh:1:dir:541677177d4dbb9dc5b612dfc41373fad40b08f0. Open peer review is available at https://openreview.net/forum?id=8JHrucviUf.
ReScience C 7.2 (#7) – Holdijk et al. 2021 1","The main difficulty arose from the difference between the experimental configurations discussed in the paper and implemented in the code. There were a number of small inconsistencies (eg. incorrect hyperparameter settings), but also some major ones (eg. using batch-normalization in training mode during evaluation). This issue was worsened by the fractured reporting of configurations in the code.
Communication with original authors Contact was made with the authors on two occasions. During the first exchange the authors confirmed a number of clarifying questions and confirmed that the configurations as presented in the codebasewere to be used instead of those provided in the paper. In the second exchange our reservations concerning the used experimental evaluation were conveyed to the authors. The authors did not share our concerns.
1 Introduction
Graph Neural Networks (GNNs) emerged as state-of-the-art models in machine learning, capturing both graph structure and node features through recursively incorporating a graphs̓ previous node information. GNNs are able to deliver state-of-the-art performances in matters such as graph/node classification and link prediction. As for most Neural Networks, the ʼreasoningʼ towards classification inside GNNs is not intuitive to humans. The authors of the paperGNNExplainer: Generating Explanations for Graph Neural Networks [1] address this problem and try to solve it by introducing GNNEXPLAINER; an optimization task thatmaximizes themutual information between a GNN s̓ prediction and a distribution of possible sub-graph structures. The GNNExplainer s̓ algorithm can identify the sub-graph and node structure responsible for a given classification. Based on the work done in [1], Luo, D. et al. claim to have further developed GNNExplainer in their paper Parameterized Explainer for Graph Neural Network [2]. The paper introduces PGEXPLAINER; a general parameterized explainer that applies to any GNN based models in both transductive and inductive settings. The authors of the paper first formulate the learning objective of PGExplainer. Using the same datasets as [1], they claim to outperform GNNExplainer up to 24.7% in Area under the ROC Curve (AUC) [3] score. Furthermore the authors state that PGExplainer can speedup computations up to 108 times faster thanGNNExplainer. These and further claimsmade in the PGExplainer paper will be evaluated in this report by replicating and extending the performed evaluation in a replication study.
Scope of reproducibility The focus of our reproducibility study is on the experimental comparison between the PGExplainer and the preceding GNNExplainer. The authors of the original PGExplainer paper include a number of other benchmarks in their evaluation, but focus their comparison primarily on the GNNExplainer. For this reason it makes sense for us to do the same. In contrast to the original paper, we will base our entire comparison on reimplementations of bothmethods. In the original paper, the authors partly copy the results from the GNNExplainer and partly use their own re-implementation to obtain the GNNExplainer scores. In communication the authors stated that the decision to partly copy the results was made due to lackluster results in their own re-implementation. As the quality of an explanation is highly dependent on the model it aims to explain, we believe that it would be beneficial to re-implement bothmethods in the same framework and perform their evaluation on equal footing. We will use PyTorch as the framework for doing so. For the reimplementation of the PGExplainer the authorsʼ own TensorFlow-based codebase provided in their paper will be used as the main starting-point. However, during
ReScience C 7.2 (#7) – Holdijk et al. 2021 2
inspection of the codebase, we found that there are a number of significant differences between the configurations used for both the trainedmodels that wewish to explain and the PGExplainer itself betweenwhat is described in the paper andwhat is actually implemented in the code. After discussing with the authors, the conclusion was reached that the configurations used in the code should serve as the starting point for the replication. Part of our reproduction experiment will focus on validating if these are indeed the correct configurations. In short, our replication experiment aims to validate the following aspects of the original paper.
1. Given the original codebase and configuration files provided therein, is it possible to reimplement the PGExplainer method using a different framework? And if so, are the provided configurations sufficient to obtain the presented quantitative, qualitative and efficiency results.
2. The authors claim that their PGExplaimer greatly improves over the previously proposed GNNExplainer. We aim to validate that this claim holds with both methods evaluated using the same framework and evaluation.
3. Evaluation of explanation methods is notoriously hard. We wish to validate if the evaluation method used in the original paper is a sound approach for doing so.
The remainder of this work will be structured as follows. In the next section we will provide the needed background on the PGExplainer. Following this, we will provide a short overview of the codebase accompanying this reproduction. In section 4, we will discuss the original experimental setup in depth and highlight some key components not discussed in the original paper. Section 5 will present the replicated results and compare them to the original paper. Based on the highlighted components in section 4 and some results presented in section 5, section 6 will raise some question regarding the evaluation setup used. In the last section, we will summarize our replication.
2 PGExplainer
The authors start by dividing an input graph Go in two subgraphs, such that Go = Gs + ∆G. Gs represents the explanatory graph that makes important contributions towards the graph classification, while ∆G represents the remainder of the initial graph. The main task therefore is to find the optimal subgraphGs. This is achieved throughMutual Information (MI) maximization:
max Gs MI (Yo, Gs) = H (Yo)−H (Yo | G = Gs) , (1)
Which uses the GNN s̓ classification prediction Yo and its input Go. The MI maximization is done by deducting the conditional entropy from the marginal entropy. Which is equivalent to minimizing the conditional entropy. To avoid having an exploding exponential amount of candidates, the authors assume the explanatory graphs used are Gilbert random graphs [4], where selections of edges from the original input graph Go are conditionally independent to each other. Using relaxation, the learning objective is rewritten as
min Gs EGs [H (Yo | G = Gs)] ≈ min Θ EGs∼q(Θ) [H (Yo | G = Gs)] , (2)
where q(Θ) is the distribution of the parameterized explanatory graph. Each graph edge obtains a continuous variable in range (0, 1). A randomgraph Ĝs is sampled fromedgedistributions and fed to the trainedGNNmodel obtaining prediction Ŷs. Following [1], the authors modify the conditional entropy with
ReScience C 7.2 (#7) – Holdijk et al. 2021 3
cross-entropy H(Yo, Ŷs), where Ŷs is the prediction of the GNN model with Ĝs as input. Using Monte Carlo approximation, the learning objective becomes
min Ω − 1 K K∑ k=1 C∑ c=1 PΦ (Y = c | G = Go) logPΦ ( Y = c | G = Ĝ(k)s ) , (3)
with Φ as the parameters in the trained GNN,K as the number of sampled graphs, C as the number of labels and Ĝ(k)s the k-th sampled graph, parameterized by Ω. Furthermore, PGExplainer is used to collectively provide explainations for multiple instances I. The authors present the learning objective of this set of instances as follows.
min Ψ − ∑ i∈I K∑ k=1 C∑ c=1 PΦ ( Y = c | G = G(i)o ) logPΦ ( Y = c | G = Ĝ(i,k)s ) (4)
Here Ψ are parameters in the explanation network, G(i) the input graph and Ĝ(i,k) the k-th sampled graph for the i-th instance. Using the above, the authors consider two explainer instances; one for node classification and one for graph classification. Both cases use a MLP parameterized by Ψ.
3 Reimplementation of code
This section shortly summarizes the main structure of the code accompanying this reproducibility check and provides the information needed to reproduce the experiments presented. Our reimplementation of the PGExplainer is based on the PyTorch [5] framework. More specifically, it uses the third party extension of PyTorch for Graph Neural Networks called PyTorch-Geometric [6]. The codebase is structured for the two main tasks performed in this paper; training the GNNs that will be explained by the PGExplainer and performing a replication of the original experiments. Additional scripts are included for performing the evaluations presented in the appendix. Each script is self-contained, handling things such as loading the dataset, loading the correct model and setting the hyperparameters. Each of these things are predefined in json configuration files.
3.1 Experiment configuration files The codebase contains a large number of predefined configuration files. These configuration files are the main working horse for making the experiments presented in this work reproducible. There are two different types of configurations, one for each of the twomain tasks mentioned previously. Shared between tasks is the common occurrence of the dataset, model and seed used. If a task is to be performed a number of times to achieve an average, the seed is replaced with a list of seeds. A full description of the configuration file setup can be found in Appendix A. As these configuration files provide a reliable source for all relevant information needed to perform our evaluation, wewill—for the remainder of this paper—only disclose the information needed to comprehend the experiment. For details irrelevant to understanding the results—e.g. the used learning rate and specific framework versions—we refer to the provided configuration and codebase1. We understand that this breaks the papers self-containment. However, we believe that regarding the balance between page restrictions and replicability completeness, separating the concern of replicability from paper to codebase is the correct way to go. A single source of replicability information also prevents inconsistencies between the paper and the code base. As the paper under consideration will highlight, this is a concern.
1https://github.com/LarsHoldijk/RE-ParameterizedExplainerForGraphNeuralNetworks
ReScience C 7.2 (#7) – Holdijk et al. 2021 4
4 Experiment Setup
In this section we will introduce the setup of the experimental evaluation performed by the authors of the PGExplainer. While replicating their evaluation, we found that a number of steps were making assumptions that were not well documented. This includes the samples used for calculating the AUC score. In this section we will spend time on these steps. Additionally, someminor mistakes made in the original evaluation were rectified during our reproduction. These changes will also be highlighted here. The experimental setup used by the authors of the PGExplainer follows that of the GNNExplainer [1] with a number of extensions. To clarify, the authorsʼ proposed method serves the purpose of explaining the classification decision of a GNN. Hence, the experiments used to evaluate the PGExplainer focus on the explanations provided by the PGExplainer for the underlying model. Specifically, the evaluation is repeated for six different datasets, and thus, for six different underlying models. The six datasets span two different classification tasks; node-classification and graph-classification.
4.1 Datasets Thenode classification task is performedusing four synthetic datasets (a-d). All ofwhich are first introduced in the GNNExplainer paper [1]. The graph classification task is performed using two datasets (e-f), one synthetic and one real. A reoccurring concept in all synthetic datasets is the so called motif. Motifs are highly structured subgraphs—e.g. 9 nodes connected in a 2D grid. These subgraphs are then expanded by attaching them to a randomly generated graph of a different structural form—e.g. Barabasi-Albert (BA) graph [7] or trees. Motifs play a crucial role in determining ground-truth explanations for our evaluations, as we will see later. (a) The BA-Shapes dataset consists of single base BA-graph with 300 nodes, 80 “house”structuredmotifs—each attached to randomBAnodes—and some extra randomly added edges. (b) BA-Community closely resembles BA-Shapes, connecting two BA-Shapes and utilizing a Gaussian distributions for each BA-Shape to sample node features. (c) TreeCycles adopts an 8-level balanced binary tree as the base graph with a set of 80 six-node cycle motifs attached to randomly selected nodes. (d) The Tree-Grids dataset is similar to Tree-Cycles, replacing cyclemotifs with 3×3 gridmotifs. (e) The authors constructed the BA-2motifs dataset consisting of 1000 BA graphs. Half of the graphs contain ”house” motifs, the other half contain five-node cycle motifs attached to the BA graph. These two types of graphs serve as the two classes for the dataset. (f) The real-lifeMutagenicity dataset copied from [1], consisting of 4337molecule graphs. These should be classified as either mutagenic or nonmutagenic.
4.2 Model There are a number of large differences between the implementation of the models trained for each dataset and how they are described in the paper. These changes are different between the node and graph classification tasks.
Node classification The authors describe the model for node classification to be three consecutive Graph Convolution layers feeding directly into the fully connected classification. The model in the codebase however first concatenates the three intermediate outputs of the Graph Convolution layers before using this enlarged embedding as the input for the fully connected classification layer. The coded version of themodels is similar to what is used for evaluation in the GNNExplainer paper [1]. To keep the evaluation consistent, we will therefore use the coded model version instead of the one described in the paper for our evaluation. Moreover, we were not able to get the model described in the paper to train to the same accuracy using the provided hyperparameters.
ReScience C 7.2 (#7) – Holdijk et al. 2021 5
In addition to the architecture change, we found the node classificationmodels to use an undocumented batch normalization layer after the first and second Graph Convolution layer. Unfortunately, the original codebase contained an error that resulted in these batch-normalization layers being kept in training mode during evaluation. This observation was confirmed by the authors in communication and has since been resolved. In the same communication the authors expressed that to be able to reproduce their results, the batch normalization layers will have to be kept in training mode. We believe that this will compromise the usability of our reproducibility experiment and therefore decided to remove the batch normalization layers all together. For completeness full replication of the authors evaluation with a model containing batch normalization is included in Appendix B.
Graph classification The graph classification models are more in line with the models described in the paper than the node classification models. The difference is the use of bothmax andmean pooling over the output of the final Graph Convolution layer. These two pooling types are concatenated to form inputs for fully connected layers.
4.3 Evaluation metrics For each dataset, the explanations are evaluated using three broad categories; quantitative, qualitative and efficiency.
Quantitative evaluation — For each dataset the explanations provided by the PGExplainer are compared to ground-truth explanations. These ground-truths describe for each samplewhich edges should or should not be included in the explanation. Using thismethodology, the quantitative evaluation can be performed similar to a binary classification task. For this reason, the authors present the quantitative score using the AUC scoring metric.
GroundTruth Fornode classification the ground-truth explanation is determined globally— i.e. for all node samples the edges have the same ground-truth explanation label. Specifically, for each edge it is determined if the two nodes it connects are part of a motif. When this is the case, the edge is labelled as positive for the ground-truth explanation. Otherwise, the edge is labelled as negative for the ground-truth explanation. For graph classifications this is dependent on the dataset used and how the ground-truth explanations are generated. For the BA-2motif dataset, being synthetic, this is done the same way as for the node datasets. The only difference being that the process is repeated for every graph in the dataset. As there are no motifs defined for the Mutagenicity dataset, the ground-truth labels can not be defined based on them. Instead, for this dataset edge labels are used, as provided by the original dataset repository2.
AUC score With the explanation mask provided by the PGExplainer and the groundtruths defined as above, the AUC score can be computed. However, there are a few important notes to consider when computing the AUC score. First, for the node classification datasets, the explanation mask is only determined for a 3-hop graph around each node. This is done because the GCN model only contains three layers. Second, only the nodes that are part of a motif are used in the AUC computation. This is because there is no real definition of ground-truth for the nodes outside the motifs. This evaluation design choice is further discussed in Sec. 6. Third, for the BA-2Motif dataset only a subset of the graphs is used to determine the AUC score, this is done to reduce computation time. Lastly, for the Mutagenicity dataset only the mutagenic graphs have a valid
2https://ls11-www.cs.tu-dortmund.de/staff/morris/graphkerneldatasets
ReScience C 7.2 (#7) – Holdijk et al. 2021 6
ground-truth interpretation. Hence, the AUC is determine using only these graphs. Of these four considerations, only the last is mentioned in the original paper.
Comparison The authors compare their method against four baselines; a gradientbased model (GRAD) [1], a graph attention network (ATT) [8] and Gradient [9]. With the exception of the scores presented for the graph-classification datasets, the scores presented are reused from the PGExplainer paper (see Table 4). In communication with the authors, it was mentioned that the reimplementation of these explainers by the authors had resulted in lackluster results. For this reason the decision was made to use the original scores by the original authors. For our replication of the evaluation we focus our comparison on the GNNExplainer. This method is the most similar and was a major inspiration for the PGExplainer. In contrast the the original evaluation, we do perform the comparison using our own reimplementation of the GNNExplainer. Our re-implementation of this method is largely inspired by the implementation in the PyTorch Geometric library. The main difference is that our re-implementation is adapted to also work with graph-classification datasets. This is not possible with the plain PyTorch Geometric implementation.
Qualitative evaluation — In order to obtain a visualisation of the chosen sub-graph the system takes as input the ground truth labels and the mask provided by the Explainer. Given the mask, two thresholds are calculated, one for importance to the explanation and one to determine which other elements to plot for the sub-graph. Then, using these thresholds all nodes that have an interesting enoughweight are selected. Following this, only nodes that are in a direct sub-graph together the node-to-be-explained are selected. When drawing the explanation for the graph classification this sub-graph is selected using the top-k edges. The original evaluation sets k to be the number of edges in the defining motif for the synthetic datasets. These edges are plotted with a colour coding in accordance to their weight, where darker edges have higher weights in themask than the lighter edges. Finally, the nodes that are connected to the previously plotted edges are plotted and colour coded by their ground-truth label.
Efficiency evaluation — In the paper, the authors only compare the efficiency of their PGExplainer to the GNNExplainer. Unfortunately, we were unable to extract the exact method for doing so from both the paper and the provided codebase. Our implementation is therefore mainly our own design. We compute the inference time as the average over ten runs. During each run we measure the times it takes to explain all samples that are also used for the quantitative evaluation. This time is divided by the number of samples explained to get the final inference time per sample in milliseconds. Note that, similar to the paper, for the evaluation of the PGExplainer only the time to explain each sample is considered. On the other hand, for the GNNExplainer the time required to train the explainer is also taken into account because it has to be retrained for each sample.
5 Results
5.1 Model training In Tab. 1 the final accuracies for all 6 trained models are provided. Note that these are the accuracies of the models that will be explained by the two explainers, not the explanation accuracy of the explainers themselves. For most of the models, using the configurations found in the code, we achieve results comparable to the results presented in the paper. The two exceptions being the BA-Community and theMutagenicitymodels. Both of these score lower then their original counterpart.
ReScience C 7.2 (#7) – Holdijk et al. 2021 7
Logically this difference could be contributed to the difference in the use of batch normalization. Where the original model in the PGExplainer paper did use batch normalization where we do not. However, as the results presented in Tab. 5 show, replication with the original batch normalization yields the same reduced accuracies. We hypothesise that therefore the difference might be the result of an undocumented use of weight regularization. We observed that in the original training script the configuration exist to use L2-weight regularization, but it is not used."
"['Sunnie S. Y. Kim', 'Sharon Zhang', 'Nicole Meister', 'Olga Russakovsky']",[Re] Don't Judge an Object by Its Context: Learning to Overcome Contextual Bias,10.5281/zenodo.4834352,Replication,Python,https://zenodo.org/record/4834352/files/article.pdf,rescience c rescience x,https://openreview.net/forum?id=PRXM8-O9PKd,https://github.com/princetonvisualai/ContextualBias,7,2,2021,"Singh et al. [1] point out the dangers of contextual bias in visual recognition datasets. They propose two methods, CAM-based and feature-split, that better recognize an object or attribute in the absence of its typical context while maintaining competitive withincontext accuracy. To verify their performance, we attempted to reproduce all 12 tables in the original paper, including those in the appendix. We also conducted additional experiments to better understand the proposed methods, including increasing the regularization in CAM-based and removing the weighted loss in feature-split.","Overall, it was easy to follow the explanation and reasoning of the experiments. The implementation ofmost (7 of 10)methodswas straightforward, especially afterwe received
Copyright © 2021 S.S.Y. Kim et al., released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Sunnie S. Y. Kim (sunniesuhyoung@princeton.edu) The authors have declared that no competing interests exist. Code is available at https://github.com/princetonvisualai/ContextualBias. – SWH swh:1:dir:bc41dd1d3cbd9c97754c3da0ee20ba2273b742fd. Open peer review is available at https://openreview.net/forum?id=PRXM8-O9PKd.
ReScience C 7.2 (#8) – Kim et al. 2021 1
additional details from the original authors.","Since therewasno existing code, we spent considerable time and effort re-implementing the entire pipeline from scratch and making sure that most, if not all, training/evaluation details are true to the experiments in the paper. For several methods, we went through many iterations of experiments until we were confident that our implementation was accurate.
Communication with original authors We reached out to the authors several times via email to ask for clarifications and additional implementation details. The authors were very responsive to our questions, and we are extremely grateful for their detailed and timely responses.
1 Introduction
Most prominent visiondatasets are afflictedby contextual bias. For example, “microwave” typically is found in kitchens, which also contain objects like “refrigerator” and “oven.” Such co-occurrencepatternsmay inadvertently induce contextual bias in datasets, which could consequently seep into models trained on them. Whenmodels overly rely on context, they may not generalize to settings where typical co-occurrence patterns are absent. The original paper by Singh et al. [1] proposes two methods for mitigating such contextual biases and improving the robustness of the learnt feature representations. The paper demonstrates their methods onmulti-label object and attribute classification tasks, using the COCO-Stuff [2], DeepFashion [3], Animals with Attributes (AwA) [4], and UnRel [5] datasets. Our exploration centers on four main directions:
First, we trained the baseline classifier presented in the paper (Section 2.1 for implementation and training details; Sections 2.3-2.4 for results). Due to likely implementation discrepancies, our results differed from the original paper by 0.6–3.1% mAP on COCO-Stuff, by 0.7–1.4% top-3 recall on DeepFashion, and by 0.1–3.2% mAP on AwA (Table 2). We ran a hyperparameter search (Appendix C), which yielded a significant (1.4–3.6%) improvement on DeepFashion.
Next, we identified the biased categories in each dataset, i.e., visual categories that suffer from contextual bias. We followed the proposed method of using the baseline classifier to identify these categories, and discovered that the classifier implementation has a non-trivial effect. For COCO-Stuff, 18 of the top-20 categories we identified matched the original paper s̓ top-20 categories (10 onDeepFashion, 18 onAwA; Section 2.2). Nevertheless, the categories we identified appear reasonable (e.g., “fork” co-occurs with “dining table”; Appendix B). As training and evaluation of most methods depend on the biased categories, we used the paper s̓ biased categories for subsequent experiments.
Third, we checked themain claim of the paper, that the proposed CAM-based and featuresplit methods help improve recognition of biased categories in the absence of their context (Section 3). On COCO-Stuff, DeepFashion, andUnRel, wewere able to reproduce the improvements gained from the proposed feature-split method towards reducing contextual bias, whereas on AwA, we saw a drop in performance. The proposed CAM-based method, which was only applied to COCO-Stuff, also helped reduce contextual bias, though not as significantly as the feature-split method. For the method, we reproduced the original paper s̓ results to within 0.5% mAP (Section 3.5). We also successfully reproduced the paper s̓ weight similarity analysis, as well as the qualitative analyses with
ReScience C 7.2 (#8) – Kim et al. 2021 2
class activation maps (CAMs) [6].
Lastly, we ran additional experiments and ablation studies (Section 3.6). These revealed that the regularization term in the CAM-based method and the weighted loss in the feature-split method are central to the methodsʼ performance. We also observed that varying the feature subspace size influences the feature-split methods̓ accuracy.
2 Reproducing the standard baseline and the biased category pairs
The first step in reproducing the original paper is doing “stage 1” training. This stage involves training a standard multi-label classifier with the binary cross entropy loss on the COCO-Stuff, DeepFashion, and AwA datasets. We describe how we obtained and processed the datasets in Appendix A. The standard model is used to identify the biased categories and serves as a starting point for all “stage 2”methods, i.e., the proposedCAMbased and feature-split methods and 7 other strong baselines introduced in Section 3.
2.1 Implementation and training details According to the original paper, all models use ResNet-50 [7] pre-trained on ImageNet [8] as a backbone and are optimized with stochastic gradient descent (SGD) and a batch size of 200. Each standard model is optimized with an initial learning rate of 0.1, later dropped to 0.01 following a standard step decay process. The input images are randomly resize-cropped to 224×224 and randomly flipped horizontally during training. We also received additional details from the authors that SGD is used with a momentum of 0.9 and no weight decay. The COCO-Stuff standard model is trained for 100 epochs with the learning rate reduced from 0.1 to 0.01 after epoch 60. The DeepFashion standard model is trained for 50 epochs with the learning rate reduced after epoch 30. The AwA standard model is trained for 20 epochs with the learning rate reduced after epoch 10.
After training with the paper s̓ hyperparameters, we found that our reproduced standardmodels for COCO-Stuff and AwAwere consistently underperforming against the results in the paper. Thus, we also tried varying the learning rate, weight decay, and the epoch at which the learning rate is dropped to achieve the best possible results. Further details can be found in Appendix C. On both COCO-Stuff and AwA, our hyperparameter search ended up reconfirming the original paper s̓ hyperparameters as the optimal ones; for DeepFashion, we were able to find a significant improvement. The original, reproduced and tuned results are shown in Table 1, following explanations of biased categories identification (Section 2.2) and evaluation details (Section 2.3).
2.2 Biased categories identification The paper identifies the top-20 (b, c) pairs of biased categories for each dataset, where b is the category suffering from contextual bias incurred by c, the associated context category. This identification is crucial as it concretely defines the contextual bias the paper aims to tackle, and influences the training of the “stage 2” models and evaluation of all models.
The paper defines bias between two categories b and z as the ratio between the average prediction probabilities of bwhen it occurs with and without z. Note that this definition of bias requires a trainedmodel, unlike themore common definition of bias that only requires co-occurrence counts in a dataset [9]. Following the paper description, we used a standardmodel trained on an 80-20 split for COCO-Stuff and one trained on the full training set for DeepFashion and AwA. For each category b in a given dataset, we calculated the bias between b and its frequently co-occuring categories, and defined category c as
ReScience C 7.2 (#8) – Kim et al. 2021 3
the context category that most biases b, i.e. has the highest bias value. Bias is calculated on the 20 split for COCO-Stuff, the validation set for DeepFashion, and the test set for AwA.1 After the bias calculation, we identified 20 (b, c) pairs with the highest bias values. The paper emphasizes that this definition of bias is directional; it only captures the bias c incurs on b and not the other way around.
We compare our pairs to the paper s̓ in Tables A1 (COCO-Stuff), A2 (DeepFashion), and A3 (AwA) in the Appendix. Out of 20 biased categories, 2 of ours differed from the paper s̓ for COCO-Stuff, 10 differed for DeepFashion, and 2 differed for AwA. The variability is expected, as bias is defined as a ratio of a trained model s̓ average prediction probabilities which will vary across different models. Nonetheless, we found our pairs to also be reasonable, as our biased categories occur frequently with their context categories and rarely without them. See Appendix B for details.
2.3 Evaluation details The paper does not specify image preprocessing or model selection. Following common practice, we resize an image so that its smaller edge is 256 and then apply one of two 224×224 croppingmethods: a center-crop or a ten-crop. Both are deterministic procedures. We observed that results with center-crop are consistently better and closer to the paper s̓ results, hence for all experiments, we report results using center-crop. In our email communications, the authors also specified that they use themodel at the end of training as the final model. We confirmed that this is a reasonable model selection method after trying three other selection methods, described in Appendix D.
We emphasize that model evaluation is dependent on the identified biased category pairs. For each (b, c) pair, the test set can be divided into three sets: co-occurring images that contain both b and c, exclusive images that contain b but not c, and other images that do not contain b. Then for each (b, c) pair, the paper constructs two test distributions: 1) the “exclusive” distribution containing exclusive and other images and 2) the “co-occur” distribution containing co-occurring and other images. We suspect that other images are included in both distributions because otherwise, both distributions would have small sizes and only consist of positive images where b occurs, disabling the mAP calculation.
The test distribution sizes can be calculated from the co-occurring and exclusive image counts in Tables A1, A2, A3 in the Appendix. As an example, for the (ski, person) pair in COCO-Stuff, there are 984 co-occuring, 9 exclusive, and 39,511 other images in the test set. Hence, there are 9+39,511=39,520 images in the “exclusive” distribution and
1We received additional information from the original authors that they restricted their COCO-Stuff biased categories to the 80 object categories and performed manual cleaning of the DeepFashion (b, c) pairs.
ReScience C 7.2 (#8) – Kim et al. 2021 4
984+39,511=40,495 images in the “co-occur” distribution. For COCO-Stuff, we also report results on the entire test set (40,504 images) for 60 non-biased object categories and for all 171 categories, following the paper.
For COCO-Stuff and AwA, we calculate the average precision (AP) for each biased category b, and report the mean AP (mAP) for each test distribution. For DeepFashion, we calculate the per-category top-3 recall and report the mean value for each test distribution. Higher values indicate a better classifier for both metrics.
2.4 Results In Table 1, we report the original, reproduced, and tuned results with the paper s̓ and our 20 most biased category pairs. Evaluated on the paper s̓ pairs, our best COCO-Stuff model underperforms the paper s̓ by 1-3%, our best DeepFashion model outperforms by 2-5%, and our best AwA underperforms on the “co-occur” distribution by 3.2% and matches the “exclusive” distribution within 0.1%. When we evaluate the same models on our biased category pairs, we get similar results for the AwA model, slightly worse results for the DeepFashion model, and significantly worse results for the COCO-Stuff model. Due to this big drop in performance for COCO-Stuff, which we suspect is caused by the discrepancy in the identified biased category pairs, we choose to use the paper s̓ pairs for training and evaluation in the subsequent sections. Overall, we conclude that the paper s̓ standard baseline results are reproducible as we were able to train models within a reasonable margin of error.
3 Reproducing the “stage 2” methods: CAM-based, feature-split, and strong baselines
In this section, we describe our efforts in reproducingmethods that aim tomitigate contextual bias: namely, the CAM-based and feature-split methods proposed by the original authors (Figure 1) and 7 other strong baselines. These are referred to as “stage 2” methods because they are trained on top of the “stage 1” standardmodel (except for one strong baseline). Apart from the feature-split method, which we discussed with the authors, all other implementations were based entirely on our interpretation of their descriptions in the original paper.
3.1 The first proposed CAM-based method The CAM-basedmethod operates on the following premise: as b almost always co-occurs with c, the network may learn to inadvertently rely on pixels corresponding to c to pre-
ReScience C 7.2 (#8) – Kim et al. 2021 5
dict b. The paper hypothesizes that one way to overcome this issue is to explicitly force the network to rely less on c s̓ pixel regions. This method uses class activation maps (CAMs) [6] as a proxy for object localization information. For an image I and category r, CAM(I, r) indicates the discriminative image regions used by a deep network to identify r. For each biased category pair (b, c), a minimal overlap of their CAMs is enforced via the loss term:
LO = ∑
I∈Ib∩Ic CAM(I, b)⊙ CAM(I, c), (1)
where⊙ denotes element-wise multiplication and Ib ∩ Ic is a set of images where both b and c appear. To prevent a trivial solution where the CAMs of b and c drift apart from the actual pixel regions, the paper uses a regularization term to keep the category s̓ CAMs close to CAMpre, produced using a separate network trained offline:
LR = ∑
I∈Ib∩Ic |CAMpre(I, b)− CAM(I, b)|+ |CAMpre(I, c)− CAM(I, c)|. (2)
In our implementation, we separate a batch into two small batches during training, one with and one without co-occurrences. A sample is put into the co-occurrence batch if any of the 20 biased categories co-occurs with its context. For the co-occurrence batch, we compute CAM with the current model being trained and CAMpre with the trained standard model, using the official CAM implementation: https://github.com/zhoubolei/CAM. We update the model parameters with the following loss, where LBCE is the binary cross entropy loss:
LCAM = λ1LO + λ2LR + LBCE. (3)
For the other batch without any co-occurrences, we update the model parameters with LBCE. With the hyperparameters reported in the paper, λ1=0.1 and λ2=0.01, we got underwhelming results and degenerate CAMs that drifted far from the actual pixel regions. Hence, we tried increasing the regularization weight λ2 (0.01, 0.05, 0.1, 0.5, 1.0, 5.0) and achieved the best results with λ2=0.1, which are reported in Table 2.
3.2 The second proposed feature-split method By discouraging mutual spatial overlap, the CAM-based approach may not be able to leverage useful information from the pixel regions surrounding the context. Thus, the paper proposes a second method that splits the feature space into two subspaces to separately represent category and context, while posing no constraints on their spatial extents. Specifically, they propose using a dedicated feature subspace to learn examples of biased categories appearing without their context.
Given a deep neural network, let x denote the D-dimensional output of the final pooling layer just before the fully-connected (fc) layer. Let the weight matrix associated with fc layer be W ∈ RD×M , where M denotes the number of categories given a multilabel dataset. The predicted scores inferred by a classifier (ignoring the bias term) are ŷ = WT x. To separate the feature representations of a biased category from its context, the paper does a random row-wise split ofW into two disjoint subsets: Wo andWs (dimension D2 × M ).
2 Consequently, x is split into xo and xs, and ŷ = WTo xo + WTs xs. When a biased category occurs without its context, the paper disables backpropagation throughWs, forcing the network to learn only throughWo, and set xs to x̄s (the average of xs over the last 10 mini-batches).
We implemented the feature-split method based on additional discussions with the original authors, to ensure that we replicated their method as closely as possible. For a
2In an email, the authors noted that a random split is not critical; they obtained similar results with a random split and amiddle split. We observed that a middle split ofW yields better results for COCO-Stuff and DeepFashion, but the opposite forAwA.As the gains fromusing amiddle split for COCO-StuffandDeepFashion were larger than the losses for AwA, we use a middle split throughout our experiments.
ReScience C 7.2 (#8) – Kim et al. 2021 6
single training batch, we first forwarded the entire batch through the model to obtain one set of scores ŷnon-exclusive = WTo xo +WTs xs and the corresponding features from the avgpool layer, which directly precedes the fc layer. We made a separate copy of these features and replaced xs with x̄s, then calculated a new set of output scores ŷexclusive = WTo xo + WTs x̄s. Separate loss tensors for each of these outputs were computed, and elements corresponding to the exclusive and non-exclusive examples in the unmodified and modified loss tensors were zeroed out, respectively. The final loss tensor was obtained by adding these two together, and standard backpropagation was done using this final loss tensor. The gradients were calculated with respect to a weighted binary cross entropy loss:
LWBCE = −α [ t log(σ(ŷ)) + (1− t) log(1− σ(ŷ)) ] , (4)
where t is the ground-truth label, σ is the sigmoid function, and α is the ratio between the number of training images in which a biased category occurs in the presence of its context and the number of images in which it occurs in the absence of its context. A higher value of α indicates more data skewness.3
3.3 Strong baselines In addition to the standard model, the paper compares the proposed methods with several competitive strong baselines.
1. Remove co-occur labels: For each b, remove the c label for images in which b and c co-occur.
2. Remove co-occur images: Remove training instances where any b and c co-occur. For COCO-Stuff, this process removes 29,332 images and leaves 53,451 images in the training set.
3. Split-biased: Split each b into two classes: 1) b \ c and 2) b ∩ c. Unlike other “stage 2” models, this model is trained from scratch rather than on top of the standard baseline because it has 20 additional classes. We later confirmed with the authors that they did the same.
4. Weighted loss: For each b, apply 10 times higher weight to the loss for class bwhen b occurs exclusively.
5. Negative penalty: For each (b, c), apply a large negative penalty to the loss for class c when b occurs exclusively. In our email communication, the authors said that the negative penalty means a 10 times higher weight to the loss.
6. Class-balancing loss [10]: For each b, put the images in three groups: exclusive, co-occurring, and other. The weight for each group is (1− β)/(1− βn) where n is the number of images for each group and β is a hyperparameter. The authors said they set β = 0.99 in our email communication.
7. Attributedecorrelation [11]: Use the proposedmethod, but replace thehand-crafted features used in [11] with deep network features (i.e., conv5 features of a trained “stage 1” ResNet-50).
3In practice, the paper ensures α is at least αmin, which they set to 3 for COCO-Stuff and AwA and 5 for DeepFashion. However, we found that most of the paper s̓ biased category pairs have α smaller than αmin. Out of 20 pairs, 13 pairs for COCO-Stuff, 20 pairs for DeepFashion, and 19 pairs for AwA had α smaller than αmin. We also tried using higher values ofαmin but didnʼt gainmeaningful improvements, so we report results with the original authorsʼ αmin.
ReScience C 7.2 (#8) – Kim et al. 2021 7
COCO-Stuff: Since our standardmodel underperforms the paper s̓ by 0.6-3.1% (Section 2), we focus on the ordering between the different methods visualized in Figure 2. In the paper, all but split-biased and negative penalty improve upon the standard baseline s̓ “exclusive” mAP; whereas in our experiments, only negative penalty fails to improve on standard s̓ “exclusive” mAP. Different from the paper, remove images has the highest “exclusive” mAP in our experiments, followed by weighted and the paper s̓ proposed methods, feature-split and CAM-based. For feature-split, we observed a similar tradeoff between “exclusive” and “co-occur” mAPs compared to the paper. All methods have similar performance of 55.0–55.7 mAP when evaluated on the full test set for all 171 categories.
DeepFashion: Consistent with the paper, all methods except remove images and splitbiased improve upon standard s̓ “exclusive” top-3 recall. We found the weighted method performs the best out of all the methods with +22.5% for “exclusive” and +20.8% for “cooccur.” However, it has a relatively low top-3 recall when evaluated on the full test set for all 250 categories: 23.3 compared to othermethodsʼ top-3 recall in the range of 23.8–24.3.
Animals with Attributes: Unlike the result reported in the paper, our reproduced featuresplit model had a -0.3% drop in “exclusive” mAP and a -0.4% drop in “co-occur” mAP compared to the standard model. In Section 3.6, when we experimented with different subspace sizes, we observed that the feature-split model trained with xo of size 1,792 improves upon the standard model on both test distributions. Among all the methods, remove images improves the “exclusive” mAP the most; however, this method also suffers from a noticeable decrease in “co-occur” performance. When evaluated on the full test set for all 85 categories, most methods have similar mAP in the range of 72.5–73.0, except for remove labels that has 70.6 mAP and remove images that has 69.7 mAP.
UnRel: The paper includes a cross-dataset experiment where the models trained on COCO-Stuff are applied without any fine-tuning on UnRel, a dataset that contains images of objects outside of their typical context. The paper evaluates the models only on the 3 categories of UnRel that overlap with the 20 most biased categories of COCO-Stuff, which we determined to be skateboard, car, and bus. While the paper does not report results from the remove images baseline, for us it had the highest mAP of the 3 categories, followed by the feature-split and CAM-based methods.
3.6 Additional analyses Cosine similarity between Wo and Ws: The paper computes the cosine similarity between Wo and Ws to investigate if they capture distinct sets of information. It reports that the proposedmethods yield a lower similarity score compared to the standardmodel, and concludes that the biased class b is less dependent on c for prediction in their methods. To reproduce their results, for feature-split, we calculated the cosine similarity between Wo[:, b] and Ws[:, b] (dimensions D2 ) for each b of the 20 (b, c) pairs and reported their average. On the other hand, Wo and Ws are not specified for standard and CAMbased. Hence, we randomly splitW in half and defined one asWo and the other asWs.
ReScience C 7.2 (#8) – Kim et al. 2021 9
In Table 3, we compare our reproduced results with the paper s̓ results. Consistent with the paper s̓ conclusion, we find that the proposed methods have weights with similar or lower cosine similarity. On the interpretation of the results, we agree that feature-split s̓ low cosine similarity suggests that the corresponding feature subspaces xo and xs capture different information, as intended by the method. However, we donʼt understand why the cosine similarity of CAM-based would be lower than standard, as there is nothing in CAM-based that encourages the feature subspaces to be distinct.
Qualitative analysis: Following Section 5.1.2 of the original paper, we used CAMs to visually analyze the proposed methods. In general, our observations are in line with those of the original paper. For example, in Figure 3, we see that CAM-based tends to only focus on the object pixel regions (e.g., skateboard, microwave) compared to standard, while feature-split also makes use of context (e.g., person, oven). More qualitative analyses are available in Appendix G.
4 Our additional experiments
To better understand the proposed CAM-based and feature-split methods, we conducted several ablation studies (Table 4).
What is the effect of the regularization term in the CAM-based method? As mentioned in Section 3.1, we tried varying the weight for the regularization term LR (λ2) in the CAM-based method that prevents the CAMs of the biased category pairs from drifting apart from the pixel regions of CAMpre. We observed that weak regularization allows for highly localized, degenerate CAMs that donʼt resemble CAMpre, while overly strong regularization makes the method less effective. We were able to strike an ideal balance with λ2=0.1, higher than the paper s̓ λ2=0.01.
What is the effect of the weighted loss in the feature-split method? To understand the effect of the weighted loss in the feature-split method, we tried training a feature-split model without it and a baseline model with the feature-split weighted loss. Both variations have lower “exclusive” mAPs, suggesting that both the feature-splitting framework and the weighted loss are important components of the method. We highlight that the feature-split model trained without the weighted loss is worse than the standard model, suggesting that the weighted loss is central for the feature-split method to achieve good performance. However, we also observed that the feature-split methods̓ weighted loss by itself is not sufficient for improving the performance of the standard model on the “exclusive” distribution.
Does the size of the feature-split subspace matter? In the feature-split method, the original paper allocates half of the 2,048 feature dimensions in the fc layer for learning exclusive image examples. We explored whether a smaller or larger xo subspace may
ReScience C 7.2 (#8) – Kim et al. 2021 10
strike a better balance and improve both “exclusive” and “co-occur” performance, as the number of exclusive images is only a small fraction of the entire training data. For COCO-Stuff, the performance peaks on “exclusive” and dips on “co-occur” at the 1,024 dimension split. For DeepFashion, performance on both distributions peak at the 1,024 dimension split. For AwA, however, the performance on both distributions improves as the subspace size increases. Lastly for UnRel, the model trained on COCO-stuff with a xo of size 768 performs best. Overall, we did not find a clear trend between feature-split performance and subspace size.
We found that the proposed CAM-based and feature-split methods help mitigate contextual bias, although we could not completely replicate the quantitative results in the original paper even after completing an extensive hyperparameter search. As an effort to check our conclusions, we tried several different approaches in how we choose our best models, train the baselines, and performed evaluation. We also conducted additional analyses of the proposed methods to check our implementations and train them to achieve their best possible performance. In all cases, decreasing contextual bias frequently came with the cost of decreasing performance on non-biased categories. Ultimately, we believe deciding what method is best depends on the trade-offs a user is willing to make in a given scenario, and the original paper s̓ proposed methods seem to strike a good balance for the tested datasets.
Recommendations for reproducibility: Overall, the paper was clearly written and it was easy to follow the explanation and reasoning of the experiments. Still, we ran into several obstacles while re-implementing the entire pipeline from scratch. Our biggest concern was making sure that most, if not all, training/evaluation details were true to the experiments in the paper. We are extremely grateful to the original authors who gave swift responses to our questions. Nevertheless, it would have been easier to reproduce the results with code or a README file listing design decisions. Given the limited information, it took us over a month to lock in various details on data processing, hyperparameter optimization, and training the standard model, before we could move onto reproducing the “stage 2” methods. Moreover, each method had its intricacies and we
ReScience C 7.2 (#8) – Kim et al. 2021 11
inevitably ran into ambiguities along the way. For example, the attribute decorrelation method took considerable time to reproduce because no hyperparameters or code were given in the paper or the original work [11]. We hope our report and published code help future use of the paper.
Recommendations for reproducing papers: In closing, we would like to share a few things that we found helpful as suggestions for future reproducibility efforts. First, writing the mandatory reproducibility plan (provided in Appendix I) at the beginning of the challengewas helpful, as it forced us to define concrete steps for reproducing the experiments. We suggest putting together a similar plan because the order in whichmaterials are presented in the paper can be different from the order in which experiments should be run. Additionally, we recommend communicating early with the original authors to determine undisclosed parameters and pin down the experimental setup. Lastly, for reproducing training processes in particular, we suggest checking how training is progressing in as many different ways as possible. In our process, this involved looking at the progression of CAMs and examining training curves for individual loss function terms, both of which helped us pinpoint our issues."
"['Ci Li', 'Ruibo Tu', 'Hui Zhang']",[Re] Reimplementation of FixMatch and Investigation on Noisy (Pseudo) Labels and Confirmation Errors of FixMatch,10.5281/zenodo.4834442,Replication,Python,https://zenodo.org/record/4834442/files/article.pdf,rescience c rescience x,https://openreview.net/forum?id=3VXeifKSaTE,https://github.com/Celiali/FixMatch.git,7,2,2021,"FixMatch is a semi-supervised learning method, which achieves comparable results with fully supervised learning by leveraging a limited number of labeled data (pseudo labelling technique) and taking a good use of the unlabeled data (consistency regularization ). In this work, we reimplement FixMatch and achieve reasonably comparable performance with the official implementation, which supports that FixMatch outperforms semi-superivesed learning benchmarks and demonstrates that the author s̓ choices with respect to those ablationswere experimentally sound. Next, we investigate the existence of a major problem of FixMatch, confirmation errors, by reconstructing the batch structure during the training process. It reveals existing confirmation errors, especially the ones caused by asymmetric noise in pseudo labels. To deal with the problem, we apply equal-frequency and confidence entropy regularization to the labeled data and add them in the loss function. Our experimental results on CIFAR-10 show that using either of the entropy regularization in the loss function can reduce the asymmetric noise in pseudo labels and improve the performance of FixMatch in the presence of (pseudo) labels containing (asymmetric) noise. Our code is available at the url: https://github.com/Celiali/FixMatch.",,
"['Toomas Liiv', 'Einar Lennelöv', 'Aron Norén']",[Re] A Reproduction of Ensemble Distribution Distillation,10.5281/zenodo.4834516,Replication,Python,https://zenodo.org/record/4834516/files/article.pdf,rescience c rescience x uncertainty estimation ensemble distribution distillation tensorflow,https://openreview.net/forum?id=p1BXNUcTFsN,https://github.com/lennelov/endd-reproduce,7,2,2021,"The authors claim that their proposed method is able to, given an ensemble of deep neural networks, capture the uncertainty estimation and decomposition capabilities of the ensemble into a singlemodel. The authors also claim that this only results in a small reduction in classification performance compared to the ensemble. We examine these claims by reproducing most of the authorsʼ experiments on the CIFAR-10 dataset.","The original paper features a thoroughmathematical formulation of themethod, aiding conceptual understanding. The datasets used by the authors are publicly available. The
Copyright © 2021 T. Liiv, E. Lennelöv and A. Norén, released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Toomas Liiv (toomasl@kth.se) The authors have declared that no competing interests exist. Code is available at https://github.com/lennelov/endd-reproduce. – SWH swh:1:dir:2c366708175b2ed7c83ce6b33a80dd43c8aad915. Open peer review is available at https://openreview.net/forum?id=p1BXNUcTFsN.
ReScience C 7.2 (#10) – Liiv, Lennelöv and Norén 2021 1
use of the simpler datasets also meant that it was computationally feasible for us to reproduce these results. The base model used is well known with several implementation available, allowing us to focus on the novel aspects of the method.","While the theoretical explanations of themethod are excellent, we initially found it hard to translate this into an implementation. Our difficulty was likely caused by our inexperience with the subject matter. Nonetheless, a pseudocode, such as the one we have provided, wouldhavee simplified the re-implementation. Wewerenot able to reproduce the results on some of the datasets due to limited computational resources.
Communication with original authors We did not contact the original authors directly, but we did refer to a public GitHub and blog post created by one of the authors. At the same time as submitting this report to the ML Reproducibility Challenge 2020 we also sent a copy to the authors and asked for their feedback.
ReScience C 7.2 (#10) – Liiv, Lennelöv and Norén 2021 2
1 Introduction
Uncertainty estimation can help to make deep learning safer and more usable by allowing the model to identify cases it is not suitable to handle. There are different kinds of uncertainty, however, and it is especially interesting to separate uncertainty caused by ambiguities or contradictions in the data from the uncertainty that arises when a model faces a situation it has not been trained for. Ensemble-based methods of uncertainty estimation are capable of making this distinction but suffer from computational requirements at the evaluation phase [1]. The authors ofEnsembleDistributionDistillation (EnD2) [2] address this issue by using the output of an ensemble to train a so-called Prior Network (PN) [3], distilling the ensemble down to a single model while also preserving its uncertainty decomposition abilities. This can be contrasted with regular ensemble distillation models [4] (EnD), which are not able to decompose uncertainty. The reproduced paper was accepted to ICLR2020.
2 Scope of reproducibility
We consider the setting of using CIFAR10 [5] as an in-distribution dataset, and LSUN [6] as an out-of-distribution dataset. Our supplementarymaterial also examines the setting of using a synthetic dataset in R2 for visualization. The claims from the original article that this reproduction is testing are as follows:
1. Classification performance: In terms of error rate, prediction rejection rate, and negative log-likelihood EnD2has worse performance than the ensemble, but similar performance to EnD and PriorNet, and better performance than the individual model. In terms of expected calibration error, EnD2 has worse performance than the ensemble, but better performance than the other methods. On CIFAR-10 in particular, EnD2 has the best expected calibration error of all models. This claim corresponds to Table 3 in the original paper.
2. Out-of-distribution detection performance: In terms of AUC-ROC on CIFAR-10 vs. LSUN, EnD2 without auxiliary dataset performs worse than the ensemble and the PriorNet, similar to the individual model, and better than EnD. With the auxiliary dataset, however, EnD2 performs as well as the ensemble, almost as well as PriorNet, and better than EnD. Using knowledge uncertainty as opposed to total uncertainty on CIFAR-10 vs. LSUN does not yield an improved AUC-ROC. This claim corresponds to Table 4 in the original paper.
3. Dependency on ensemble size: Using 20 models in the ensemble does better than using 5 models, but there is no conclusive gain when using more than 20 models.
4. Dependency on temperature: It is necessary to use temperature of at least 5 to successfully distribution-distill the ensemble. Using higher initial temperatures do not result in conclusive improvement.
5. Uncertainty decomposition: EnD2 trained with an auxiliary dataset is able to reconstruct the uncertainty decomposition made possible by ensembles.
We reproduce all experiments of the main article and most of the appendix, except for the use of CIFAR100 and Tiny Imagenet datasets. Some of these results can be found in our supplementary material. From their appendix, we do not reproduce Table 7 in appendix B.We did not recreate the OOD-detection plots when reproducing the ablation study.
ReScience C 7.2 (#10) – Liiv, Lennelöv and Norén 2021 3
Thesemodels are all based on almost identical VGG16 architectures [7], adapted toCIFAR10 data as in [3] by adding dropout, batch normalization and reducing the size of the fully connected layers. The only exception being that batch normalization is not used for PN.
3.2 Dataset The training set of CIFAR-10 was used as the primary training dataset. The training set of CIFAR-100 was used as an auxiliary dataset. For evaluating the classification task the test set of CIFAR-10 was used. For evaluating the out-of-distribution detection task the CIFAR-10 test set was used as in-domain dataset, while the LSUN test set was used as the out-of-domain dataset. Information about the datasets is listed in Table 1. Each image x was normalized according to x′ = x/127.5 − 1 where the operations are elementwise, causing all values to lie in the range (-1, 1). The LSUN images were also scaled down to 32x32. Furthermore, dataset augmentation was used for all models, consisting of rotations with 15◦ range, horizontal flips, width and height shifts of up to 4 pixels in each direction, and using nearest-neighbour interpolation.
3.3 Hyperparameters The models were trained with the hyperparameters listed in Table 2.
3.4 Experimental setup and code Using thesemodels and dataset we ran a number of experiments, as detailed below. The full code is available on https://github.com/lennelov/endd-reproduce. Our implementation was made in TensorFlow Keras, as opposed to the original implementation which was made in PyTorch. Classification: The classification task was evaluated on the test set of CIFAR-10. We use the same fourmetrics as in the original paper, ERR, PRR, ECE, andNLL. ERR is themean
ReScience C 7.2 (#10) – Liiv, Lennelöv and Norén 2021 4
classification error. PRR is the prediction rejection area ratio introduced in Appendix B of [2]. ECE is the expected calibration error1. Finally, NLL is the negative log-likelihood. This experiment tests Claim 1. Out-of-distribution detection: The OOD-detection task was evaluated with the CIFAR-10 test set as the in-domain set, and the LSUN test set as the out-of-domain set. The AUCROC was computed both when total uncertainty and when only knowledge uncertainty is used to make rejection decisions. This experiment tests Claim 2. Ensemble size ablation study: Our examinationof the effect of ensemble size goes slightly beyond the original authors. We extend the error analysis to also consider the sensitivity of EnD2 to variations in the underlying ensemble. We began by training a set of 400 VGG16 models on CIFAR-10. Next, we sampled randomly from this set to create 4 different sets, each consisting of 100 models. For each N ∈ {1, 2, 3, 4, 6, 8, 10, 13, 16, 20, 25, 30, 45, 60, 75, 100} we trained four EnD2 models on an ensemble consisting of the first N models in the first of the four sets, corresponding to what was done in the original study. We also trained one model on an ensemble consisting of the firstN models for each of the three remaining sets, capturing the sensitivity of EnD2 to changes in the underlying ensemble. All ensemble and EnD2 models were then evaluated on the classification task. This experiment tests Claim 3. Temperature ablation study: We reproduce the temperature ablation study by training EnD2 models for various initial temperatures. For each T ∈ {1, 2, 3, 4, 5, 7.5, 10, 15, 20} we trained three EnD2 models with initial temperature T on an ensemble consisting of 100 VGG16 models. The EnD2 models were then evaluated on the classification task. In this experiment, we have chosen to use a slightly finer spacing between the temperatures than what the original authors used. This experiment tests Claim 4. Simplex visualization: A key motivation for EnD2 is the idea that an ensemble can distinguish between knowledge uncertainty and data uncertainty, and that this distinction is retained by the EnD2 model. This is communicated using a schematic figure showing ensemble predictions on a simplex. A similar schematic figure can be found in [3], depicting a Dirichlet PDF of a PriorNet on a simplex. We recreated these figures using experimental data in order to examine Claim 5 from a novel perspective. A new training set was created, consisting of all images from the CIFAR10 train set with one of three labels chosen for their similarity: ʼdeer ,̓ ʼhorse ,̓ and ʼdog .̓ The remaining images were reserved as out-of-distribution dataset for testing. CIFAR-100 was used as auxiliary data. An ensemble and EnD2 was then trained on this data using the same architecture and processed as before. We then selected various images from the test set and visualized the ensemble predictions as well as the PDF of the EnD2 model. The simplex visualization was created using open source code 2.
1We used the open-source implementation in https://github.com/google/uncertainty-metrics. 2http://blog.bogatron.net/blog/2014/02/02/visualizing-dirichlet-distributions/
ReScience C 7.2 (#10) – Liiv, Lennelöv and Norén 2021 5
The OOD-detection results are shown in Table 4. The results suggest plain EnD2 performs worse than ENSM, but that the addition of an auxiliary dataset brings the performance up to at least the level of ENSM. More surprising, perhaps, is that EnD2 seems to perform worse than EnD. In both metrics PN+AUX has a significant lead. Using knowledge uncertainty instead of total uncertainty decreases the effectiveness of all tested models. The supplemental material contains histograms showing the distribution of estimated total and knowledge uncertainty over the images.
4.3 Ensemble size ablation study Figure 1 shows the results of the ensemble size ablation study. The lines ʼENSM Paperʼ and ʼEnD2 Paperʼ show the results of the original paper. The bands indicate two standard deviations. Two bands surround the ʼEnD2+AUXʼ line, representing the two types of variation we have examined. The purple band represents the variation of four EnD2 models each trained on a different ensemble. The orange band represents the variation of four EnD2 models all trained on the same ensemble. The band surrounding the ʼEnD2+AUX Paperʼ line corresponds to the latter type of variation.
ReScience C 7.2 (#10) – Liiv, Lennelöv and Norén 2021 6
There appears to be a trend of small improvement when the number of models is increased, but the high level of uncertainty makes it difficult to draw conclusions from the remaining points. Nonetheless, the results seem to generally indicate that EnD2 is not particularly sensitive to ensemble size.
4.4 Temperature ablation study The results of our temperature ablation study are shown in Figure 2, along with the results of the original paper. For initial temperature equal to 1 and 2 our models fail to converge, resulting in poor classification performance. Raising the initial temperature to 3 allows the model to converge. Increasing the initial temperature further has no significant effect. It is worth noting the negative PRR values for T = 2. The original authors mention this possibility when they propose the metric, and offer the interpretation that this means that the model is increasing the classification error by rejecting samples, performing worse than simply rejecting at random.
4.5 Simplex visualization Predictions for four images are visualized in Figure 3. These four images were selected from the CIFAR10 dataset for respectively having the lowest total uncertainty, highest data uncertainty, highest knowledge uncertainty, and highest total uncertainty, as measured by the ensemble. The third row shows the Dirichlet PDF of EnD2. There is a strong tendency towards extremely sharp distributions, even when the ensemble has high spread, making comparison difficult. For this reason the fourth row plots the PDF after being transformed by the transformation log(x+ 1). It is now possible to see that the PDF is adapting to the distribution of the ensembles.
ReScience C 7.2 (#10) – Liiv, Lennelöv and Norén 2021 7
ReScience C 7.2 (#10) – Liiv, Lennelöv and Norén 2021 8
We also plot randomly selected images from the in, out, and auxiliary datasets respectively. The PDF has again been transformed using log(x + 1). Figure 4 shows images from the in-domain dataset, and Figure 5 shows images from the out-of-domain dataset. The PDF appears to follow the ensemble fairly well, but it is noteworthy that the ensembles show such a low degree of spread despite encountering samples onwhich they have not been trained.
5 Discussion
5.1 Comparison with original paper We now revisit the six claims which we specified in Section 2.
1. Classification performance: When compared to the original table we see overall worse performance. This is likely rooted in the fact that we were unable to achieve as high accuracy on our base VGG16 as in the original article. We therefore instead consider the relative performance between the models. Our supplementary material contains a table allowing for easy comparison with the original results. For example, we find that our EnD2 has 112.5% of the classification error of the ensemble, while in the original paper this figure is 117.7%. The absolute difference is the same in both papers, 1.1 percentage units. Our results generally agree well, with those of the authors. There are some discrepancies in expected calibration error, but our extremely high ECE for the individual model suggests that there might be an issue in our computations of this metric. Overall our findings support Claim 1.
2. Out-of-distribution detection performance: For the most part, our results agree with Claim 2. For instance, we found that using total uncertainty EnD2 without auxiliary data had 98.1% of the AUC-ROC of the ensemble, while the corresponding figure with auxiliary data was 100.0%. In the original paper, these figures were 96.8% and 99.8% respectively. There is one very significant discrepancy, however. With auxiliary dataset, our EnD2had 99.6% of the AUC-ROC of our EnD, while in the original paper this figure is 106.5%. A similar relationship exists without the auxiliary dataset. It is worth noting that in the original paper EnD performs worse than even the individual model, and the authors themselves note that this is odd. Since EnD2 is designed to overcome certain shortcomings of EnD in terms of uncertainty estimation we believe that this warrants further investigation.
3. Dependency on ensemble size: For prediction error and negative log-likelihood, our results confirm the relative performance between ensembles and EnD2+AUX, with increased resolution. For expected calibration error, the relative performance is confirmed for a large number of models, but for a small number of models, we get contradictory results. Their results seem to suggest that smaller ensembles have worse calibration, which is not expected, as per [1]. Our results confirm this expectation. In their paper, they state this expectation, but we see no comment
ReScience C 7.2 (#10) – Liiv, Lennelöv and Norén 2021 9
for this discrepancy. For prediction rejection rate, we confirm the relative performance, and also show that it starts to drop rapidly below their tested range.
4. Dependency on temperature annealing: Our results diverge heavily from the results in the paper for temperatures 1 and 2. While the original authors are able to train working but sub-par models with these temperatures, we are unable to get the models to converge at all. We re-did the experiments with a new ensemble, and experimented with the smoothing factor and auxiliary data, but were unable to find any explanation for this difference. Nevertheless, these findings support the claim that temperature annealing is essential for successful use of the EnD2 method. The authors suggested temperature 5 as a minimum value beyond which larger values make no difference. Our findings support this as well, although our increased resolution reveals that the minimum value for the CIFAR-10 dataset is closer to 3 than 5.
5. Uncertainty decomposition: Based on the description in [3] an image with a high knowledge uncertainty should produce a Dirichlet PDF with a close to uniform spread. Our simplex visualizations on the 3-class+AUX dataset shows that this is not the case. This is not too surprising, given that high knowledge uncertainty correlates with small alphas, and this in turn produces convex as opposed to flat probability density surfaces. Overall, these plots suggest that EnD2can capture the uncertainty decomposition of the ensemble. The plots also show an interesting behaviour in the ensemble. The ensembles agree to a surprising extent on the out-of-domain samples. In fact, when they do disagree it normally takes the form of data uncertainty as opposed to knowledge uncertainty. This could perhaps shed some light on the observation that knowledge uncertainty does not seem to be useful for OOD-detection on CIFAR-10. The original authors explain this as essentially being a property of the dataset. We feel, based on the visualizations, that another possibility might be that the ensemble models simply are not diverse enough to provide a useful measure of knowledge uncertainty.
5.2 What was difficult Although the general idea of the paper is well formulated in mathematical terms, the original paper does not providemany hints regarding how to implement themethod. In our case, this imposed a significant barrier to immediately reproducing the work, since our inexperience meant that weʼre unable to immediately see how it could be implemented in a modern deep learning framework. There is some code available in a public repository hosted by one of the authors but this is not mentioned in the paper, and so we could not treat it as an official implementation. We have provided a pseudocode in our supplemental material, in order to hopefully assist future reproducers. There are also some missing details regarding the models used. Most importantly, the authors mention that they have used a modified VGG model, but do not specify what these modifications are. The authors also do not specify the min and max value of the cyclic LR. These details may explain the consistently worse performance of our models despite the attempt of replication.
5.3 What was easy The synthetic dataset was fairly easy to reconstruct, and the other datasets are well known and publicly available. The data augmentation was straightforward and easy to incorporate into a training pipeline. The base model (VGG16) used in most of the experiments is well known and was computationally feasible to train. Similarly, the datasets are not excessively demanding in terms of computation, although in our case training
ReScience C 7.2 (#10) – Liiv, Lennelöv and Norén 2021 10
time did become a limiting factor due to the amount of time we spent on implementation and experimentation. The mathematical formulation of the model is very good, helping the conceptual understanding.
5.4 Communication with original authors We did not communicate with the authors while reproducing their work, although we did refer to some resources which one of the authors has made publicly available, including an repository 3 made for [3] containing an implementation of EnD2. At the same time as submitting this report, we also sent a copy to the authors and asked for their comments."
"['Kevin Stephen', 'Varun Menon']",[Re] Learning Memory Guided Normality for Anomaly Detection,10.5281/zenodo.4834610,Replication,Python,https://zenodo.org/record/4834610/files/article.pdf,rescience c rescience x,https://openreview.net/forum?id=vvLWTXkJ2Zv,https:/github.com/alchemi5t/MNADrc,7,2,2021,"The authors have introduced a novel method for unsupervised anomaly detection that utilises a newly introduced “MemoryModule” in their paper [1]. We validate the authorsʼ claim that this helps improve performance by helping the network learn prototypical patterns, and uses the learnt memory to reduce the representation capacity of Convolutional Neural Networks. Further, we validate the efficacy of two losses introduced by the authors, “Separateness Loss” and “Compactness Loss” presented to increase the discriminative power of the memory items and the deeply learned features. We test the efficacy with the help of t-SNE plots of the memory items.","• The authors provide codes to run the Prediction task with memory.
• The ideas presented in the paper were clear and easy to understand.
• Thedatasetswere easily available, with the exceptionof the ShanghaiTechdataset[2].
Copyright © 2021 K. Stephen and V. Menon, released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Varun Menon (vk2148@nyu.edu) The authors have declared that no competing interests exist. Code is available at https:/github.com/alchemi5t/MNADrc – DOI 10.5281/zenodo.4681515. – SWH 1:dir:120b52bc3dfe115b3329698a39ea71c7cd5862d1. Open peer review is available at https://openreview.net/forum?id=vvLWTXkJ2Zv.
ReScience C 7.2 (#11) – Stephen and Menon 2021 1","• After training the model on the ShanghaiTech dataset[2], we found that the “Memory” variants of the model had issues as described in Sections 4 and 5. We investigated the behaviour of thememorymodule and introduced additional supervision to solve the problem.
• We required hyperparameter optimization to hit the reported scores.
• The paper also lacked information as to which parts of the pipeline were actually to be credited for the improvement in performance, as discussed in Section 5.
Communication with original authors The codebase has scripts only for the Prediction task ”Memory” variant of the benchmarks. We reused portions of the codebase to create the other variants. We then validated our modifications with the authors. We also communicated the discrepancies we saw in parts of the results and the authors asked us to wait until they update their repository with the missing scripts.
1 Introduction
The paper that we have tried to reproduce attempts to detect anomalous events in a video sequence. Anomaly detection based on Convolutional Neural Networks (CNNs) usually leverage proxy tasks like reconstruction of input frames or prediction of future frames, i.e., trained only on the ”Normal” scenes thereby having a hard time reconstructing anomalies. Conventionally, Peak Signal-To-Noise ratio (PSNR) is used to gauge if the input batch of images has anomalous frames. The authors have introduced a hybrid metric for Abnormality Score calculation, comprising a weighted sum of the PSNR value and L2 loss between the Queries and the Memory items. We utilise the term ”Reconstruction” to refer to the model and the term ”reconstruction” to refer to the output generated by the model (s). The author s̓ primary contribution is the introduction of a ”Memory Module” which is claimed tomemorize prototypical patterns of normal data, and thesememory items are used to reduce the representation capacity of the CNN which, in theory, decreases the quality of the output (Reconstruction or Prediction) when the input batch has anomalous frames, therebymaking it easier to classify input batches as anomaly or not. The authors also introduce two losses, namely, Compactness loss and Separateness loss which help increase the diversity and discriminative power of thememory items. Thefinal contribution is the introduction of Test-Time Updation of memory to help tune thememory items according to the normal scenes during inference.
2 Scope of reproducibility
We have attempted to reproduce the reported scores of the ”Memory” variant and ”Non Memory” variant on all datasets for both the Prediction and Reconstruction tasks, alongside reproducing the scores for the ablation studies as well. The author s̓ central claim is that the ”memory module” helps the network learn prototypical patterns of normal scenes, and using the learnt memory items as ”noise” reduces the representation capacity of the CNN and makes it harder for the network to reconstruct/predict anomalous output thereby making it increasingly easier to classify anomalous input batch of images.
ReScience C 7.2 (#11) – Stephen and Menon 2021 2
We ran experiments to compare the performance of the Reconstruction and Prediction models with and without memory modules. While benchmarking these models we observed a few deviations in the reported results and reproduced results which lead us to experiments to get more clarity on the behaviour of the memory module, which we shall discuss in Section 4. We provide the hyperparameters with which we got the best results on the provided datasets. Their secondary claims revolve around the Compactness loss and Separateness loss, which they claim helps the network space out and the memory items and decreases the spread between similar deeply learned features. They also claim that the Test-Time updation of the memory items helps tune the memory items to the normal scenes during inference time, subsequently classifying anomalies more accurately. We attempted to reproduce the ablation studies results which covers both the secondary claim and the Test-Time updation scheme claim. The claims we are testing:
• ”Memorymodule” helps thenetwork to learnprototypical patterns of normal scenes, and using learnt memory items to lessen the capacity of CNNs.
• feature compactness and separateness losses to train the memory, ensuring the diversity and discriminative power of the memory items. improves performance.
• update scheme of the memory, when both normal and abnormal samples exist at test time, improves performance.
3 Methodology
3.1 Model descriptions The authors present a novel algorithm for unsupervised anomaly detection that makes use of amemorymodule. Themodel architecture comprises of three parts: The encoder, the memorymodule and the decoder. Themodel either reconstructs or predicts a video frame with a combination of features from the encoder and the memory items rather than just the features from the encoder. The memory module consists of 10 items of 512 each. A “read” operation generates a tensor of size 32*32*512 from the memory module which is then concatenated to the tensor obtained from the encoder. This obtained matrix is concatenated with the query features to generate a tensor of depth 1024, then passed to the decoder. The key idea here is that the memory item is used to generate a tensor using a weighted average, thus utilising all the memory items. This allows the model to learn diverse patterns. The network and memory module is trained only on normal frames. As a result, the cosine distance between the query and the relevant memory item is less and they are close to each other. On the contrary, since the network has not seen the anomalous frames during the training phase, thememory itemwill be far from the queries obtained. Since they are far, the Query-Memory pair will be sub-optimal thus resulting in poor reconstruction of the input frames. To read the items, the cosine similarity score is computed between each query qkt and all memory items pm, resulting in a 2-dimensional correlation map of size M × K, A softmax function is then applied along a vertical direction, and matching probabilities wk,mt are obtained as shown in Equation 1.
wk,mt = exp
( (pm) T qkt ) ∑M
m′=1 exp ( (pm′) T qkt ) , (1) For each query qkt , the memory items are read by a weighted average of the items pm with corresponding weights wk,mt and obtain p̂kt as shown in Equation 2. The p̂kt values
ReScience C 7.2 (#11) – Stephen and Menon 2021 3
computed from each querymakes up the featuremapwhich is then concatenated to the features obtained from the Encoder depth wise.
p̂kt = M∑ m′=1 wk,m ′ t pm′ , (2)
The ”update” operation updates the memory items as it iterates through the dataset and learns the pattern of normal features. To update the memory, for each item, all queries that are closest to thememory item are chosen using thematching probabilities in Equation 1. The set of indices for the corresponding queries form-th item in thememory are denoted byUmt . The item using the queries indexed byUmt is updated as shown in Equation 3. f(·) is the L2 norm.
pm ← f pm + ∑ k∈Umt v′ k,m t q k t  , (3) A weighted average of the queries is used. The matching probabilities are computed by applying the softmax function to the correlation map of M × K along a horizontal direction as shown in Equation 4.
vk,mt = exp
( (pm) T qkt ) ∑K
k′=1 exp ( (pm) T qk ′ t ) (4) The authors choose to use PSNR as a part of the metric to check the output quality from the decoder. Along with this, the authors utilise an L2 distance loss calculated between the queries and its corresponding nearest memory item. The PSNR and L2 distance is coupled together as shown in Equation 5.
St = λ ( 1− g ( P ( Ît, It ))) + (1− λ) g (D (qt, p)) , (5)
The authors also introduce a new pair of losses, Compactness loss and Separateness loss. The Separateness loss minimizes the distance between each feature and its nearest item, while maximising the discrepancy between the feature and the second nearest one, similar to Triplet loss [3]. The feature Compactness loss maps the features of a normal video frame to the nearest item in the memory and forces them to be close. These losses coupled, spread the individual items in the memory and as a result enhance the discriminative power of the features and the memory items. The architecture used in Reconstruction task ”Memory” variant is similar to that of the Prediction task ”Memory” variant with the exception that it does not have skip connections. The Prediction ”Non Memory” variant resemble a U-Net [4] and the Reconstruction models resemble a simple Autoencoder [5]. The authors haveprovided a codebase available at https://github.com/cvlab-yonsei/MNAD. However, the codebase has only the codes for the ”Memory” variant of the Prediction task1. We reused a major portion of the available code to build scripts for the Reconstruction task and variants with and without memory. We validated the new scripts and changes by communicating with the authors over email to ensure there is no gap between their intention and our developed codebase. The completed codebase for all tasks available at https://bit.ly/3s3nTIR. The available code for the “Prediction” task could be run on the Ped2[6] and CUHK[7] datasets without any changes. However, the ShanghaiTech dataset[2] required us to generate the frames from the provided videos. We utilise theVideoCapture class available on theOpenCV library to generate 2,74,515 frames. We make the following changes in the available code to create the scripts for the Reconstruction task:
1Post Submission for review, the authors updated their GitHub repository to include the scripts for the ”Memory” variant of the Reconstruction task. Discrepancies in this code are available on our code repository.
ReScience C 7.2 (#11) – Stephen and Menon 2021 4
• We tweak the code to accept one input and generate one output of the same frame by changing the time step parameter.
• We remove the skip connections present in the architecture for the Prediction task.
We make the following changes for the ”Non Memory” variants:
• The decoder needs only the query features and hence we change the first layer of the decoder to accept and create a 512 size vector.
• For the ”NonMemory” variants of themodels, we cannot calculate the L2 distance and only the PSNR value is to be used for Abnormality Score calculation in the evaluation script.
3.2 Datasets We test and report results on all datasets that the authors have reported scores on. The three datasets used areUCSDPed2[6], CUHKAvenue[7] and the ShanghaiTech[2] anomaly detection dataset. All three datasets are readily available in the author s̓ repository. However, only the UCSD Ped2 dataset[6] and CUHK Avenue dataset [7] are available directly in the format required by the authorsʼ code. The ShanghaiTech dataset[2] contains only videos which we had to split into frames using OpenCV to generate 274,515 frames. We have provided the script used to save the frames on the GitHub repository.
3.3 Hyperparameters We experimented heavily with the λ hyperparameter to achieve the reported scores. We could not find a fixed trend in its behaviour across the three datasets. We have provided the best results after tweaking λ and the results obtained as per the author s̓ recommendation of hyperparameters as discussed in Section 4.1. As for the other hyperparameters, we found that the recommended values worked well and gave us similar results to the paper with the exception of the ShanghaiTech dataset[2].
3.4 Experimental setup Weusemultiple hardware set-ups for our experiments, namely, vast.ai instances, Google Colab and our personal systems. We used NVidia Tesla T4 and P100 from Google Colab, along with 1080 Ti, 2070, 2070 SUPER, 2080 Ti rented on vast.ai. To maintain uniformity, we benchmark all our scores on a 2080 Ti. We recorded all our training metrics on “wandb”2.
3.5 Computational requirements For our experiments and benchmarking, we use a rented GPU from vast.ai. All our scores are reported on a 2080Ti with 8 GB vRAM. The training times are as shown in Table 1. The inference times andmodel parameters for the Prediction task ”Memory” variant and Reconstruction task ”Memory” variant are as shown in Table 2 and Table 3 respectively.
2wandb logs are available in the repository. 3Denotes the Model size and Memory tensor size
ReScience C 7.2 (#11) – Stephen and Menon 2021 5
Parameter Category Parameter Value Storage Saved Weights Size 62.7 MB + 20.8 kB 3
Time (GPU) Inference 0.012s
4.1 Benchmarking Results The results obtained on the hyperparameter values provided by the authors are provided in Table 4.
The best obtained results are provided along with the hyperparameter values in Table 5. We evaluated the models saved at every 5th epoch and tweaked values of λ and Batch Size.
4.2 Ablation Results In our ablation study experiments, we validate the following:
• We test the efficacy of the Separateness Loss, Compactness Loss and Test-Time updation for both theReconstruction andPrediction tasks on theUCSDPed2dataset[6]. The results are as shown in Table 6 and Table 7.
• We compare the distribution of query features, learnt with and without the Separateness Loss on the UCSD Ped2 dataset[6] as shown in Figure 1.
4value of λ used is 1 due to issues discussed in Section 5.
ReScience C 7.2 (#11) – Stephen and Menon 2021 7
Separateness Loss Compactness Loss Test Time Updation λ AUC N N Y 0.87 84.03% N Y Y 1 88.99% Y N Y 0.8 87.24% Y Y N 0.8 87.72% Y Y Y 0.7 87.34%
on the Reconstruction task.
• Memory Distribution plots for better understanding the utilisation of memory: The model architecture offers 10memory items of size 512 each. During our evaluation of the ShanghaiTech dataset[2], we found that the Abnormality Score vector had a large number of NaNs, due to which we could not evaluate the model. We further investigated the Prediction ”Memory” variant of the model in order to fix this bottleneck. To validate our doubts and concerns, we plotted the distribution of the memory items vs the deeply learned features and observed that the distribution was lopsided and only some of the items were being utilised. We saw this behaviour repeat across the three datasets however the worst affected was ShanghaiTech[2] where only one memory item was being utilised (See Figure 4a). Ped2[6] and CUHK[7] utilised 6 and 9 memory items respectively but the distribution was still lopsided as it seems that some memory items are utilised more than the others as shown in Figure 2. The abnormality score is a proportional summation of the PSNR and L2 distance between theDeeply learned feature and the closestmemory item. In case of ShanghaiTech[2], onememory itemwas responsible for all of the features anddue tominmax normalisation used in the abnormality score, theminimumandmaximumL2 would be computed to the exact same value which meant that the normalization process would have to divide by 0, which resulted in NaNs. We found that other developers had similar issues as shown in this issue. https://github.com/cvlabyonsei/MNAD/issues/6 This problem resulted in Evaluation failing on the ShanghaiTech dataset[2] and returning NaNs in the final anomaly score. A temporary work around was setting the λ value to 1, as a result weighting only the reconstruction or PSNR scores and not using the L2 loss between the query and memory items for the Abnormality Score calculation. As a solution, we added a new supervision to force a uniform distribution across the memory items. We were able to reproduce the reported results on ShanghaiTech[2] without any issues, which previously failed. The methodology used and results are further discussed ahead.
• Proposed memory distribution Supervision: We introduce a new supervision to ensure that all the memory items are utilised uniformly. We create a uniformly distributed correlation map of size 10 × 1024 which is used to supervise the distribution of Query features across the memory items using Mean Squared Error (MSE) Loss as shown in following the code snippet. loss_mse = torch.nn.MSELoss() softmax_score_query, softmax_score_memory = self.get_score(keys,
query) mem_dist = torch.argmax(softmax_score_memory,dim = 1)
ReScience C 7.2 (#11) – Stephen and Menon 2021 9
mem_dist = F.one_hot(mem_dist, num_classes = 10) mem_dist = torch.sum(mem_dist, dim = 0) query_reshape = query.contiguous().view(batch_size*h*w, dims) mem_dist_loss = loss_mse(softmax_score_memory, self.ideal.float())
Figure 3 is only a representation of the ProposedMemory distribution supervision. This gives a more uniform distribution of query features across the memory items as shown in Figure 4b.
the scores reported by the authors onboth the Prediction andReconstruction tasks. The obtained results are as shown in Table 8. We observed that our obtained scores on the Reconstruction task was more than the Prediction task. The fact that the Reconstruction model performs better than the Prediction model here is deeply concerning as the Prediction model also has Temporal informationwhichhelps recognise Temporal and Spatio-Temporal anomalies while the Reconstruction model does not. Thus, the Reconstruction model completely misses out on Temporal anomalies but is still able to outperform the Prediction model. A possible explanation for the same could be the fact that the ShanghaiTech dataset[2] is too complex for the memory mechanism to be utilised as intended. However, we can say with surety that the ”Memory” module does not seem to be helping the performance of the model on the ShanghaiTech dataset[2]. While forcing the model to use each memory item equally is not an ideal solution, it helps the model work without errors and shows the need for a better and dynamic learning scheme for the memory items.
ReScience C 7.2 (#11) – Stephen and Menon 2021 11
• Results with and without Test-Time updation: The authors claim that Test-Time updation of the memory helps improve the performance of the model. However, we found contrary results for the Reconstruction with Memory task on ShanghaiTech[2] and Ped2[6]. For the Prediction task, we empirically found that the 1st skip connection is heavily weighted and is highly responsible for the reconstruction quality. As a result, the intermediate and memory items are not involved in the Prediction task. We passed zeros, ones and random tensors for skip 2,3 and the deeply learnt features from the encoder and the output was optically unchanged for this experiment. As a result, the memory does not seem to affect the output quality much for complex datasets like ShanghaiTech[2]. For Reconstruction task, we can clearly see the drop in performance “with Test-Time-Updation” in ShanghaiTech[2] as there are no skip connections to overcompensate. The results on ShanghaiTech[2] are as shown in Table 9.
Model AUC Reconstruction w/ Memory w/ Proposed Supervision w/o Test-Time Updation 71.07% Reconstruction w/ Memory w/o Proposed Supervision w/ Test-Time Updation 64.14%
Prediction w/ Memory w/ Proposed Supervision w/o Test-Time Updation 70.40% Prediction w/ Memory w/ Proposed Supervision w/ Test-Time Updation 70.35%
6 Discussion
Our results as shown in Section 4.1, show that the memory models do perform better than the ones without for Ped2[6] and CUHK[7] datasets. However, the ”Memory” variants achieve lower AUC scores than the ”Non-Memory” variants on the ShanghaiTech dataset[2] (Table 4). Our Ablation study experiments on Separateness Loss, Compactness Loss and Test-Time updation do not follow the same trend as the authors, shown in Table 6 and Table 7. However, our generated t-SNE plots (Figure 5) show that the Separateness Loss and Compactness Loss help increase the discriminative power of the Memory items by spacing the Query Features out. Our results in Table 9 show that TestTime updation fails on complex datasets like ShanghaiTech[2]. As shown in Section 5, the memory distribution is lopsided. Utilising only one memory item results in similar reconstruction for both anomalous and normal frames. We provide a temporary solution to ensure that the model works smoothly. Our newly introduced Supervision is described in Section 5 and is backed with results (Table 8) and histograms to show the uniform distribution of features among the memory items as shown in Figure 4b . While most of our results corroborate with the claims made by the authors, we believe there are a number of changes that can be brought about to improve performance. As shown in Figure 4a, in Section 5, for a complex dataset like ShanghaiTech[2], only one memory item is being utilised. This is against the core idea of the paper, that is to reduce the representative power of CNNs. The utilisation of just one memory item means that irrespective of the features being close or far, the same tensor obtained after reading the memory is concatenated to the features obtained from the encoder. As a result, there is no difference in reconstruction quality for anomalous features as compared to the normal features. In Figure 10, we
ReScience C 7.2 (#11) – Stephen and Menon 2021 13
illustrate how a number of query features correspond to a particular Memory item and how it is concatenated depending on the cosine distance from the query features.
While our proposed supervision is not ideal, we were able to get this script running and were able to achieve the reported scores by the author as shown in Table 8 without any issues described in Section 5. Further, for ShanghaiTech[2], we found that the Reconstructionmodelswith our new Supervision seem to work better than the Prediction with Memory models. Given the fact that the Prediction task has Temporal information as well, it should be outperforming the Reconstruction task due to the correct classification of Temporal anomalies. Thus, the Reconstruction task outperforming the Prediction task shows that the model does not work as intended.
ReScience C 7.2 (#11) – Stephen and Menon 2021 14
Finally, we show the difference between the reconstruction of Spatial, Temporal and Spatio-Temporal anomalies from both the Prediction and Reconstruction models as depicted using the Synthetic Dataset discussed in Section 5 and as shown in Figures 6, 7, 8 and 9.
6.1 What was easy • Training and evaluation of the Prediction task ”Memory” variant is straightforward with the codebase that the authors provide.
• The codebase was clear enough for us to easily reuse it for implementing the missing variants discussed in the paper, namely the Prediction ”Non Memory” variant and both the ”Memory” and ”Non Memory” variants of the Reconstruction task.
• The ideas presented in the paper were clear and easy to understand.
• All benchmarking datasets were readily available in the format required by the codebase, with the exception of the ShanghaiTech dataset[2].
6.2 What was difficult • Training on the ShanghaiTech dataset[2] took 25 hrs, and once trained, we observed the ”Memory” variants had clear issues (discussed in Section 5) whichmade it difficult to hit the reported scores. We further investigated the behaviour of the memorymodule andhad to introduce additional supervision to helpwith the problems (Section 5).
• We found that the hyperparameters specified by the author were not suitable for a number of tasks and thus needed hyperparameter optimization to hit the reported scores.
• Therewas also awant of information onwhichparts of the pipelinewere to be credited for the results. The heavy emphasis on benchmarking on the Reconstruction vs Prediction tasks misdirects the reader from why certain inclusions and modifications in the network architecture is the reason for reported state of the art performance (discussed in Section 5).
6.3 Communication with original authors The codebase has scripts only for the Prediction task ”Memory” variant of the benchmarks. We reused the majority of the codebase to create the other variants so as to have minimum variation from what the authors intended. We then validated our modifications with the authors through e-mail communication and will have all correspondence available in the code repository. We also communicated the discrepancies we saw in parts of the results and the authors told us they would update their repository with the missing scripts soon to help match the reported scores.
7 Reproducibility Recommendations
We have the following recommendations:
• We believe that the ideal value of the hyperparameter λ is 0.7-0.8 for most datasets as this seems to yield the best results for the ”Memory” variant of the Prediction task as compared to 0.6 suggested by the authors.
ReScience C 7.2 (#11) – Stephen and Menon 2021 15
• There also appears to be a problemwith PyTorch versioning where the best results are obtained with PyTorch 1.1.0. This is an issue that other developers noticed as well (https://github.com/cvlab-yonsei/MNAD/issues/1). The reason for this behaviour is unclear."
"['Sami Menteş', 'Furkan Kınlı', 'Barış Özcan', 'Furkan Kıraç']",[Re] Spatial-Adaptive Network for Single Image Denoising,10.5281/zenodo.4834672,Replication,Python,https://zenodo.org/record/4834672/files/article.pdf,image denoising image restoration image processing,https://openreview.net/forum?id=yiAI9QN9nYt&noteId=SMFjCY6qG8,https://github.com/sami-automatic/SADNet_Replication,7,2,2021,"In this study, we present our results and experience during replicating the paper titled ”SpatialAdaptive Network for Single Image Denoising”. This paper proposes novel spatial-adaptive denoising architecture for efficient noise removal by leveraging the deformable convolutions to adapt spatial information (i.e. edges and textures). We have implemented the model from scratch in PyTorch framework, and then have conducted real and synthetic noise experiments on the corresponding datasets. We have achieved to reproduce the results qualitatively and quantitatively.","The code was open-source, and implemented in PyTorch, hence adopting the training loop and proposed blocks to our implementation facilitated our reproduction study. The loss function is straightforward and the architecture has a U-Net-like structure, so that we could achieve to implement the architecture in a fair time.","Due to the lack of compatibility with the current versions of PyTorch and TorchVision and the dependency on an external CUDA implementation of deformable convolutions, we have encountered several issues during our implementation. Then, we have considered to re-implement residual spatial-adaptive block and context block from scratch for deferring these dependencies, however, we could not achieve it just by referring to the paper in limited time. Therefore, we have decided to directly use the provided blocks as in the author s̓ code.
Communication with original authors We did not make any contact with the authors since we achieved to solve the issues encountered during the implementation of SADNet by examining the author s̓ code.
1 Introduction
Recent works [1, 2, 3, 4] have shown that the previous assumption of an identicallydistributed additive white Gaussian noise (AWGN) is not an accurate representation of the real noise occurring in images. Traditional denoiser architectures lack the ability to adapt textures and edges, and thus miss the details while denoising, due to the oversmoothing behaviour of CNNs. A workaround to this problem is implementing a deeper network, however, such a practice introduces a more complex model with its computational burden. In the original paper [5], an encoder-decoder architecture consisting a residual spatialadaptive block, namely RSAB, is proposed for removing spatially-variant and channeldependent noise while processing larger regions in each step by utilizing deformable convolutions. As themain claim of the paper, thismethod produces better performance than the compared methods in given benchmark, and also for the synthetic noise removal task. In this reproducibility report, we studied SADNet architecture for both real and synthetic noise removal in detail, which contains implementing the architecture described in the paper, running the experiments, reporting the important details about certain issues encountered during reproducing, and comparing the obtained results with the ones reported in the original paper.
2 Scope of reproducibility
The main idea of the paper is to present a spatial-adaptive architecture with encoderdecoder structure which captures the relevant features from the complex image content while removing real noise appearing in images. Residual spatial-adaptive block (RSAB) makes it possible to achieve this in an efficient manner. The proposed model, namely SADNet, claims to outperform the state-of-the-art performances in SSIM and PSNR metrics with a moderate run-time. To validate these claims, we try to investigate the following questions:
ReScience C 7.2 (#12) – Menteş et al. 2021 2
• Is the implementation details described in the paper and provided code sufficient for replicating the quantitative results reported in the paper?
• Are the qualitative results visually-plausible?
• Are the replicated quantitative results competitive enough?
• Could our replication obtain a proximate denoising duration compared to the reported results in the original paper?
3 Methodology
We have implemented the model, namely SADNet, from scratch in PyTorch [6], as described in the paper by adopting RSAB, Context block and Offset block from the author s̓ code. The implementation of residual blocks (ResBlock) in the author s̓ code differs from the common residual block implementation [7] by not using the output activation. In contrast to the common practice of applying a nonlinear activation function to the output, their ResBlock implementation directly forwards its output to the next level layers. At this point, the authors handle those activations at the model scope. We also removed Batch Normalization [8] from the residual blocks as proposed by the original paper. To enhance the readability of the model structure in our implementation, we imported those activation functions back in to ResBlock. Thedeformable convolutions inRSABare implemented inCUDA,henceweusedNVIDIA GPUs with the relevant CUDA driver. For validating the reported results on real noisy images, we have implemented the data loaders, which are missing in the author s̓ code. Furthermore, we integrated WandB [9] library to the training loop in order to track our experiments during training.
3.1 SADNet SADNet is an encoder-decoder architecture with skip connections which favors spatial adaptability and large receptive field over deeper networks for the well-studied denoising task. The proposed model aims to achieve the state-of-the-art denoising performance while maintaining the computational complexity by exploiting residual spatialadaptive block (RSAB), Context Block and Offset Block. The visual representation of SADNet architecture is shown in Figure 1, and also the structural details about our implementation of SADNet can be seen in Table 1.
ReScience C 7.2 (#12) – Menteş et al. 2021 3
Regions with the sharp texture changes in an image, typically edges and corners, raise difficulties for training the regular convolutions, due to its fixed-size weighting mechanism. Such regions, where different textures co-occur in a particular receptive field of the regular convolutions, are simply ignored during the weighting process, due to the fixed size kernels. To address this issue, self-similarity weighting is attained via modulated deformable convolutions [10] in RSAB. The kernels of the deformable convolutions have a learnable offset for each location in an image, and thus it has the capacity to adapt to the spatial texture changes. The formula of modulated deformable convolutions can be seen as follows
y(p) = ∑
pi∈N(p)
wi · x(pi +∆pi) ·∆mi (1)
where ∆pi denotes the learnable offset for location pi, and ∆mi is the extra degree of freedom for adjusting the modulation scalar between [0, 1]. The nature of the decoder architectures enforces to transform the feature maps from coarse to fine at each scale. For learning the offsetsmore accurately in RSABs, the offsets ∆ps−1 and themodulation scalars∆ms−1 from theprevious scale are further transferred into the current scale s with the help of Offset Blocks. The offset transfer is formulated as
(∆ps,∆ms) = Foffset ( x, Fup (( ∆ps−1,∆ms−1 ))) (2)
where Fup denotes the up-sampling operation. RSAB receive the extracted features and the reconstructed features from the previous scale conveyed by the Offset Block. The inputs are then fused through a modulated deformable convolution layer with a subsequent regular convolution layer. Moreover, a skip connection similar to ResBlock is employed to enhance the information transferring. At this point, RSAB can be formulated as,
FRSAB(x) = Fcn(Fact(Fdcn(x))) + x (3)
where Fcn and Fdcn denote regular convolution and modular deformable convolution, respectively. Lastly, Fact stands for the leaky ReLU activation function [11] with a negative slope of 0.2. Another introduced block is the Context Block, which resides at the bottleneck of the model. To increase the size of the receptive fields while preserving the spatial resolution, Context Block is employed for the model, just between the encoder and decoder structures. Furthermore, unlike the common implementation of Context Block, Batch Normalization layer is removed in the published code, and only four dilation rates are used, which are 1, 2, 3 and 4. Following the original paper, we usedL1 loss for training ourmodel on real-noise image datasets, and L2 loss for training on synthetic image datasets.
3.2 Datasets The original paper uses SIDDMedium [12] and RENOIR [13] datasets during training for denoising real noisy images and reports the qualitative and quantitative results on DND [14] and SIDD validation [12] datasets. Since the author s̓ code only provides the data loader for synthetic image datasets, we have integrated our SIDD validation data loader implementation and the DND test script provided by TU Darmstadt [14] to our pipeline. For synthetic noise removal, additive white Gaussian noise with standard deviation of 30, 50 and 70 have been added to DIV2K dataset [15], which consists 800 high resolution images. To validate the performance of SADNet on synthetic noise removal task, the models are tested on BSD68 [16] and Kodak24 datasets processed with the same noise addition mechanism.
ReScience C 7.2 (#12) – Menteş et al. 2021 4
Both test and validation data for all settings are composed of high resolution images. Therefore, they are fed to themodel as 128x128 patches cropped by fixed coordinates, as described in the paper. We have applied 90◦ rotation, horizontal and vertical flipping to the images during training, following the practice in the paper.
3.3 Hyperparameters In our replication study, we used the ADAM optimizer [17] with β1 = 0.9, β2 = 0.999, and ϵ = 1e− 8, with an initial learning rate of 1e− 4 during training, as described in the paper. The provided code initializes the weights of the convolutional layers in all blocks with Xavier Uniformmethod [18]. Since this choice has not been discussed in the paper, we left each convolution layer initialized by the default weight initialization method in PyTorch (i.e. Kaiming [19]) in our experiments.
3.4 Experimental setup In this study, we have followed the same training procedures for all setting, and employed SSIM and PSNR values as performance metrics, as described in the original paper. The parameters for all training settings can be found in the configuration file in our GitHub repository. Our implementation and the trained weights are open-sourced, and can be accessed at https://github.com/sami-automatic/SADNet_Replication.
3.5 Computational requirements The experiments have been conducted on a single RTX 2080Ti for approximately 3 days, and only requires highGPUmemory,mostly due tomodulated deformable convolutions. It requires ∼3GB GPUmemory for training, and ∼8GB CPUmemory for loading the data, due to the file structure of datasets.
4 Results
Wehave implemented themodel fromscratchby following the descriptions presented in the original paper, and then achieved to replicate the claimed results by referring to the published code. Overall, our implementation of SADNet achieved on-par performances
ReScience C 7.2 (#12) – Menteş et al. 2021 6
in SSIM and PSNR metrics on test datasets, and we also validated the results on both denoising tasks by examining their qualitative results. As shown in Table 2, our quantitative results on SIDD sRGB validation dataset has 39.41 PSNR value, which is only 0.12% less than the one reported in the original paper. Moreover, the average duration of a single inference of SADNet is 26.7 ms. according to the paper, while our implementation of SADNet completes the single inference on 25.9 ms. The visual comparisons of real noise removal of the images are shown in Figure 2 and Figure 3. The samples are from SIDD validation dataset, according to the ones reported in the paper. The first two rows in these figures are directly taken from the original paper for further comparison with our replication results, which can be seen in the third row. On the results from the original paper, SADNet mainly differs from the compared methods by generating a distinct clear continuous stripe texture on the background while preserving the object surface appearance. Our replication clearly shares the similar behaviour. Therefore, we can state that the replicated quantitative results on real noise removal task are competitive enough, and also supports the main claim in the original paper. Similarly, Table 3 demonstrates that the results of our SADNet implementation achieves on-par PSNR values with the ones reported in the paper for different noise levels (i.e. σ ∈ {30, 50, 70}) on BSD68 and Kodak24 datasets. Particularly, we have obtained better results than all other compared methods and the reported SADNet results on Kodak24 dataset for all noise levels. Moreover, the replicated SADNet model imitates the qualita-
ReScience C 7.2 (#12) – Menteş et al. 2021 7
tive results of the original model on both datasets. Although the images from Kodak24 and BSD68 are heavily exposed to the synthetic noise, SADNet has the ability to remove noise, and to generate well-defined textures when compared to the recent works. As shown in Figure 4, all other compared methods have smoothed the texture and swept away the feather details, meanwhile the original implementation of SADNet and ours achieve to generate more plausible feather-like texture. Similar to the previous example, in Figure 5, the clothing details are significantly preserved, especially pilling on the top-left part of the cloth and the vertical texture details on the cloth. The ground truth of DND validation set is private, and thus it is not possible to locally validate the results on this dataset. Despite of several attempts to submit our results to DND online validation system, we could not obtain SSIM and PSNR results, due to the server error. We have tried to contact with DND Team, but we could not get any advice for solving this issue.
5 Discussion
The qualitative results generatedwith our replication strongly resemble to the presented results, and differs from the other compared studies. According to these results, we can state that our implementation of SADNet consistently yields visually-plausible results on both real and synthetic noisy images, and supports the claims of the original paper. In addition, our experiments firmly correlates with the reported PSNR values. Overall, the paper and the provided codewas sufficient for replicating the results on real and synthetic noise removal. For re-implementing themodel from scratch, wehave only referred to the paper, and ended up on-par performance with the ones in the paper on all settings. Lastly, to provide an insight for run-time on different hardware, our replication has 25.9 ms. inference run-time on real noise removal task, whereas the reported run-time duration is 26.7 ms. Note that we used a single RTX 2080Ti GPU during our experiments, while a single GTX 1080Ti GPU is used in the original study, and we assume that this is the reason of this difference.
5.1 What was easy The code was open-source, and implemented in PyTorch, hence adopting the training loop and proposed blocks to our implementation facilitated our reproduction study. The loss function is straightforward and the architecture has a U-Net-like structure, so that we could achieve to implement the architecture in a fair time.
5.2 What was difficult Due to the lack of compatibility with the current versions of PyTorch and TorchVision and the dependency on an external CUDA implementation of deformable convolutions, we have encountered several issues during our implementation. Then, we have considered to re-implement residual spatial-adaptive block and context block from scratch for deferring these dependencies, however, we could not achieve this just by referring
ReScience C 7.2 (#12) – Menteş et al. 2021 9
to the paper. Therefore, we have decided to directly use the provided blocks as in the author s̓ code.
5.3 Communication with original authors We did not make any contact with the authors since we achieved to solve the issues encountered during the implementation of SADNet by examining the author s̓ code."
"['David Mizrahi', 'Oğuz Kaan Yüksel', 'Aiday Marlen Kyzy']",[Re] Can gradient clipping mitigate label noise?,10.5281/zenodo.4834744,Replication,Python,https://zenodo.org/record/4834744/files/article.pdf,rescience c machine learning deep learning label noise python pytorch,https://openreview.net/forum?id=TM_SgwWJA23,https://github.com/dmizr/phuber,7,2,2021,"All the experiments described in the paper were fully re-implemented using NumPy, SciPy and PyTorch. The experiments on synthetic data were run on a CPU, while the deep learning experiments were run using a Nvidia RTX 2080 Ti GPU. Running the experimentationnecessary to gain some insight on someof the network architectures used and reproducing the real-world experiments required over 550 GPU hours.","The original paper is well written and insightful, whichmade it fairly easy to implement the partially Huberised version of standard losses based on the information given. In addition, recreating the synthetic datasets used in two of the original paper s̓ experiments was relatively straightforward.
Copyright © 2021 D. Mizrahi, O.K. Yüksel and A.M. Kyzy, released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to David Mizrahi (david.mizrahi@epfl.ch) The authors have declared that no competing interests exist. Code is available at https://github.com/dmizr/phuber. – SWH swh:1:dir:3363073199859b8bec0c4362e47aa1e786985793. Open peer review is available at https://openreview.net/forum?id=TM_SgwWJA23.
ReScience C 7.2 (#13) – Mizrahi, Yüksel and Kyzy 2021 1","Even though the authors were very detailed in their feedback, finding the exact hyperparameters used in the real-world experiments required many iterations of inquiry and experimentation. In addition, the CIFAR-10 and CIFAR-100 experiments can be difficult to reproduce due to the high number of experiment configurations, resulting in many training runs and a relatively high computational cost of over 550 GPU hours.
Communication with original authors We contacted the authors onmultiple occasions regarding some of the hyperparameters used in their experiments, to which they promptly replied with very detailed explanations.
ReScience C 7.2 (#13) – Mizrahi, Yüksel and Kyzy 2021 2
1 Introduction
Gradient clipping is a well-established technique in machine learning, usually motivated by its benefits in optimization. For example, clipping is used extensively to remedy the well-known problem of exploding gradients [1], commonly faced when training recurrent neural networks. Intuitively, it ensures that the norm of the gradient behaves well under iterates of optimization. Indeed, Zhang et al. [2] provide a theoretical explanation of the improved convergence speed of gradient clipping over standard gradient descent. In this work, however, we reproduce the paper ”Can gradient clipping mitigate label noise?” (referenced as ”the paper” or ”the original paper”) byMenon et al. [3] (referenced as ”the authors”) which focuses on robustness properties of gradient clipping. Informally, clipping caps the influence of any descent direction, whichmight help in the presence of label noise. Startingwith this intuition, the authors studywhether clipping can alleviate the problem of label noise studied in Ekholm and Palmgren [4], Menon et al. [5], and Zhang and Sabuncu [6]. More specifically, they analyze the problem under symmetric label noise with the following simple linear setting: stochastic gradient descent with a linear model in a binary classification task. Before turning our attention to the paper s̓ experiments, which are themain focus of this reproducibility work, we state twomain theoretical findings in this linear setup and the resulting novel extension of the cross-entropy loss function: • Gradient clipping does not provide label noise robustness even in this simple lin-
ear setup. Specifically, clipping is linked to using a Huberised loss, which preserves classification-calibration but is not robust to symmetric label noise.
• A new clipping variant for composite losses is proposed, where only the contribution from the base loss is considered for clipping. The equivalent partially Huberised loss preserves classification-calibration and is robust to symmetric label noise.
• The resulting multi-class generalization of the partially Huberised cross-entropy loss is given in Equation 1. Suppose we have softmax probability estimates pθ(x, y), then the partiallyHuberised softmax cross-entropy loss (PHuber-CE) is defined for τ > 1 as:
ℓθ(x, y) = { −τ · pθ(x, y) + log τ + 1, if pθ(x, y) ≤ 1τ − log pθ(x, y), otherwise.
(1)
Then, the authors evaluate their partially Huberised loss in experiments on synthetic data (referenced as ”synthetic experiments”) to demonstrate its behavior under symmetric label noise. They show symmetric label noise scenarios that defeat the logistic loss and the Huberised logistic loss, but not the partially Huberised logistic loss. Moreover, they assess the effectiveness of partial Huberisation on real-world datasets subject to symmetric label noise (referenced as ”real-world experiments”). They empirically verify that partially Huberised versions of existing losses behave well in the presence of symmetric label noise, through deep-learning experiments on theMNIST, CIFAR-10 and CIFAR-100 datasets. We thoroughly reproduce the synthetic and real-world experiments in section 3 and section 4 respectively. Then, we evaluate the experimental results in section 5 and conclude with the assessment of empirical claims in section 6.
2 Background
Gradient clipping. Consider a supervised learning task with samples (x, y) ∈ (X ×Y) ∼ D, and a loss function lθ : X ×Y → R. For this setting the gradient g(θ) and the clipped gradient ḡτ (θ) are defined as follows:
ReScience C 7.2 (#13) – Mizrahi, Yüksel and Kyzy 2021 3
g(θ) = 1
N N∑ n=1 ∇lθ(xn, yn) ḡτ (θ) = { τ g(θ)∥g(θ)∥2 if ∥g(θ)∥2 ≥ τ g(θ) otherwise.
Label noise. In classification under label noise, one has samples from a noisy distribution PD̄(x, y) instead of a clean distribution PD(x, y). For example, under symmetric label noise, all instances have a constant probability of their labels being flipped uniformly to any of the other classes. The task remains to minimize risk over the clean distribution D. Some recent loss-based proposals for learning under symmetric label noise are the linear or unhinged loss [7] and the generalized cross-entropy loss [6]. Huberised losses. Huberised and partially Huberised losses, as defined in the paper, are closely related to the Huber loss [8], which is widely employed in robust regression. In the binary classification setting, for a predictor f : X → R and labels y ∈ {±1}, these losses are derived from the logistic loss ϕ(f(x) · y) = ϕ(z) = log(1 + e−z), which can also be written as ϕ(z) = φ(F (z)), with the base loss φ(u) = − logu and the link function F (z) = σ(z). The Huberised logistic loss ϕ̄τ (Equation 2) linearises the entire logistic loss beyond a certain threshold, while the partially Huberised logistic loss ϕ̃τ (Equation 3) linearises only the base loss but leaves the link function intact.
ϕ̄τ (z) = { −τ · z − log(1− τ)− τ · σ−1(τ) if z ≤ −σ−1(τ) log (1 + e−z) otherwise. (2)
ϕ̃τ (z) =
{ −τ · σ(z) + log τ + 1 if z ≤ σ−1 ( 1 τ ) log (1 + e−z) otherwise. (3)
The partially Huberised softmax cross-entropy loss (Equation 1) is obtained by applying that same partial Huberisation to the softmax cross-entropy loss, in which the link function is a softmax instead of a sigmoid. For more information on Huberised losses, we kindly refer to the original paper [3].
3 Synthetic experiments
We now study two synthetic experiments proposed by the authors to show the existence of label noise scenarios that defeatHuberised but not partiallyHuberised losses. Wewill start by discussing the 2D setting proposed in Long and Servedio [9] and then discuss the 1D outliers setting given in Ding [10]. These experiments are fully re-implemented with NumPy [11] and SciPy [12]. Experimental setups including methods and hyperparameters are fully verified according to the original paper and in necessary cases, according to the additional details obtained from the authors. Our experiments are configurable through the Hydra framework [13]. Our code re-implementing both the synthetic and real-world experiments is available at: https://github.com/dmizr/phuber
3.1 Long and Servedio dataset Long and Servedio [9] consider a set of four positive labeled points: one large margin example (1, 0), one puller example (γ, 5γ) and two penalizer examples (γ,−γ)where 0 < γ < 16 , in a binary classification task with a linear model without a bias term. The halfspace x1 > 0 correctly classifies all the samples. However, one can show that under symmetric label noise, minimizing over a wide range of convex losses with a suitable γ will result in a predictor equivalent to a random predictor. The authors build on Long and Servedio [9], and consider amixture of six isotropic Gaussians N (µi, σ2I2), with σ = 0.01 and µi ∈ {±(1, 0),±(γ, 5γ),±(γ,−γ)} ⊂ R2, with γ = 124 . Mixing weights are 1 4 for the two Gaussians centered around ±(γ,−γ) and 1 8
for the rest. An instance (x1, x2) is labeled positive if x1 ≥ 0 and negative otherwise.
ReScience C 7.2 (#13) – Mizrahi, Yüksel and Kyzy 2021 4
N = 1000 random samples are drawn from this distribution, and the label of each sample is flipped with corruption probability ρ < 0.5. Then, a linear classifier is trained using Scipy s̓ SLSQP (Sequential Least Squares Programming) optimizer for a maximum of 100 iterations with each of the following losses:
• the logistic loss • the Huberised version of the logistic loss, with τ = σ(−1) ≈ 0.26 • the partially Huberised version of the logistic loss, with τ = 1 + e−1 ≈ 1.36
After contacting the authors, we found that the above τ values were used instead of the values provided in the original paper, which were τ = 1.0 and τ = 2.0 for the Huberised and the partially Huberised loss respectively. Once trained, the classifier is evaluated on 500 clean test samples. Figure 1a and Figure 1b show our results over 500 independent runs for ρ = 0.45 and ρ = 0.2 respectively. When using ρ = 0.45, as stated in the original paper, we fail to reproduce a figure that exactly matches the authorsʼ results. However, through experimentation, we found that for a lower level of noise corruption such as ρ = 0.2, we get results that are very similar to the original paper, with the partially Huberised loss always achieving perfect classification, while the logistic and Huberised losses succumb to label noise and perform no better than chance.
3.2 Outliers dataset The 1D setting fromDing [10] is composed of 10,000 linearly separable inliers: 5000 samples from the unit variance GaussianN (1, 1)with positive label, and 5000 samples from the mirror image N (−1, 1) with negative label. In addition, 50 outliers are added: 25 samples fromN (−200, 1) with positive label, and 25 samples fromN (200, 1) with negative label. Assuming a linear model characterized by a scalar θ ∈ R, we comparatively evaluate the empirical risk with andwithout outliers. We use the same three losses as in subsection 3.1 but with τ = 0.1 and τ = 1.1 for the Huberised and partially Huberised loss respectively. 1 Figure 1c shows our results where dashed and solid curves represent the cases with and without outliers respectively. As in the original paper, the optimal solutions for the logistic and Huberised loss are changed from θ∗ = +∞ to θ∗ = 0 with the introduction of outliers, whereas the partially Huberised loss remains intact.
1In the original paper, the τ values mistakenly reported as 1.0 and 2.0, along with the values in subsection 3.1. These updated values are obtained from the authors, after informing them τ = 1.0 for Huberisation is equivalent to keeping base loss intact.
ReScience C 7.2 (#13) – Mizrahi, Yüksel and Kyzy 2021 5
4 Real-world experiments
We now consider the deep learning experiments performed on three image classificationdatasets: MNIST, CIFAR-10 andCIFAR-100. These experimentswere fully re-implemented with PyTorch [14], according to the description from the paper and implementation details obtained from the authors after contacting them. Configuration management for these experiments was done with the help of the Hydra framework [13].
4.1 MNIST
Methodology —MNIST is a dataset of handwritten digits, consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image associated with a label from 10 distinct classes. The dataset is normalized using the mean and standard deviation from the training set, and no data augmentation is applied. The training labels are then corrupted with symmetric noise at flip probability ρ ∈ {0.0, 0.2, 0.4, 0.6}. As in the original paper, the same random seed is used to corrupt the training labels across all trials. We use a LeNet-5 [15], with a few modifications in order to reproduce the authorsʼ settings as accurately as possible. Most notably, the tanh activation layers from the original LeNet are changed toReLU , and the weights are initialized according to a truncated normal distribution with standard deviation σ = 0.1. This model is trained for 20 epochs using Adam [16] with batch sizeN = 32, and weight decay of 10−3. The initial learning rate is set to 0.001, and is lowered following an exponential decay schedule with decay rate 0.1 and decay steps of 10,000. That is, the learning rate at iteration n is set to: ηn = η0 · rn/s, with η0 = 0.001, r = 0.1 and s = 104. According to the authors, these hyperparameter values were chosen to obtain a good baseline performance in a setting with no label noise. For each level of label noise corruption, the test set accuracy of 6 different loss functions is compared:
• the cross-entropy loss (CE) • the linear or unhinged loss [7] • the generalized cross-entropy loss (GCE), with α = 0.7 [6] • the cross-entropy loss, with global gradient clipping applied using a max norm threshold of τ = 0.1 • the partially Huberised version of the cross-entropy loss (PHuber-CE), with τ = 10 • the partially Huberised version of the generalized cross-entropy loss (PHuber-GCE), with α = 0.7 and τ = 10. The CE loss serves as a baseline, while the linear and GCE losses serve as representative noise-robust losses. The model and hyperparameters used are identical for all losses at all levels of label noise. For each of the real-world experiments and for each of the partially Huberised losses, the authors selected τ ∈ {2, 10} so as to maximize accuracy on a validation set, in a setting with flip probability ρ = 0.6.
Computational requirements — This LeNetmodelwas trainedwith aNvidia RTX 2080 Ti GPU. Each run took roughly 2 minutes. Fully reproducing the authorsʼ experiments required training this model 72 times, in order to do 3 trials for each combination of loss function and level of label noise. This resulted in a total training time of around 2 hours.
Results — Our results are reported in Table 1, and a comparison with the original paper s̓ results can be found in Figure 2. Our reproductionmatches the results from the original paper for both the PHuber-CE and PHuber-GCE losses, although the CE, CE with gradient clipping and linear losses perform considerably better at high levels of label noise than what was reported. As a consequence, the partially Huberised version of these losses do not outperform the base losses at high levels of label noise, contrary to the
ReScience C 7.2 (#13) – Mizrahi, Yüksel and Kyzy 2021 6
original paper s̓ results. It is of note that in our reproduction, all losses, except for the CE loss with gradient clipping, perform comparably, with a test accuracy higher than 97.5% at all levels of label noise.
4.2 CIFAR-10 and CIFAR-100
Methodology — The CIFAR-10 and CIFAR-100 datasets [17] both consist of a training set of 50,000 examples and a test set of 10,000 examples. Each example is a 32 × 32 color image, associated with a label from 10 distinct classes for CIFAR-10, and 100 distinct classes for CIFAR-100. Both datasets are normalized using per-channel mean and standard deviation, and the standard data augmentation for these datasets is applied, akin to Zagoruyko and Komodakis [18]. That is, images are zero-padded with 4 pixels on each side to obtain a 40×40 image, and then a random 32×32 crop is extracted andmirrored horizontally with 50% probability. As in the MNIST experiment, the training labels are corrupted with symmetric noise at flip probability ρ ∈ {0.0, 0.2, 0.4, 0.6}, with identical noise seed across trials. For both of these experiments, we use a ResNet-50 [19], as implemented in Liu [20]. This implementation of the ResNet-50 differs from the one described byHe et al. [19] tomake it more appropriate for classification on small images. The number of filters per layer is identical, but the first layer, originally a 7x7 convolutional layer with stride 2 and padding 3, is changed to a 3x3 convolutional layer with stride 1 and padding 1, and the max-pooling layer that follows is removed. By removing these early downsampling layers, this architecture performs better on CIFAR-10 and CIFAR-100 than the original ResNet-50 2, which was designed for classification on ImageNet [21]. We decided to use such an implementation for several reasons: First, it is used inmany popular papers performing classification on CIFAR with ResNets, such as DeVries and Taylor [22], Zhang et al. [23], Li, Socher, and Hoi [24], and Zhang et al. [25]. Second, using the original ResNet50 yielded poor results, especially on partially Huberised losses. Third, after contacting the authors about their implementation, they confirmed using a ResNet-50 with some of
ReScience C 7.2 (#13) – Mizrahi, Yüksel and Kyzy 2021 7
the early downsampling layers removed, but could not provide more details as to which layers were specifically changed or removed. For CIFAR-10, this ResNet is trained for 400 epochs using SGDwith Nesterovmomentum 0.1 [26, 27], batch size N = 64, and weight decay of 5× 10−4. 3 The initial learning rate is set to 0.1 and is divided by 10 at the 160th, 300th and 360th epoch. For CIFAR-100, this ResNet is trained for 200 epochs using SGD with Nesterov momentum 0.1, batch size N = 128, and weight decay of 5 × 10−4. 4 The initial learning rate is set to 0.1 and is divided by 5 at the 60th, 120th and 160th epoch. According to the authors, these hyperparameters were partially based on the setting from DeVries and Taylor [22], and were chosen to obtain a good performance with CE in a setting with no label noise. As in the MNIST experiment, the test set accuracy of the CE, CE with gradient clipping, linear, GCE, PHuber-CE and PHuber-GCE losses are compared. The tunable parameters for these losses are identical to the ones used in the MNIST experiment, except for PHuber-CE for CIFAR-10, where τ = 2. The model and hyperparameters used are identical for all losses at all levels of label noise. We also report an additional experiment, wherewe train amodel onCIFAR-100 using the PHuber-CE loss with τ = 50. This corresponds to linearizing the base loss at probability threshold 0.02.
Computational requirements —Weuse aNvidia RTX 2080 Ti GPU to train thesemodels. With full precision training, a run on CIFAR-10 takes approximately 11 hours, while a run on CIFAR-100 takes approximately 4 hours, due to the lower amount of epochs and higher batch size. In order to accelerate the training process, we implement mixed precision training [28], which results in a 2x speed-up with no decrease in accuracy compared to full precision training. Fully reproducing the authorsʼ experiments required training each model 72 times, resulting in a total training time of around 400 hours for the CIFAR-10 experiments, and around 150 hours for the CIFAR-100 experiments.
Results — Our results are reported in Table 2, and a comparison with the original paper s̓ results can be found in Figure 3 and Figure 4. On CIFAR-10, our reproduction achieves comparable or better results than the original paper for nearly all configurations, except for the Linear, GCE and PHuber-GCE losses which perform worse for ρ = 0.6. Surprisingly, the CE loss with gradient clipping performs considerably better than what was reported in the presence of label noise, achieving the second-highest accuracy for ρ = 0.6, behind PHuber-CE. Similar to the original paper s̓ results, PHuber-CE with τ = 2 is competitive with CE in the absence of label noise, and achieves very good results under label noise, outperforming all the other losses. Notably, in our reproduction, PHuber-CE outperforms the linear loss for ρ = 0.4, which was not the case in the original paper. OnCIFAR-100, our reproduction achieves better results than the original paper for nearly all configurations. Most notably, the accuracy of the CE, GCE and PHuber-GCE losses are noticeably better at all levels of noise corruption. As in the original paper, PHuberGCE with τ = 10 achieves the best accuracy out of all losses for ρ = 0.4 and ρ = 0.6, and performs comparably to GCE for ρ = 0.0 and ρ = 0.2. Unlike the paper s̓ results, PHuber-CE with τ = 10 performs quite poorly compared to CE, even in settings with
2In the ResNet paper, He et al. also propose ResNet architectures suited for CIFAR-10 classification, such as the ResNet-44 and ResNet-56, which have fewer filters per layer compared to the implementations from Liu [20], resulting in faster training at the cost of lower accuracy. These ResNet architectures were not used in our reproduction as the authors specifically mentioned using a ResNet-50.
3In the original paper, the weight decay is mistakenly reported as 5 × 10−3, and it was not specified that the type of momentum used was Nesterov momentum. These updated hyperparameters were obtained from the authors, after informing them of our difficulty reproducing their experiments with the values from the paper.
4See previous footnote.
ReScience C 7.2 (#13) – Mizrahi, Yüksel and Kyzy 2021 8
high levels of label noise where it should supposedly perform well. However, with our additional experiment using PHuber-CE with τ = 50, we show that there exist values of τ for which PHuber-CE performs comparably to CE in the noise-free case, and outperforms CE at high levels of label noise.
ReScience C 7.2 (#13) – Mizrahi, Yüksel and Kyzy 2021 9
5 Discussion
We now discuss whether our experimental results support the claims of the paper. For the Long and Servedio experiment, when reusing exactly the parameters described in the paper and in the authorsʼ clarifications, our results do not perfectly match those from the original paper. After experimenting with some of the parameters, we did find values that produce results nearly identical to those shown in the paper. Nonetheless, these results still support the claim the authors made for the synthetic experiments, namely, that there exist label noise scenarios for both the Long and Servedio [9] setting and the Ding [10] setting which defeat a Huberised but not a partially Huberised loss. While we made a considerable effort to ensure that our implementation matches the paper s̓ description, the difference in results could be due to some minor differences in our implementations, or to a difference in the random seeds used to sample from the mixture model and flip the labels. For the MNIST experiment, all losses, except for CE with clipping, perform comparably, achieving very high accuracy for all levels of label noise. This differs from the results of the original paper, where CE and linear losses were affected by label noise. As a result, it is difficult to support or reject any claim made regarding these losses with this experiment. For both the CIFAR-10 and CIFAR-100 experiments, our results differ even after fixing the hyperparameters which were accidentally misreported in the original paper, with our implementation yielding a noticeably higher test accuracy for the CE loss with clipping on CIFAR-10, and the CE, GCE and PHuber-GCE losses on CIFAR-100. This is likely due to the ResNet-50 architecture used, as the generally higher accuracy could be explained if our model happens to have a higher number of parameters than theirs. The deep learning framework used could also lead to different results, as the authors mentioned using TensorFlow while we used PyTorch. Finally, this could also be caused by the random seed used to add label noise, although we did not notice any significant difference in results when changing this seed. For theCIFAR-10 experiment, our reproduction supports the claim that for these specific hyperparameters, partially Huberised losses are competitive with the base loss in the noise-free case and can outperform it under label noise. In addition, this experiment also shows that PHuber-CE can be very effective at mitigating symmetric label noise, as it performs considerably better than the representative noise-robust losses at high levels of label noise. For the CIFAR-100 experiment, our reproduction shows that PHuber-GCE loss with τ = 10 is competitive with the base loss (GCE) in the noise-free case and can outperform it at high levels of label noise, which supports the aforementioned claim. However, this claim does not hold for the PHuber-CE loss with τ = 10, which performs worse than CE in all cases. Despite that, we show with our additional experiment that there exists a value of τ for which the PHuber-CE loss performs comparably to CE in the noise-free case, and improves upon it under label noise. Our additional experiment shows that the value of τ plays a crucial role in the performance of partially Huberised losses. Both the PHuber-CE and GCE losses interpolate between the linear and the CE loss. PHuber-CE and GCEmimic the linear loss for τ → 1 and α = 1 respectively, while for τ → +∞ and α → 0, they mimic the CE loss. As the linear loss fails to train properly in our CIFAR-100 experiment, it is expected to obtain poor results for these losses if the tunable parameter usedmakes them too similar to the linear loss. As PHuber-GCE combines both of these losses, it can also perform poorly in such a scenario. Furthermore, the CE loss with gradient clipping also has a tunable parameter which strongly affects performance, as our reproduction shows that for a max norm τ = 0.1, CE with clipping can perform significantly better than CE on CIFAR-10, and significantly worse on CIFAR-100. In order to properly compare these losses, it would therefore be of interest to find, for
ReScience C 7.2 (#13) – Mizrahi, Yüksel and Kyzy 2021 10
each level of label noise, the tunable parameter values for which they perform best, by using random search or a hyperparameter tuning framework such as Optuna [29] on a validation set. While such a hyper-parameter search has a high computational cost, it would offer some valuable insights on how well each of these losses performs, and how sensitive they are to changes to their tunable parameters. We leave such exploration for future work.
6 Conclusion
In this work, we fully re-implement the experiments performed in Menon et al. [3]. For the synthetic experiments, our results differ when using the exact values described in the paper, although they still support themain claim, and by slightlymodifying some experiment settings, we obtain results almost identical to those of the original paper. Our results also differ for the deep learning experiments, with some of the baselines performing better than described. Nonetheless, these experiments still support the claim that partiallyHuberised losses performwell on real-world datasets subject to label noise. Our additional experiment also provides further insight on the performance of partially Huberised losses, as it empirically shows that the value of τ can play an important role in the performance of models trained with these losses. We thus believe it would be of interest to perform further experiments focused on tuning these losses for different levels of label noise, although this would incur a relatively high computational cost."
"['Klim Kireev', 'Amirkeivan Mohtashami', 'Ehsan Pajouheshgar']",[Re] Warm-Starting Neural Network Training,10.5281/zenodo.4834856,Replication,python,https://zenodo.org/record/4834856/files/article.pdf,warm-starting generalization deep learning,https://openreview.net/forum?id=N43DVxrjCw,https://github.com/CS-433/cs-433-project-2-fesenjoon,7,2,2021,"We reproduce the results of the paper ”On Warm-Starting Neural Network Training.” In many real-world applications, the training data is not readily available and is accumulated over time. As training models from scratch is a time-consuming task, it is preferred to use warm-starting, i.e., using the already existing models as the starting point to obtain faster convergence. This paper investigates the effect of warm-starting on the final model s̓ performance. It identifies a noticeable gap between warm-started and randomly-initialized models, hereafter referenced as the warm-starting gap. Furthermore, they provide a solution to mitigate this side-effect. In addition to reproducing the original paper s̓ results, we propose an alternative solution and assess its effectiveness.","The experiments described in the paper were based on regular training of neural networks on a portion of widely-used datasets, possibly from a pre-trained model. Therefore implementing each experiment was relatively easy to do. Furthermore, since many of the parameters were reported in the original paper, we did not need much tuning
Copyright © 2021 K. Kireev, A. Mohtashami and E. Pajouheshgar, released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Amirkeivan Mohtashami (amirkeivan.mohtashami@epfl.ch) The authors have declared that no competing interests exist. Code is available at https://github.com/CS-433/cs-433-project-2-fesenjoon. – SWH swh:1:dir:a7205bcd48196c1391d8c56414a1e20c39b52aa7. Open peer review is available at https://openreview.net/forum?id=N43DVxrjCw.
ReScience C 7.2 (#14) – Kireev, Mohtashami and Pajouheshgar 2021 1
in most experiments. Finally, it is straightforward to implement and use the proposed solution.","Though implementing each experiment is relatively simple, the numerosity of experiments proved to be slightly challenging. In particular, each of the online experiments in the original setting requires training a deep network to convergence more than 30 times. In these cases, we sometimes changed the settings, sacrificing granularity to reduce computation time. However, these changes did not affect the interpretability of the final results.
Communication with original authors We briefly communicated with the authors to clarify the experimentsʼ details, such as the convergence conditions.
1 Introduction
Training large models from scratch is usually time and energy-consuming, so it is desired to have a method to accelerate retraining neural networks with new data added to the training set. The well-known solution to this problem is warm-starting. WarmStarting is the process of using the weights of a model, pre-trained on a subset of the data, as the starting point of training with the complete data. The paper investigates the effect of warm-starting on the final model s̓ accuracy and identifies a generalization gaponwarm-startedmodels. Thepaper also provides amethod to mitigate this gap by shrinking the pre-trained weights and adding a random perturbation. In this report, we repeat the original paper s̓ experiments and compare them with the reported results. Also, we extend the original paper results by investigating the effect of data augmentation on this phenomenon. In particular, we establish that using data augmentation might be a second solution to mitigating the generalization gap. We report and discuss our results in Section 2. In section 3, we detail our experimental settings and hyperparameters.
2 Results & Discussion
2.1 Warm-Starting Generalization Gap Similar to the paper, we start by demonstrating the existence of a generalization gap when using warm-starting before training. We use the same set of experiments used by the authors. Unless otherwise stated, we follow the settings described in the paper for our experiments. In particular, in the offline setting, we first train our model on half of the training data and then further train the pre-trained model on the whole dataset. We compare the resulting model with a model trained from randomly initialized weights. Figure 1 depicts the test accuracy of ResNet-18 [1] during training in this setting andmatches Figure 1 of the paper. We repeat this experiment with different datasets, models, and optimizers. In particular we perform experiments on CIFAR-10 [2], CIFAR-100 [2], and SVHN [3]. As our model, we experiment with ResNet-18, a three-layer perceptron, and logistic regression. The same models and datasets were used in the original paper. For the optimizers, we compare SGD [4] and Adam [5]. In this particular experiment, we compare SGD with and
ReScience C 7.2 (#14) – Kireev, Mohtashami and Pajouheshgar 2021 2
without momentum. In the rest of this work, unless explicitly stated, SGD is used without momentum. The final accuracies are reported in Table 1 similar to Table 1 of the original paper. Our results are similar to the paper s̓ results for CIFAR-10 and CIFAR100 datasets. In particular, we observe a generalization gap when using a warm-started model instead of training from scratch. However, we did not observe the same gap on the SVHN dataset. Furthermore, we were unable to obtain a reasonable accuracy with the MLP model using SGD without momentum with the reported setting on SVHN. We instead report the result of using 0.005 learning rate. We did not perform hyperparameter tuning for the other experiments.
In the online setting, we follow the original paper and train our model in several steps, increasing the amount of data available at each step. This setting is a more accurate simulation of the real-world problems where the training data grows over time. We split the training data into batches of 1000 samples and start adding them, one by one, to the pool of available data. We follow two different scenarios. In one scenario, we reinitialize ourmodel randomly after each batch is added and train it from scratch. In the other scenario, we continue training themodel with the parameters learned in the previous step. After each batch is added, we continue training our model until convergence before adding the next batch. We assume convergence when the model reaches 99% training accuracy. By communicating with the origi-
nal paper s̓ authors, we confirmed that this is the same condition used in the original paper. As in the paper, we optimize the model using Adam optimizer with a learning rate of 0.001 on CIFAR-10. Given the discrepancy of our results on the SVHN datasets in the offline settings, we additionally perform the same experiment on this dataset. For the CIFAR-10 dataset, the generalization gap between random-initialization training and warm-start training is clearly observed (Figure 2a). However, like the offline experiment, we did not observe the gap for the SVHN dataset (Figure 2b). Still, we were able to reproduce the gap by increasing the convergence accuracy threshold to 99.9% (Figure 2c). Note that 99% train accuracy is more challenging to achieve on the CIFAR-10 dataset than on SVHN and therefore requires more training, possibly leading to more over-fitting. Increasing the convergence threshold compensates for this difference. This result and the fact that the authors show that the proposed Shrink-Perturb method is similar to an aggressive regularization brings up the question of whether this gap might be a side-effect of over-fitting when training on partial data. There are various known techniques to prevent overfitting. The original paper investigates the effect of some of these techniques, namely regularization, and early-stopping. We reproduced these experiments and explained the results below. Early-Stopping: To investigate the effect of early-stopping, following the original paper, we trained a ResNet-18 model on half of the CIFAR-10 data and checkpointed its parameters every 20 epochs. The result is plotted in Figure 3, which matches Figure 4 of the original paper and shows the warm-starting gap can be observed even after 20 epochs of training. To decrease computational costs, we used lower granularity than the original paper to perform this experiment, saving parameters every 20 epochs rather than 5 epochs. Also, we only perform each experiment once.
ReScience C 7.2 (#14) – Kireev, Mohtashami and Pajouheshgar 2021 3
Regularization: Regularization is commonly used to improve generalization. The original paper explores the effect of various types of regularization. Due to time and resource limitations, we only look into weight decay, which is widely used and is a de-facto standard for training the state-of-the-art models. We repeat the offline setting experiment on CIFAR-10 with a weight decay of 0.1 on both the pre-training and main training. However, contrary to the original paper s̓ results, we observe that the warm-starting gap decreases when applyingweight decay. We also test with weight decay values of 0.01 and 0.001. We find out that higher values of weight decay result in lower warm-starting gap. The results are reported in Table 2, which corresponds to Appendix Table 13 of the original paper. Data Augmentation: Data augmentation is widely used to obtain state-of-the-art performance and is known to help generalization [6], but it is not used in the other experiments of this paper. It is specifically important to check the effect of data augmentation since it is widely used in practice. Therefore we extend the original paper s̓ experiments by investigating the impact of data augmentation. We report our results in Section 2.4.
2.2 Effect of Hyperparametes Our results show that in some cases, a generalization gap exists when pre-training our model on a portion of the final dataset. However, when training in the online setting on SVHN, we could only observe this gap with a high enough convergence threshold. The paper investigates the effect of other training hy-
perparameters, namely learning rate and batch size. To investigate the effect of learning rate and batch size, we train a ResNet-18 with different values for thesehyperparameters. Wechoose the learning rate from {0.1, 0.01, 0.001} and the batch size from {128, 64, 32, 16}. We iterate over all pairs for these values. For each pair, we train over the full CIFAR-10. We also train a different model over 50% of the CIFAR-10 dataset and use it to warm-start a model and train it on the whole dataset. We use a different learning rate and batch size, randomly chosen from the sets of values, in the second part of the training, i.e., for training the warm-started model. We repeat each experiment 9 times. Each model is trained to 99% training accuracy. The test accuracy is plotted against training time in Figure 4, which corresponds with Figure 3 of the paper. Note that the training time for the warm-started model corresponds to the time of the second part of the training. In other words, the time of training on half of the dataset is not included. This is justified because the goal is to assess if warmstarting leads to comparable accuracy while saving training time when a new batch of data arrives. In our results, choosing the right hyperparameters can lead to achieving comparable or even better accuracy, when using warm-starting, faster than training a randomly initialized model. This does not match the results of the paper, where the
ReScience C 7.2 (#14) – Kireev, Mohtashami and Pajouheshgar 2021 4
warm-started models with comparable accuracy take the same amount of training time as the randomly initialized models. While we perform less experiments in the warmstarted setting, we perform the same number of experiments with random initialization as described in the original paper s̓ text. However, the number of points in Figure 3 of the original paper corresponding to randomly initializedmodels, is more than what has been described in the text. We note that performing more randomly initialized experiments might be the reason for the mismatch in our results with the original paper.
2.3 Shrink & Perturb Solution In addition to establishing the warm-starting gaps̓ existence and investigating its roots, the paper also provides a method to mitigate this issue. In this method, the training starts from a shrunk and perturbed version of the pre-trained weights, so we reference it as the Shrink-Perturb method. More specifically, for a given λ and σ, the new weight is computed as
wnew = λwpretrained + σwrandom (1)
where wold is the pre-trained weight and wrandom is the corresponding weight from a randomly initializedmodel. Whenever we apply the Shrink-Perturb transformation, we create a new randomly initialized model and use its weights as wrandom. We tested the effectiveness of this method in both offline and online settings. In the offline setting, we applied the Shrink-Perturb transform after pre-training on 50% of CIFAR-10. We used σ = 10−4 and repeated this experiment with different values of λ. We plotted the test accuracy during training on all of the data in Figure 5. It can be seen that the method is effective and leads to even better performance than the randomly initialized model. In the online setting, we applied the Shrink-Perturb transform every time a new batch
ReScience C 7.2 (#14) – Kireev, Mohtashami and Pajouheshgar 2021 5
of data is added. To reduce computation cost, we add data in batches of 2500 samples. The result for σ = 10−4 and different values of λ is plotted in Figure 6. Figure 6 matches Figure 7 of the original paper. The result of applying the Shrink-Perturb method in the offline setting is not reported in the original paper.
To assess the impact of shrinking weights on the model s̓ performance, we fit different models to CIFAR-10. Then, we shrink the weight with different values of λ and evaluate the accuracy. Similar to the paper, we train ResNet18 and an MLP with ReLU activation with and without bias. In addition, we also train an MLP with Tanh activation with and without bias. The result is shown in Figure 7, which corresponds with Figure 6 of the paper. The only difference in our findings with the original paper s̓ is that we observe classifier performance damage for MLP with ReLU for λ > 0.6. Though for λ > 0.8 the damage is negligible. Also, note that shrinking the weights of anMLP without bias and ReLU activation only scales the final output, which does not affect the output labels. Therefore its immunity to shrinkage is expected. The
more interesting result is that even for ResNet-18 or MLP with Tanh activation, the test accuracy is not significantly damaged for λ values greater than 0.2. In order to explain why the Shrink-Perturb method is effective, the original paper compares the average gradients over the first and second half of the dataset during the train-
ReScience C 7.2 (#14) – Kireev, Mohtashami and Pajouheshgar 2021 6
ing of the warm-started model in the offline setting. In particular, a ResNet-18 is first trained on half of CIFAR-10. Warm-starting from the pre-trained model, the model is trained on the full dataset while measuring the average gradient over the first and second half of the dataset simultaneously. It is observed that the gradient for the first half, which the model was pre-trained on, is substantially lower than for the second part. However, applying the Shrink-Perturb transformation eliminates this difference. We reproduced this experiment with some slight modifications. In particular, instead of averaging the gradient over part of the dataset after each batch, we did it at the beginning of each epoch. We plotted these values in Figure 8. Our result matches Figure 5 of the original paper. In particular, we confirm that the Shrink-Perturb method successfully eliminates the gap between the gradients.
2.4 Effect of Data Augmentation Data augmentation is widely used in practice. However, it is not used for the experiments in the original paper. Therefore, we decided to assess its impact on the generalization gap for warm starting training. We perform our experiments on ResNet-18 and CIFAR-10. To augment the data, we first pad the image with 4 pixels on each side and then randomly crop it back to 32x32. We then perform a random horizontal flip with probability 0.5. We also apply color jitter with brightness, contrast, and saturation factor equal to 0.25. Finally, we also apply small random rotations. All experiments were done with SGD and a learning rate equal to 0.001 in order to make the setup consistent with previous warm start experiments. The results are reported on Figure 9 . It can be seen that applying the augmentationmitigates thewarm-starting gap. We allow themodels to train for 350 epochs. However, because the learning rate is low, themodels are not fully converged even after 350 epochs. We did not continue the training because of resource limitations. However, it is visible thatwarm-startingwith data augmentation can achieve good performance faster than training from scratch. To explain the effectiveness of the Shrink-Perturb solution, the original paper s̓ authors looked at the differences of the gradient norm for the first and the second part of the dataset, which is heavily reduced after applying Shrink-Perturb (as shown in Figure 8). Following the same direction, we checked if applying data augmentation can affect the difference as well. It can be seen in Figure 10 that, similar to the shrink perturbmethod, the gradient norm difference is also mitigated when using data augmentation. It is clear that applying data augmentation prevented overfitting. The original warm start setup has a large divergence between train and test accuracy from the beginning of the training. On the contrary, the model trained with data augmentation has close performance on train and test datasets. We leave the investigation of other overfitting prevention techniquesʼ effects as future work. Additionally, we note that data augmentation usually slows down the convergence and it cannot be applied to every task since for some types of data transform set cannot be
ReScience C 7.2 (#14) – Kireev, Mohtashami and Pajouheshgar 2021 7
defined. Due to the limits of this report, we also leave the careful comparison between data augmentations and Shrink & Perturb as future research in this area.
2.5 Warm-Starting Gap in Transfer Learning Deep learning models require large training sets to perform well. This presents a problem in many practical cases where only limited data is available, and acquiring additional data is expensive. This has encouraged the use of transfer learning [7, 8, 9]; the practice of warm-starting from a model trained on a different dataset. To investigatewhether a similar gap is observed in transfer learning, we trained aResNet18 model on one dataset and used the pre-trained weights to warm-start training on a different dataset. We performed this experiment for all pairs of CIFAR-100, CIFAR-10, and SVHN datasets. To also investigate the effect of the amount of the data available, we also considered subsets of these datasets where only a fraction p of data is available. More accurately, for every two datasets and p ∈ {0.1, 0.3, 0.6, 1.0}, we chose a random subset from each dataset containing p × n data points, where n is the total number of data points in that dataset. We performed the described transfer learning experiment for these subsets and recorded the final test accuracy. To assess the effect of warmstarting and the Shrink-Perturb method, we plotted the final test accuracy of each of the described three settings (random initialization, warm starting, and warm-starting with Shrink-Perturb) with respect to p in Figure 11. In this experiment, we used Adam as our optimizer. This figure corresponds with Figure 9 of the original paper. At each part of the training, we train our models for 200 epochs. When training CIFAR100 starting from weights of a model trained on SVHN or CIFAR-10, the last layer is initialized randomly because of the mismatch in the number of classes. It can be seen that, as mentioned in the paper, the warm-starting gap exists in the transfer learning settings as well, and that it is worsened when the amount of data available is increased. Furthermore, the Shrink-Perturb method proves useful in this setting, as well.
3 Methodology
In this section, we define the setting we used for our experiments. There was no available code for the original paper, and we implemented everything from scratch. We use the PyTorch framework for the implementations.
ReScience C 7.2 (#14) – Kireev, Mohtashami and Pajouheshgar 2021 8
3.1 Model descriptions Most of the experiments are performed using ResNet-18 [1]. Some experiments are also performed on a Multi-Layered Perceptron (MLP) and Logistic Regression. We detailed the structure of each of these models below.
• ResNet-18: We used an implementation of ResNet-18 tuned for CIFAR-10 dataset. We used the code from https://github.com/huyvnphan/PyTorch_CIFAR-10. In all experiments, batch normalization [10] was enabled.
• MLP: The MLP has three hidden layers, each of which has 100 neurons. Either ReLU or Tanh was used as the activation function. Unless explicitly stated, the bias term is added.
• Logistic Regression: We implement Logistic Regression as a Multi-Layered Perceptron with no hidden layers.
We used either Adam or SGD optimizers for training the models. More accurately, we use Adam in Table 1, Figure 2, Figure 6, and Figure 11. In all other experiments, we use SGD. We use 0.001 learning rate and batches of size 128. Unless otherwise stated, we used SGD without momentum and without weight decay. In cases where momentum wasused (such as in Table 1), the value ofmomentumwas set to 0.9. TheAdamoptimizer was usedwith default parameters fromPyTorchs̓ implementation, namely β1 = 0.9, and β2 = 0.999.
3.2 Datasets Same as the original paper, we perform experiments on CIFAR-10, CIFAR-100, and SVHN datasets. We normalize each of the RGB channels by the mean and standard deviation of that channel in the CIFAR-10 dataset. Except for the data augmentation experiments, we do not apply any data augmentation.
3.3 Hyperparameters We used hyperparameters stated in the original paper in most of our experiments. In cases where we deviated from the reported values, mostly due to computational resource and time limitation, we have reported them in the text where we described the experiment. In case a hyperparameter is not reported in the original paper, we either communicated with the authors to ask the hyperparameters, pick a value making reasonable assumptions, or try out different values and report the result for all of them. In all these cases, we clarified the parameter we used in the text.
ReScience C 7.2 (#14) – Kireev, Mohtashami and Pajouheshgar 2021 9
3.4 Experimental setup We ran our experiments on both public cloud infrastructure, such as Google Colab and private GPUs that were available to us. Therefore the infrastructure varies between different experiments. Our implementations for all the experiments in this work is available in the SupplementaryMaterial and also in https://github.com/CS-433/cs-433-project-2-fesenjoon.
4 Communication with Authors
In the original paper [11], it was not clear what convergence condition was used to stop the training. Therefore, We communicated with the authors via email and asked them to explain the convergence condition used in the experiments more clearly. They stated that convergence happens when the training accuracy reaches 99%. However, for reproducing the Table 1 which also uses simpler models like Logistic Regression and MLP, it is not possible to reach 99% accuracy. They clarified that in this scenario, the convergence condition is met when the training accuracy stops improving.
5 Conclusion
We have verified the existence of the generalization gap in certain training settings. Additionally, we have confirmed that the introduced Shrink-Perturb method can be effective in removing this gap. We did this by repeating experiments of the original paper and performing some experiments of our own. However, we also encountered cases where wewere not able to reproduce the warm-starting gap or where the Shrink-Perturb method was not very successful. In addition, we reproduced several experiments to investigate the effect of hyper-parameters, such as learning rate, on this phenomenon. Finally, we have shown that applying data augmentation can also help to remove this gap. To allow others to reproduce our results, we have detailed our experiments and have released our code."
"['Jishnu Jaykumar P', 'Ashish Sardana']",[Re] Improving Multi-hop Question Answering over Knowledge Graphs using Knowledge Base Embeddings,10.5281/zenodo.4834942,Replication,Python,https://zenodo.org/record/4834942/files/article.pdf,knowledge graph embeddings multi-hop question-answering deep learning,https://openreview.net/forum?id=VFAwCMdWY7,https://github.com/jishnujayakumar/MLRC2020-EmbedKGQA,7,2,2021,"We have used the code provided by [1] with some customization for reproducibility. In addition to making the codebase more modular and easy to navigate, we have made changes to incorporate different transformers in the question embeddingmodule. QuestionAnswering models were trained from scratch as no pre-trained models were available for our particular dataset. The code for this work is available on GitHub (See page footer for the link).",,
"['Damiaan J. W. Reijnaers', 'Daniël B. van de Pavert', 'Giguru Scheuer', 'Liang Huang']",[Re] Explaining Groups of Points in Low-Dimensional Representations,10.5281/zenodo.4835056,Replication,Python,https://zenodo.org/record/4835056/files/article.pdf,rescience c rescience x python counterfactual explanations transitive global translations dimensionality reduction explainable artificial intelligence,https://openreview.net/forum?id=hq3TxQK5cox,https://github.com/damiaanr/fact-ai,7,2,2021,"We have upgraded the original code provided by the authors such that it is compatible with recent versions of popular deep learning frameworks, namely the TensorFlow 2.xandPyTorch 1.7.x-libraries. Furthermore, we have created our own implementation of the algorithm in which we have incorporated additional experiments in order to evaluate the algorithms̓ relevance in the scope of different dimensionality reduction techniques and differently structured data. We have performed the same experiments as described in the original paper using both the upgraded version of the code and our own implementation taking the authorsʼ code and paper as references.","The authors have provided an implementation1 that cleanly separates different experiments on different datasets and the core functional methodology. Given a working environment, it is easy to reproduce the experiments performed in [1].
Copyright © 2021 D.J.W. Reijnaers et al., released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Damiaan J. W. Reijnaers (info@damiaanreijnaers.nl) The authors have declared that no competing interests exist. Code is available at https://github.com/damiaanr/fact-ai – DOI 10.5281/zenodo.4686025. – SWH swh:1:dir:df71f3541f882bfb2474dc177b8eaba31f905d9d. Open peer review is available at https://openreview.net/forum?id=hq3TxQK5cox.
ReScience C 7.2 (#16) – Reijnaers et al. 2021 1","Minor difficulties were experienced in setting up the required environment for running the code provided by Plumb et al. locally (i.e. trivial changes in the code such as the usage of absolute paths and obtaining external dependencies). Evidently, it was timeconsuming to rewrite all corresponding code, including the architecture for the variational auto-encoder provided by an external package, scvis 0.1.02.
Communication with original authors No communication with the original authors was required to reproduce their work.
1 Introduction
As AI models are getting more integrated into applications with economic or social implications, the need for explaining decisions made by (potentially complex) models is increasing. In many AI applications, big datasets form the basis of a decision-making algorithm [2]. As these datasets often involve data of high dimensionality, the dimensionality of data is, in many different applications, often reduced using dimensionality reduction (DR) techniques [3].
Data, and consequently the decisions made by an algorithm that are (in)directly based on that data, often involve some sort of ʻgrouping,̓ either by utilizing a clustering method or by (manually) pre-defined ʻclusters of data.̓ The ʻgrouping processʼ may happen before the dimensionality reduction, forwhich, assumingwell-organized data inwhich the dimensions correspond to explainable ʻreal-lifeʼ features of the phenomena measured in the data, the distinguishing characteristics of a certain group becomes relatively explainable as these groups aremarked by boundaries in terms of explainable dimensions. However, this process can also happen after the dimensionality of the data has been reduced, which results in the groups being defined in terms of dimensions in a latent space. Especially when grouping occurs after dimensionality reduction, different clusters in data often play a key role in the decision-making process of an algorithm – one could, for example, when regarding credit riskmodelling, point out a group in latent spacewhich ʻposes a high riskʼ when provided a loan [4]. Moreover, such groupings arise naturally under the context of (variational) auto-encoders, which are the architecture of preference for many deep learning applications [1, p. 8].
Thus, considering the above-mentioned need for explainable machine decisions, in combinationwith the increasing use of DR algorithms and the reliance on observed data clusters in abstract latent spaces which are not understandable to the humanmind, it is of great relevance and importance to develop methods to explain differences between groups in the light of the application of a certain dimensionality reduction technique.
Elaborating upon the earlier introduced example of credit risk, one could argue that a reasonable explanation for a machine decision is of the kind: “Your loan was rejected, but if you would have earned e422,86 more per month, your loan would have been accepted.” This type of explanation is a counterfactual explanation – a decision on the basis of a ʻfake,̓ counterfactual, ʻworld,̓ in which featureswould have been shaped differently. The proposed explanatory technique in [1] does exactly this: it reverse-engineers obtained cluster labels in latent space to label corresponding data in original space; then ʻtweaksʼ
1GitHub, Explaining Low Dimensional Representations, https://github.com/GDPlumb/ELDR, accessed on January 29th, 2021
2GitHub, shahcompbio/scvis: Python package for dimension reduction of high-dimensional biological data, https: //github.com/shahcompbio/scvis, accessed on January 22nd, 2021
ReScience C 7.2 (#16) – Reijnaers et al. 2021 2
an initial cluster by translating that cluster in original space, so that it is mapped to (approximately) the area of the target cluster in latent space. Since the dimensions in original space correspond to explainable features—the groupsʼ characteristics—which are comprehensible for a humanmind; a translation that corresponds to merely adding or subtracting values to each of these features can be perfectly explained in ʻhuman language.̓ Since it is desirable for the explanations to be concise, the translation should be as sparse as possible: the translation should ʻtweakʼ as few dimensions as possible. The intuition behind this idea is visualized in figure 1.
2 Scope of reproducibility
As follows from the introduction, the authors of [1] opted for a counterfactual, sparse explanation for key differences between (naturally arising) groups. Plumb et al. propose an algorithm that generalizes this idea and attempts to find global differences between all groups, constructed through a composition of simpler explanations and introduced as Transitive Global Translations (TGT). The main tested contributions are that “TGTs provide a global and counterfactual explanation between all groups which is mathematically consistent (i.e. symmetrical and transitive)” and that “TGTs overcome the shortcomings of statistical andmanual interpretation which do not use themodel that learned the low dimensional representation that was used to define the groups in the first place.”
In addition to replicating these claims using the provided code, we further evaluated these statements by testing compatibility with other DR methods than the originally used variational auto-encoder and tested the applicability of the algorithm on different datasets with different internal structures. All the latter mentioned experiments were performed by rewriting and implementing the algorithm in PyTorch (taking the authorsʼ code andpaper as references), whereas the original code iswritten inTensorFlow, motivated by the development of PyTorch in becoming the preferred framework by researchers [5] and the assertion that it offers clearer coding structure3. For the sake of ensuring future reproducibility of the experiments originally presented in [1], as an addition, we have also provided an upgraded version of the original code, without further modifications, to make it compatible with recent versions of TensorFlow.
3Kirill Dubovikov, PyTorch vs TensorFlow – spotting the difference, https://towardsdatascience.com/ pytorch-vs-tensorflow-spotting-the-difference-25c75777377b, accessed on January 25th, 2021
ReScience C 7.2 (#16) – Reijnaers et al. 2021 3
3 Methodology
In accordancewith section 2, for the purpose of reproducing [1], several stepswere taken in order to best cover the scope of the original paper with limited resources. Firstly, the provided artifactswere ʻmodernized.̓ Concretely – the code provided by Plumb et al. and the external library scviswere upgraded to be compatible with TensorFlow 2.4.14 and matplotlib 3.3.35. Secondly, the provided code was rewritten from scratch – both the code complementing the original paper; and the scvis library, to make the computation of the explanations independent from the DR algorithms. Thirdly, we have run our implementation on different DR algorithms—both linear and non-linear (see section 3.1)—and on different datasets (see section 3.3). Both the reproduced version (using the original code) and the rewritten version are further explained in section 3.2. All relevant code complementing [1]—the chunks which we have chosen to rewrite—are explicitly stated in the paper, making the method by Plumb et al. reproducible, even if the code would not have been provided by the authors.
3.1 Dimensionality reduction algorithms Throughout [1], DR algorithms are only mentioned in the general sense. Only in section 4 the algorithm which Plumb et al. use for their experiments is introduced: a variational auto-encoder (VAE), which is a non-linear family of dimensionality reduction algorithms based on (deep) symmetrical neural networks with a bottleneck in themiddle layers which form the latent representation of the input data. The implemented VAE is based on the architecture proposed by [6].
The presented explanatory method should work for any DR algorithm while effectively treating the algorithm as a ʻblack box.̓ Apart from testing this hypothesis, it is relevant to compare ʻexplanatory performanceʼ on different DR algorithms as different algorithms suit different types of data. Furthermore, an explanation based solely on translations could possibly perform worse in situations wherein data is transformed in a non-linear manner, especially when methods inherently non-linearly transform (and warp) the input space. Therefore, as an addition to simply reproducing the implementation, experiments were done with several commonly known DR algorithms listed below.
Linear methods —We have opted for two different linear DR algorithms: truncated SVD (TSVD) and sparse PCA (SPCA) [7]. Both TSVD and SPCA reduce the dimensionality in a linear fashion. However, a key difference between both algorithms is that SPCA centers the data before computing the decomposition, where TSVD does not. As a result, TSVD handles sparse data more efficiently. The objective of SPCA is to find the sparse components that best reconstruct the data. While standard PCA, in most cases, extracts components using dense expressions, these are often hard to interpret. However, the sparse vectors extracted by sparse PCA naturally match the latent components, which increases explainability.
Non-linear methods — The implemented VAE is based on a Gaussian distribution, which results in a probabilistic generative model that preserves both local and global neighbor structures in the data [6]. As the VAE is solely used for encoding a constant latent space, themodel is trained on the entire dataset. We further incorporate the use of three additional non-linear methods: kernel PCA (KPCA), locally linear embedding (LLE) [8] and isomaps. The latter twomentioned techniques are examples ofmanifold learning [9].
4TensorFlow, Automatically upgrade code to TensorFlow 2, https://www.tensorflow.org/guide/upgrade, accessed on January 22nd, 2021
5Matplotlib, API Changes, https://matplotlib.org/3.3.3/api/api_changes.html, accessed on January 22nd, 2021
ReScience C 7.2 (#16) – Reijnaers et al. 2021 4
To achieve a non-linear tranformation, KPCA [10] extends standard PCA through the use of kernels. These kernels effectively mimic a complex function that projects the input data on a higher dimensional space in which, consequently, a lower-dimensional subspace is found in which the data is represented, resulting in a more efficient lowdimensional latent representation. The advantage is that KPCA is able to identify clusterswhich are not linear separable. For our experiments, we found that a sigmoid kernel provided the best performance (measured by the metrics proposed in section 3.2) when the latent space resulting from the KPCA was used to find TGTs.
Finally, manifold learning techniques are implemented to analyse whether TGTs can still perform on a higher-dimensional embedding of a low-dimensional manifold, especially for datasets of which its data might not lay on an underlying low-dimensional manifold. Isomaps can be seen as an extension of KPCA. Isomaps present a lowerdimensional space while maintaining distances between all points, while LLE aims to map to a lower-dimensional space while maintaining the distance in local neighborhoods. While Isomap could be seen as an extension of KPCA, LLE can be understood as a combination of PCAs run on local neighborhoods.
As shown in section 4.1, different latent spaces (resulting from applying different processes for the purpose of reducing dimensions) seem to perform better in terms of explainability, which is further discussed in section 5.
3.2 Model descriptions The original paper aimed to find an explanation for the key differences between a pair of groups in latent space where the explanation is expressed in terms of the original dimensions. This explanation is represented by a counterfactual translation of one of the groups (in the pair) in original space: “what if all points in group A, thus ∀x ∈ A, x ∈ Rd, would have been translated, so that ∀x ∈ A, δ ∈ Rd, x′ = x + δ? Would group A have been roughly the same as group B after the groups have beenmapped to latent space, so that ∀x ∈ A,∀y ∈ B, x ∈ Rd, y ∈ Rm, r : Rd → Rm, r(x′) ≈ r(y)?”.
As both the original space (Rd) and latent space (Rm) are Euclidean spaces, translations between any pair of groups within a larger number of groups (> 2) can be constructed by composing two translations (a vector addition in this context) or negating a translation (in this context equivalent to vector-scalarmultiplicationwith λ = −1). Using these operations and a reference group, explanations (δ) can be obtained for every possible pair of groups. The intuition behind this idea is illustrated in figure 2. Points in figure 2 do not directly correspond to the groups for which we want to find differences, since these locations will be approximated using sparse translations (see figure 1). Moreover, this linearity enables the possibility to measure the difference between the points in the two groups in latent space using the l2-norm of the squared differences. At the same time, it is also possible tomeasure the sparsity of δ using l1-regularization, which directly relates to the comprehensibility of the explanation posed by δ.
In order to obtain adequate components for the δ-vector between a group and the reference group, all δ-vectors can be initialized to zero and optimized by adjusting the components of δ corresponding to two randomly chosen groups in the negative direction of the gradient of a loss function which accounts for the above-mentioned constraints. This loss function is formulated in equation 9 of the original paper. While Plumb et al. decide to incorporate the calculation of the gradient as an ʻextensionʼ of the scvis package, whichwe have reproduced using the provided code, we have decided to analytically compute the gradient using SciPy 1.6.0 (using the optimize.approx_fprimemethod). This implementation choice is in line with our aim to rewrite all code from scratch to obtain a ʻstand-aloneʼ division between the explanatory algorithm (which is
ReScience C 7.2 (#16) – Reijnaers et al. 2021 5
the main idea of the original paper) and various ʻblack-boxʼ dimensionality reduction algorithms, including the variational auto-encoder (the only algorithm Plumb et al. experiment with), as introduced in the beginning of this section.
The model s̓ performance is measured by two separate, but related (see section 4.1), metrics defined by [1, p. 3]: correctness, whichmeasures the degree to which projected points are actually in the vicinity of points they should map to (which they, in a sense, should ʻimitateʼ) and coverage, which measures the degree to which projected points cover the target group. Both are defined in equation 3–4.
3.3 Datasets In the upgraded-code model, we decided to reproduce the explanations on all provided datasets, including the synthetic and corrupted versions. The datasets used in the experiments in the original paper are the Heart Disease, Boston Housing, and Iris datasets; and the single-cell RNA dataset [11]. Our from-scratch model has incorporated all provided datasets, except for the latter, due to lack of computation power. However, experiments were
run on three additional UCI datasets: Seeds, Wine and Glass.6 The additional data allow us to understand how varying underlying structures in data influence explainability using different DR algorithms. Not all datasets can be reduced by all techniques: all three added datasets do not yield eigencomponents for a sigmoidal Kernel-PCA procedure.
3.4 Hyperparameters A constraint on the resulting explanations is that theymust be sparse. The sparsity level is formally defined by k, representing the number of dimensions in the original space (with ʻreal-lifeʼ features) used as the main components of the translation that forms the explanation. The hyperparameter k is enforced after the learning process by truncating the δ-vector. To enforce sparsity during the learning process, the δ-vector is being l1-regularized by a term λ, as follows from [1, p. 5] and was inspired by the field of compressed sensing. The resulting equation, which is minimized, is stated in equation 1. As further explained in section 3.5, different values for λ are tested for optimization.
loss(δ) = ||r(x̄initial + δ)− r̄target||22 + λ||δ||1 (1)
Following [1, p. 6], in equation 2 a similarity measure is defined to capture the degree of which the features of a k1-sparse explanation correspond to k1 dimensions of a k2-sparse explanation where k2 > k1.
similarity(e1, e2) =
∑ |e1[i]|1[e2[i] ̸= 0]
||e1||1 (2)
Lastly, hyperparameter ϵ defines a threshold for the correctness and coverage metrics, as defined in equation 3–4. Although Plumb et al. do hint on the type of search they have performed to find values for ϵ, it is not clearly expanded upon [1, p. 4]. For the purpose of analysing reproducibility, wehave adopted the same values for ϵ (whichwere not present
6UCI Machine Learning Repository, https://archive.ics.uci.edu/ml/datasets/{heart+disease,iris,seeds,Wine,glass+ identification} and https://archive.ics.uci.edu/ml/machine-learning-databases/housing/, accessed on January 29th, 2021; note the set notation in the latter section of the URL.
ReScience C 7.2 (#16) – Reijnaers et al. 2021 6
in the paper) for the same datasets. For all new data, we have introduced similar static values for ϵ. Plumb et al. do, however, propose an evaluationmethod for ϵ, although it is again notmentioned in the paper. The authors take themean, minimum andmaximum of the diagonal values of the matrix of the correctness measures for all clusters (similar to the matrices shown in figure 4). These values can be misleading, as larger values for ϵ would inherently score high on correctness. Therefore, we have constrained ϵ ∈ [0, 2] and dynamically scale the latent spaces to force the data to be spread out (see section 3.5). We evaluated all values for ϵ and outline the means in table 1.
correctness(t) = 1 |Xinitial| ∑
x∈Xtarget
1[∃x′ ∈ Xtarget|||r(t(x))− r(x′)||22 ≤ ϵ] (3)
coverage(t) = 1 |Xtarget| ∑
x∈Xinitial
1[∃x′ ∈ Xinitial|||r(x)− r(t(x′))||22 ≤ ϵ] (4)
3.5 Experimental setup and computational requirements We have reproduced the experiments in [1] by using the upgraded TensorFlow-code. Additionally, we have run our from-scratch code on three additional datasets and six other dimensionality reduction algorithms. All experiments were run for five trials for eleven different values of λ (evenly spaced between 0 and 5), for which the best set of δ-vectors is chosen for all values of k (k is evenly spaced between 1 and the number of dimensions d in the original space, with a step size of 1 for d ≤ 5, and 2 otherwise).
As pointed out in the previous section, an inadequately high value for ϵ poses a problem if the data in latent space is of low variance (especially if variance < ϵ), as the performance measures, introduced in section 3.2 and shown in equations 3–4, would unjustly report very high scores. We have solved this problem by rescaling the data in latent space so that a variance of 10 is preserved (which amounts to a standard deviation of ≈ 3.16). We have deliberately chosen not to utilize a method for removing outliers prior to defining the factor with which to rescale the data in latent space, as to preserve ʻthe spirit of the data,̓ especially since the internal structure of some datasets contain outliers which potentially correspond to groups with a significantly different character, as opposed to outliers resulting from noisy measurements. We further discuss our choice in section 5. However, as we failed to preserve an adequate amount of variance when performing TSVD on the Glass-dataset using this method, we manually scaled the data in this latent space, for this particular dataset, with an additional factor of 20.
In the from-scratch implementation, K-means is used for clustering, while for the replicated experiments in the original notebooks, following the code provided by the authors, clusters were manually selected.
ReScience C 7.2 (#16) – Reijnaers et al. 2021 7
Experimental meta-results are shown in table 2. The original code, the ʼmodernizedʼ version of the original code and the code for the from-scratch implementation can be found on our GitHub repository [12].
4 Results
Using our upgraded TensorFlow-code and the provided pre-trained VAE models, the obtained results are identical to those provided by the paper s̓ codebase for all datasets and methods.7 After re-training all VAE models and relearning all explanations, using the same upgraded TensorFlow-code, we obtain very similar results.8 The results are not identical, as the models learn slightly different representations, in which the man-
ually selected clusters also differ. This indicates that the used cluster generation techniques influence themodel s̓ ability to explain based on a translation. An example arises with the Iris dataset: Plumb et al. yield 0.833 coverage, while we get only 0.66. This difference caused by a different organization of clusters propagates further into the results for the corrupted data. Except for minor differences arising from this same issue, we successfully reproduced the results for all other datasets.
When running the Housing, Iris and Heart datasets on the from-scratch implementation of the explanation algorithm using our implementation of scvis, we obtain either similar (see figure 3) or even better results than Plumb et al. do. This again indicates that the method for dimensionality reduction does impact the results.
For different datasets and different dimensionality reduction algorithms that map the datasets to different latent spaces, we have encountered the same problem related to the inability of explaining pairs of groups of which the clusters have a different standard deviation, as shown in the original paper in figures 4-7 [1, p. 4]. This problem occurs, among others, in figure 5f in appendix A (and the corresponding measures in figure 6f).
7To compare, open the .ipynb in all folders (except ʻcode,̓ ʻscvis,̓ ʻMiscFigures,̓ and ʻIntegrated-Gradientsmasterʼ) on both repositories, and look at the resulting plots: https://github.com/GDPlumb/ELDR and https://github. com/damiaanr/fact-ai/tree/main/ELDR-TF2.x_(pre_trained_models)
8Now, compare the plots with https://github.com/damiaanr/fact-ai/tree/main/ELDR-TF2.x_(newly_trained_models)
ReScience C 7.2 (#16) – Reijnaers et al. 2021 8
4.1 Additional results not present in the original paper As [1, p. 6] pointed out, the correctness and coverage metrics are closely related. If the translations between arbitrary groups are symmetrical, the former translation—which is the technical representation of the explanation—is the negative of the latter (and viceversa). Thus, when applying different linear dimensionality reduction algorithms, both metrics will exactly equal each other, as follows from the results shown below in table 3, and in figure 4 (note that the color map plot for correctness is the ʻtransposeʼ of the plot for coverage, and vice-versa) and figure 6 (along all different values for k, the graphs conveying correctness and coverage are on top of each other for all linear algorithms).
0 2 4 Target Group
0
1
2
3
4
5
In iti al Gr ou
p
Correctness - 0.908
0 2 4 Target Group
Coverage - 0.908
0.0
0.2
0.4
0.6
0.8
1.0
Figure 4. Metrics for Housing on PCA, k = 5
An additional observation is that topologybased dimensionality reduction techniques are less suitable for data compression when the compressed data consequently needs to be explained using translation-based counterfactual explanations. Locally linear embedding and isomapping are methods based on manifold mapping: a one- or two-manifold is embedded in two-dimensional space, and points of a higher-dimensional space are mapped onto this manifold. This often yields problem-
atic data structures. For instance, when data is represented using a line (a one-manifold) and embedded in two-dimensional space in which the one-dimensional line is twirled. Since we are only considering translations (and, e.g., no rotations), themethod is unable to adequately explain differences between clusters present onmanifolds in latent space.
Furthermore, we observed that certain datasets yield constant results when varying the sparsity-constraint. In this case, the compression from high-dimensional to twodimensional space was (nearly) lossless – a single component suffices to explain the difference between any group. This phenomenon is shown in figure 6e in appendix A, indicating that the chemical composition of wine actually depends on only one latent variable: when using PCA, 99.98% of the variance is explained by only two components (of which 99.81% by the first component) out of 13 input dimensions. Note that the VAE seems to learn an approximation of LLE space (see figure 5e).
All results for all introduced performancemeasures, datasets and dimensionality reduction algorithms, are shown in table 3 below and illustrated in figures 5–7 in appendix A.
ReScience C 7.2 (#16) – Reijnaers et al. 2021 9
5 Discussion
We have been able to successfully reproduce and upgrade the code provided by Plumb et al., which is the implementation of the technique presented in [1]. We were able to reproduce results by running the pre-trained models; after re-training these models; and by rewriting the algorithm from scratch.
The performance depends on themapping to latent space. A limitation of the algorithm is the lack of variable freedom: only translations can be used to explain differences between groups. By utilizing different DRmethods, we have shown that not all algorithms produce latent spaces in which translations suffice for an explanation between clusters. Especially manifold-based algorithms require a more sophisticated type of explanation using, for instance, rotation and scaling.
A possible solution would be to generate an explanation in terms of a matrix (so that x′ = Mx + δ instead of x′ = x + δ). However, explanations using translations are directly interpretable for humans as the dimensions of the tested datasets correspond to explainable features. Considering, for example, rotations, would come at the cost of explainability. However, forcing M to be diagonal (which leads to multiplying all data features by the corresponding diagonal factors) might yield proper explanations (of the type “If your monthly income would have been twice as big...”).
Furthermore, by using different datasets, we have shown that some DR techniques do a better job in terms of explainability between clusters. Data might be structured in different ways and produce different types of clusters. It directly follows from our results that the explanation method heavily relies on the generated clusters, and more importantly, its shapes and variance in latent space, which is another limitation.
In section 3.5, we opted for an approach in which the latent spaces are dynamically scaled for the purpose of achieving a certain amount of variance in the data, as to obey the fixed hyperparameter ϵwhich was introduced in section 3.4. A more robust method would be to dynamically define ϵ based on the variance in the latent space depending on the dataset and, potentially, proper handling of its outliers. We view the lack of expansion on this hyperparameter in the original paper as a (minor) limitation.
As VAEs are sampling points in latent space from a distribution, an identical point x in the input spacewhich is repeatedlymapped to latent spacewill yield differentmappings. It would be interesting to further investigate to what extent explanatory algorithms can ʻhandleʼ this variance – to what extent such algorithms could find a stable and unchanging explanation in an ever-changing counterfactual world.
5.1 What was easy After having asserted the dependencies needed to run the code provided by the authors on their GitHub repository, replicating the experiments performed in the paper was easy; the code was cleanly written, and it was easy to understand the architectural choices which the authorsʼ made in their model.
5.2 What was difficult Although the code required for computing the explanations was separated from the implementations in other folders in which it is applied on the different datasets, Plumb et al. decided to perform experiments using a VAE and intertwined all code for generating the explanations with the scvis-library. This caused the explanatory model to rely
ReScience C 7.2 (#16) – Reijnaers et al. 2021 10
on TensorFlow, while the explanation method itself does not require any deep learning. It is preferred to dissect the model into independent components, considering that the explanatory model should work with other DR algorithms, including those which do not require neural pipelines. Because of the authorsʼ choice to use a VAE, the entire repository relied on TensorFlow. Mainly for this reason, we rewrote everything from scratch, as to provide the code for the dimensionality reduction methods on a ʻstandaloneʼ basis. As we were aiming to reproduce the results provided by the original paper, we also had to rewrite the external scvis-library, which provided the VAE architecture, in PyTorch (for the sake of keeping clean, separated and object-oriented code). This was very time-consuming as both frameworks are fundamentally different (dynamic vs static graph definition). The process of rewriting took approximately two weeks.
Lastly, the results for the Bipolar dataset could only be replicated with the provided model configuration file. Although we have re-trained the model using the upgraded originally provided code, we have chosen to exclude this dataset for the additional experiments due to lack of computation power and time.
5.3 Communication with original authors A short interaction occurred to gain more insight into the required external libraries as these were not listed in any documentation. Although the authors responded quickly, the issue had already been solved in the meantime."
"['Hidde Lekanne gezegd Deprez', 'Geerten Rijsdijk', 'Bart de Rooij', 'Wouter Zwerink']",[Re] Reproducing 'Identifying through flows for recovering latent representations',10.5281/zenodo.4839595,Replication,Python 3,https://zenodo.org/record/4839595/files/article.pdf,identifiability iFlow iVAE Normalizing Flows Python 3,https://openreview.net/forum?id=8jmIpypMzE,https://github.com/HiddeLekanne/Reproducibility-Challenge-iFlow,7,2,2021,"To reproduce the results of the paper, the main experiments are reproduced and the figures are recreated. To do so, we largely worked with code from the repository belonging to the original paper. We added plotting functionality as well as various bug fixes and optimisations. Additionally, attempts weremade to improve the iVAE bymaking it more complex and fixing a mistake in its implementation.We also tried to investigate possible correlation between the structure of the dataset and the performance. All code used is publicly available at https://github.com/HiddeLekanne/Reproducibility-Challenge-iFlow.","The GitHub repository associated with the paper providedmost necessary code and ran with only minor changes. The code included all model implementations and data generation. The script that was used to obtain results was provided, which allowed us to determine which exact hyperparameters were used with experiments on the iFlowmodels. Overall, the code was well organised and the structure was easy to follow.
Copyright © 2021 H.L.G. Deprez et al., released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Geerten Rijsdijk (geertenrijsdijk@hotmail.com) The authors have declared that no competing interests exist. Code is available at https://github.com/HiddeLekanne/Reproducibility-Challenge-iFlow – DOI 10.5281/zenodo.4704869. – SWH swh:1:dir:a08aac73d57611c3d2abc0a55437d7bae40d02f7. Open peer review is available at https://openreview.net/forum?id=8jmIpypMzE.
ReScience C 7.2 (#17) – Deprez et al. 2021 1","The specific versions of the Python libraries used were unknown, which made it infeasible to achieve the exact results from the paper when running on the same seeds. The code used to create figures 1-3 in the original paper wasmissing and had to be recreated. Furthermore, the long time themodels needed to trainmade experimentation with e.g., different hyperparameters challenging. Finally, the code was largely undocumented.
Communication with original authors Communication with the authors was attempted but could not be established.
ReScience C 7.2 (#17) – Deprez et al. 2021 2
1 Introduction
Nowadays, different types of deep generative models excel at generating new data by either explicitly or implicitly modelling the distribution of the training data. However, sometimes it is useful to recover the distribution that generated the observed data, i.e. the latent distribution, rather than the data distribution itself. It is easy to see that this is a more difficult task due to the unknown relation between the unobserved latent variables and the observed data. The concept of recovering the true latent distribution underlying the data is a form of identifiability. Some research has been done in this area. Previously, models (notably β-VAE [1] and its variations) were created with the purpose of creating disentangled representations, where single latent units correspond to single generative factors. While related to identifiability, such models do not provide any proof or guarantee that they can recover the true latent representations. More recently, an identifiable variation of the VAE called iVAE was proposed [2], which uses a factorised prior conditioned on an auxiliary variable to guarantee a basic form of identifiability. In practice however, the fact that this model optimises a lower bound on the posterior, rather than the actual posterior, could negatively affect the capability of the model to recover the true latent variables. The paper ”Identifying through flows for recovering latent representations” proposes iFlow, a model that aims to alleviate these problems by using Normalising Flow models rather than VAEs [3]. The fact that Normalising flows model exact distributions rather than approximating the posterior could make them more suitable for this task.
2 Scope of reproducibility
In this review, the work of the proposed iFlow model by Li et al. [3] is reproduced and examined. The aim is to reproduce the results obtained by the authors and to investigate the claims made in the paper. The claims made can be seen below. Each claim will be examined in a corresponding subsection in section 4.
1. Simulations on synthetic data validate the correctness and effectiveness of the proposed iFlow method and demonstrate its practical advantages over other existing methods.
2. iFlow outperforms iVAE in identifying the original sources while preserving the original geometry of source manifold.
3. iFlow exhibits much stronger correlation than iVAE does in each single dimension of the latent space.
4. Making iVAE more expressive does not help it approximate the real latent space further, justifying the discrepancy in parameters.
3 Methodology
Most of the original source code was available and used to test the reproducibility of the paper which can be found in the corresponding GitHub repository 1. This repository itself contained code from the repository of the iVAE model2 and nflows 3. The iFlow implementations were used largely as is, while the iVAE implementation was refactored to apply modifications more easily. The nflows code base has been removed
1https://github.com/MathsXDC/iFlow 2https://github.com/siamakz/iVAE 3https://github.com/bayesiains/nflows
ReScience C 7.2 (#17) – Deprez et al. 2021 3
from the repository and imported as a library instead. Furthermore, some small optimisations were made to make certain functions more efficient by vectorising them. For reproducing the results the models were trained on a GPU (see section 3.5). The code for creating the visualisations was not included in the repository and was therefore recreated. The implementation was made using the PyTorch and NumPy libraries with Python 3.7.9. TensorBoard was used for logging of variables during training.
3.1 Model descriptions The paper compares two models: the proposed iFlow model and the iVAE model. The iFlow model is a variation on the Normalising Flow model rational-quadratic neural spline flows (featuring autoregressive layers) (RQ-NSF (AR)) [4], where the prior has been replaced with a factorised exponential prior distribution conditioning the latent variables z on auxiliary variables u to obtain identifiability up to an equivalence relation. The natural parameters of the prior are obtained through a trainable multi-layer perceptron (MLP) which takes the auxiliary variable u as input. Each iFlowmodel contains approximately 3 million trainable parameters. The iVAE model is implemented as an extension of vanilla VAE models [5], using MLPs for both the encoder and decoder. The number of layers, hidden dimensions and activation functions are hyperparameters. The encoder uses two MLPs (one for mean and variance each), while the decoder uses just one. Additionally, the prior mapping the auxiliary variables u to the latent variables z is also implemented as an MLP. In total, the iVAE model with standard parameters has roughly 18,000 trainable parameters. There is a significant difference in the complexities of iFlow and iVAE, seen in the number of trainable parameters themodels have. The authors argue that this is not the cause of the inferior performance of the iVAE, showing that addingmore layers/increasing the hidden dimensions of the model does not increase performance. However, only a limited range of parameters were used for this, resulting in only weak evidence to support the claim that the comparison is fair. We further investigate this claim by scaling up the complexity of iVAE through various methods, namely adding residual connections and layer normalisation in addition to changing hyperparameters. When looking at the implementation of the iVAEmodel, there appears to be a difference with the theory: the mean of the prior distribution is not a function of the auxiliary variables u, as the theory states, but simply fixed to be 0 at all times. We aim to incorporate this change into the implementation of iVAE to see if it leads to better performance.
3.2 Dataset A synthetic dataset is required in order to truly know the underlying latent distribution, which is necessary for quantitative analysis of the performance. The authors chose to use a dataset consisting of sources of non-stationary Gaussian time-series. Such data was previously used to introduce time-contrastive learning as ameans of achieving identifiable non-linear independent component analysis [6] and was additionally used to assess the performance of the iVAE [2]. The latent representation (source) is created as non-stationary Gaussian time series. This data consists of M segments, which are modelled as Gaussian distributions with different, randomly selected mean and variance. The means are sampled from uniform distribution [−5, 5], while the variances are sampled from uniform distribution [0.5, 3]. Each segment contains L samples drawn from the corresponding distribution of segmentM . The segment labels serve as the auxiliary variables u. A 3 layer invertible MLP is used to transform the samples in a non-linear manner to obtain the observable data. The invertibleMLP consists ofmixingmatriceswith the nonlinear activation function h(x) = tanh(x) + α · x. The last layer does not contain a nonlinear activation function. Due to the constraints of Flow models, the dimensionality
ReScience C 7.2 (#17) – Deprez et al. 2021 4
d of these observed data points has to be the same as the dimensionality of the latent representation n. The data generator allows for the addition of noise to the data points, but this is not utilised. In the paper, results are reported on a dataset created usingM = 40,L = 1000, n = d = 5 and α = 0.1. For visualisations of the sources and the estimations of themodels,M = 5, L = 1000, n = d = 2 and α = 0.1 are used. This differs from the reported M = 40 from the original paper where the figure indicates that the trueM = 5.
3.3 Hyperparameters The authors of the original paper mention specific values for some of the hyperparameters. However, for other hyperparameters only a range is provided without a clear indication of what values were used for each evaluation. As mentioned before, for generating the data, the parameters M = 40, L = 1000, n = d = 5 and M = 5, L = 1000, n = d = 2 were used for experiments and visualisation respectively. A factorised Gaussian distribution was used as a prior for the source distributions. The means and variances for these distributions were sampled from uniform distributions [−5, 5] and [0.5, 3] respectively. The data was transformed with an invertible MLP of depth 3 with tanh activation function and a slope of 0.1. Both the iVAE and iFlow used the same batch size (B = 64) and learning rate of 0.001. A learning rate drop factor of 0.25 was used and a learning patience of 10. An Adam optimiser without weight decay and with standard β values (0.9, 0.999) and ϵ (1e-8) was used [7]. A learning rate scheduler to reduce the learning rate with a factor 0.1 on plateaus ensured that the learning rate decreased over time. The iFlow models were initialised with a flow length of 10 with 8 bins. The Rational Quadratic Neural Spline Flows with Autoregressive transforms (RQNSF-AR) was used as flow type. The Softplus activation was exerted on the natural parameters. To replicate the iVAE baseline, a model with a hidden dimensionality of 50, a latent dimension equal to that of the data (d = n = 5) and 3 layer MLPs with leaky ReLU with α = 0.1 as activation function. These same hyperparameters were used for the additional experiments.
3.4 Experimental setup and code The code for this reproducibility review is publicly available at https://github.com/HiddeLekanne/ Reproducibility-Challenge-iFlow. As mentioned earlier, this code consist of a combination of the iFlow and iVAE codebases (see section 3). The iFlow and iVAE models were trained with 100 different seeds to generate datasets and the aforementioned hyperparameters. As is standard for these types of models, the iFlow model was trained using negative log likelihood as a loss, and the iVAE was used using the ELBO as a loss [5]. Model performance was evaluated using the mean correlation coefficient (MCC) between the original source of the data and the estimated latent variables from the models.
3.5 Computational requirements
All experiments were run on the LISA system4 provided by the University of Amsterdam. This system providesmulti-core nodes for research projects. A GeForce GTX 1080 Ti was used to train the models. Training of iVAE models for 100 different seeds took approximately 2 hours. Training of a single iFlow model with a flow length of 10 took approximately 45 minutes. To alleviate some of the computational cost, the 100 models were trained in two worker nodes instead of one. This totalled to approximately 1.5 days of training per 100 models.
4https://userinfo.surfsara.nl/systems/lisa
ReScience C 7.2 (#17) – Deprez et al. 2021 5
Upgrading of computational resources would not garner better results, with respect to time, based on the fact that the bottleneck for the computations was the speed of a single thread CPU. Attempts were made to improve this performance but these did not decrease training time.
4 Results
In this section, results from the original paper are recreated. In addition, some further experiments were done of which the results can also be found below. These additional experiments consist of improving the existing base line proposed in the paper, as well as exploring the relation between the complexity of the synthetic data and the achieved MCC scores.
4.1 Results reproducing original paper
Comparison of identifying performance — The MCC scores and log-likelihood over 100 seeds are displayed in figure 1a and figure 1b respectively. The figures show that there is high variance in MCC scores for different datasets. The iFlow models obtained a mean accuracy of 0.718 with a standard deviation of 0.067 whereas the iVAE models obtained a mean accuracy of 0.483 with a standard deviation of 0.059 which is in compliance with the results produced in the original paper. The results for the iVAE models are significantly worse than in the original iVAE paper. An improvement to the implementation was made to better emulate the performance of this paper which resulted in a fairer comparison (see section 4.2.1). As can be seen in figure 1b, the energy values of the iVAE are significantly lower compared to those of iFlow, matching the results of the paper. The authors noted that the difference in energy values could indicate that the gap between the ELBO and the actual log likelihood is not negligible.
Preservation of original source manifold geometry — Figure 2 shows the 2D visualisation for different data seeds. The original paper stated that an M = 40 was used but figures indicated that this should beM = 5. The results largely support the claim of the author that the original geometry of the sourcemanifold is preserved. The estimations from the iFlowmodel seemmore similar to the original source than the estimations from the iVAE models, although it still contain artefacts from the observations. Figure 2a is an example of such where the latent
ReScience C 7.2 (#17) – Deprez et al. 2021 6
dimensions are not successfully recovered. In other examples, the original Gaussian distributions are mostly recovered apart from some transformation as was the case in the original paper. The collapse of the latent space from iVAE models observed in the original paper was not prevalent during experiments. However, the preservation of the original geometry of the source manifold is better captured by the iFlow models.
Separate latent dimension correlation — Figure 3 and figure 4 show the correlation between the source signal used to generate the data and the latent variables recovered by the iFlow and iVAE models. Figure 3 shows the results of the best performing iFlow, which we assume is what figure 3 of the original paper also depicts. For fairness, we also show the results for the dataset that iVAE performed best on in figure 4. These results largely support the claim that iFlow exhibits stronger correlation thandoes iVAE in each single dimension of the latent space: while this is generally the case, it does occur for some datasets that iVAE has a higher correlation coefficient than iFlow on one or even two of the latent dimensions, as shown in figure 4.
ReScience C 7.2 (#17) – Deprez et al. 2021 7
ReScience C 7.2 (#17) – Deprez et al. 2021 8
4.2 Results beyond original paper
Improved baseline — In figure 5a and 5b the MCC scores and energy values over 100 seeds are displayed for the iFlow model, iVAE model and improved iVAE model. The addition of the trainable mean, based on auxiliary parameters, shows an increase in the mean MCC score from 0.483 (0.059) to 0.556 (0.061). The ELBO score improves almost with a constant value for every seed. Other attempts had beenmade to improve this baseline by increasing the complexity of the iVAEmodel. However, were tried before themistake in the iVAE implementation had been noticed, and are therefore not very useful. These results can be seen in appendix B. In addition to figure 1, recreations of figures 2 3 using the improved baseline weremade. These are not included in this report but can be found in appendix C
Synthetic data complexity — To measure the complexity of the dataset, the mean KullbackLeibler divergence [8] of each source and its nearest neighbour was used. This metric showed no correlation (0.06) with theMCC scores obtained by iVAE or iFlow, showing that the randomly sampled parameters of the source distribution were likely not to blame for the high variance in MCC scores.
5 Discussion
The results reproduced in the previous section largely support the claims by the original authors. Firstly, the MCC scores that we obtained after training the model on synthetic data are very similar to the ones reported. Secondly, the recreated visualisation of 2D latent sources seems to support the claim that the iFlow method outperforms iVAE in identifying the original sources. Finally, the claim that iFlow exhibits much stronger correlation than iVAE in each single dimension of the latent space is not fully supported by our results. In the original paper, the authors show this correlation only for the best iFlow results. When visualising the individual dimensions of the latent variables for the best iVAE results, iVAE outperforms iFlow in two of the latent dimensions. This shows that the claim does not strictly hold true for all seeds. Nevertheless, since iFlow outperforms even the best iVAE on most latent dimensions, it still seems to be a reasonable claim. Our experiments to improve the performance of the iVAEmodel, bymodelling the prior means as a trainable function of the auxiliary variable u, managed to increase its perfor-
ReScience C 7.2 (#17) – Deprez et al. 2021 9
mance significantly. However, the performance remains worse than that of iFlow. This further cements the claim that the iFlow model is more suited for the task of identifiability than iVAE. The strength of our approach was that we were generally faithful to the original implementation, using largely the same code which we examined thoroughly. Therefore, the chance of implementation differences with the original code is very small. Additionally, we rigorously compared the code with the underlying theory, allowing us to correct an important mistake in the baseline. A weakness of our approach was that we did not do any work to examine the models on a more realistic dataset, meaning the generalisability of the model remains an open question. Furthermore, due to the high variance in the results of identifyingmodels, all experiments had to be run with a large number of seeds (100), which took a long time given the fact that training of a single model took approximately 40 minutes. For this reason, experimentation done with hyperparameters was limited. The experiments in the appendix of the paper were not replicated for similar reasons. These experiments looked at the effect of different activation functions on the performance of iFlow and the effect of more and larger hidden layers on the performance of iVAE. Overall, the authors provided a model which outperforms the previously best method for this problem in a quantifiable measure. Additionally, high variance in the results is addressed appropriately by running the experiments over a large number of seeds. Furthermore, the visualisation of the true sources and the estimations by themodelsmakes it easier to interpret the MCC scores. Lastly, the model is theoretically well motivated. Despite these strengths of the original paper, some improvements could be made to further substantiate the claims made in the paper. There is a clear advantage that iVAE has over iFlow, which is not mentioned by the authors: iVAE can be used when the dimensionality of the latent sources differs from the data dimensionality, while iFlow cannot. The fact that iFlow needs data with such corresponding dimensionalities also means that the iVAE had to be trained without a bottleneck. This is an important part of the VAE architecture, and the lack thereof could have contributed to the weaker performance of iVAE; compared to the paper introducing iVAE (MCC of above 0.95), the MCC scores of the iVAE reported by the authors are significantly worse (MCC of 0.496). This discrepancy is not addressed or explained by the authors.
5.1 What was easy The code provided in the GitHub repository worked almost out of the box, with only small adjustments needed; the source code of the nflows library that was included in the repository was replaced with an import. This fixed an issue that prevented the code from running on a CPU. The code was well organised into separate files for e.g., the iFlow model, iVAE models or training, making it easy to quickly find specific parts of the code when needed. The code that generates the data the models are trained on also came with the implementation, and worked without any issues. With the code, a shell script was provided that seems to be the one used for the experiments on iFlow in the paper (although this was not explicitly stated). This allowed for easy replication of these experiments, with all of the used hyperparameters provided.
5.2 What was difficult There were difficulties in replicating some parts of the paper. The lack of a provided environment means that our code was likely run using different versions of some libraries such as PyTorch or NumPy. This could have contributed to the difference in outcomes of our experiments compared to the paper while using the same seeds. While the script used to run iFlow experiments was provided, the same was not true for the iVAE experiments. This was not a large problem, however, since the authors do state
ReScience C 7.2 (#17) – Deprez et al. 2021 10
that the hyperparameters used are the same as in the original iVAE paper [2]. The code for creating plots (Figures 1,2,3 in the iFlow paper) was also not provided and additional code had to be written to recreate these figures. The training of the iFlowmodels for all 100 seeds took a significant amount of time. With the training for one seed taking approximately 40minutes, the full training took roughly a day and a half (running two batches of 50 seeds simultaneously). This made it difficult to do full-scale experiments with different hyperparameters. Lastly, there was a large portion of unused code present in the repository, whichmade it more difficult to understand the overall structure of the code. This includes the source code of the nflows library, code for planar flows, multiple different iVAE variations, an alternative dataloader, an unused dataset and an implementation of training using annealing."
"['Carles Balsells Rodas', 'Oleguer Canal Anton', 'Federico Taschin']",[Re] Hamiltonian Generative Networks,10.5281/zenodo.4835278,Replication,Python,https://zenodo.org/record/4835278/files/article.pdf,Hamiltonian generative network variational python pytorch,https://openreview.net/forum?id=Zszk4rXgesL,https://github.com/CampusAI/Hamiltonian-Generative-Networks,7,2,2021,"Hamiltons̓ equations are widely used in classical and quantum physics. The Hamiltonian Generative Network (HGN) is the first approach that aims to ”learn the Hamiltonian dynamics of simple physical systems from high-dimensional observations without restrictive domain assumptions”. To do so, a variational model is trained to reconstruct the evolution of physical systems directly from images by integrating the learnedHamiltonian. New trajectories can be sampled and rollouts can be performed forward and backward in time. In this work, we re-implement the HGN architecture and the physical environments (pendulum, body-spring system, and 2,3-bodies). We reproduce the paper experiments and we further expand them by testing on two new environments and one new integrator. Overall, we find that obtaining both good reconstruction and generative capabilities is hard and sensitive to the variational parameters.","The architecture of the model and training procedure was easy to understand from the paper. Besides, creating simulation environments similar to those of the original authors was also straightforward.","While the overall model architecture and data generation were easy to understand, we encountered the optimization to be especially tricky to perform. In particular, finding a good balance between the reconstruction loss and KL divergence loss was challenging. We implemented GECO [2] to dynamically adapt the Lagrangemultiplier but it proved to be surprisingly brittle to its hyper-parameters, resulting in very unstable behavior. We were unable to identify the cause of the problem and ended up training with simpler techniques such as using a fixed Lagrange multiplier as presented in [3].
Communication with original authors We exchanged around 6 emails with doubts and answers with the original authors.
1 Introduction
Consider an isolated physical system with multiple bodies interacting with each other. Let q ∈ Rn be the vector of their positions, and p ∈ Rn the vector of their momenta. The Hamiltonian formalism [4] states that there exists a functionH : (q,p) ∈ Rn+n → R representing the energy of the system which relates q and p as:
∂q ∂t = ∂H ∂p , ∂p ∂t = −∂H ∂q (1)
In this work H is modeled with an artificial neural network and property 1 is exploited to get the temporal derivatives of both q and p. One can then use a numerical integrator (see Section 4.1) to solve the ODE and infer the system evolution both forward and backward in time given some initial conditions (see Figure 2). These initial conditions are inferred from a natural image sequence of the system evolution (see Figure 1). The authors propose a generative approach to learn low-dimensional representations of the positions and momenta (q0,p0). This allows us to sample new initial conditions and unroll previously unseen system evolutions according to the learned Hamiltonian dynamics.
ReScience C 7.2 (#18) – Balsells Rodas, Canal Anton and Taschin 2021 2
2 Scope of reproducibility
Themain claim of the paper is that the proposed architecture is able to ”learn theHamiltonian dynamics of simple physical systems from high-dimensional observations without restrictive domain assumptions”. This means that the architecture is capable of learning an abstract position and momentum in latent space from RGB images. Then, with the help of an integrator, the architecture will be capable of reconstructing the system evolution. Modifying the integrator time-step will result in a slow-motion or fastforward evolution. Moreover, the architecture can generate previously unseen system evolutions through sampling. Briefly, we will evaluate the following claims:
• The architecture reconstructs RGB frames of a physical system evolution with an error comparable to [5].
• The architecture can generate new samples qualitatively similar to the originals.
• The timescale of the predicted evolution can be tuned as an integrator parameter without significant degradation of the resulting video sequence.
3 Methodology
Todate (Jan 1st 2021), authors didnot release their code. Therefore, we fully re-implement the Hamiltonian architecture, the integrators, and the simulated environments. To further evaluate the system, we implement two additional environments and one additional integrator. We developed our implementation in Python3 using PyTorch [1] machine learning library for the Hamiltonian architecture and the Scipy [6] ODE solver for the simulated environments, as well as OpenCV [7] for image manipulation. Our code can be found in this repository1. We runmost of the experiments using an NVIDIA GeForce RTX 2080Ti and some on an NVIDIA GTX 970.
3.1 Hamiltonian Generative Network (HGN) The HGN [5] architecture can be split into two high-level components. The first (Figure 1) reads the initial k+1 frames of an environment rollout and extracts the abstract positions and momenta (qk,pk) correspondent to the k-th step. Second, a recurrent model takes (qk,pk) as first input and performs integration steps of a fixed ∆t, predicting the evolution of the system in terms of abstract positions and momenta 2. For each step, the abstract position is decoded into an RGB image. As figures 1, 2 depict, this model is composed by four main networks:
• Encoder: Parametrized by: ϕ. 8-layer 64-filter Conv2D network with ReLU activations that takes a sampled video rollout from the environment and outputs the mean and variance of the encoder distribution qϕ(z) parametrized as a diagonal Gaussian with prior p(z) = N (0, I). The latent variable z is sampled from qϕ with the reparametrization trick [8]. The input of this layer is constructed by concatenating all the rollout frames in the channel axis. Therefore, if working with RGB images, the input has shape: H ×W × 3 · N . Where H,W,N are Height, Width, and Number of frames, respectively.
• Transformer: Parametrized by: ψ. Takes in the sampled latent variable z and transforms it into a lower-dimensional initial state sk = (qk,pk), by applying 3 Conv2D layers with ReLU activations, stride 2, and 64 filters.
1https://github.com/CampusAI/Hamiltonian-Generative-Networks 2In addition, we test how the network performs when trained as an autoencoder, ie: fit the complete se-
quence and reconstruct it. (Section 4)
ReScience C 7.2 (#18) – Balsells Rodas, Canal Anton and Taschin 2021 3
• Hamiltonian: Parametrized by: γ. It is a 6-layer 64-filter Conv2Dnetworkwith SoftPlus activations which takes in the abstract positions and momenta (qt,pt) and outputs the energy of the system et ∈ R. This network is used by the integrator (Section 4.1) to compute the system state at the next time-step (qt+1,pt+1) exploiting Eq. 1. Since Eq. 1 involves partial derivatives of H w.r.t. q and p, the training process involves second-order derivatives of the Hamiltonian network weights. For this reason, SoftPlus activations are used instead of ReLU.
• Decoder: Parametrized by: θ. 3-residual block upsampling Conv2D network (as in [9]) which converts the abstract position qt into an image close to the source domain.
Given an input sequence: (x0, ...,xT ) and a value k+1 of input-length, the loss function 3 to optimize is:
L(ϕ, ψ, γ, θ;x0, ...,xT ) = 1
T + 1− k T∑ t=k ( Eqϕ(z|x0,..xk) [ log pψ,γ,θ(xt | qt) ]) − Λ ·KL ( qϕ(z) || p(z)
) (2) Notice that the loss is the combination of two terms: first, the error coming from the reconstruction of the images, and second, a termwhich forces the latent distribution qϕ to be close to a standard Gaussian. It is interesting to see that there is no conditioning over the behavior of latent positions and momenta during the rollout. The architecture connections are enough to force qk to encode the position information and pk themomenta information at timestep k. We use the same optimizer as in [5]: Adam [10] with a constant learning rate of lr = 1.5e−4 with the GECO algorithm presented in [2] to adapt the Lagrange multiplier Λ during training. This Lagrange multiplier is dynamically updated according to an exponential moving average proportional to the reconstruction error of the assessed minibatch. The main parameters controlling the Lagrange multiplier are the exponential moving average constant α, the initial Lagrange multiplier, and a parameter to control its growth λ. The authors did not include the values used in the paper, so we performed a grid search to find the most adequate ones for each environment (see Section 6). In addition, we trained a version of the model with a fixed Lagrange multiplier.
3The formulation of the loss in Eq. 2 particularly w.r.t. the distribution qϕ is different from that of the paper[5] where it was written as qϕ(z|x0, ...,xT ), which initially led us to think that the encoder had access to the whole rollout. Discussion with the authors clarified that the encoder reads only the first k frames. Therefore, we decided to slightly modify the loss notation in order to avoid confusion. Still, we show results with both approaches to get a more complete idea of the differences.
ReScience C 7.2 (#18) – Balsells Rodas, Canal Anton and Taschin 2021 4
Mass-spring. Assuming no friction, the Hamiltonian of a mass-spring system is H = p2 2m + 1 2kq 2, where m is the object s̓ mass and k is the spring s̓ elastic constant. We gen-
ReScience C 7.2 (#18) – Balsells Rodas, Canal Anton and Taschin 2021 5
erate our data consideringm = 0.5, k = 2 and r ∼ U(0.1, 1.0).
Pendulum. An ideal pendulum is modelled by the HamiltonianH = p 2
2ml2 + 2mgl(1− cos q), where l is the length of the pendulum and g is the gravity acceleration. The data is generated consideringm = 0.5, l = 1, g = 3 and r ∼ U(1.3, 2.3).
Two-/three- body problem. The n-body problem considers the gravitational interaction between n bodies in space. Its Hamiltonian is H = ∑n i ||pi|| 2 2mi − ∑n i ̸=j gmimj ||qi−qj ||
, where mi corresponds to the mass of object i. In this dataset, we set {mi = 1}ni=1 and g = 1. For the two-body problem, we modify the observation noise to σ = 0.05 and set r ∼ U(0.5, 1.5). When considering three bodies, we set σ = 0.2 and r ∼ U(0.9, 1.2).
Dobule pendulum The double pendulum consists of a system where we attach a simple pendulum to the end of another simple pendulum. For simplicity, we conider both simple pendulums with identical properties (equal mass and length). The Hamiltonian of this system isH = 12ml2 p21+p 2 2+2p1p2cos(q1−q2) 1+sin2(q1−q2) +mgl ( 3−2 cos q1−cos q2 ) , where {q1, p1} and {q2, p2} refer to the phase state of the first and second pendulum respectively. Our data is generated by settingm = 1, l = 1, g = 3 and r ∼ U(0.5, 1.3). In this scenario we consider a very low intense source of noise σ = 0.05.
Damped oscillator The damped mass-spring system is obtained by considering a dissipative term in the equations of motion of the ideal mass-spring system. For such systems, one can obtain its dynamics using the Caldirola-Kanai HamiltonianH = eγt ( p2
2m+
1 2kq
2 ) [12], where γ is the damping factor of the oscillator. In our experiments, we
consider an underdamped harmonic oscillator and set γ = 0.3, m = 0.5, k = 2, r ∼ U(0.75, 1.4) and σ = 0.1.
3.4 Hyperparameters We set the same hyperparameters for all experiments as the original paper [5] except for GECO parameters, which were not included. Thus, we perform a grid search on each environment to find the most adequate ones (see Section 4.1).
3.5 Computational requirements A standard training of 50K train samples using the Leapfrog integrator takes around 4 hours on an RTX 2080T GPU and requires around 1910MB.
ReScience C 7.2 (#18) – Balsells Rodas, Canal Anton and Taschin 2021 6
4 Results
We first test whether the HGN [5] can learn the dynamics of the four presented physical systems by measuring the average mean squared error (MSE) of the pixel reconstructions of each predicted frame. Furthermore, we test the original HGN architecture along with different modifications: a version trained with Euler integration rather than Leapfrog integration (HGN Euler), and a version that does not include sampling from the posterior qϕ(z|x0...xT ) (HGN determ). Since we could not find suitable GECO[2] hyperparameters, we use a fixed Lagrange multiplier[3] in all the experiments. Table 1 shows the results of the experiments described previously along with the results of the original authors. As it can be seen, we achieve average pixel reconstruction errors that are similar (30% avg absolute error w.r.t. the reported values on the test set using Leapfrog integrator) to the ones reported in the original paper when reconstructing the same sequence that is inputted (we call this version autoencode). However, when attempting to train to reconstruct a rollout given only the first 5 frames our model performs poorly, with 107% average absolute error on the test set, using Leapfrog integrator. In Figure 4, we show some qualitative examples of the reconstructions obtained by the full version of HGN. The model can reconstruct the samples and its rollouts can be reversed in time, sped up, or slowed down by changing the value of the time step used in the integrator. Since theHGN is designed as a generativemodel, we can sample from the latent space to produce initial conditions and perform their time evolution. We show some rollouts obtained this way in figure 5. We observe that our model is only able to generate plausible and diverse samples in the mass-spring dataset. This behavior is different than the one shown by [5] and might be caused by different hyper-parameter configurations in the training procedure or some implementation mistake. We achieve slightly larger MSE in the autoencode version and significantly larger in the
ReScience C 7.2 (#18) – Balsells Rodas, Canal Anton and Taschin 2021 7
5-frame inference problem on both the mass-spring and pendulum. The latter presents roughly double MSE probably because of a wider span of movement. In general, these two environments show worse results in comparison to two/three-bodies. For these last cases, our implementation using the autoencode setting outperforms the original HGN [5], and when using the 5-frame inference the results are similar. As we can see, these two environments show much less average pixel MSE compared to the first ones (almost one order of magnitude). We believe this may be due to the differences when rendering the instances of each dataset. The elements appearing in mass-spring and pendulum (represented by a large yellow ball) are larger than the ones present in the two/three bodies (two/three small coloured balls). Because of this, it would be reasonable to assume that localization errors aremore penalized in the first two environments, since the total difference in areas is larger. Furthermore, the dynamics representing mass-spring and pendulum show faster movements in comparison to two/three-bodies, resulting in being harder to represent with our HGN. Consequently, we hypothesise the following: larger elements and faster dynamics, produces higher average MSE on our model regardless of the difficulty of the environment physics. However, this is not the case for the original author s̓ results, who seem to strugglemore on the two/three-bodies. Surprisingly, it seems that our hyperparameter and architecture choices led to poorer reconstruction capabilities (higher MSE) but learning better physics (qualitatively more realistic movements).
4.1 Additional experiments GECO parameter search The paper does not provide the values of GECO [2] used. In GECO, the Lagrangian multiplier is optimized at each step with a rate γ. Figure 6 shows the behavior of GECO for γ ∈ {0.1, 0.05, 0.01} in terms of reconstruction loss and KL divergence. Higher values of β give a better reconstruction loss but greatly increase the KL divergence. However, we found that hyperparameters were not consistent among different environments and integrators. For this reason, we do not use GECO in our experiments.
Integrators Performing the integration step is key to generate the time evolution of a rollout given the initial state. In the HGN paper [5] the system is tested using Euler and
ReScience C 7.2 (#18) – Balsells Rodas, Canal Anton and Taschin 2021 8
Leapfrog integration. Wewonder if using higher order integrationmethodsmight boost the performance of the rollout generation process. Therefore, we implement and test the HGN architecture with two additional numerical integration methods: the RungeKuttas̓ 4th-order integrator [13] and the 4th-order Leapfrog integrator (Yoshidas̓ algorithm [14]). Table 2 shows a comparison of all four integrators on the Pendulum dataset. Both Leapfrog and Yoshida are symplectic integrators: they guarantee to preserve the special form of the Hamiltonian over time [15]. Table 2 shows the average pixel MSE, the averaged standard deviation of the output of the Hamiltonian network during testing, and the reconstruction time of a single batch (batch = 16) using the different integration methods that we have described previously. The model has been trained on the simple pendulum dataset. As we can see, the reconstruction time increases when using higher-order integration methods, since they require more integration steps. In general, we see that Euler integration offers a fast and sufficiently reliable reconstruction of the rollouts. Moreover, we observe that the fourth-order symplectic integrator (Yoshida) achieves the best performance. Surprisingly, the symplectic integration methods show more variance in the output of the Hamiltonian networks throughout a single rollout. This behavior is unexpected since using a symplectic integrationmethod should ideally keep the value of the Hamiltonian invariant. We conclude that more experiments need to be performed to guarantee that the implementation of both Leapfrog and Yoshida integration methods are faithful to their formulation.
Integrator modelling We train the modified architecture of Section 3.2 on the Pendulum dataset for 5 epochs. The architecture is the same as HGN, but the Hamiltonian Network now outputs∆q and∆p. The average MSE error over the whole Pendulum dataset is 1.485×10−3, while in the test set it is 1.493×10−3, which are both very close (∼ ±2%) to those of autoencoding HGN (see Table 1). The modified architecture is still capable of performing forward slow-motion rollouts by modifying ∆t. We set ∆t′ = ∆t2 and we compute the averageMSE of the slow-motion reconstruction over 100 rollouts. Themodified architecture achieved an error of 8x10−4, while the standardHGN achieved 9x10−4. Note that reconstruction losses are smaller for slow-motion as the images change less between timesteps.
Extra environments Apart from the four physical systems presented by [5] we test our re-implementation of the HGN with physical systems that do not have a simple Hamiltonian expression. As described previously, these are the damped harmonic oscillator and the double pendulum. On one hand, we are interested in a damped system since it introduces a dissipative term to the equations of motion; a feature that differs from the previous systems. On the other hand, the double pendulum is modelled by a non separable Hamiltonian: H(q,p) ̸= K(p)+V (q) as described previously. In figure 7 we show some visual examples of the reconstructions provided by the HGN trained on the two systems. As we can see, HGN is able to reconstruct the damped oscillator with high reliability. Regarding the double pendulum, we observe that the model reconstructs well small oscillations, but fails when the trajectory is too chaotic as expected. The average
ReScience C 7.2 (#18) – Balsells Rodas, Canal Anton and Taschin 2021 9
pixel MSE of the reconstructions of the damped oscillator and the double pendulum are 6.39 ·10−4 and 6.91 ·10−4 respectively. TheHGN is able to provide better reconstructions for these systems in comparison to the mass-spring and pendulum systems.
5 Discussion
We were able to implement and train an Hamiltonian Generative Network with similar reconstruction performance of the ones of the original paper (30% average absolute relative error wrt to their reported values when treating it as an autoencoder). These results show that the network is capable of exploiting the Hamiltonian equations to learn dynamics of a physical system from RGB images. However, the value of the resulting Hamiltonian does not remain constant throughout the system evolution. This means that the network is learning something that is different from the Hamiltonian equations described in Section 3.3. Tomake the variational samplingwork, we tried performing a grid search on the Geco[2] hyperparameters and using a fixed Lagrange multiplier as in [3]. However, despite our best efforts, the samples produced by the variational model have very poor quality. This is generally due to the difficulty in minimizing both KL divergence and reconstruction loss. We believe that further experiments are needed to understand better the behavior of the system and to improve it. Future work could include further testing on each network architecture, probably smaller networks would also be able to encode the needed information. Another next step is to try the approach onmore challenging (and realistic-looking) environments. In addition, it would be interesting to tackle the transfer learning capabilities of such architecture between different environments. How re-usable each network is? Howmuch faster the system is able to learn the newdynamics? Finally, another field which could benefit from this research is model-based reinforcement learning. A generative approach from which to sample example rollouts could be very useful for training agents without the need of directly interacting with the environment.
5.1 What was easy Once we implemented the code it resulted quite easy to perform multiple experiments on different environments, architectures and hyper-parameters due to the code s̓ modularity and flexibility. We can define the the previously mentioned experiments and most common testing behaviors from a set of yaml files which can then be modified from command-line arguments. While this required extra planning and work at the beginning it really payed off when debugging and evaluating in later stages.
ReScience C 7.2 (#18) – Balsells Rodas, Canal Anton and Taschin 2021 10
5.2 What was difficult The main challenge we encountered is finding the correct tools to debug a model composed of somany interconnected networks. The fact that it has a variational component with a dynamic Lagrange multiplier term makes it especially tricky to train. Furthermore, no public implementation existed and some details and parameters weremissing in the original paper leading to some necessary assumptions or parameter searches.
5.3 Communication with original authors We first tried to understand and re-implement the code by ourselves. Nevertheless, at some point we had gathered a significant set of doubts and we decided to email them to the original authors, which they answered with great detail. From that point onwards, we sent a couple more set of doubts, also receiving answers.
Most of our doubts were about network architecture clarifications (either of unclear or missing descriptions from the original paper), and loss function evaluation. Furthermore, they provided us with some of their environment images so we could more easily make our environments as similar as possible.
5.4 Improving reproducibility Having worked in re-implementing the whole original work, we feel it is important to share our experience as well as providing a recommendation on how it could be made more easily reproducible. First, having the environments data or code to generate it available online would save the effort and, most importantly, it would constitute a baseline against which to compare future work. Secondly, publishing all the hyperparameters andmore details of thenetworks architecturewouldmake thewholeworkmuch easier to reproduce and require less training attempts, especially for what concerns GECO."
"['Maja Schneider', 'Marco Körner']",[Re] Satellite Image Time Series Classification with Pixel-Set Encoders and Temporal Self-Attention,10.5281/zenodo.4835356,Replication,python,https://zenodo.org/record/4835356/files/article.pdf,rescience c rescience x python transformer self-attention time series crop classification earth observation,,https://github.com/maja601/pytorch-psetae,7,2,2021,"The presented study evaluates “Satellite Image Time Series Classification with Pixel-Set Encoders and Temporal Self-Attention” by Garnot et al. [1] within the scope of the ML Reproducibility Challenge 2020. Our work focuses on both aspects constituting the paper: the method itself and the validity of the stated results. We show that, despite some unforeseen design choices, the investigated method is coherent in itself and performs the expected way.","Running the provided code and obtaining the presented dataset turned out to be easily possible. Even adapting the method to our own ideas did not cause issues, due to a well documented and clear implementation.
Copyright © 2021 M. Schneider and M. Körner, released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Maja Schneider (maja.schneider@tum.de) The authors have declared that no competing interests exist. Code is available at https://github.com/maja601/pytorch-psetae. – SWH swh:1:dir:631305811058b775406ae624095e3ec66ace6437. Data is available at http://www.eurocrops.tum.de/.
ReScience C 7.2 (#19) – Schneider and Körner 2021 1","Reimplementing the approach from scratch turned out to be harder than expected, especially because we had a certain type of architecture inmind that did not fit the dimensions of the layers mentioned in the paper. Furthermore, knowing how the dataset was exactly assembled would have been beneficial for us, as we tried to retrace these steps, and therefore would have made the results on our dataset easier to compare to the ones from the paper.
Communication with original authors While working on the challenge, we stood in E-mail contact with the first and second author, had two online meetings and got feedback to our implementation on GITHUB. Additionally, one of the authors of the Transformer paper [2] provided us with further answers regarding their modelsʼ architecture.
ReScience C 7.2 (#19) – Schneider and Körner 2021 2
1 Introduction
The machine learning community showcases impressively and with great success how to design systems for analysing large data inventories, with the goal of identifying relevant patterns within them. At the same time, the remote sensing and Earth observation sector found itself confronted with the availability of novel dedicated sensor platforms. These are now capable of continuously acquiring new data at high temporal, spatial, and spectral frequencies, requiring the development of innovative and efficient ways to process these data stocks. In light of that, several machine learning methods have found wide application in the field of remote sensing and Earth observation. As the availability of observation data increased massively during the last decades [3], various retrieval, detection, and prediction problems can be addressed this way. Nevertheless, Earth observation data is mostly of a very inhomogeneous nature, which is due to the different designs and layouts of the receiving sensor platforms. In addition, geophysical processes on the Earths̓ surface are complex andmanifest themselves in observable changes with different dynamic patterns. Therefore, the goal of gaining deeper understanding of such processes requires the use of interpretable models [4]. In their recent CVPR publication “Satellite Image Time Series Classification with PixelSet Encoders and Temporal Self-Attention,” Garnot et al. [1] propose a new method to address these issues. Motivated by the practical problem of crop type classification from sequences of optical satellite imagery—that we consider a proxy for the entirety of vegetative processes on the Earthʼ surface—, the authors made use of attention mechanisms. In particular, they claimed adapting the Transformer architecture [2] that has gained considerable popularity in the recent past, enabling it to digest such specific Earth observation data modalities. Additionally, they introduce a pixel-set encoder as a new option to dealwithmedium-resolution satellite images instead of the known convolutional neural networks in image processing. Due to their aforementioned properties, the handling of Earth observation data in practical applications requires special care. Most prevalently, they exhibit a considerable amount of spatial autocorrelation [5], reinforcing the already known issues of underspecification inherent to data-driven machine learning models [6]. This generally leads to overfitting effects and poor generalisation performance. Hence, we carefully reproduced the proposed methods, first by starting from scratch just following the descriptions given in the paper under investigation, and subsequently by adapting the reference implementation openly provided by the original authors. To sanity-check both implementations and to further assess the transferability and generalisation properties of the studied model, we carried out further experiments relying on an alternative but comparable dataset. Following the idea of this reproducibility challenge, we will make our implementation and data public, allowing the community to likewise evaluate our findings.
1.1 Reproducibility questions As a foundation of our reproduction study, we identified the following key questions, each one examining one particular aspect or claim of the original paper:
i) Is it possible to reproduce the presented methods and their performance with and without referring to the authorsʼ publicly available code?
ii) To which extent do the author s̓ implicit claim of adapting the transformer architecture affect the model and its performance?
iii) Does the model perform comparably well when being only tested or both trained and tested on a different dataset?
ReScience C 7.2 (#19) – Schneider and Körner 2021 3
iv) How is the outcome influenced by the choice of the test set assembly, namely by splitting the data randomly or regionally?
1.2 Contributions beyond the original paper In addition to the results in the original paper, we also report the performance of the method evaluated on an alternative dataset and on a test set that does not show regionally overlap with the training set.
2 Methodology and experimental setup of the reproduction study
In order to study the reproducibility of the original publication, we followed different approaches to answer the questions raised in Section 1.1. Each of the following subsections will address one of these questions by introducing the methodology behind the chosen experiments and present our obtained results as replies to the author s̓ claims. Generally, we traversed the following three different experimental stages that we will also publish on GITHUB1 for better traceability: We first started by developing the entire approach ourselves in PYTHON and PYTORCH [7], as described in Section 2.1.1, followed by a short study on the original implementation in Section 2.1.2 and a comparison of one particular technical aspect in Section 2.2. Eventually, we conducted experiments on the influence of input data in the remaining sections.
2.1 Reproduction and accuracy of the satellite time series classification Theproposed architecture for satellite time series classification consists of two components which the authors introduce as the pixel set encoder (PSE) and the temporal attention encoder (TAE). While the former takes care of a randomly sampled pixel set from a crop parcel and produces an embedding of the input, the latter, an adapted variant of the Transformer architecture [2], produces an output by applying self-attention to these multi-temporal embeddings. Unlike practices familiar from natural language processing, PSE and TAE get both optimised during the training phase. A detailed summary of the composition and number of parameters in the networks can be obtained from Table 1 in the studied paper. All experiments were conducted on an UBUNTU 20.10 workstation equipped with 64GB of RAM, an INTEL I7-8700 CPU and an NVIDIA GEFORCE RTX 2060 GPU.
Full replication study of the approach —We reimplemented the proposed architecture described in Section 3: Methods of the investigated paper almost literally in PYTHON. As the section is subdivided into the three parts describing the spatial encoder, also referred to as the pixel-set encoder, the temporal attention encoder, and the spatio-temporal classifier, these three modules likewise build the core of this reproduction study. More precisely, Table 1 of Garnot et al. [1] allowed us to inherit all model hyper-parameters straightforwardly. For one of the four used multi-layer perceptrons (MLPs), it was stated that it consisted of fully-connected layers FC, batch normalisation, and ReLU activations. We, thus, inductively assumed these components to be part of the other three MLPs as well. While we managed to develop an inefficient yet working version of the spatial encoder, some aspects of the temporal attention encoder appeared unintuitive at first sight. Unlike the original Transformer model [2], on which this module is based, the values v are not calculated by a fully-connected layer. Instead, the sum of the spatial encoder outputs and the positional encoding is multiplied with the attention mask a, which is visualised in Figure 1a. The authors motivated this change with the claim that it “removes needless computations, and avoids a potential information bottleneck” [cf. 1, Section
1https://github.com/maja601/RC2020-psetae
ReScience C 7.2 (#19) – Schneider and Körner 2021 4
3.2.]. Having the original Transformer implementation in mind, we misinterpreted this design choice. Thus, in our implementation, we divided the multi-head attention input into four equal tracks, as we were not able to think of another way to end up having 512 nodes to be passed over to the MLP3 (cf. Table 1 of [1]). This misconception was partially reinforced by the superscript (h) in formula (5) in [1], i.e.,
k (t) h , q (t) h = FC (h) 1
( e(t) + p(t) ) , (1)
suggesting that, for each head h, an entirely independent fully-connected layer FC(h) was used. This way, our network reimplementation became incredibly blown up and we were not able to spot the correct approach. All hyper-parameters and training details were directly taken from the Section 3.4: Implementation details from Garnot et al. [1]. After completing the first presented stages of the implementation, we were able to achieve an accuracy of about 60%. Subsequently, we had a first online meeting with the first and second author of the investigated paper, where we identified somemisconception concerning the used labels: Instead of using all 20 classes from the label_19class dictionary in the provided lables.json file, only the top-20 classes from the label_44class dictionary of the same file were utilised by the authors, i.e., the classes withmore than 100 occurrences in the dataset. It also got to our attention that, in lieu of the proposed batch normalisation, themulti-layer perceptrons should perform layer normalisation. Unfortunately, despite the first author providing helpful feedback on our implementation via GITHUB, we were still not able to achieve a relevant increase in accuracy compared to the previously stated 60%. After comparing our implementation to the reference implementation provided by the authors, it became apparent that we struggled to grasp the authorsʼ ideas about the data organisation and the spatio-temporal classifier. Therefore, we will investigate what led us to misinterpret the Transformer s̓ adaption in Section 2.2 and the data organisation in Section 2.3.2.
Evaluation of the original implementation — Obtaining the authorsʼ code and running it locally proved to be easy thanks to a well-documented GITHUB repository2. In general, their reference implementation is modular, clearly structured, and sufficiently commented which makes the entire architecture easy to adapt to one s̓ own needs. The model can either be trained from scratch or, together with a provided checkpoint, used to solely run the inference. We present a comparison of the test results from the checkpoint and when training from scratch in Table 1a. Using the system specified in Section 2.1, training the model for one single epoch took approximately 27 s, while running the inference on one sample batch containing 128 parcels completed within about 0.04 s. For the following experiments, we exclusively used the official reference implementation to ensure comparability.
2.2 Experiments on the transformer architecture As stated in Section 2.1.1, we previously relied on some faulty assumptions related to the architecture of the adapted Transformer multi-head attention. Fortunately, the original code provided by the authors helped us to reconstruct their initial idea. Nevertheless, having the vanilla off-the-shelf Transformer implementation in mind, we were inquisitive about the impact of the particular architectural change proposed by Garnot et al. Hence, we took the reference implementation and changed two lines of it in a way that the temporal attention encoder then employed a third fully-connected layer FCv, just like the vanilla Transformer attention model does, as described by Vaswani et al. [2]. Figure 1b illustrates this subtle change in comparison to the architecture realized by
2https://github.com/VSainteuf/pytorch-psetae
ReScience C 7.2 (#19) – Schneider and Körner 2021 5
the authors of the paper under investigation, shown in Figure 1a. We provide the code for this version as a fork of the original repository.3 While this adaption of the proposed architecture reduces the number of trainablemodel parameters to 80%, we were able to reproduce the reported performance or even experienced a slight increase in accuracy, as summarised in Table 1a.
2.3 Generalisation and transferability Until that stage, wemainly considered the theoretical aspects of this reproduction study. Conversely, this section focuses on the application-oriented side. In light of our observations described before, we wanted to investigate whether the increased number of parameters in the original model can become beneficial when scaling the underlying classification problem by confronting it with an alternative dataset.
Datasets — Althougha tremendous amount of satellite data, especially from the SENTINEL2 platforms, is publicly available, the computer vision andmachine learning community still lacks labels or annotations for addressing most relevant research questions. Therefore, Garnot et al. [1] did not only publish a newmethod, but also complemented it with a dataset containing crop type labels of more than 190 000 agricultural parcels within the area of a particular tile of the SENTINEL-2 tiling grid T31TFM, located in France.
3https://github.com/maja601/pytorch-psetae
ReScience C 7.2 (#19) – Schneider and Körner 2021 6
Additionally and to evaluate the reproducibility of the presented methodsʼ results on a different input, an analogous dataset with parcels located in Slovenia was constructed in the course of this study. The following two sections gives insight into the background and properties of these two datasets.
FR-T31TFM: Dataset from the paper Unlike CNN-basedmethods, the approach by Garnot et al. does not require the observation data to be stored as imageswith defined neighborhood relations, but rather as an unordered set of pixels for each parcel. From their GITHUB page, a toy dataset containing 500 parcels, each saved as NUMPY data files, can be obtained. To get access to the entire dataset, an inquiry needs to be sent to the authors, which they reply to within no time. This dataset includes 192 056 NUMPY data files of dimension T ×C ×N , with T , C = 10, andN being the number of observations dates, spectral bands, and pixels for each particular parcel, respectively. It additionally comes with several metafiles, i.e., the dates of the observations, the labels of the parcels, the geometric features of the parcels—which are stated to be necessary for the pixel set encoder—, and pre-computed normalisation values. By design, the dataset is randomly partitioned into test, validation, and training parcels, following a split ratio of 3:1:1. This dataset also faces one of the biggest challenges in crop type classification from satellite data, namely the uneven distributed data foundation, as visualised in Figure 3a. In their original paper, Garnot et al. refer to several data preprocessing steps, such as reducing the number of spectral bands delivered by the SENTINEL-2 satellite from 13 to 10, linearly interpolating ground pixels that are affected by cloud cover, normalising the reflectance data, and adding Gaussian noise.
SI-T33TWM: Additional dataset As part of another project at our lab, a pan-European reference dataset for crop type classification is currently under development andwill be made publicly available early next year. This way, we had the chance to use some of the data obtained from Slovenia to construct a pixel set similar to the one presented by Garnot et al. [1]. In order to keep it as close as possible to the original, we selected similar time steps and also performed a linear cloud pixel interpolation on L2A SENTINEL-2 data. As we did not have access to the precise cloud detectionmodule used by the authors, we manually annotated cloudypixels in this regionof interest. Thedataset_preparation.py script provided byGarnot et al. took care of pooling the Sentinel-2 data and the reference data in GEOJSON format. The necessary normalisation parameters had likewise to be calculated manually, as well as the operation to extract the geometric features used in the spatial encoder. Contrasting the description given in the paper under investigation, the sequential order of componentswithin this geometry feature vector differed in away
ReScience C 7.2 (#19) – Schneider and Körner 2021 7
that its second element appeared not to be the pixel count N but rather, as we assume from looking at the original dataset, the area of the bounding box. Considering the labels, we prepared two versions: One file with the previously stated top-20 crop classes from the original dataset, called top-20-F, and another one containing the top-20 classes from our alternatively chosen region, analogously named top-20-S and illustrated in Figure 3b. Since the crop cultivation in Slovenia differs from France, several classes of the original top-20-F were not represented in the new dataset, as shown in Figure 3c. This appears to render the classification on top-20-F an easier problem than on top-20-S. Section 2.4 will provide more background regarding the split of the dataset and to one of the particular difficulties inherent to geospatial data, which is why we put one region aside in advance. This way, we were able to evaluate the performance of the method also on regionally unseen data. A visual explanation of the train and test split is shown in Figure 2.
Cross-dataset evaluation — The first experiment on the generalisation abilities of the describedmethod was performedwith themodel being trained on the FR-T31TFM dataset. After the descriptions of the chosen classes were obtained from the original authors, we picked the same classes from our SI-T33TWM dataset and ran the inference on our prepared test pixel set. Table 1b summarises the overall results, showing that the performance dropped significantly compared to the ones reported previously (cf.Table 1a).
Method application to a different region — Taking advantage of the relatively short training time, it was easily possible to train the entire model on our own data. This way, we evaluated whether the outcomes reported by Garnot et al. could be reproduced, even without having access to data at exactly the same preprocessing level. For this purpose, we ran the experiment twice on the new SI-T33TWM dataset, i.e., first with the top-20F labels and then with the top-20-S labels. In Table 2, the columns random split show the results of these experiments. These can directly be compared to the ones from the paper.
2.4 Experiments on the choice of the test set Beside the issue of limited geometric resolution in SENTINEL-2 data, the influence of spatial autocorrelation has always to be taken into account when dealing with Earth obser-
ReScience C 7.2 (#19) – Schneider and Körner 2021 8
vation satellite imagery [5]. Due to the coarse sampling of the Earths̓ surface, adjacent pixels might share relevant amounts of information with each other. Therefore, using contiguous field parcels for training as well as for testing can lead to non-representative results over-estimating the true performance of the classification model. We tried to account for these effects by reserving an entirely separate region, shown in Figure 2, as an additional test set. This region was selected to approximate one-fifth of the parcels and a class distribution representative for the entire SI-T33TWM dataset. Results of this experiment are included into Table 2, where we compare the original random split to the new regional split.
3 Discussion
This section focuses on the analysis of reproducibility in general and will not justify the authors claim that their method is the current state-of-the-art approach to solve satellite time series classification. We therefore split the findings of the study into two aspects thatwe tried to evaluate: On the onehand, wewill discuss the insightswehave gained by reproducing themethodological process itself, and on the other hand, we will elaborate our approach to reproduce the desired results produced by the method.
3.1 Reproducibility of the method When reimplementing the full architecture, we found that, despite having all parameters at hand, it would have been helpful to have access to more information concerning the data preprocessing and organisation, as well as to the adaption of the original Transformer model [2], to achieve performance similar to that reported by the authors. From our perspective, we cannot tell whether or not better PYTHONprogramming skills would have been beneficial and if someone with more experience with the multi-head attention would have been able to understand and implement the method right away. In any case, the authors certainly developed a coherent methodology and, by providing the
ReScience C 7.2 (#19) – Schneider and Körner 2021 9
corresponding code alongside with the paper, have ensured that all interested parties can clearly follow their ideas. As a result of our misinterpretation of the Transformer adaptation proposed by Garnot et al., we came across an alternative approach that performed comparably well as the one from the paper, but requiring only 80% of its parameters. When we asked the authors about this observation, we concluded that we all had different opinions on the most obvious derivative of the method developed by Vaswani et al. [2] applied to the problem of satellite time series classification. Upon request, the authors of the Transformer paper confirmed that keeping the fully-connected layer FCv has proven to be helpful and acknowledged the validity of our approach. Under these circumstances, it is not straightforwardly answerable whether the implicit claim of having the Transformer adapted in the papersʼ way can be supported. However, it can be said that the well-documented code and clean GITHUB repository contributed strongly to our understanding of the method and helped us answer most of our comprehension question. Since this all is publicly available, a reproduction of the presented method based on that implementation is possible.
3.2 Reproducibility of the outcomes Besides the possibility to reproduce themethodological aspects of the original paper, we were also interested in whether we could achieve the results stated in the investigated paper. By training the entire model by ourselves with the original dataset, we faced no considerable difficulties using the data. We were, in fact, able to achieve a slightly higher overall accuracy on the original test set compared to using themodel pre-trained by the authors. However, a slight drop in performance became observable when we used an alternative yet similarly preprocessed dataset. While we still reached an overall accuracy of over 87% for the random split on our new and potentially more challenging dataset, we were not able to reach 84% when running the inference on a regionally separated test set. This result highlights the importance of the right choice of a representative test set, especially when using Earth observation imagery, while still acknowledging that the presented method is potentially able to generalise to unseen and new data. Nevertheless, our reproduction experiments confirmed the claimed validity of the approach and it is to be left to the authors and the entire research community to investigate whether the presentedmodel is able to compete with state-of-the-art methods given broader and more diverse datasets. The only issue with the presented method arose when we used one dataset for training and another one for testing. Although we tried to preprocess our new dataset exactly the way the authors did, we were not able to obtain convincing results. There might be
ReScience C 7.2 (#19) – Schneider and Körner 2021 10
several reasons causing this issue, like an incorrect harmonisation of the dataset, other parameters for the interpolation of the cloud-covered pixels, or assumptions about the data we unknowingly and implicitly made different than the authors. Hence, it remains interesting for us to know how exactly the data was processed. To summarise, we support the claim that the method can successfully classify crop parcels when it was trained on data that was acquired under the same conditions, as the data it eventually gets tested on.
4 Conclusion
During the proposed study of “Satellite Image Time Series Classification with Pixel-Set Encoders and Temporal Self-Attention” by Garnot et al. [1], we assessed several questions regarding different aspects of the reproducibility of the paper. Therefore, we first attempted to reimplement themethodology from scratch based on the descriptions given in that paper. As this proved to be more challenging than expected and prone to misunderstandings, we proceeded to evaluate the provided clean implementation in terms of an adaption of the Transformer architecture [2]. There, we came across a discrepancy between our understanding of the vanilla multi-head attention concept and the one used in the paper. Our obtained results show that, by changing the proposed adaptation in a subtle way towards the more basic multi-head attention, the model uses considerably fewer parameters, while still performing equally well. When employing the authorsʼ implementation and dataset, we were able to reproduce the presented results straightforwardly and even on a new dataset that we specifically developed for this survey, the approach delivered meaningful results. The only issues arose when the training and the test dataset did not share exactly the same properties lifting the accurate preprocessing of the data to a crucial component of the proposed method. In conclusion, we can state that the examined method is conclusive in itself and valid. Our experiments speak in favour of the approach andourfindingsmight highlight a path in which further works should proceed. This direction of research could take advantage of the dataset which we will make publicly available within the next few months."
"['Arsen Sheverdin', 'Alko Knijff', 'Noud Corten', 'Georg Lange']","[Re] Reproducibility report of ""Interpretable Complex-Valued Neural Networks for Privacy Protection""",10.5281/zenodo.4835431,Replication,Python,https://zenodo.org/record/4835431/files/article.pdf,rescience c rescience x machine learning deep complex valued neural network python pytorch,https://openreview.net/forum?id=P30M7d9DyXw,https://github.com/GANA-FACT-AI/gana-fact-ai,7,2,2021,"In contrast to the first claim, we have discovered that for most of the architectures, reconstruction errors for the attacks are quite low, which means that in our models the first claim is not supported. We also found that for most of the models, the classification error is somewhat higher than those provided in the paper. However, these indeed relate to the original work and partially support the second claim of the authors.","Authors of the original paper utilized famous architectures for some of architecturesʼ parts, such as ResNet and LeNet, that were well explained and defined in the literature. In addition, authors, provided formulas on the modified rotation-invariant Complex DNN modules (ReLU, max pooling etc.), implementation of which was relatively straightforward. The paper was based on the openly available datasets.
Copyright © 2021 A. Sheverdin et al., released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Arsen Sheverdin (arsen.sheverdin@student.uva.nl) The authors have declared that no competing interests exist. Code is available at https://github.com/GANA-FACT-AI/gana-fact-ai. – SWH swh:1:dir:16f75580c3619b9e0b00b6dceef8e5bf2f5a47c4. Open peer review is available at https://openreview.net/forum?id=P30M7d9DyXw.
ReScience C 7.2 (#20) – Sheverdin et al. 2021 1","Thepaper didnot provide any information on the architecture of the critic for theWGAN, along with the architecture of the angle discriminator utilized in inversion attack 1. It also does not provide any information about crucial hyperparameters, such as the k value used for k-anonimity.
Communication with original authors We did not contact the original authors of the publication.
ReScience C 7.2 (#20) – Sheverdin et al. 2021 2
1 Introduction
DeepNeural Networks (DNNs) can process amassive data volume but require great computing power to process this data. Therefore it is an interesting option for small devices like smartphones or IoT devices to use a cloud operator for these computationally expensive tasks. Although this is an efficient way to process data, the cloud operator is susceptible to privacy threats. A potential attacker could reconstruct or infer private properties of the data. Possible solutions are subject of current research. Xiang et al.1 proposed a possible solution using encryption and complex-valued neural networks to address this problem. They showed that their approach increases the difficulty of inferring inputs or properties from intermediate layer features. Our paper aims at reproducing their findings. Xiang et al.1 extended the standard DNN by encrypting the intermediate layer features using complex-valued DNNs (Trabelsi et al.2). The local device encodes the original input into intermediate features. Those features are encrypted and sent to a processing unit, a complex-valued neural net located in the cloud. It does the computationally expensive operations while not being able to infer properties of its input. The result is sent back to the local device and decrypted. Ideally, the local device is able to decrypt the encodeddata using the secret key. However, an adversary shouldnʼt be able to decrypt the features without the key. Xiang et al.1 achieved this by rotating intermediate layer features into the complex plane using a random angle. The angle acts as a key and can be used to reverse the rotation. The processing unit consists of rotation-invariant operations only. Thus, the local device can reverse the rotation after receiving the results from the processing unit. Tomake it hard to deduce the angle, a generative adversarial network is trained to alter the intermediate features to introduce obfuscation whilst keeping important information.
2 Scope of reproducibility
Themain problemXiang et al.1 addresses is the danger of adversary attackers being able to recover original inputs or hidden properties of the input. Xiang et al.1 claim their complex-valued model to be robust against these kinds of adversary attacks and show this by attacking their model with various inversion and inference attacks. Here, they claim that attacking their complex-valued DNNs acquires greater reconstruction loss than when they attack the original DNNs, meaning they are more resistant to adversary attacks. Furthermore, even though the input is encoded, they claim that their complexvalued DNNs have almost the same utility performance (classification error rates) as the original DNNs. In this paper, we test the following concrete claims:
1. Xiang et al.1 proposed complex-valued DNNs effectively boost the difficulty of inferring inputs for the adversary compared to the baseline.
2. Xiang et al.1 proposed their privacy-preserving complex-valued DNN largely preserves the accuracy when compared to the baseline.
3 Methodology
The paper from Xiang et al.1 was replicated 1 by solely using the methods described in their paper, since there was no implementation available online. Our approach involved implementing the models used by Xiang et al.1, which included the ResNet-α, β20/32/44/56/110 (He et al.3), the LeNet (Lecun et al.4), the VGG-16 (Simonyan and Zisser-
1Our implementation can be found at our GitHub (https://github.com/GANA-FACT-AI/gana-fact-ai)
ReScience C 7.2 (#20) – Sheverdin et al. 2021 3
man5) and the AlexNet (Krizhevsky, Sutskever, and Hinton6). Most of these papers had implementations available online, which were adjusted slightly to be able to process complex-valued intermediate layer features. Furthermore, these DNNs had to be disassembled to create the complex-valued DNN structure proposed by Xiang et al.1 that consists of an encoder, processing module and decoder. The encoder is in principle the same as the first few layers of the used DNN, but at the end of the encoder a complex rotation is applied (Eq. 1).
x = exp(iθ)[a+ bi] (1)
The value a represents the regular input that is put through the encoder. The value b is the fooling counterpart that can be seen as a different input that is also put through the encoder. Theta is picked to be random angle, which will act as the secret key we mentioned earlier. The resulting features are then fed to the processing unit. The processing unit consists of the middle layers of the used DNN. The processing unit has to deal with complex features, which means adjustments had to be made to the regular functions that the DNN uses. We used the proposed functions in Trabelsi et al.2 to achieve this. Furthermore it is important that the processing unit does not change the rotation of the features, because otherwise if we try to rotate it back with our randomly picked angle we will get random results. Therefore we also had to make the used functions rotation invariant. Methods for achieving this were described in Xiang et al.1. Finally the features are put through the decoder, which consists of the final layers of the used DNN. The decoder first rotates the features back with the randomly picked angle (Eq. 2) and then feeds the result to the final layers.
ŷ = d(R[h exp(−iθ)]) (2)
The value h represents the output of the processing unit and the value ŷ is the prediction that the decoder d made. Xiang et al.1 also uses a Wasserstein Generative Adversarial Network which was proposed by Arjovsky, Chintala, and Bottou7 and is part of the encoder. ThisWGAN consists of a generator and a critic that use complex rotations to teach the network to generate synthesized features to hide the original ones. Since no implementation with a WGAN that works with complex-valued features was available online, this WGAN encoder had to be completely remade. Lastly, for the adversary attacks, Xiang et al.1 attacked the model with inversion and inference attacks. For the inversion attacks, we adopted the U-netmodel proposed by Ronneberger, Fischer, and Brox8, which had similar variants online that had to be hardly modified to fit their implementation. For the inference attack, a model had to be implemented that functions as a classifier to predict hidden properties of the input.
3.1 Model descriptions
Complex-valued DNNs — In Xiang et al.1 approach, the DNN is split into two local parts that are used to encode and decode the data (encoder and decoder, respectively) and a middle part that performs all of the heavy data processing (processing module). In the originalwork, twoResNet implementationswere described: ResNet-α andResNetβ. In ResNet-α the input is transformed until the first 16x16 featuremap, fromwhere the output is sent to the encoder. After the encoding, the processingmodule transforms the data until the first 8x8 feature map. From that point on, all following layers constitute to the decoder. The difference in ResNet-β is that the decoder was composed by the last residual block and the layers following it. For describing the other classical DNNs, we only specify the encoder and the decoder, where all the remaining layers contribute to the processing unit. For the LeNet model,
ReScience C 7.2 (#20) – Sheverdin et al. 2021 4
the encoder consisted of the first convolutional layer and the WGAN, whereas the decoder contained only the softmax layer. In the VGG-16 all layers before the last 56x56 feature map constituted the encoder. Here, the decoder consisted of fully-connected layers and the softmax layer. For the AlexNet, the first three convolutional layersʼ output was fed into the encoder, where the decoder contained fully-connected layers and the softmax layer.
WGAN — To introduce obfuscation and make it hard for the adversary to reconstruct the original features, a WGAN is utilized. A WGAN is a variant of a generative adversarial network known to be more resistant against hyperparameters or mode collapse compared to the original approach. TheWGANs encoder is used to introduce obfuscation to the features. The critic is only used to train the generator, and its objective is to distinguish rotated features from those without rotation. The generator of the WGAN shares the same network as the encoder we described earlier. This means that one part of the network (the encoder/generator) is trained with two different purposes; One is for classification and the other is for the WGAN. To train the generator, the encoded and rotated (Eq. 1) features it produced are passed to the critic, which is trying to retrieve the original features by rotating the given features back.
a′ = ℜ[x exp(−iθ′] (3)
The critic creates k-1 fake samples and rotates them by k-1 randomly sampled angles θ′ (Eq. 3), where θ′ ̸= θ. The critic then discriminates whether these rotated features are close to the original complex-valued features. From Xiang et al.1, it was unclear whether the generator is only a part of the encoder or whether the WGAN trains all encoder layers. Because no architecture was given for the generator, we decided to train all the encoder layers with the WGAN loss and not introduce a stand-alone generator after the encoder. The original WGAN uses weight clipping for the critic network. However we found that all theweights converged to the clipping values rather quickly. Because of thiswe cannot train the WGAN appropriately. To fix this issue we used a gradient penalty which was introduced in Gulrajani et al.9.
Adversary models — Inversion attacks The objective of the inversion attack was to reconstruct the input images from the encoded intermediate features. Xiang et al.1 implemented two inversion attacks: in inversion attack 1 a new discriminator (D′) is first trained to predict the most probable features (a∗) by learning the most likely angle at which the intermediate layer features are rotated (Eq. 4). The most probable features (Eq. 5) are then used to help train a decoder model that tries to reconstruct the original images (Eq. 6). In inversion attack 2 the angle prediction discriminator is not included and the attacker only trains a decoder that tries to reconstruct the original images from the given intermediate layer features.
θ̂ = max θ
D′(ℜ[x exp(−iθ̂) (4)
a∗ = ℜ[x exp(−iθ̂] (5) Î = dec(a∗) (6)
The structure of the reconstruction model for both inversion attacks was based on a modified U-Net (Ronneberger, Fischer, and Brox8) described in the original work. UNet is a neural network architecture widely used for image segmentation. It is based on an Autoencoder architecture decorated by skip connections. The skip connections help to reconstruct the exact low-level attributes such as the location of edges. Intermediate
ReScience C 7.2 (#20) – Sheverdin et al. 2021 5
layer features from the encoder are scaled up to the original input size and then fed into the U-Net, aiming to reconstruct the original image. Inference attacks During inference attacks a classifier is trained on either similar raw images (inference 1), rotated features a∗ (inference 2) or fully reconstructed images Î (inference 3). Furthermore, amodel is trained using k-nearest neighbors (k-NNs), where the attacker compares a∗ against features of each training example to find similarities in the training set. We did not implement the inference attacks, because the results of the inversion attacks showed that the privacy protection was not working properly. Instead of implementing the inference attacks, which would yield similar poor results, we decided to investigate further into why the privacy protection was not working.
3.2 Datasets
Xiang et al.1 used CIFAR-10/100 (Krizhevsky10) to train the ResNets and LeNet, CUB-200 (Welinder et al.11) to train VGG-16 and CelebA (Liu et al.12) for AlexNet. Since we did not implement VGG-16 and AlexNet, we only used the CIFAR-10/100 datasets using the train/test split described in Table 1. Each split was halved to create two smaller datasets used for training/testing either the privacymodel or the adversary attacker. Before training, all datasets were normalized.
3.3 Hyperparameters Unfortunately, none of the standard hyperparameters such as learning rate, optimizer, weight decay, etc. were mentioned in the paper. Therefore we had to adapt and choose them ourselves. For the WGAN, we used the hyperparameters given in the original implementation by Arjovsky, Chintala, and Bottou7. We implemented weight clipping and gradient penalty. For the first one, we used RMSprop with a learning rate of 5e−5 for both the generator and the critic. Weights were clipped between −0.01 and 0.01 for the Critic s̓ weights. As this learning rate was too low for the classification task, we used a different optimizer. Adam was used with a learning rate of 5e−4. For the gradient penalty approach, we set lambda to 10 and used Adam with a learning rate of 5e−4. We did not do an intensive hyperparameter search to optimise these parameters. Finally, another hyperparameter specific to this paper is called k. k represents the number of times the discriminator decides on an input per iteration. The discriminator always has to calculate a real score based on the real features a, so there are k-1 fake inputs that determine the fake score. This hyperparameter is also never defined in the paper. We set the k value on 8, and we have not been able to test other options, unfortunately. We trained our adversary networks with the Adam optimizer and a learning rate of 5e−4. For training the U-net we used the Mean Squared Error loss and for training the angle predictor network we used the Absolute Mean loss.
3.4 Experimental setup and code Since PyTorch currently does not fully support complex-valued tensors, we chose to split up the ʼrealʼ part and the ʼimaginary partʼ into two tensors, where we have created new complex functions to process these two tensors correctly.
ReScience C 7.2 (#20) – Sheverdin et al. 2021 6
We introduced complex and, most-importantly, rotation-invariant ReLU, BatchNorm, and MaxPool layers according to the original work s̓ formulae. In addition, we have also discovered that for Complex Linear Layers, the bias term should not be involved in matrix computations, even though it was only mentioned for the case Complex Convolutional Layers in the original paper. The architecture of processing unit is designed so that after the the features x from encoder are passed through processing unit, we could express the output as a complex rotation of outputs of processing unit, i.e Φ(x), specifically it means:
Φ(eiθx) = eiθΦ(x) (7)
To keep the equation 7 true for the Convolutional Linear Layers Φ(eiθx) and eiθΦ(x) should be equal to each other, meaning that for:
Φ(eiθx) = w · (eiθx) + b (8)
eiθΦ(x) = eiθ(w · x+ b) (9)
Given any θ, we see that the equality would hold only if b = 0, which would mean that no bias term would be needed. This is exactly the objective of rotation invariance for our network as it was mentioned in the publication. In the original work, the Critic s̓ architecture was not described, so some assumptions regarding its architecture were made. We found that one linear layer is not sufficient. Thus, we added a convolution, a ResNet block and another convolution. Since the LeNet network looks very different from theResNet networkswe decided to change to the critic architecture to look more like the generator of LeNet. In the paper, they describe how the decoder of the AlexNet only consists of a softmax layer. This is not possible, because they train the network on the attributes of CelebA and since multiple attributes per image are used, introduction of a sigmoid function is essential. The output of the last layer in the decoder is a sigmoid and the binary crossentropy loss is applied in order to estimate how well it assigns attributes to each image. The paper implements inversion and inference attacks to test whether it is preserving the privacy. For inversion attack 1 it uses a network to determine the angle that wasmost likely used for rotation. We decided to implement this network by creating a network that is identical to the critic that we used for that specific network. TheU-Net architecture used in the inversion attacks is constructed using 6 convolutional layers per block, instead of the standard 2 convolutional layers per block. Furthermore, the U-net architecture consisted of 4 down and 4 upsampling blocks. Each downsampling block reduced the featuresʼ dimensions by 2, while the up-sampling ones doubled the aforementioned dimensions. Thus, input and output imagewidths and heightswere preserved. We found that the inversion attacks were reconstructing the images very well when we used them on our trained networks. Adding a convolution layer without a ReLU activation function to our generator increased the overall reconstruction loss, effectively making our network preserve the privacy better. This was further improved by randomly swapping a and b in our generator, which lead to a significant increase in the reconstruction loss. From all the networks that were used in Xiang et al.1 we implemented LeNet and the ResNet-32/44/56/110-α, β architectures. We did not implement the other architectures, because the ResNet and LeNet architectures showed that the privacy protection was not working as described. We decided to continue our investigation into ResNet and LeNet, instead of implementingmore networks whichwould face the same problems as ResNet and LeNet.
ReScience C 7.2 (#20) – Sheverdin et al. 2021 7"
"['Varun Sundar', 'Rajat Vadiraj Dwaraknath']",[Re] Rigging the Lottery: Making All Tickets Winners,10.5281/zenodo.4835564,Replication,Python,https://zenodo.org/record/4835564/files/article.pdf,rescience c rescience x python pytorch sparse-networks,https://openreview.net/forum?id=riCIeP6LzEE,https://github.com/varun19299/rigl-reproducibility,7,2,2021,"For a fixed parameter count and compute budget, the proposed algorithm (RigL) claims to directly train sparse networks thatmatch or exceed the performance of existing denseto-sparse training techniques (such as pruning). RigL does so while requiring constant Floating Point Operations (FLOPs) throughout training. The technique obtains state-ofthe-art performance on a variety of tasks, including image classification and characterlevel language-modelling.",The authors provide code for most of the experiments presented in the paper. The code was easy to run and allowed us to verify the correctness of our re-implementation. The paper also provided a thorough and clear description of the proposed algorithmwithout any obvious errors or confusing exposition.,"Tuning hyperparameters involved multiple random seeds and took longer than anticipated. Verifying the correctness of a few baselines was tricky and required ensuring that the optimizer s̓ gradient (or momentum) buffers were sparse (or dense) as specified by the algorithm. Compute limits restricted us from evaluating on larger datasets such as Imagenet.
Communication with original authors We had responsive communication with the original authors, which helped clarify a few implementation and evaluation details, particularly regarding the FLOP counting procedure.
ReScience C 7.2 (#21) – Sundar and Dwaraknath 2021 2
1 Introduction
Sparse neural networks are a promising alternative to conventional dense networks— having comparatively greater parameter efficiency and lesser floating-point operations (FLOPs) (Han et al., Ashby et al., Srinivas, Subramanya, and Venkatesh Babu1,2,3). Unfortunately, present techniques to produce sparse networks of commensurate accuracy involve multiple cycles of training dense networks and subsequent pruning. Consequently, such techniques offer no advantage over training dense networks, either computationally or memory-wise.
In the paper Evci et al.4, the authors propose RigL, an algorithm for training sparse networks from scratch. The proposedmethod outperforms both prior art in training sparse networks, as well as existing dense-to-sparse training algorithms. By utilising dense gradients only during connectivity updates and avoiding any global sparsity redistribution, RigL canmaintain a fixed computational cost and parameter count throughout training.
As a part of the ML Reproducibility Challenge, we replicate RigL from scratch and investigate if dynamic-sparse training confers significant practical benefits compared to existing sparsifying techniques.
2 Scope of reproducibility
In order to verify the central claims presented in the paper we focus on the following target questions:
• Does RigL outperform existing sparse-to-sparse training techniques—such as SET (Mocanu et al.5) and SNFS (Dettmers and Zettlemoyer6)—and match the accuracy of dense-to-sparse training methods such as iterative pruning (Zhu and Gupta7)?
• RigL requires two additional hyperparameters to tune. We investigate the sensitivity of final performance to these hyperparameters across a variety of target sparsities (Section 5.3).
• How does the choice of sparsity initialization affect the final performance for a fixed parameter count and a fixed training budget (Section 6.1)?
• Does redistributing layer-wise sparsity during connection updates (Dettmers and Zettlemoyer6) improve RigL s̓ performance? Can the final layer-wise distribution serve as a good sparsity initialization scheme (Section 6.2)?
3 Methodology
The authors provide publicly accessible code1 written in Tensorflow (Abadi et al.8). To gain a better understanding of various implementation aspects, we opt to replicate RigL in Pytorch (Paszke et al.9). Our implementation extends the open-source code2 ofDettmers and Zettlemoyer6 which uses a boolean mask to simulate unstructured sparsity. Our source code is publicly accessible on Github3 with training plots available on WandB4 (Biewald10).
1https://github.com/google-research/rigl 2https://github.com/TimDettmers/sparse_learning 3https://github.com/varun19299/rigl-reproducibility 4https://wandb.ai/ml-reprod-2020
ReScience C 7.2 (#21) – Sundar and Dwaraknath 2021 3
Mask Initialization — For a network with L layers and total parameters N , we associate each layer with a randombooleanmask of sparsity sl, l ∈ [L]. The overall sparsity of the network is given by S = ∑ l slNl N , where Nl is the parameter count of layer l. Sparsities sl are determined by the one of the following mask initialization strategies:
• Uniform: Each layer has the same sparsity, i.e., sl = S ∀l. Similar to the original authors, we keep the first layer dense in this initialization.
• Erdos-Renyi (ER): Following Mocanu et al.5, we set sl ∝ ( 1− Cin+CoutCin×Cout ) , where
Cin, Cout are the in and out channels for a convolutional layer and input and output dimensions for a fully-connected layer.
• Erdos-Renyi-Kernel (ERK):Modifies the sparsity rule of convolutional layers in ER initialization to include kernel height and width, i.e., sl ∝ ( 1− Cin+Cout+w+hCin×Cout×w×h ) , for
a convolutional layer with Cin × Cout × w × h parameters.
Wedonot sparsify either bias or normalization layers, since these have anegligible effect on total parameter count.
Mask Updates — Every∆T training steps, certain connections are discarded, and an equal number are grown. Unlike SNFS (Dettmers and Zettlemoyer6), there is no redistribution of layer-wise sparsity, resulting in constant FLOPs throughout training.
Pruning Strategy — Similar to SET and SNFS, RigL prunes f fraction of smallest magnitude weights in each layer. As detailed below, the fraction f is decayed across mask update steps, by cosine annealing:
f(t) = α
2
( 1 + cos ( tπ
Tend
)) (1)
where, α is the initial pruning rate and Tend is the training step after whichmask updates are ceased.
Growth Strategy — RigL s̓ novelty lies in how connections are grown: during every mask update, k connections having the largest absolute gradients among current inactive weights (previously zero + pruned) are activated. Here, k is chosen to be the number of connections dropped in the prune step. This requires access to dense gradients at each mask update step. Since gradients are not accumulated (unlike SNFS), RigL does not require access to dense gradients at every step. Following the paper, we initialize newly activated weights to zero.
4 Experimental Settings
4.1 Model descriptions
For experiments onCIFAR-10 (AlexKrizhevsky11), weuse aWideResidualNetwork (Zagoruyko and Komodakis12) with depth 22 and width multiplier 2, abbreviated as WRN-22-2. For experiments on CIFAR-100 (Alex Krizhevsky11), we use a modified variant of ResNet-50 (He et al.13), with the initial 7× 7 convolution replaced by two 3× 3 convolutions (architecture details provided in the supplementary material).
ReScience C 7.2 (#21) – Sundar and Dwaraknath 2021 4
On both datasets, we train models for 250 epochs each, optimized by SGD with momentum. Our training pipeline uses standard data augmentation, which includes random flips and crops. When training on CIFAR-100, we additionally include a learning rate warmup for 2 epochs and label smoothening of 0.1 (Goyal et al.14). We also initialize the last batch normalization layer (Ioffe and Szegedy15) in each BottleNeck block to 0, following He et al.16.
4.3 Hyperparameters RigL includes two additional hyperparameters (α,∆T ) in comparison to regular dense network training. In Sections 5.1 and 5.2, we set α = 0.3,∆T = 100, based on the original paper. Optimizer specific hyperparameters—learning rate, learning rate schedule, and momentum—are also set according to the original paper. In Section 5.3, we tune these hyperparameters with Optuna (Akiba et al.17). We also examine whether indivdually tuning the learning rate for each sparsity value offers any significant benefit.
4.4 Baseline implementations
We compare RigL against various baselines in our experiments: SET (Mocanu et al.5), SNFS (Dettmers and Zettlemoyer6), and Magnitude-based Iterative-pruning (Zhu and Gupta7). We also compare against two weaker baselines, viz., Static Sparse training and Small-Dense networks. The latter has the same structure as the dense model but uses fewer channels in convolutional layers to lower parameter count. We implement iterative pruning with the pruning interval kept same as the masking interval for a fair comparison.
4.5 Computational requirements We run our experiments on a SLURM cluster node—equipped with 4 NVIDIA GTX1080 GPUs and a 32 core Intel CPU. Each experiment on CIFAR-10 and CIFAR-100 consumes about 1.6 GB and 7 GB of VRAM respectively and is run for 3 random seeds to capture performance variance. We require about 6 and 8 days of total compute time to produce
ReScience C 7.2 (#21) – Sundar and Dwaraknath 2021 5
all results, including hyper-parameter sweeps and extended experiments, on CIFAR-10 and CIFAR-100 respectively.
5 Results
Given a fixed training FLOP budget, RigL surpasses existing dynamic sparse training methods over a range of target sparsities, on both CIFAR-10 and 100 (Sections 5.1, 5.2). By training longer, RigLmatches ormarginally outperforms iterative pruning. However, unlike pruning, its FLOP consumption is constant throughout. This a prime reason for using sparse networks, and makes training larger networks feasible. Finally, as evaluated on CIFAR-10, the original authorsʼ choice of hyper-parameters are close to optimal for multiple target sparsities and initialization schemes (Section 5.3).
5.1 WideResNet-22 on CIFAR-10 Results on the CIFAR-10 dataset are provided in Table 2. Tabulatedmetrics are averaged across 3 random seeds and reported with their standard deviation. All sparse networks use random initialization, unless indicated otherwise.
While SET improves over the performance of static sparse networks and small-dense networks, methods utilizing gradient information (SNFS, RigL) obtain better test accuracies. SNFS can outperform RigL, but requires a much larger training budget, since it (a) requires dense gradients at each training step, (b) redistributes layer-wise sparsity during mask updates. For all sparse methods, excluding SNFS, using ERK initialization improves performance, but with increased FLOP consumption. We calculate theoretical FLOP requirements in a manner similar to Evci et al.4 (exact procedure is described
ReScience C 7.2 (#21) – Sundar and Dwaraknath 2021 6
in the appendix).
Figure 1 contains test accuracies of selectmethods across two additional sparsity values: (0.5, 0.95). At lower sparsities (higher densities), RigL matches the performance of the dense baseline. Performance further improves by training for longer durations. Particularly, training RigL (ERK) twice as long at 90% sparsity exceeds the performance of iterative pruning while requiring similar theoretical FLOPs. This validates the original authorsʼ claim that RigL (a sparse-to-sparse training method) outperforms pruning (a dense-to-sparse training method).
5.2 ResNet-50 on CIFAR100
Wesee similar trendswhen training sparse variants of ResNet-50 on theCIFAR-100 dataset (Table 3,metrics reported as in Section 5.1). We also include a comparison against sparse networks trained with the Lottery Ticket Hypothesis (Frankle and Carbin18) in Table 3—we obtain tickets with a commensurate performance for sparsities lower than 80%.
ReScience C 7.2 (#21) – Sundar and Dwaraknath 2021 7
Finally, the choice of initialization scheme affects the performance and FLOP consumption by a greater extent than the method used itself, with the exception of SNFS (groups 1 and 2 in Table 3).
5.3 Hyperparameter Tuning
(α,∆T ) vs Sparsities — To understand the impact of the two additional hyperparameters included in RigL, we use a Tree of Parzen Estimator (TPE sampler, Bergstra et al.19) via Optuna to tune (α,∆T ). We do this for sparsities (1 − s) ∈ {0.1, 0.2, 0.5}, and a fixed learning rate of 0.1. Additionally, we set the sampling domain for α and∆T as [0.1, 0.6] and {50, 100, 150, ..., 1000} respectively. We use 15 trials for each sparsity value, with our objective function as the validation accuracy averaged across 3 random seeds.
ReScience C 7.2 (#21) – Sundar and Dwaraknath 2021 8
Table 4 shows the test accuracies of tuned hyperparameters. While the reference hyperparameters (original authors, α = 0.3,∆T = 100) differ from the obtained optimal hyperparameters, the difference in performance is marginal, especially for ERK initialization. This in agreement with the original paper, which finds α ∈ {0.3, 0.5},∆T = 100 to be suitable choices. We include contour plots detailing the hyperparameter trial space in the supplementary material.
Learning Rate vs Sparsities —We further examine if the final performance improves by tuning the learning rate (η) individually for each sparsity-initialization pair. We employ a grid search over η ∈ {0.1, 0.05, 0.01, 0.005} and (α,∆T ) ∈ {(0.3, 100), (0.4, 200), (0.4, 500), (0.5, 750)}. As seen in Figure 3, η = 0.1 and η = 0.05 are close to optimal values for a wide range of sparsities and initializations. Since these learning rates also correspond to good choices for the Dense baseline, one can employ similar values when training with RigL.
6 Results beyond Original Paper
6.1 Sparsity Distribution vs FLOP Consumption
While ERK initialization outperforms Random initialization consistently for a given target parameter count, it requires a higher FLOPbudget. Figure 4 compares the two initialization schemes across fixed training FLOPs. Theoretical FLOP requirement for Random initialization scales linearly with density (1 − s), and is significantly lesser than ERK s̓ FLOP requirements. Consequently, Random initialization outperforms ERK initialization for a given training budget.
6.2 Effect of Redistribution One of themain differences ofRigL over SNFS is the lack of layer-wise redistribution during training. We examine if using a redistribution criterion can be beneficial and bridge the performance gap between Random and ERK initialization. Following Dettmers and Zettlemoyer6, during every mask update, we reallocate layer-wise density proportional to its average sparse gradient or momentum (RigL-SG, RigL-SM).
Table 5 shows that redistribution significantly improves RigL (Random), but not RigL (ERK). We additionally plot the FLOP requirement against training steps and the final sparsity distribution in Figure 5. The layer-wise sparsity distribution largely becomes constant within a few epochs. The final distribution is similar, but more “extreme” than ERK—wherever ERK exceeds/falls short of Random, redistribution does so by a greater
ReScience C 7.2 (#21) – Sundar and Dwaraknath 2021 9
extent.
By allocating higher densities to 1 × 1 convolutions (convShortcut in Figure 5), redistribution significantly increases the FLOP requirement—and hence, is not a preferred alternative to ERK. Surprisingly, initializing RigLwith the final sparsity distribution in a manner similar to the Lottery Ticket Hypothesis results in subpar performance (group 3, Table 5).
7 Discussion
Evaluated on image classification, the central claims of Evci et al.4 hold true—RigL outperforms existing sparse-to-sparse training methods and can also surpass other denseto-sparse training methods with extended training. RigL is fairly robust to its choice of hyperparameters, as they can be set independent of sparsity or initialization. We find that the choice of initialization has a greater impact on the final performance and compute requirement than the method itself. Considering the performance boost obtained by redistribution, proposing distributions that attain maximum performance given a FLOP budget could be an interesting future direction.
ReScience C 7.2 (#21) – Sundar and Dwaraknath 2021 10
For computational reasons, our scope is restricted to small datasets such asCIFAR-10/100. RigL s̓ applicability outside image classification—in Computer Vision and beyond (machine translation etc.) is not covered here.
What was easy — The authorsʼ code covered most of the experiments in their paper and helped us validate the correctness of our replicated codebase. Additionally, the original paper is quite complete, straightforward to follow, and lacked any major errors.
What was difficult — Implementation details such as whether momentum buffers were accumulated sparsely or densely had a substantial impact on the performance of SNFS. Finding the right ϵ for ERK initialization required handling of edge cases—when a layer s̓ capacity is exceeded. Hyperparameter tuning (α,∆T ) involved multiple seeds and was compute-intensive.
Communication with original authors —We acknowledge and thank the original authors for their responsive communication, which helped clarify a great deal of implementation and evaluation specifics. Particularly, FLOP counting for various methods while taking into account the changing sparsity distribution. We also discussed experiments extending the original paper—as towhether the authors had carried out a similar study before."
"['Pieter Bouwman', 'Yun Li', 'Rogier van der Weerd', 'Frank Verhoef']",[Re] Reproducibility study - Does enforcing diversity in hidden states of LSTM-Attention models improve transparency?,10.5281/zenodo.4835592,Replication,Python,https://zenodo.org/record/4835592/files/article.pdf,Attention NLP Transparency Explainability Faithfulness Plausibility Reproducibility LSTM ReScience,https://openreview.net/forum?id=lE0wqKGROKa,https://github.com/MotherOfUnicorns/FACT_AI_project,7,2,2021,"Methodology — The paper includes a link to a repository with the code used to generate its results. We follow four investigative routes: (i) Replication: we rerun experiments on datasets from the paper in order to replicate the results, and add the results that are missing in the paper; (ii) Code review: we scrutinize the code to validate its correctness; (iii) Evaluation methodology: we extend the set of evaluation metrics used in the paper with the LIME method, in an attempt to resolve inconclusive results; (iv) Generalization to other architectures: we test whether the authorsʼ claims apply to variations of the base model (more complex forms of attention and a BiLSTM encoder).",,
"['Ivo Verhoeven', 'Xinyi Chen', 'Qingzhi Hu', 'Mario Holubar']",[Re] Replication Study of 'Generative causal explanations of black-box classifiers',10.5281/zenodo.4835600,Replication,python,https://zenodo.org/record/4835600/files/article.pdf,rescience c rescience x python causal explanations variational  autoencoders  explainable  artificial  intelligence post-hoc explanation,https://openreview.net/forum?id=Vqtf4kZg2j,https://github.com/shin-ee-chen/UvA_FACT_2021,7,2,2021,"We verify the outcome of the methodology proposed in the article, which attempts to provide post-hoc causal explanations for black-box classifiers through causal reference. This is achieved by replicating the code step by step, according to the descriptions in the paper. All the claims in the paper have been examined, and we provide additional metric to evaluate the portability, expressive power, algorithmic complexity and the data fidelity of their framework. We have further extended their analyses to consider all benchmark datasets used, confirming results.","The original paper comes with extensive appendices, many of which contain crucial details for implementation and understanding of the intended function. The authors provide code for most of the experiments presented in the paper. Although at the beginning their code repository was not functional, we use it as a reference to re-implement our code. The author also updated their code two weeks after we start our own implementation, whichmade it easy for us to verify the correctness of our re-implementation.","The codebase the authors provided was initially unusable, with missing or renamed imports, hardcoded filepaths and an all-around convoluted structure. Additionally, the description of Algorithm 1 is quite vague and no implementation of it was given. Beyond this, computational expense was a serious issue, given the need for inefficient training steps, and re-iterating training several times for hyperparameter search.
Communication with original authors This reproducibility study is part of a course on fairness, accountability, confidentiality and transparency in AI. Since it is a course project where we interactedwith other group in the forum, and another group also working with this paper has reached out to the authors about problems with the initial repository, we did not find necessary to do it again.
1 Introduction
Machine learning is increasingly used in different applications. The wide-scale spread of these methods places more emphasis on transparent algorithmic decision making, which has the potential tomitigate the potential for disruptive social effects. Yet, despite reliable results of complex black boxes, their internal reasoning and inner workings are not necessarily apparent to end-users or even designers. As a result, not even trained experts can grasp the reasoning behind forecasts. Moreover, modern legislation have necessitated the opportunity challenging these systems, especially in heavily regulated domains, increasing the need for machine learning systems that are (post-hoc) interpretable [1].
Black-box artificial intelligence approaches likeDeepNeuralNetworkshave oftenproven to be able to capture complex dependencies within data, and allow for making accurate predictions. However, the actual internal logic used by systems dependent on such approaches is often nebulous or totally unclear. In this paper, we will reproduce the paper which focuses on the explainability aspect of AI.
Explainable Artificial Intelligence (XAI) refers to systems that seek to clarify how a blackbox AImodel achieves its performance. Post-hoc XAI achieves the desired explainability be generating reasons for decisions after having trained a black-box classifier. This is often achieved by extracting correlations between input features and the eventual forecasts [2]. This paper aims to reproduce such a post-hoc XAI algorithm, capable of providing clear and interpretable explanations for complex black-box classifiers [3]. The central contribution made by [3] is placing explanations in a causal-generative framework. By using a variational auto-encoder (VAE) [4] , low dimensional representations of the data canbe achieved. By further incorporating amutual information loss between the classifier and the latent variables, the latent space is decorrelated into factors that
ReScience C 7.2 (#23) – Verhoeven et al. 2021 2
actively influence the classifier s̓ prediction, and those that capture superfluous variation in the underlying dataset. The causal-VAE , dubbed a generative causal explainer (GCE) by [3] can be studied and intervened with to provide a powerful framework for inducing explainability.
There exists literature suggesting that some studies cannot be replicated [5]. This is valid also for the most respected journals and conferences in AI. Steps must be taken to ensure high trustworthiness of AI algorithms [6]. In the experiments presented here, we re-implement the framework used by [3], extend their analyses to all benchmark datasets discussed and provide an extension to a novel domain. When beginning our process, the officially provided code repository corresponding to the authorsʼ publication was not capable of running in all discussed scenarios, nor producing results similar to those presented 2. However, our re-implementation has ascertained all results, and been extended to incorporate all analyses, and can report their framework to be reproducible. All code has been made publicly available via a Github repository3.
2 Scope of Reproducibility
The original paper establishes a causal inference framework. While intuitive, this introduces the additional challenge of balancing causal intervention with expressive latent variables. To overcome this hurdle, [3] integrate causal inference into the VAE learning objective. This system consists of two basic components: a way to describe the data distribution, and a method of generating a consistent classification model. In order to get a clear objective of the reproduction, we consider the the main claim(s) of the original paper as:
• Claim 1: creating a generative framework that describes a black-box classifier, and a process that achieves this while maintaining latent descriptions that result in high data fidelity and scalability of the overall system
• Claim 2: their objective function helps the generativemodel disentangle the latent variables into causal and non-causal factors for the classifier. Their approach is sufficient for any black-box classifier that can provide class gradients and probabilities with respect to the classifier input
• Claim 3: the resulting explanations show what is important to the accompanying classifier
• Claim 4: the learned representation may also be used to explain counterfactual explanations as it incorporates both generative and causal modelling
The standard of reproducibility demands that machine learning methods be routinely evaluated on the verifiability of their results. The following additional metrics (properties) will be used as measurement of reproducibility:
• Portability: themodelling domains and types ofmachine learningmodels that can benefit from their framework
• Expressive Power: the explanation structure that can be produced by their framework
• Algorithmic Complexity: the computational complexity of their algorithm 2Since, the authors have responded to suggestions and rewritten their code base substantially. 3https://github.com/shin-ee-chen/UvA_FACT_2021
ReScience C 7.2 (#23) – Verhoeven et al. 2021 3
• Data Fidelity: the degree of precision of the datawill range from low tohighfidelity. In cases where high-faithfulness data to train the model are not necessary, lowfaithfulness data often may be used. The small amount of usable data will greatly influence the model s̓ ability to yield accurate estimates.
3 Project Description
As stated, we evaluate the performance of the method proposed in paper[3] as a causal post-hoc explainer of black-box classifiers by reproducing the code necessary. At the beginning of this project, the code provided by the authors was not in a usable state. Hence, we decided to reimplement the code for the necessary architectures and conduct experiments with the implementation details provided in the paper. By the time we finished our implementation, the project repository had been updated to be able to reproduce the initial claims in the paper. Beyond just re-implementing already existing code, two extensions were considered. First, the paper suggests a technique for selecting theK, L and λ hyperparameters used to train the generative model (Algorithm 1). However, no implementation of this algorithm is present in the authorsʼ code. To test its validity and because of the tedious and time-consuming nature of manual hyper-parameter search, we implemented the automated algorithm using reasonable assumptions. Second, in an effort to verify the robustness of this method, similar experiments for image classification were also conducted using a textual domain. Compared to the simple image benchmark datasets used in the initial experiments, text classification and generation are considerably more complex. These models will be used to test the scalability of the proposed framework.
4 Methodology
The Generative Causal Explainer (GCE), is at its core a generative model with awareness of a discriminative black-box classifier. For the generative model, this paper exclusively uses the Variational Auto-Encoder (VAE) [4]. While the VAE allows expression of a dataset in terms of a low-dimensional posterior distribution, the addition of the classifier allows for disentangling the proposed latent space into variable subsets that causally influence decisions of the classifier and those that capture superfluous variance. The former subset is denoted α, whereas the latter is denoted β, having cardinalitiesK and L respectively. The goal of this modelling framework is to learn a generative mapping g : (α, β) → X that further satisfies the following criteria: p(g(α, β)) ≈ p(X), the factors (α, β) are statistically independent and α has strong clausal influence on the classifier s̓ output Y . The proposed objective function of this framework is thus,
argmax g∈G C(α, Y ) + λ · D(p(g(α, β)), p(X)) (1)
where g is theGCEmodel that satisfies the constraints from the set of possible generative models G, C(α, Y ) is a metric that quantifies the causal influence of α on Y and D is a variational lower bound thatmeasures the proximity of p(g(α, β)) to p(X). The inclusion of the D(p(g(α, β)), p(X)) is necessary to ensure the generated explanations remain in, and ideally closely approximate, the data distribution. While there are several candidates for a causal influence metric, the original authors opted for the information theoretic motivated mutual information (MI). OʼShaughnessy et al. offer several reasons for choosingMI, including its compatibility with deep neural networks, its ability to quantify indirect causal links between the GCE s̓ latent space and
ReScience C 7.2 (#23) – Verhoeven et al. 2021 4
the classifier, and its equivalence to ʻinformation flowʼ in the proposed causal model when considering do-calculus. Thus, in the above provided loss function,
C(α, Y ) = I(α;Y ) = Eα,Y [ log p(α, Y )
p(α)p(Y )
] , (2)
where I(α;Y ) is the aforementionedMI between the causal factors and the classifier. No closed form solution computation for Eq. 2is provided. Rather, aMonte-Carlo estimator is employed, using data samples drawn from the GCE posterior and their classifications by the accompanying black-box classifier. For detailed explanation of the underlying method, we direct the reader to Appendix D of [3]. Note that this estimation method requires passing drawn samples through both the GCE s̓ decoder network and the classifier, and for low variance estimates of I(α;Y ), numerous estimates are required. As such, estimating this quantity at every training step is computationally expensive, especially when considering the cost of a vanilla VAE.
4.1 GCE Architectures As VAEs do not explicitly limit the architectures used in the encoder and decoder networks, much like the classifiers in question, they can make use of the same inductive knowledge encoded into the black-box classifiers. Thus, for image classification, given the performance of convolutional neural networks, a similar set of networks can be considered for the GCE. Naturally, while replicating and unspecified, the same architectures as used by OʼShaughnessy et al. are used here as well. The image classification datasets used (see Sec. 5) are benchmark datasets of low complexity. Hence, both the classification and generative models were limited to shallow neural networks. The classifiers consisted of 2 ReLU activated convolutional layers fed into a max-pooling layer before 2 ReLU activated linear classification layers. Drop-out was present prior to either linear layer. In all instances, this sufficed for achieving near perfect accuracy. Both the encoder and decoder used 3 layers of convolution (transposed for the decoder), with additional linear layers for converting the feature maps. Specifics for the models used are given in Table 3. For text classification, the architecture is shown in Figure 4. The core architecture used was the Long Short-Term Memory (LSTM) network [7]. The classifier consisted of a bidirectional LSTM, whose hidden states at every time-step were concatenated and fed into a 3 successive convolution/ReLU/max-pooling blocks, before being projected into classification nodes via a linear layer. The embeddings used came from the 840b token Common Crawl pre-trained 300 dimensional GloVe vectors, limited to the vocabulary present in the SST dataset4. Ultimately, this model achieves 84% accuracy on the binary SST classification task. The encoder and decoder nets used a common VAE generation architecture [4], consisting of single layer LSTM, with embeddings not using pre-initialised weights. The hidden and cell states at the last time-step were used for predicting the input-dependent posterior statistics, with the posterior samples being fed into the decoder as the initial hidden and cell states, while also being appended to every embedding vector. Posterior collapse, a situation where the decoder network essentially ignores the encoder output, proved a serious problem for text generation. To overcome this issue, an aggressive training regiment was used [8]. Here, the encoder network is trained until convergence before updating the decoder network, resulting in stable and informative signals for the decoder network. This method of training is necessary for the first few epochs, but quickly ameliorates the situation and allows for regular VAE training to continue. However, given the sheer computational expense of using aggressive training, combining this withMC-estimation of I(α;Y )would quickly prove intractable. As such,
4Available at https://gist.githubusercontent.com/bastings/b094de2813da58056a05e8e7950d4ad1/raw/ 3fbd3976199c2b88de2ae62afc0ecc6f15e6f7ce/glove.840B.300d.sst.txt
ReScience C 7.2 (#23) – Verhoeven et al. 2021 5
both the classifier and generativemodel were first trained disjoint, resulting in a regular VAE text-generator, before attempting to fine-tune into a functioning GCE.
4.2 Implementation Upon start of this project, the original authorsʼ official code repositorywasnon-functioning. Hence, all models were implemented from scratch using the descriptions and guidelines provided in the original paper. The only exception to this was the MC-estimation for information flow, although this was further optimised during the project. We exclusively used PyTorch, PyTorch-Text and PyTorch-Lightning for implementation, and all models were trained on Nvidia GeForce GTX 1080 GPUs provided by Surfsaras̓ LISA cluster computing service.
5 Experimental Setup and Code
5.1 Datasets Experiments using image classifiers are conducted on the traditionalMNISThand-written digits [9] and the newer Fashion MNIST (fMNIST) datasets [10]. The official training set of traditional MNIST was split into training and validation subsets of 50,000 and 10,000 images, respectively. The test set remained the same as the original dataset, composed of 10,000 images. Only the images labelled ʻ3ʼ or ʻ8ʼ were used to train the binary 3/8 classifier, whereas images labelled ʻ1 ,̓ ʻ4ʼ and ʻ9ʼ were selected to train the 1/4/9 classifier. For fMNIST, the training set remains the same as the original dataset containing 60,000 images. The test set is divided into a validation set and a test set, containing 6,000 and 4,000 images, respectively. The t-shirt, dress, and coat images, labelled ʻ0 ,̓̒3 ,̓ and ʻ4 ,̓ were used to train the 0/3/4 classifier. Both traditional MNIST and fMNIST were limited to samples with the labels of interest. All images were scaled to size 28 × 28. In both datasets, the train/validation/test splits was done using the file indices. Experiments conducted using text classification used the Stanford sentiment treebank [11] movie reviews corpus. Here the officially recommended train/validation/test splits were used. Rather than using the 5-class fine-grained classification, only positive and negative reviews were used, with the ʻvery-ʼ classes being converted to their less polar alternatives.
5.2 Hyperparameters In the reproduction experiments, hyperparameters are set to be the same as the original paper. The lists of hyperparameters of CNN classifier and GCE model can be found in
ReScience C 7.2 (#23) – Verhoeven et al. 2021 6
Table 4 and Table 5, see Appendix 8. Beyond just the values provided, however, Algorithm 1 from the original paper was also implemented to conduct a hyperparameter search for K, L and λ. This procedure was not rigorously defined in the original paper, using terms that are left open for interpretation, such as ”plateaus” or ”approaches”. Due to this, some assumptions were made in the process:
• “Plateauing” was defined as the value in question achieving a local optimum, with the next iteration reversing its trend.
• “Approaching the value from step 1” was defined as either coming within a certain percentage threshold of the target value, or being closer to the target value than the next iteration.
• D and C were defined as loss values subject to minimization.
This technique requires three parameters to be chosen:
1. ξ: a factor that dictates how close to theD obtained in step 1 a value must be to be considered as having approached D.
2. λ0: the value of λ to start with.
3. κ: the factor by which to increase λ.
In our hyperparameter search experiments, we use ξ = 0.05, λ0 = 10−3 and κ = 100.5.
5.3 Model Training In reproduction experiments, we trained a GCE model to generate explanation factors for image classifier outputs. The CNN classifier was trained for image recognition task using SGD as optimizer. The network architecture is shown in Table 2 and the hyperparamters settings are listed in Table 5. The GCE model is trained to maximize the objective 1 with Adam optimizer. We use the values of K, L and λ suggested in the original paper. Hyperparameter details can be found in Table 4.
6 Results
6.1 Results reproducing original paper Using the GCE model described in Section 4.1, explanations for the CNN classifiers trained on MNIST and fMNIST datasets were found. The latent factors α and β are visualized in Figure 1, showing exactly how g(α, β) and the classifier output change as the
ReScience C 7.2 (#23) – Verhoeven et al. 2021 7
latent factors are modified for the 3-8 classifier. One can observe that α1 influences the features that separate the digits 3 and 8 (the classifier s̓ output being given by the colour surrounding the digits) while retaining stylistic features unrelated to the classifier such as skew and thickness. By contrast, non-causal factors βi controls features irrelevant to classifier outputs. As shown in Figure 1(b-d), changing βi leads to stylistic changes of digits but does not affect classifier predictions. By visualizing high-resolution latent factor sweeps in Figure 2, the GCEmodel can assist a practitioner in identifying important data features for classification results. As shown in the first row from the top in Figure2, the digits ʻ4ʼ smoothly transition into ʻ9ʼ by completing the loop of the digit ʻ9ʼ while the digit stem remains fixed. Finally, the ʻ9ʼ digit gradually transitions to a ʻ1 .̓ To verify the causal influence of theGCEon the classifier, the informationflow is studied, along with an ablation study of individual factors on classifier performance. Figure 3(a) shows the information flow fromα factors to Y is highwhile the information flow from β factors to Y is low. For the ablation study, we delete individual data points from the data by fixing individual latent factors in each validation data set to different random values taken from the prior N(0, 1). This decrease in the precision of the classification is seen in Figure 3 (b). Note that modifying aspects influenced by causal factors degrades the accuracy of the classifier substantially, whereas elimination of non-causal aspects only has amarginal effect on the accuracy of the classifier. In the original paper, the ablation study was only implemented for 0/3/4 classifier with FMNIST dataset. In addition, we also plot the information flow and accuracy s̓ plot for MNIST dataset (in Figure 9). Our implementation reproduces the results in the original paper and supports the authorsʼ claim that their method is able to separate causal and non-causal factors of a classifier. The learned latent factors can then be applied to explain classification decisions of a classifier.
ReScience C 7.2 (#23) – Verhoeven et al. 2021 8
Given the results presented above, and their proximity to those presented in the original paper, we tentatively verify all claims presented in Sec. 2. The GCE model produces high-quality examples that seem to align with the classifier s̓ internal decisionmaking process. Furthermore, by using interventions in the GCE s̓ posterior, information regarding features important to the black-box classifier were made apparent. Such a framework also clearly supported the use of counterfactuals, with alterations in the causal factors seeing the class change, and the stylistic interpretation of the produced examples remaining unaltered. Lastly, the computation of information flow to individual factors and the performed ablation study (now extended to all initial experiment domains), clearly show the success of mutual information in disentangling the GCE s̓ latent space into causal and non-causal factors. However, upon implementing GCEs for simple classification models, the scalability of the proposed framework can already be drawn into question. As mentioned in 4.1, the introduction of aMC-estimated quantity likemutual information has significant impact on the computational expense required for training, essentially forcing significantly more passes of data through the decoder and classifier networks for a single weight update. Even for the relatively sparse CNN-basedGCE and classifier, the suggested number of α and β estimates in conjunction with current implementation, implied 2500 additional forward passes for a single backward pass. All our experiments indicated this being the bottleneck of the modelling pipeline. Future research into optimising this process, for example by ensuring lower variance estimates or mixing of new sample estimates with older generations, could prove valuable in extending the original research. The issues with computational efficiency were strongly exacerbated by the requirement of a more complex generative model for the text domain. In fact, given the use of an al-
ReScience C 7.2 (#23) – Verhoeven et al. 2021 9
ternative training regiment, incorporating information flow to induce causal disentanglement would have made training until convergence virtually intractable. While the eventual failure to fine-tune from a functioning language generation model to a GCE could be an artefact of the pathologies plaguing text generation using auto-regressive architectures, it also speaks to the potential of portability for this framework. Using a classifier to produce interpretable understanding of the latent space in such a language generation model could prove tremendously interesting, allowing for a causal framework similar to the work of [12]. Furthermore, being able to fine-tune pre-trained VAEs into GCEs would provide the suggested framework far more flexibility, essentially addressing the computational efficiency issues mentioned before.
7.1 Shortcomings of the original paper The greatest shortcoming found in the original paper is the failure to address the scalability problem of the approach, along with the lack of rigour when describing the hyperparameter selection technique.
7.2 Reflection: What was easy? What was difficult? It was not trivial to re-implement the proposed method because the specifics and some details required for the implementation do not appear in the paper. However, we still managed to reproduce the results in their paper. In order to extend the algorithm to another domain, code modifications were required. No instruction is given in their original repository on how this could be done, which makes it difficult to extend this framework or apply it to other domains without reading their paper and code in depth. Having access to the (updated) codebase was quite helpful however, as it includes some implementation specifics that are not mentioned in their paper, which we made use of as a source of reference when implementing and debugging our own repository.
8 Conclusion
While some issues and discrepancies were encountered while re-implementing, ultimately we conclude that the original paper combined with the official repository are enough to validate the claims of [3]. Results were comparable, and indeed led to highquality explanations. However, while the central idea is elegant and is now proven to work, we bring into doubt the extensibility of their approach. Due to the computational expense required, it is likely that the GCEmodels introduced will only function, in their current implementation, for small datasets and simple classifiers. Finally, this project confirms just how difficult it is to make implementations of AI transparent and reproducible."

{"abstractText": "We evaluate the following claims related to fairness\u2010based objective functions presented in [1]: (1) For the four objective functions, the success rate in the worst\u2010served neighbor\u2010 hood increases monotonically with respect to the overall success rate. (2) The proposed objective functions do not lead to a higher income for the lowest\u2010earning drivers, nor a higher total income, compared to a request\u2010maximizing objective function. (3) The driver\u2010side fairness objective can outperform a request\u2010maximizing objective in terms of overall success rate and success rate in the worst\u2010served neighborhood. This means that this objective, whilst reducing the spread of income, also positively impacts rider fairness and profitability.", "authors": [{"affiliations": [], "name": "Vera Neplenbroek"}, {"affiliations": [], "name": "Sabijn Perdijk"}, {"affiliations": [], "name": "Victor Prins"}, {"affiliations": [], "name": "Koustuv Sinha"}, {"affiliations": [], "name": "Sharath Chandra Raparthy"}], "id": "SP:76784f5056618e275677a16ad9292f812df76f9e", "references": [{"authors": ["N. Raman", "S. Shah", "J. Dickerson"], "title": "Data-Driven Methods for Balancing Fairness and Efficiency in RidePooling.", "venue": "[cs] (Oct", "year": 2021}, {"authors": ["C. Cook", "R. Diamond", "J.V. Hall", "J.A. List", "P. Oyer"], "title": "The gender earnings gap in the gig economy: Evidence from over a million rideshare drivers.", "venue": "The Review of Economic Studies", "year": 2021}, {"authors": ["J. Moody", "S. Middleton", "J. Zhao"], "title": "Rider-to-rider discriminatory attitudes and ridesharing behavior.", "venue": "Transportation Research Part F: Traffic Psychology and Behaviour", "year": 2019}, {"authors": ["S. Shah", "M. Lowalekar", "P. Varakantham"], "title": "Neural Approximate Dynamic Programming for On-Demand RidePooling.", "venue": "[cs, eess] (Nov", "year": 2022}, {"authors": ["P. Santi", "G. Resta", "M. Szell", "S. Sobolevsky", "S. Strogatz", "C. Ratti"], "title": "Quantifying the benefits of vehicle pooling with shareability networks.", "venue": "Proceedings of the National Academy of Sciences 111.37 (Sept", "year": 2014}, {"authors": ["Y. N"], "title": "Neplenbroek, Perdijk and Prins 2022 13 [Re] Replication study of \u2019Data-Driven Methods for Balancing Fairness and Efficiency in Ride-Pooling\u2019 A NeurADP Algorithm Algorithm 1 NeurADP(N,T) 1: Initialize: replay memoryM", "venue": "City. \u201cNew York Yellow Taxi data,", "year": 2016}], "sections": [{"text": "R E S C I E N C E C"}, {"heading": "Replication / ML Reproducibility Challenge 2021", "text": "[Re] Replication study of \u2019Data-Driven Methods for"}, {"heading": "Balancing Fairness and Efficiency in Ride-Pooling\u2019", "text": "Vera Neplenbroek1,2, ID , Sabijn Perdijk1,2, ID , and Victor Prins1,2, ID 1University of Amsterdam, Amsterdam, the Netherlands \u2013 2Equal contributions\nEdited by Koustuv Sinha,\nSharath Chandra Raparthy\nReviewed by Anonymous Reviewers\nReceived 04 February 2022\nPublished 23 May 2022\nDOI 10.5281/zenodo.6574683"}, {"heading": "Reproducibility Summary", "text": ""}, {"heading": "Scope of Reproducibility", "text": "We evaluate the following claims related to fairness\u2010based objective functions presented in [1]: (1) For the four objective functions, the success rate in the worst\u2010served neighbor\u2010 hood increases monotonically with respect to the overall success rate. (2) The proposed objective functions do not lead to a higher income for the lowest\u2010earning drivers, nor a higher total income, compared to a request\u2010maximizing objective function. (3) The driver\u2010side fairness objective can outperform a request\u2010maximizing objective in terms of overall success rate and success rate in the worst\u2010served neighborhood. This means that this objective, whilst reducing the spread of income, also positively impacts rider fairness and profitability."}, {"heading": "Methodology", "text": "The code provided by [1] was used as a base for our re\u2010implementation in PyTorch. We evaluate the claims by the original authors by (a) replicating their experiments, (b) test\u2010 ing for sensitivity to a different value estimator, (c) examining sensitivity to changes in the preprocessing method, and (d) testing for generalizability by applying their method to a different dataset."}, {"heading": "Results", "text": "We reproduced the first claim since we observed the same monotonic increase of the success rate in the worst\u2010served neighborhood with respect to the overall success rate. The second claim we did not reproduce, since we found that the driver\u2010side fairness ob\u2010 jective function obtains a higher income for the lowest\u2010earning drivers than the request\u2010 maximizing objective function. We reproduced the third claim, since the driver\u2010side objective function performs best in terms of overall success rate and success rate in the worst\u2010served neighborhood, and also reduces the spread of income. Changes of the value estimator, preprocessing method and even dataset all led to consistent results re\u2010 garding these claims.\nCopyright \u00a9 2022 V. Neplenbroek, S. Perdijk and V. Prins, released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Vera Neplenbroek (vera.neplenbroek@student.auc.nl) The authors have declared that no competing interests exist. Code is available at https://github.com/Veranep/rideshare-replication \u2013 DOI 10.5281/zenodo.6501799. \u2013 SWH swh:1:dir:f5439c1a7a15c4eb709da6f32eb252679a1d44bd. Data is available at https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page. Open peer review is available at https://openreview.net/forum?id=BEhgn2zm3CK.\nReScience C 8.2 (#29) \u2013 Neplenbroek, Perdijk and Prins 2022 1"}, {"heading": "What was easy", "text": "The paper is written engagingly and the theoretical sections, in particular, give a clear description of the problem setup and objectives. The paper is also accompanied by an open\u2010source code base, which supports reproduction efforts."}, {"heading": "What was difficult", "text": "The provided code lacks a script to preprocess raw data, which is required to reproduce the experiment, nor was the preprocessed data openly available. Additionally, complex code structure and scarce commenting complicated replication.\nCommunication with original authors Due to the absence of preprocessed data, we contacted the authors, who quickly pro\u2010 vided the requested data.\nReScience C 8.2 (#29) \u2013 Neplenbroek, Perdijk and Prins 2022 2\n1 Introduction\nRide\u2010pooling platformsmatch independent drivers with multiple riders. This matching is performed by machine learning algorithms, which are designed to maximize com\u2010 pany profit. The profit motive behind these algorithms can cause unfairness among drivers and riders, for instance by unequally distributing rides between drivers, or by servicing requests originating in some neighborhoods at lower rates [1, 2, 3]. The paper Data-Driven Methods for Balancing Fairness and Efficiency in Ride-Pooling [1] (henceforth referred to as \u201cthe paper\u201d or \u201cthe authors\u201d) explores the tradeoff between rider fairness, driver fairness, and total income (i.e. company profitability) by measur\u2010 ing fairness and profitability metrics across simulations using four objective functions. These objective functions are maximized by an algorithm that matches rider requests to drivers, using actual request data from the New York Yellow Taxi dataset. The follow\u2010 ing metrics are studied: a) the percentage of all requests that are serviced (the overall success rate), b) the success rate in the neighborhood with the lowest local success rate (the success rate in the worst-served neighborhood), and c) the distribution of income across drivers. The overall success rate is used as a proxy for company profitability, whereas the success rate in the worst\u2010served neighborhood and the income of the least\u2010earning drivers are measures of rider and driver fairness, respectively. The matching algorithm, introduced by [4], uses a Markov decision process (MDP) in combination with a neural value estimator to match rides to drivers non\u2010myopically, that is, with awareness of future events that could impact the value of a match. The pa\u2010 per\u2019s algorithm requires a strongly connected graph (i.e. street network) on which the taxis operate, precomputed routes and travel times between all pairs of nodes (i.e. inter\u2010 sections), and a dataset of requests, each containing an origination node, a destination node, and the time the request was issued. Thepaper compares twoprofitability\u2010focusedobjective functions and two fairness\u2010focused objective functions. Theprofitability\u2010focused request objectivemaximizes the total num\u2010 ber of requests serviced during the simulation, given by the sum of ongoing requests pi and completed requests si, for each driver i:\norequest(R,W ) = n\u2211 i=1 (|pi|+ |si|), (1)\nwhere R and W are sets respectively containing the states of the drivers, and all pre\u2010 viously unaccepted and accepted requests. The profitability\u2010focused income objective maximizes the total income of all drivers:\noincome(R,W ) = n\u2211 i=1 \u03c0i, (2)\nwhere \u03c0i is the income of driver i, which is made up of a constant part and a variable part that depends on the distance of the trip. The rider fairness objective maximizes profit whilst minimizing the variance of the success rate across all neighborhoods j:\norider(R,W ) = \u2212\u03bbV ar( hj kj ) + n\u2211 i=1 \u03c0i, (3)\nwhere hj is the number of serviced requests originating in neighborhood j, kj is the total number of requests originating in j, and \u03bb a hyperparameter moderating the reg\u2010 ularization. The driver\u2010side fairness objective maximizes profit whilst minimizing the variance of the income across all drivers i:\nodriver(R,W ) = \u2212\u03bbV ar(\u03c0i) + n\u2211\ni=1\n\u03c0i. (4)\nReScience C 8.2 (#29) \u2013 Neplenbroek, Perdijk and Prins 2022 3\n2 Scope of reproducibility\nWe focus our reproducibility study on the claims related to the fairness\u2010based objective stated in the previous section. These claims (henceforth referred to as the claims) can be summarized as follows:\n1. For the four objective functions, the success rate in theworst\u2010servedneighborhood increases monotonically with respect to the overall success rate.\n2. The proposed objective functions do not lead to a higher income for the lowest\u2010 earning drivers, nor a higher total income, compared to a request\u2010maximizing ob\u2010 jective function. This extends claim 1, suggesting that a profit motive generally leads to increased fairness for drivers and riders alike.\n3. The driver\u2010side fairness objective (4) can outperform a request\u2010maximizing objec\u2010 tive (1) in terms of overall success rate and success rate in the worst\u2010served neigh\u2010 borhood. This means that this objective while reducing the spread of income, also positively impacts rider fairness and profitability.\nThe authors have demonstrated claim 3 to hold only for 50 drivers. For 200 drivers they find the opposite, namely that equation (1) outperforms equation (4) in terms of fairness as well as profitability metrics. We evaluate these claims by testing whether they still hold under a variety of modifica\u2010 tions to the experimental setup. We conduct four experiments that deviate increasingly from the exact setup of the paper: (a) the experiment of the paper is reproduced using the author\u2019s preprocessed data, (b) the non\u2010myopic neural value estimator is replaced by a myopic greedy estimator, (c) the experiment of the paper is replicated using data generated with our own preprocessing method, and (d) the experiment is applied to a different dataset (New York Green Taxi dataset), using our own preprocessing method. Note that all experiments except for (b) use the neural value estimators also used in the original paper.\n3 Methodology\nThis section explains the methodology used for the four experiments we carried out. An overview of the used code is provided, followed by descriptions of the model, the datasets and the hyperparameters. Finally, we outline the experimental setup and state the computational resources needed to perform the experiments.\n3.1 Code The code provided by the authors, which is largely based on the code by [4], was used as a base for our re\u2010implementation in PyTorch. The provided code was sufficient to re\u2010 produce the experiments performed in the original paper, after the authors emailed the preprocessed data that they used in the paper. This data consists of the graph of Man\u2010 hattan, travel times, routes, and rider requests from the New York Yellow Taxi dataset mapped to nodes on the graph. Neither the code to generate this data nor the data itself are publicly available. To solve the integer linear problem that determines which set of actions is assigned to which driver, the original code uses the callable library CPLEX 12.8. However, at the time of this replication study, the free edition of CPLEX does not suffice to train the required models, since the problem size limits were exceeded. Therefore, the no\u2010cost academic edition of CPLEX 20.11 was used instead.\n1https://pypi.org/project/cplex/\nReScience C 8.2 (#29) \u2013 Neplenbroek, Perdijk and Prins 2022 4\nIn addition to an exact reproduction, we examine the paper\u2019s claims\u2019 robustness against a different method of preprocessing the same raw data. The paper uses the method described in [5] to preprocess the raw trip data. However, this method is computation\u2010 ally demanding and complex to implement. We developed an algorithm that generates routes and travel times on a graph, but that differs in two ways from [5]. First, we use travel time estimates from OpenStreetMap (OSM), corrected by a multiplication con\u2010 stant, equal to the mean ratio between the actual travel time and the OSM estimate of the travel time, computed over all trips in the dataset. Second, unlike the method used in the paper, we do not compute the Dijkstra algorithm for each pair of nodes, which is an O(n2) approach, where n is the number of nodes in the graph. For the street network of Manhattan (n \u2248 4000), this can take days on a typical laptopwithoutGPUacceleration. Instead, our routing algorithm invokesDijkstra on a total of \u2248 500, 000 pairs of randomly sampled nodes, which yields a coverage of \u2248 60% of all n2 = 16M routes, because all subroutes of each route are also optimal routes. The optimal routes between the remaining 40% of node pairs are approximated by setting each remaining route (n,m) equal to the concatenation of subroutes (n, p) and (p,m), for a predecessor p selected from a set of predecessors of nodem, for which routes (n, p) and (p,m) are known and yield the lowest total travel time. Lastly, to test the generalizability of the methods used in the paper, we performed addi\u2010 tional simulations using trips in Brooklyn from the New York Green Taxi dataset. The algorithm described above is used to generate routes and travel times between all nodes, given the graph of Brooklyn\u2019s street network.\n3.2 Model descriptions The original paper has adapted the model that incorporates an MDP to assign a set of actions to each vehicle from [4]. An overview of this algorithm is provided in Appendix A. Themodel makes use of a neural value estimator that assigns a value to each possible set of actions. In the original paper, the objective functions (equations 1, 2, 3, 4) that this model aims tomaximize are varied, alongwith the number of drivers (50 and 200 drivers are used). The input to the neural value estimator [4] is composed of the current location and path of the vehicle, the permissible delay, the current epoch, the number of other vehicles in the vicinity and the number of requests that were placed in the current epoch. By using an LSTM, this value estimator can take into account non\u2010myopic considerations like the possibility that a future rider request will appear along the route of a current rider request, therefore increasing the value of the current request. The location and path features are embedded using pretrained embeddings, which were computed by a separate network that was trained to predict travel times between any two nodes in the graph.\n3.3 Datasets\nThe original experiments are conducted on the New York Taxi dataset [6], available at 2, consisting of pickup and drop\u2010off locations and times for Yellow Taxi passengers from March 23rd to April 1st and from April 4th to April 8th, 2016. The generalization experiments are conducted on the New York Green Taxi dataset 3, consisting of pickup and drop\u2010off locations and corresponding times for Green Taxi pas\u2010 sengers in the months February, March and June. We take the subset of trips in Brook\u2010 lyn, to keep the size of the graphmanageable and similar to the graph ofManhattan used in the original paper. Whereas Yellow taxis in practice only serve the business district of downtownManhattan, the Green taxis serve all of New York. This makes the Green Taxi\n2https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page 3https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\nReScience C 8.2 (#29) \u2013 Neplenbroek, Perdijk and Prins 2022 5\ndataset a good choice to test the generalization of results concerning rider\u2010side metrics, because of differences in affluence between various districts of New York. In addition, Brooklyn is a different geographical area and the Green Taxi dataset contains a different distribution of requests, compared to the Yellow Taxi dataset.\n3.4 Hyperparameters Nohyperparameter searchwas done for this replication study. Instead, the hyperparam\u2010 eters provided by [1] were used to adhere to the original experimental setup as much as possible. This meant that for the driver\u2010side fairness objective function we set \u03bb to be 4 6 , and for the rider\u2010side fairness objective function, \u03bb was set to be 10\n9. Additionally, we set the constant costs of a ride to $5, the capacity of a car to 4 riders, the number of neighborhoods to 10, and we batch rider requests per minute.\n3.5 Experimental setup For each experiment containing a neural value estimator (section 2), themodel is trained for each combination of objective function (equations 1, 2, 3, 4) and number of drivers (\u2208 {50, 200}). For the specific packages and their versions that were used to obtain our results, we refer to our codebase 4. Reproducing the experiments by [1] means that we trained allmodels on 3 days of data, except for the rider\u2010side fairness objective (equation 3) models, which were trained on 2 days of data. All models were evaluated on one day of data. In order to evaluate the claims, the followingmetrics are of interest: the overall success rate, the success rate in the worst\u2010served neighborhood (also calledminimum request success rate), and the income per driver. To compare the objective functions, three plots are generated per experiment, in line with the reporting of the original paper: 1) the min\u2010 imum request success rate as a function of the overall success rate for the simulation with 50 drivers, 2) the same plot for the simulation with 200 drivers, and 3) the distri\u2010 bution of income across drivers for each objective function for the simulation with 200 drivers. During the exact reproduction of the paper\u2019s experiments, we observed that the neural model is not trained (seemingly inadvertently) in the experiment with 50 drivers. The number of training examples for the neural net grows in the number of drivers and the number of days of training data. The authors included a minimum threshold of training examples, which is not met by the experiment with 50 drivers. However, the algorithm silently executes, therefore using an untrained randomly\u2010initialized neural network. Importantly, the value assigned to each action is a linear combination of a deterministic term and the output of the (untrained) neural net. Therefore, even though the network\u2019s outputs are random in the case of 50 drivers, the computed values are not. This finding motivated the experiment where the neural value estimator is replaced by a greedy value estimator. To test the claims under a different data preprocessing method, we run an experiment using the same rawdata as the original paper, but with our self\u2010developed preprocessing method (i.e. a graph of Manhattan with routes and travel times computed as outlined in section 3.1). Apart from the data preprocessing, this experiment is identical to the experiment in the paper. With this, we aim to investigate the sensitivity of the claims and the method used by [1] to different data preprocessing methods and in particular to a different travel time computation, which is inherently noisy. Our final experiment uses the Green Taxi dataset and our own preprocessing method in order to study the generalizability of the work by [1]. The models for the Green Taxi dataset were trained on 6 days of data, except for the rider\u2010side fairness objective (equa\u2010 tion 3) models, which were trained on 4 days of data. All these models were evaluated\n4https://github.com/Veranep/rideshare-replication\nReScience C 8.2 (#29) \u2013 Neplenbroek, Perdijk and Prins 2022 6\non two days of data. For all experiments using our preprocessing method, two new sets of pretrained embeddings were trained for the corresponding graphs of Manhattan and Brooklyn.\n3.6 Computational requirements All experiments were run on one Nvidia GeForce 1080Ti GPU, using three CPU nodes. Training and evaluating a model on the Yellow Taxi dataset for 50 drivers took roughly 2.5 hours, whereas training and evaluating one for 200 drivers took 6\u20107.5 hours. For the rider\u2010fairness objective function models, which were only trained on two days of data, runtimes were two\u2010thirds of this. The experiments that use a greedy non\u2010neural value estimator took an hour less for 200 drivers and roughly the same amount of time for 50 drivers. For the Green Taxi dataset, more days of data were used to train on, since this dataset contains fewer requests per day. Here, the model took roughly 1 hour to train and evaluate for 50 drivers and 10 hours for 200 drivers. Computing embeddings of size 100 for all \u2248 4000 locations took approximately 10 hours. Finding shortest paths and computing travel times between all pairs of locations took 1.5 hours on a laptop with an Intel i5 processor 5.\n4 Results\nIn this section, we present the results of the reproduction of the original paper, the re\u2010 placement of the neural value estimator by the greedy non\u2010neural value estimator, the replication using our data preprocessingmethod, and the generalization experiment us\u2010 ing the Green Taxi dataset. For each experiment, we evaluate whether the claims listed in Section 2 are supported by the presented results.\n4.1 Reproduction of the original experiment The first claim states that objective functions which improve the overall success rate for riders also improve the success rate in the worst\u2010served neighborhood. The figures that the authors use to support this are displayed in Appendix B and our reproduced results in Figures 1a and 1b. If objective functions that improve the overall success rate also improve the success rate in the worst\u2010served neighborhood, we should see the success rate in theworst\u2010servedneighborhoodmonotonically increase as the overall success rate increases. This is indeed a pattern that we see in the figures from the original paper, as well as in our figures. Second, the authors claim that no objective function raises wages for the lowest\u2010earning drivers or raises the total income, compared to the requests objective function (equation 1). In the original paper, results related to the income distribution used to support this claim are only obtained for 200 drivers, as can be seen in Appendix B. In our reproduc\u2010 tion the function thatmaximizes total income at 200 drivers is also the requests objective function. However, the maximum income for the least\u2010earning drivers is obtained with the driver\u2010side fairness objective function, as displayed in Figure 1c. The final claim states that the driver\u2010side fairness objective function (equation 4) outper\u2010 forms the requests objective function (equation 1) in terms of overall success rate, suc\u2010 cess rate in the worst\u2010served neighborhood, and reducing the spread of income. These first two results are only obtained for 50 drivers, as seen in the figures in Appendix B, and the last result only for 200 drivers. We reproduce all three of these results. In Fig\u2010 ure 1a, we see that both the highest overall success rate and the highest success rate in the worst\u2010served neighborhood are obtained with equation (4). Finally, we find that\n5Specifically, a MacBook Pro (13\u2010inch, 2020) with 1.4 GHz Quad\u2010Core Intel Core i5 CPU\nReScience C 8.2 (#29) \u2013 Neplenbroek, Perdijk and Prins 2022 7\nequation (4) reduces the spread of income compared to (1), as can be seen from Figure 1c.\n4.2 Results beyond original paper In addition to reproducing the results in the original paper, we performed supplemen\u2010 tary experiments to test the generalizability of the methods used in the original paper. First we discuss the results of replacing the neural value estimator with a greedy value estimator. Further, we examine the results of using our preprocessing method. Lastly, we discuss the results obtained using the Green Taxi dataset.\nReScience C 8.2 (#29) \u2013 Neplenbroek, Perdijk and Prins 2022 8\nResults using a greedy non-neural value estimator \u2014 These results are obtained by replacing the neural non\u2010myopic value estimator with a myopic greedy value estimator. This serves both to test the added value of the neural estimator, and to test the sensitivity of the claims to a different estimation method. Interestingly, the results obtained with the greedy estimator (Figure 2) closely resemble the results obtained with the neural es\u2010 timator (Figure 1), even in the case of 200 drivers where the neural estimator does train (as opposed to the case with 50 drivers). This suggests that, given the limited training examples for 200 drivers and 3 days of taxi data, the neural model provides little added benefit over amyopic greedy estimator. By extension, this experiment reaches the same conclusions: claims 1 and 3 are replicated, but claim 2 is not.\nResults using our preprocessing method \u2014 To examine the sensitivity to changes in the pre\u2010 processing method, we compare the results of this experiment to the results of the re\u2010\nReScience C 8.2 (#29) \u2013 Neplenbroek, Perdijk and Prins 2022 9\nproduction. The obtained results, as displayed in Figure 3, are similar to the reproduced results. We see the same monotonic increase in Figures 3a and 3b as we saw in Figure 1 for the reproduction. Similarly, the income distribution (Figure 3c) shows that objec\u2010 tive (4) obtains the highest income for the lowest\u2010earning drivers and reduces the spread of income. Therefore, we can conclude that these results support claim 1 and claim 3, but do not support claim 2, and that the method proposed by the authors is robust to changes in the preprocessing method.\nResults on Green Taxi dataset \u2014 In order to analyze the generalizability of the original paper, we use the results obtained on the Green Taxi dataset to see if the claims described in Section 2 hold for a different dataset. These results (Figure 4) are similar to the ones ob\u2010 tained on the Yellow Taxi dataset in both the reproduction experiment (Figure 1) and the experiment using our preprocessing (Figure 3). This experiment again supports claims\nReScience C 8.2 (#29) \u2013 Neplenbroek, Perdijk and Prins 2022 10\n1 and 3, but does not support claim 2. Important to note is that the success rates are much higher compared to those obtained on the Yellow Taxi dataset. This is because the Green Taxi demand in Brooklyn is signif\u2010 icantly less than the Yellow Taxi demand in Manhattan. Hence, with an equal number of taxis a greater share of requests can be met. The fact that the findings of this ex\u2010 periment are consistent with the previous experiments, all of which have much lower success rates, provides confidence that the claims also generalize to realistic success rates (i.e. success rates approaching 100%, as is expected from real taxi companies).\nReScience C 8.2 (#29) \u2013 Neplenbroek, Perdijk and Prins 2022 11\n5 Discussion\nTo conclude, our results support the first claim, since we find that the success rate in the worst\u2010served neighborhood increases monotonically with respect to the overall success rate for both 50 and 200 drivers. Unlike the original paper, wedonot find that the request\u2010 maximizing objective function (equation 1) maximizes income for the lowest\u2010earning drivers, so we do not support the second claim. Instead, we find that at 200 drivers the driver\u2010side fairness objective function (equation 4) obtains the highest income for the lowest\u2010earning drivers. We support the third claim since our results show that the driver\u2010side fairness objective function yields the greatest overall success rate, the highest success rate in the worst\u2010 served neighborhood, and reduces the spread of driver income. Indeed, our results provide even stronger support for this claim than the original paper. Unlike the paper, we have found the driver\u2010side objective to provide the best success rates in both cases of 50 and 200 drivers. Furthermore, this objective lifts the income of the least\u2010earning drivers above what they make under the request\u2010maximizing objective. This makes the driver\u2010fairness objective attractive in all respects, and an interesting subject for further research. One avenue to explore is why the driver\u2010fairness objective produces greater success rates than the request\u2010maximizing objective, even though the latter\u2019s sole pur\u2010 pose is to maximize the success rate. The obtained results are generally consistent across the four conducted experiments, showing that the claims which are supported by our results (claims 1 and 3) are robust and relatively insensitive to a range of reasonable changes to the experimental setup. This provides confidence that these claims and the corresponding objective functions generalize well beyond the precise setups in which we and [1] tested them. One limitation of ourwork, which is also shared by the original paper, is that the success rates across all experiments are unrealistically low, because the number of drivers (50 or 200) is insufficient to meet demand (there are more than 10,000 Yellow taxis in Manhat\u2010 tan). This creates an abundance of possible actions for each driver that is not represen\u2010 tative of the competition that exists for real\u2010world taxi services. Running experiments in a setup where success rates are more realistic would be a worthwhile additional gen\u2010 eralization experiment. Such experiments may require more computational resources than some researchers, ourselves included, have access to. However, our results for the Green Taxi dataset already mitigate concerns that the claims would not generalize to greater success rates; the claims were upheld in this setup with success rates of over 50%.\n5.1 What was easy The paper is written engagingly and the theoretical sections in particular give a clear description of the problem setup and objectives. The paper is also accompanied by an open\u2010source codebase with their implementation, which is extremely helpful to obtain\u2010 ing accurate reproductions.\n5.2 What was difficult Even though the code was sufficient to reproduce the experiments done in the original paper, it was cluttered at times. It contains functions that are never used, as well as print statements solely used to check if a certain point in the code is reached without errors. Additionally, the code used to create the location embeddings creates embeddings of size 10, when embeddings of size 100 are expected by the model. When reimplement\u2010 ing the code in PyTorch, most difficulty was experienced when having to feed masked data into an LSTM backwards, as a result of how masking is implemented in PyTorch. Further, various important details could only be found in the code, such as which days\nReScience C 8.2 (#29) \u2013 Neplenbroek, Perdijk and Prins 2022 12\nthey used to train the model on and the used epoch duration. One of the most impor\u2010 tant details that was missing is the notion that the model does not train for 50 drivers and three days of Yellow Taxi data, as it will not train without enough examples. Fur\u2010 ther, the data to perform the original experiments and the script to preprocess the raw data were not publicly available. After contacting the authors, they provided us with the missing data. Despite what is stated in the paper, approximately 1% of the routes in this data were not computed. These omitted routes, however, were not present in any of the rider requests and therefore did not pose a problem to this research.\n5.3 Communication with original authors We contacted the authors because the data and the embeddings used to perform the original experiments are not publicly available. The authors provided the missing data quickly and expressed willingness to help with further queries."}], "title": "[Re] Replication study of \u2019Data-Driven Methods for Balancing Fairness and Efficiency in Ride-Pooling\u2019", "year": 2022}
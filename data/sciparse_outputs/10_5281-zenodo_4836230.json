{"abstractText": "DOI 10.5281/zenodo.4836230 Abstract Cache systems keep data close to the processor to access it faster than main memory would. Graph algorithms benefit from this when a cache line contains highly related nodes. Hao Wei extitet al. propose to reorder the nodes of a graph to optimise the proximity of nodes on a cache line. Their contribution, Gorder, creates such an ordering with a greedy procedure. In this replication, we implement ten different orderings and measure the execution time of nine standard graph algorithms on nine real-world datasets. We monitor cache performances to show that runtime variations are caused by cache management. We confirm that Gorder leads to the fastest execution in most cases due to cache-miss reductions. Our results show that simpler procedures are yet almost as efficient and much quicker to compute. This replication validates the initial results but highlights that generating a complex ordering like Gorder is time-consuming. A replication of [1].", "authors": [{"affiliations": [], "name": "Fabrice L\u00e9cuyer"}, {"affiliations": [], "name": "Maximilien Danisch"}, {"affiliations": [], "name": "Lionel Tabourier"}, {"affiliations": [], "name": "Nicolas P. Rougier"}, {"affiliations": [], "name": "Ozan Caglayan"}, {"affiliations": [], "name": "Emmanuel Hadoux"}], "id": "SP:beca5ffd11d81368c1aec3a068dc5f8047b9a295", "references": [{"authors": ["H. Wei", "J.X. Yu", "C. Lu", "X. Lin"], "title": "Speedup Graph Processing by Graph Ordering.", "venue": "In: SIGMOD", "year": 2016}, {"authors": ["A. Ailamaki", "D.J. DeWitt", "M.D. Hill", "D.A. Wood"], "title": "DBMSs on a modern processor: where does time go?", "year": 1999}, {"authors": ["J. Cieslewicz", "K. Ross"], "title": "Database Optimizations for Modern Hardware.", "venue": "Proceedings of the IEEE", "year": 2008}, {"authors": ["M. Then", "M. Kaufmann", "F. Chirigati", "T.-A. Hoang-Vu", "K. Pham", "A. Kemper", "T. Neumann", "H.T. Vo"], "title": "The More the Merrier: Efficient Multi-Source Graph Traversal.", "venue": "Proceedings of the VLDB Endowment", "year": 2014}, {"authors": ["T.H. Cormen", "C.E. Leiserson", "R.L. Rivest", "C. Stein"], "title": "Introduction to algorithms", "venue": "MIT press,", "year": 2009}, {"authors": ["R. Tarjan"], "title": "Depth-First Search and Linear Graph Algorithms.", "venue": "SICOMP", "year": 1972}, {"authors": ["L. Page", "S. Brin", "R. Motwani", "T. Winograd"], "title": "The PageRank citation ranking: Bringing order to the web.", "venue": "InfoLab", "year": 1999}, {"authors": ["V. Batagelj", "M. Zaversnik"], "title": "An O(m) algorithm for cores decomposition of networks.", "year": 2003}, {"authors": ["D.G. Corneil", "F.F. Dragan", "E. K\u00f6hler"], "title": "On the power of BFS to determine a graph\u2019s diameter.", "year": 2003}, {"authors": ["M. Latapy", "C. Magnien"], "title": "Measuring Fundamental Properties of Real-World Complex Networks.", "year": 2006}, {"authors": ["E. Cuthill", "J. McKee"], "title": "Reducing the Bandwidth of Sparse Symmetric Matrices.", "year": 1969}, {"authors": ["Y. Lim", "U. Kang", "C. Faloutsos"], "title": "SlashBurn: Graph Compression andMining beyond Caveman Communities.", "venue": "TKDE", "year": 2014}, {"authors": ["I. Stanton", "G. Kliot"], "title": "Streaming graph partitioning for large distributed graphs.", "venue": "In: ACM SIGKDD", "year": 2012}, {"authors": ["V. Balaji", "B. Lucia"], "title": "When is Graph Reordering an Optimization?", "venue": "IEEE IISWC", "year": 2018}, {"authors": ["P. Boldi", "S. Vigna"], "title": "The webgraph framework I: compression techniques.", "year": 2004}, {"authors": ["R. Milo", "S. Itzkovitz", "N. Kashtan", "R. Levitt", "S. Shen-Orr", "I. Ayzenshtat", "M. Sheffer", "U. Alon"], "title": "Superfamilies of Evolved and Designed Networks.", "venue": "Science", "year": 2004}], "sections": [{"text": "Edited by Nicolas P. Rougier ID\nReviewed by Ozan Caglayan ID\nEmmanuel Hadoux ID\nReceived 26 March 2021\nPublished 28 May 2021\nDOI 10.5281/zenodo.4836230\n1 Introduction\nIn graph algorithmics, various procedures use the same few atomic operations. For in\u2010 stance, accessing the neighbours of a given node is key to a wide range of problems such as computing shortest paths, finding connected components, detecting communi\u2010 ties etc. Making this type of elementary operation fasterwould improve such algorithms without having to modify their implementation [1]. Cache optimisation can have that effect: if two variables are often accessed together by algorithms, they should be stored side\u2010by\u2010side in memory so that they are copied together on a cache line. In a graph, it means reordering the nodes so that neighbours have close\u2010enough indices. A cache\u2010 miss happens when data is not available in cache. The processor then has to fetch it in main memory, which is up to twenty times slower, depending on the machine architec\u2010 ture. As this cache stall is known to represent a significant share of the computation time [2, 3], reducing it can lead to important speedups. This work replicates [1] by Hao Wei et al. which introduces Gorder, a new procedure to order nodes in a graph, and compares it to other standard orderings using typical algorithms and datasets as benchmarks. Because of the variety of graph algorithms, it is impossible to find an ideal ordering, which makes it interesting to propose and compare different strategies. The authors of the original paper claim an improvement of 10 to 50% in runtime, due to lower cache\u2010miss rate. We were able to replicate most of the experiments and confirm that ordering nodes ac\u2010 cording to Gorder makes the implementations 10 to 50% faster than without ordering. Section 2 presents the algorithms, orderings and datasets as well as issues faced during the replication. Our results are presented in Section 3 and are compared to the origi\u2010 nal results. Finally, Section 4 discusses the relevance of such an ordering compared to simpler ordering methods that offer satisfactory performances.\n2 Method\nThe original study [1] was motivated by the observation that cache stall can take up to 70% of the whole computation time, which is supported by the observations reported\nCopyright \u00a9 2021 F. L\u00e9cuyer, M. Danisch and L. Tabourier, released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Fabrice L\u00e9cuyer (fabrice.lecuyer@lip6.fr) The authors have declared that no competing interests exist. Code is available at https://github.com/lecfab/rescience-gorder. \u2013 SWH swh:1:dir:e318a0ad72f81e2cb2af1ca614d1c171dd3f0909. Open peer review is available at https://github.com/ReScience/submissions/issues/52.\nReScience C 7.1 (#3) \u2013 L\u00e9cuyer, Danisch and Tabourier 2021 1\nin Figure 1. This issue has been addressed for specific algorithms such as breadth\u2010first search [4]. In [1], the authors use a more general method: they reorganise the data to draw more benefit from the cache system, regardless of the algorithm or of the exact hardware specifications. Gorder clusters nodes that are likely to be accessed simultaneously by any graph algo\u2010 rithm. More precisely, let us consider a graph G = (V,E) with n = |V | nodes and m = |E| edges. The proximity of two nodes u and v is measured by a score S(u, v)which increases if they are neighbours and if they share many common in\u2010neighbours. The to\u2010 tal score F is the sum of S(u, v) for all nodes u and v that have close indices. Window size w is the parameter that defines this closeness. Gorder creates an arrangement \u03c0 of the indices to maximise F . We note \u03c0u the index of a node u in such an arrangement. We give a more formal definition in Section 2.3. The authors prove that finding the optimal ordering \u03c0 is a NP\u2010hard problem and propose a heuristic method with a theoretical approximation bound. They also present practical optimisations to reduce its time complexity. Finally, they run extensive experiments to compare their order to other standard orders. Although the theoretical results of the original paper are important to explain the effi\u2010 ciency of Gorder, we only focus here on the algorithms and experiments. They provide an extensive analysis by comparing the runtimes for nine typical algorithms on eight large datasets with nine possible orderings. The current section describes them all and presents the replication issues that they imply. It also details the data structures that we used in this project. All the codes and instructions for this purpose can be found in our repository1.\n2.1 Algorithms The original paper selects typical graph algorithms to test the different orderings. As implementation details are not fully documented and as its authors were not able to provide answers to some of our questions on this topic, we list below the details of our implementations.\nNeighbour query (NQ) \u2014 Listing the neighbours of a given node is a standard elementary operation in graph algorithmics. As defined in [1], this operation must access the outneighbours of each node. To ensure that neighbours are put in cache, thus benefiting\n1https://github.com/lecfab/rescience-gorder\nReScience C 7.1 (#3) \u2013 L\u00e9cuyer, Danisch and Tabourier 2021 2\nfrom a wise node ordering, an arbitrary operation is made over the set of neighbours. We compute for each node u the sum of degrees of its neighbours: qu = \u2211 v\u2208Nu dv.\nBreadth and Depth-first search (BFS, DFS) \u2014 BFS and DFS are standard graph traversal algo\u2010 rithms [5]. We adapted them to the data structure detailed in Section 2.2. Note that neighbours are selected in lexicographic order.\nStrongly connected components (SCC) \u2014 To cluster nodes of the graph that can be accessed from one another, we use Tarjan\u2019s algorithm [6], which is a based on DFS.\nShortest paths (SP) \u2014 As in the original paper, we use Bellman\u2010Ford algorithm [5] to com\u2010 pute theminimum distance from a source node to any other node. The time complexity after simple optimisations is in O(\u2206m) where \u2206 is the diameter of the graph and m is the number of edges. As real\u2010world networks are known to have relatively small diam\u2010 eters (\u2206 \u226a n), this algorithm works on massive datasets (see section 2.2). Note that for unweighted graphs, shortest paths can be computed in linear time and space using a BFS, but we keep the algorithm suggested in [1] for comparison purposes.\nPage rank (PR) \u2014 This is the algorithm presented in [7] to rank webpages. It gives a score to each node according to its importance in the network structure. The original paper hints at an approximation based on the power iteration method with 100 iterations. We implement it with a damping factor set to \u03b1 = 0.85 which is a usual configuration.\nDominating set (DS) \u2014 A dominating set is a subset of nodes such that every node of the graph either belongs to the subset or has a neighbour in it. The implementation is not described in the original paper so we use a greedy approximation [5]: first, we select the nodewith themost uncovered neighbours and add it to the dominating set. Second, this node and all its neighbours are removed from the graph because they are now covered. The two steps are then repeated among the remaining nodes.\nCore decomposition (Kcore) \u2014 This graphpealing algorithm [8] recursively removes thenode of smallest degree until only a core of well\u2010connected nodes remains. We use a binary heap structure to keep track of the degrees, leading to a quasi\u2010linear time complexity.\nDiameter (Diam) \u2014 Efficient approximations with theoretical bounds exist [9] to compute the aforementioned diameter \u2206. In [1], the authors run 5000 times the shortest paths algorithm SP from a random node, and output the highest distance obtained. Note that the accuracy and efficiency of the algorithm are not key here, as the aim is to compare the performances in terms of computation time of different orderings.\n2.2 Datasets and data structure\nSize \u2014 Eight real\u2010world datasets are used as benchmarks in the original work [1]. Their basic features are reported in Table 1. As per usual with real\u2010world graphs [10], these graphs are sparse (m \u226a n2) and have small diameter and a skewed degree distribution, etc. As shown in Table 1, their sizes range from 1.6 million nodes and 30 million edges to almost 100 million nodes and two billion edges. In order to facilitate further experi\u2010 ments, we attach the epinion dataset to the repository, a smaller network on which our code can be tested quickly.\nSources \u2014 In the original paper, the sources are provided in the form of URLs where datasets can be downloaded. These data are available with the links given in Table 1.\nReScience C 7.1 (#3) \u2013 L\u00e9cuyer, Danisch and Tabourier 2021 3\nCategories \u2014 The authors of [1] selected two main categories of real\u2010world networks: on\u2010 line social platforms, where a node is a user and a directed edge represents a social interaction, and web graphs, where a node is a web page and an edge is a hyperlink.\nFormat \u2014 The datasets are directed graphs given as lists of edges. Most algorithms (e.g. computing shortest paths) have different results depending on whether edges are di\u2010 rected or not. In order to store large graphs in main memory, an efficient data structure is needed. Libraries exist for that purpose, but we develop our own light structure to have better control over the implementation of the algorithms. A list of edges does not provide quick access to the list of neighbours of a given node, which is the crucial op\u2010 eration for most of the above graph algorithms. The data is therefore converted into an adjacency list, where a node points to the list of its neighbours. To store it efficiently, we use a Compressed Sparse Row format, as described in Figure 2.\n2.3 Orderings We list below the different ordering methods considered in the original study and used as a benchmark for comparison with Gorder.\nOriginal \u2014 Datasets are collected in a way that is not random but is rarely reported. As shown in Section 3, the original orderings perform quite well regarding cache miss.\nReScience C 7.1 (#3) \u2013 L\u00e9cuyer, Danisch and Tabourier 2021 4\nRandom (added) \u2014 In comparison to [1], we added a random ordering, obtained by shuf\u2010 fling the indices of nodes. We use it as a non\u2010favourable benchmark for comparison to all other orderings.\nMinLA and MinLogA \u2014 These acronyms stand for minimum linear (respectively logarithmic) arrangement. The goal is to find an arrangement \u03c0 of the nodes that minimises a given \u201cenergy\u201d function. The energy E is computed over the set E of edges in the following way:\nEMinLA = \u2211\n(u,v)\u2208E\n|\u03c0u \u2212 \u03c0v| and EMinLogA = \u2211\n(u,v)\u2208E\nlog |\u03c0u \u2212 \u03c0v|\nAs both exact optimisations are NP\u2010hard, a heuristic method is necessary. The authors of [1] use simulated annealing: random permutations are achieved to decrease the en\u2010 ergy E , while the temperature goes down which allows less and less modifications. Sim\u2010 ulated annealing is known to be hard to tune. Our implementation has two parameters: the number of steps S and the standard energy k. The temperature T decreases linearly so that, at step s, T (s) = 1\u2212 s/S At each step, two nodes are picked at random. Swapping their indices in \u03c0 leads to a variation e of the total energy E . If e is negative, the swap is registered. Otherwise, it is registered with a probability p, inspired by statistical physics:\np(e, T ) = exp ( \u2212 e k \u00b7 T ) In Figure 3 we test a wide range of values of S and k on epinion. While we cover a significant fraction of the parameter space, we are not able to find a combination of S and k that outperforms a simple local search (k = 0, p = 0), where only the favourable swaps are accepted. Below, we set S = m and k = m/n.\nRCM \u2014 The Reverse Cuthill\u2013McKee ordering [11] is a Breadth\u2010First Search where nodes of small degree are favoured. It is meant to find an arrangement \u03c0 that reduces the bandwidth of a sparse graph, given by max(u,v)\u2208E |\u03c0u \u2212 \u03c0v| with \u03c0u the index of node u.\nReScience C 7.1 (#3) \u2013 L\u00e9cuyer, Danisch and Tabourier 2021 5\nDegsort \u2014 As proposed in the original paper, nodes are sorted in descending order of in\u2010 going degree.\nChdfs \u2014We assume that the children-depth first search traversal mentioned in [1] is a usual Depth\u2010First Search algorithm. The first node is chosen at random, then the selection of children is made following the original order of node indices.\nSlashBurn (simplified) \u2014 SlashBurn is an iterative process that separates hubs (high\u2010degree nodes) from low\u2010degree nodes connected to hubs. It creates an ordering by iterating over an array of size n, initially empty. Each iteration divides the array in parts A, B and C. Part A takes only one node, selected at random among those with highest degree. All isolated nodes go to part C. Then these nodes are removed from the graphwhich creates new isolated nodes, and degrees are updated. Part B is filled by the next iteration until no node remains. The original SlashBurn algorithm [12] fills part Cwith disconnected components instead of isolated nodes and puts r hubs in part A, where r is a parameter. As no precise infor\u2010 mation was given in [1], we implement the simpler version described above instead.\nLDG \u2014 Linear Deterministic Greedy partitioning [13] creates nk bins of size k and puts nodes in the bin where most of their neighbours belong. Larger bins are penalised: a node u with neighbours Nu is placed in a bin that achieves\nargmax binB\n( 1 + |Nu \u2229B| ) \u00d7 ( 1\u2212 |B|\nk ) At the end of the process, each bin contains about k nodes. In [1], the authors choose k = 64 so that a bin can fit on a cache line. Indeed, common contemporary processors have L1 caches of a few dozen kilobytes (32kB in our case) made of lines of 64 bytes each.\nMetis (removed) \u2014Metis is a powerful and extensive tool for graph partitioning. A C++ im\u2010 plementation is available2 but it is not suitable for large graphs: the original paper could only test it on the three smallest datasets because of its excessive memory consumption. Since this ordering does not scale, we do not use it in our experiments.\nGorder \u2014 Gorder is the orderingmethod introduced in [1], where it is precisely described. A C++ implementation is available3. As mentioned at the beginning of Section 2, the authors define the quality function F of an arrangement \u03c0 by:\nF (\u03c0) = \u2211\n0<\u03c0u\u2212\u03c0v\u2264w\nS(u, v) = \u2211\n0<\u03c0u\u2212\u03c0v\u2264w\n( Ss(u, v) + Sn(u, v) ) where w is the window size; Ss(u, v) is the number of times u and v coexist in sibling relationships or their number of common in\u2010neighbours; Sn(u, v) is thenumber of times they are in a neighbour relationship, which is either 0, 1 or 2 since both edges (u, v) and (v, u)may exist. The greedy algorithm presented in [1] creates the ordering \u03c0 by recursively inserting the node that has the highest proximity to nodes presently within the window. Storing the proximity scores S requires a complex structure called unit heap, made of a linked list and pointers to different positions. We took the functions provided in the original code and adapted them to our data structure. In [1], Figure 8 shows how parameter w is selected. The authors create versions of Gorder for window sizes ranging from 1 to 8. For each version, they run the PR algo\u2010 rithm on flickr dataset. The fastest runtime is obtained with w = 5, so they use this value for subsequent experiments. However, the 8 versions only lead to a small relative variation of runtime (3%).\n2http://glaros.dtc.umn.edu/gkhome/metis/metis/overview 3https://github.com/datourat/Gorder\nReScience C 7.1 (#3) \u2013 L\u00e9cuyer, Danisch and Tabourier 2021 6\nIn Figure 4 we compare a wider range of window sizes, because w could in theory be anything between 1 and n. We find that setting w between 64 and 2048 gives a further 3% speedup compared to w = 5.\nThe choice of a small w is yet relevant because of two other factors: first, the compu\u2010 tation of Gorder is faster when the window is narrow, because a candidate node has to compute its proximity score S with all the nodes of the window. Second, the authors of the original paper show that their heuristic is a 12w \u2010approximation of the optimal score: reducing w makes this bound tighter. Considering all these remarks and for the purpose of replication, we also use w = 5 in the following experiments.\n3 Results\n3.1 Implementation hardware To deal with bigger datasets and ensure stability, we run the experiments on an isolated cluster (SGI UV2000 Intel Xeon E5\u20104650L @2.6 GHz, 128GB RAM). Each processor has three levels of cache of respective size 32kB, 256kB and 20MB. The hardware used in [1] has similar cache and RAM storage but higher clock frequency, which can explain the differences in runtime (in addition to programming techniques and optimisation). Note however that these differences should not modify the relative performance of different orderings.\n3.2 Ordering time Computing an ordering on a large network can be a long process, and some of the or\u2010 dering methods have limited scalability. As mentioned above, Metis has been removed from the experiments for this reason. Table 2 reports the duration of the ordering pro\u2010 cesses. For datasets under a hundredmillion edges, they can all be computed in a couple of minutes at most, with DegSort and ChDFS orderings requiring less than a second. When the number of edges rises however, the computation takes hours for MinLA, Min\u2010 LogA, and Gorder. In the case of MinLA and MinLogA, the number of steps is chosen arbitrarily as described in Section 2.3. The process could thus be interrupted earlier, at the cost of a less efficient resulting ordering. As for Gorder, we can see that it does not scale linearly: the edges processed per second decrease from 380k for pokec to 60k for\nReScience C 7.1 (#3) \u2013 L\u00e9cuyer, Danisch and Tabourier 2021 7\nsdarc, which requires an almost 9\u2010hour\u2010long computation. Using a smaller window size accelerates the process but slightly worsens the resulting ordering, as seen in Figure 4.\n3.3 Running time The main purpose of [1] is to measure if the node orderings listed above allow for faster execution of standard graph algorithms. We compare in Figure 5 the performances of all the orderings to Gorder. The results are reported for each dataset and algorithm in the same way as Figure 9 of the original paper. We also propose in supplementary figure S1 another visualisation of the same results but grouped by ordering instead of dataset, which emphasises the overall performance of an ordering method. A first few observations can be made from the raw results of the experiments. As in [1], we observe that Gorder almost always leads to the fastest execution times. The speed\u2010up factor reaches up to 2.5 compared to default for Diameter on sdarc and 3.7 compared to random for PageRank on wiki, but for the sake of clarity we limit the y\u2010axis of Figure 5 to a factor 2. To help making sense of the results, we propose an aggregated visualisation in Figure 6, where each ordering is ranked according to its performance in comparison to the other orderings through the 81 series of experiments reported in Figure 5. It shows in particu\u2010 lar that Gorder is the best ordering method in half of the experiments, and second\u2010best in most other cases. Below, we comment on the performances of the different ordering methods under ex\u2010 amination.\nOriginal ordering \u2014 The experiments show that the default ordering performs better than more elaborate methods such as MinLA or MinLogA, which have a high computation overhead as shown in Table 2. It was also observed in [1]. This indicates that the way in which datasets are constructed tends to give close indices to nodes that are in the same neighbourhood. In a web graph for instance, if webpages are listed alphabetically by URL, it is likely that two consecutive nodes have a hyperlink between them since they belong to the same website.\nPoorly performing orderings \u2014 The random ordering is always the worst performer except for 6 experiments where it is second\u2010worst. It is not surprising as any other ordering tends to bring neighbouring nodes together, which should improve the algorithm run\u2010 time. Note however that LDG performs only slightly better than random, and that it is almost always the slowest in [1] too. In a quarter of the experiments, it is more than twice as slow as Gorder. These poor results lead to think that either its parameter (the size of bins k = 64) is not optimal, or that its quality function is not highly correlated to\nReScience C 7.1 (#3) \u2013 L\u00e9cuyer, Danisch and Tabourier 2021 8\nReScience C 7.1 (#3) \u2013 L\u00e9cuyer, Danisch and Tabourier 2021 9\ncache efficiency. MinLA andMinLogA are always faster than LDG but, except for twitter dataset, they are slower than the original ordering. As reported in Figure 3, we could not find any parameters with better results than local search, which is not ideal when the problem has local minima.\nDegree-based orderings \u2014 Both InDegSort and SlashBurn use the degree of nodes as their main criterion. The experiments show that they outperform the default orderings, es\u2010 pecially for larger datasets. For some algorithms such as BFS or NQ, they are less than 20% slower than Gorder. This indicates that cache misses are reduced when nodes of similar degree are copied together on a cache line. The original paper found similar re\u2010 sults, though their implementation of SlashBurn did not perform as well; the different version that we use here (see Section 2.3) may be responsible for this discrepancy.\nOrderings outperforming Gorder on specific algorithms \u2014We also notice that some orderings performparticularlywell on specific algorithms, evenoutperformingGorder. TheChDFS ordering is the most efficient for DFS algorithm on all datasets. This is due to the close relation between these two processes: the algorithm explores the graph in the exact same way as the ordering is created. Likewise, RCM is a variation of a BFS that takes node degrees into account and it is the most efficient ordering for BFS algorithm. Both also outperform Gorder for algorithms that are not as visibly related: ChDFS is up to 10% more efficient for SCC on smaller datasets, and RCM is the most efficient for Diameter and SP. More generally, Figure 6 shows that these two orders are among the three fastest ones in 75% of the experiments. The original paper has different results on that matter: RCM and ChDFS are the best alternatives as well, but they are always 10 to 20% slower than Gorder.\n3.4 Comparison to the original paper Our purpose here is to detect if there are significant discrepancies in performance be\u2010 tween the original paper and our replication study. Figure 6 presents an aggregate view of the results grouped by ordering method. For each series of experiments (i.e. a given algorithm applied to a given dataset), we rank ordering methods from best to worst performance. The figures report how many times each ordering has been ranked in each position. For instance Gorder is ranked first in 40 of our 81 replication series.\nResults for Gorder \u2014 In both the original study and our replication, Gorder ranks first over\u2010 all. This shows that this ordering is the best choice overall. However, our study shows that Gorder is outperformed by different orderings in half of the experiments, while it is only outranked once in the original paper. Figure 6b thus leads us to think of Gorder as the perfect choice whereas Figure 6a establishes RCM and ChDFS as relevant chal\u2010 lengers, with 24 and 16 first places respectively. This difference between the two papers is probably due to implementations: in our replication, ChDFS uses exactly the DFS al\u2010 gorithm. In particular, the nodes are visited in the same order, which leads to a quick execution of DFS. The original paper likely prevents this mechanism, for instance by shuffling the nodes at each step of the search.\nRanking of other orders \u2014 The three best orderings are evidently the same in both studies, but there are some nuances for the other ones. First, this visualisation does not always allow for exact ranking: in Figure 6b, InDegSort has more second and third places than SlashBurn but fewer fourth and fifth places. There is no obvious way of deciding which is better, while Figure 6a clearly indicates InDegSort. The same issue happens between Original and MinLogA: we can say that their rank in [1] is equal. The last nuance comes for the slowest orderings: in our study, LDG is only better than Random while MinLA competes with MinLogA and Original. In [1] on the other hand, LDG is better than MinLA overall. Still, the limit at factor 1.5 makes the ranking unreli\u2010 able for slowest orderings which can explain this difference.\nReScience C 7.1 (#3) \u2013 L\u00e9cuyer, Danisch and Tabourier 2021 10\n40\n50\n60 70\n80\nIn the end, both studies rank the orderings in a very similar way.\nLimits of visualisation \u2014 The aggregate view of Figure 6 induces several approximations. First of all, there are 72 experiments in the original study and 81 experiments in ours, which adds epinion dataset. This extra dataset is much smaller than the others and all its results in Figure 5 range in a 40% factor, to be compared with more than 200% for the biggest datasets. Yet, the ranking of ordering methods on epinion is consistent with other datasets. The original study does not test random orderings. This does not disturb the results as this method ranks last in most experiments. Similarly, our study omits Metis so we ignore it in Figure 6b as well. Moreover, the original paper hides precise information when a runtime exceeds 1.5 times the runtime of Gorder. We consider that all orderings above this bound are equal. The main issue is that this visualisation only shows the rank and hides the extent of runtime variations. This information is only visible in Figure 5, where a rift separates two categories: faster orders with Gorder, RCM, ChDFS, InDegSort and SlashBurn, from slower orders with the other ones. However, Figure 6 is useful to grade ordering meth\u2010 ods. If original ordering is taken as a limit between faster and slower orders, we find the same gap again.\nReScience C 7.1 (#3) \u2013 L\u00e9cuyer, Danisch and Tabourier 2021 11\n3.5 Cache miss A cache miss is a state of an execution when the data requested by the processor is not found in the cache memory. The program has to fetch the data in further cache levels or in main memory, which causes delays. Gorder capitalises on the intuition that if we cluster nodes that are frequently accessed together, higher levels of cachewill holdmore relevant data and thus make algorithms run faster. To prove that Gorder speedup is due to cache optimisation, we compute the proportion of the total computation time spent in data retrieval. We use Unix perftools with the wrapper ocperf. It provides various hardware metrics such as the number of CPU cycles, branch predictions, cache misses\u20264 Depending on the machine architecture, different metrics are available. Table 3, just like the Tables 3 and 4 of the original paper, shows the cache\u2010miss rates at different levels. The first column is the total number of L1\u2010references which is the number of times a piece of data was required by the processor. A proportion of this data is not found (second column) and requested in intermediate levels of cache, until reaching L3 (third and fourth columns). The remaining data (last column) has to be retrieved in main memory. Note that each further level of cache roughly implies an additional factor 4 latency. We observe that first\u2010level cache references are similar for all orderings: the algorithms\n4See https://perf.wiki.kernel.org. We select the following counters: the total time task-clock, cpu-cycles, L1-dcacheloads and L1-load-misses to measure the efficiency of the first layer of data cache (we are not interested in instruction cache here), LLC-loads and LLC-load-misses to measure the efficiency of the last cache layer, and metrics specifically designed to measure the impact of cachemisses such as cycles-l1d-pending or cycles-l3-miss in the cycle\u2010activity category.\nReScience C 7.1 (#3) \u2013 L\u00e9cuyer, Danisch and Tabourier 2021 12\nrun in the exact same way so they need to access the same amount of data, regardless of the arrangement of nodes. However, the miss\u2010rate in L1 reveals important variations: withGorder, only 10%of the data is not directly available in L1, while it reaches 20%with Random or LDG orders. The percentage of data requested in L3 is even more scattered, from 5% with Gorder to 20% with Random or LDG on sdarc. Finally, all the orderings have a low cache\u2010miss rate (between 1.6 and 3.6%) on flickr and RCM has the smallest. The gap is more striking on sdarc where Random and LDG have 9% of cache\u2010miss, three times as much as Gorder. This ratio is the proportion of data that had to be retrieved in main memory (RAM), which is about 60 times slower than the L1 cache5. In general, the ranking for cache\u2010miss rates matches the ranking for runtime shown in Figure 6a. Gorder has the best results and RCM and ChDFS are close behind. MinLA, MinLogA and Original orders have high cache\u2010miss rates for all levels. This shows that the speedup is indeed due to cache\u2010miss reduction. When compared to Original order, Gorder reduces cache\u2010miss rates to speed up the algorithms. Figure 1 shows that the total runtime is reduced by 15 to 50% on sdarc, but the CPU execution time is almost identical: it is the factor 3 reduction on cache stall that makes the algorithm faster.\n4 Discussion\nOur experiments replicate the ones proposed in [1] but some aspects are not discussed in sufficient detail in the original paper to allow for immediate replication. For instance, the algorithmsNQandDS only have a succinct description, whichmay explainwhy their performances reported in our Figure 1 do not align perfectly with Figure 1 of [1]. Simi\u2010 larly, we were not able to tune the simulated annealing procedure correctly, which ques\u2010 tions the relevance of our experiments with MinLA and MinLogA. Nonetheless, most of these technical issues have been solved or circumvented thanks to the answers of Hao Wei to our questions. Above all, this study replicates the main observation of the original paper: Gorder re\u2010 duces cache latency significantly and is the best performer among all the orderingmeth\u2010 ods under study, as shown in Figure 6. Its consistent efficiency on all algorithms and datasets suggests that it could speed up other graph algorithms as well. The only important difference with the original paper is that RCM and ChDFS follow closely behindGorder and even outperform it in half of the experiments. They are based on straightforward graph searches, which are simple to program and very quick to exe\u2010 cute, as reported in Table 2. On the other hand, computing Gorder requires a complex procedure and a lot of time. It has been pointed out in [14] that this high overhead time can only be amortised if algorithms are run thousands of times. In the case where net\u2010 works evolve and require constant recomputation of the node ordering, Gorder needs to be adapted to integrate the modifications without running the whole process again. A parallel version of Gorder could reduce this problem. Beyond algorithm speed\u2010up, the contribution of HaoWei et al. is an efficient framework that could be applied for other purposes. For example, graph compression also benefits from orderings that cluster nodes with high proximity [15]. Gorder could be an input for such existing methods. It would also be interesting to investigate how different types of real\u2010world datasets [16] behave when a new ordering is applied.\n5 Conclusion\nThe replication of paper [1] shows that Gorder is an efficient cache optimisation for various standard algorithms. We confirm its superiority for networks ranging from 30 million to 2 billion edges, and the hardware measurement tools prove that this is due to reduced cache stall. However, orders such as DFS are among the best performers, and they are much simpler to design. Indeed, the computation of Gorder does not scale\n5At 4GHz, a cycle is 1c = 1/(4 \u00b7 109)s = 0.25ns, so latency is 4c = 1ns for L1 and 42c+ 51ns \u2243 62ns for RAM. Values are taken from https://www.7-cpu.com/cpu/Skylake.html.\nReScience C 7.1 (#3) \u2013 L\u00e9cuyer, Danisch and Tabourier 2021 13\nlinearly, which makes it very time\u2010consuming for bigger graphs. It is then a matter of balance between this long overhead time and the substantial speedup for subsequent graph algorithms."}, {"heading": "Acknowledgements", "text": "Wewarmly thank HaoWei for replying to our questions about the original paper, which settled several technical hesitations relative to the implementation. This work is funded by the ANR (French National Agency of Research) partly by the LiMass JCJC project (under grant ANR\u201019\u2010CE23\u20100010) and partly by the ANR FiT LabCom."}], "title": "[Re] Speedup Graph Processing by Graph Ordering", "year": 2021}
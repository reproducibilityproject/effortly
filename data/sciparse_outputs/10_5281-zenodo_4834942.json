{"abstractText": "We have used the code provided by [1] with some customization for reproducibility. In addition to making the codebase more modular and easy to navigate, we have made changes to incorporate different transformers in the question embeddingmodule. QuestionAnswering models were trained from scratch as no pre-trained models were available for our particular dataset. The code for this work is available on GitHub (See page footer for the link).", "authors": [{"affiliations": [], "name": "Jishnu Jaykumar P"}, {"affiliations": [], "name": "Ashish Sardana"}, {"affiliations": [], "name": "Apoorv Saxena"}], "id": "SP:e6f17fb3e18e7b053a76fcf3b83d4382b3cc4ae1", "references": [{"authors": ["A. Saxena", "A. Tripathi", "P. Talukdar"], "title": "Improving Multi-hop Question Answering over Knowledge Graphs using Knowledge Base Embeddings.", "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. Online: Association for Computational Linguistics,", "year": 2020}, {"authors": ["N. Reimers", "I. Gurevych"], "title": "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks.", "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics,", "year": 2019}, {"authors": ["Y. Liu", "M. Ott", "N. Goyal", "J. Du", "M. Joshi", "D. Chen", "O. Levy", "M. Lewis", "L. Zettlemoyer", "V. Stoyanov"], "title": "RoBERTa: A Robustly Optimized BERT", "venue": "Pretraining Approach", "year": 2019}, {"authors": ["F.M. Suchanek", "G. Kasneci", "andG.Weikum"], "title": "Yago: A Core of Semantic Knowledge.", "venue": "In:Proceedings of the 16th International Conference on World Wide Web. WWW \u201907. Banff, Alberta, Canada: Association for Computing Machinery,", "year": 2007}, {"authors": ["J. Lehmann", "R. Isele", "M. Jakob", "A. Jentzsch", "D. Kontokostas", "P.N. Mendes", "S. Hellmann", "M. Morsey", "P. Van Kleef", "S. Auer"], "title": "Dbpedia\u2013a large-scale, multilingual knowledge base extracted from wikipedia.", "year": 2015}, {"authors": ["T. Mitchell"], "title": "Never-Ending Learning.", "venue": "(Apr", "year": 2018}, {"authors": ["T. Trouillon", "J. Welbl", "S. Riedel", "\u00c9. Gaussier", "G. Bouchard"], "title": "Complex Embeddings for Simple Link Prediction.", "venue": "Proceedings of the 33rd International Conference on International Conference on Machine Learning Volume 48. ICML\u201916", "year": 2016}, {"authors": ["Y. Zhang", "H. Dai", "Z. Kozareva", "A.J. Smola", "L. Song"], "title": "Variational Reasoning for Question Answering with Knowledge Graph.", "year": 2018}, {"authors": ["W.-t. Yih", "M. Richardson", "C. Meek", "M.-W. Chang", "J. Suh"], "title": "The Value of Semantic Parse Labeling for Knowledge Base Question Answering.", "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics", "year": 2016}, {"authors": ["T. Wolf"], "title": "Transformers: State-of-the-Art Natural Language Processing.", "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. Online: Association for Computational Linguistics,", "year": 2020}, {"authors": ["Y. Wang", "D. Ruffinelli", "R. Gemulla", "S. Broscheit", "C. Meilicke"], "title": "On Evaluating Embedding Models for Knowledge Base Completion", "year": 2019}, {"authors": ["I. Bala\u017eevi\u0107", "C. Allen", "T.M. Hospedales"], "title": "Tucker: Tensor factorization for knowledge graph completion.", "venue": "arXiv preprint arXiv:1901.09590", "year": 2019}, {"authors": ["Z. Lan", "M. Chen", "S. Goodman", "K. Gimpel", "P. Sharma", "R. Soricut"], "title": "Albert: A lite bert for self-supervised learning of language representations.", "venue": "arXiv preprint arXiv:1909.11942", "year": 2019}, {"authors": ["Z. Yang", "Z. Dai", "Y. Yang", "J. Carbonell", "R.R. Salakhutdinov", "Q.V. Le"], "title": "Xlnet: Generalized autoregressive pretraining for language understanding.", "venue": "Advances in neural information processing systems", "year": 2019}, {"authors": ["I. Beltagy", "M.E. Peters", "A. Cohan"], "title": "Longformer: The Long-Document Transformer", "year": 2020}, {"authors": ["Y. Wang", "S. Broscheit", "R. Gemulla"], "title": "A Relational Tucker Decomposition for Multi-Relational Link Prediction", "year": 2019}, {"authors": ["S.M. Kazemi", "D. Poole"], "title": "SimplE Embedding for Link Prediction in Knowledge Graphs. 2018", "year": 2018}, {"authors": ["S. Hochreiter", "J. Schmidhuber"], "title": "Long short-term memory.", "venue": "Neural computation", "year": 1997}, {"authors": ["J. Chung", "C. Gulcehre", "K. Cho", "Y. Bengio"], "title": "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling", "year": 2014}, {"authors": ["C.R. Harris"], "title": "Array programming with NumPy.", "venue": "Nature", "year": 2020}, {"authors": ["S. Broscheit", "D. Ruffinelli", "A. Kochsiek", "P. Betz", "R. Gemulla"], "title": "LibKGE-A knowledge graph embedding library for reproducible research.", "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations", "year": 2020}, {"authors": ["M. Sachan"], "title": "Knowledge Graph Embedding Compression.", "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics", "year": 2020}, {"authors": ["K. Choromanski"], "title": "Rethinking Attention with Performers", "year": 2020}, {"authors": ["N. Kitaev", "\u0141. Kaiser", "A. Levskaya"], "title": "Reformer: The Efficient Transformer", "year": 2020}, {"authors": ["I. Chami", "A. Wolf", "D.-C. Juan", "F. Sala", "S. Ravi", "C. R\u00e9"], "title": "Low-Dimensional Hyperbolic Knowledge Graph Embeddings.\u201d In:Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. Online: Association for Computational Linguistics", "year": 2020}, {"authors": ["B. Dhingra", "C. Shallue", "M. Norouzi", "A. Dai", "G. Dahl"], "title": "Embedding Text in Hyperbolic Spaces.", "venue": "Proceedings of the Twelfth Workshop on Graph-Based Methods for Natural Language Processing (TextGraphs12)", "year": 2018}, {"authors": ["B. Wang", "C. .-.-. J. Kuo"], "title": "SBERT-WK: A Sentence Embedding Method by Dissecting BERT-Based Word Models.", "venue": "IEEE/ACM Transactions on Audio, Speech, and Language Processing", "year": 2020}], "sections": [{"text": "R E S C I E N C E C Replication / ML Reproducibility Challenge 2020\n[Re] Improving Multi-hop Question Answering over"}, {"heading": "Knowledge Graphs using Knowledge Base Embeddings", "text": "Jishnu Jaykumar P1, ID and Ashish Sardana1, ID 1NVIDIA, Bengaluru, India\nEdited by Koustuv Sinha\nReviewed by Anonymous Reviewers\nReceived 29 January 2021\nPublished 27 May 2021\nDOI 10.5281/zenodo.4834942\n1 Reproducibility Summary\n1.1 Scope of Reproducibility Our work consists of four parts:\n1. Reproducing the results from [1].\n2. Exploring the effect of various knowledge graph embedding models in the Knowledge Graph Embedding module.\n3. Exploring the effect of various transformer models in the Question Embedding module.\n4. Verifying the importance of the Relation Matching (RM) module.\nBased on the code shared by the authors, we have reproduced the results for EmbedKGQA[1]. We have not performed relation matching deliberately to validate point-4.\n1.2 Methodology We have used the code provided by [1] with some customization for reproducibility. In addition to making the codebase more modular and easy to navigate, we have made changes to incorporate different transformers in the question embeddingmodule. QuestionAnswering models were trained from scratch as no pre-trained models were available for our particular dataset. The code for this work is available on GitHub (See page footer for the link).\n1.3 Results Wewere able to reproduce the Hits@1 to be within\u00b12.4% of the reported value (in most cases). Anomalies were observed in 2 cases.\n1. In MetaQA-KG-Full (3-hop) dataset.\n2. WebQSP-KG-Full dataset.\nCopyright \u00a9 2021 J.J. P and A. Sardana, released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Jishnu Jaykumar P (jishnu.jayakumar182@gmail.com) The authors have declared that no competing interests exist. Code is available at https://github.com/jishnujayakumar/MLRC2020-EmbedKGQA. \u2013 SWH swh:1:dir:c95bc4fec7023c258c7190975279b5baf6ef6725. Open peer review is available at https://openreview.net/forum?id=VFAwCMdWY7.\nReScience C 7.2 (#15) \u2013 P and Sardana 2021 1\nFrom our experiments on the QAmodel, we have found that a recent transformer architecture, SBERT[2] producedbetter accuracy than the original paper. ReplacingRoBERTa[3] with SBERT[2] increased the absolute accuracy by \u22483.4% and \u22480.6% in the half KG and the full KG case respectively. (KG: Knowledge Graph, \u201d\u2248\u201d: Approximately)\n1.4 What was easy As the code was open-sourced, we didn\u02bct have to implement the paper giving us the liberty to customize the codebase to focus on the author s\u0313 claim validation, perform extended experiments and explore shared as well as new models. In addition to this, pretrained KG embedding models were shared which helped in the reproduction experiment.\n1.5 What was difficult The lack of comprehensive documentation along withmissing comments defining functions/classes/attributes etc. made it laborious to review the code and modify it. In addition to large training times for question answering models, the knowledge graph embeddings also required a significant amount of computing resources.\n1.6 Communication with original authors\nWe had a couple of virtual meetings with Apoorv Saxena1, the primary author of EmbedKGQA[1].\n2 Introduction\nKnowledge is the key to question answering task. Knowledge Graph (KG) is a multirelational graph consisting of entities as nodes and relations among themas typed edges. KGs can accommodate a wide variety of facts, making them one of the potential candidates for intelligent decision-making. Question Answering over KG (KGQA) task aims to answer natural language queries posed over the KG. Multi-hop KGQA is a trending topic and has gained traction from both academia and industry recently. Multi-hop KGQA task involves reasoning over multiple edges of the KG to arrive at the correct answer. Earlier works on KGs(e.g. [4], [5], [6], [7]) have some element of sparsity, i.e. they do not capture all the facts available in the real world. Recent research onmulti-hop KGQA has attempted to reduce this sparsity with the help of relevant external textual resources that are not readily available. On the other side, KG embeddings have emerged as an effective tool to overcome the KG sparsity by predicting missing links in the KG. Although effective, KG embeddings have not been explored for the multi-hop KGQA task. [1] fills this gap with the proposed EmbedKGQA method. This work intends to reproduce and perform an ablation (removing relation matching module) as well as an extended study on EmbedKGQA[1]. EmbedKGQA claims to be the first of its kind to use KG embeddings for multi-hop KGQA and improves over other state-of-the-art (SOTA) baselines.\n3 Scope of reproducibility\nAccording to [1], using ComplEx [8] KG embeddings significantly improves Hits@1 for multi-hop KGQA task and it has been proved with the help of the results on MetaQA [9] andWebQSP [10] datasets. This reproducibilitywork tries to test this claim and conducts\n1https://apoorvumang.github.io\nReScience C 7.2 (#15) \u2013 P and Sardana 2021 2\nexperiments as mentioned in table:{2,3} of the original paper. Section 5.1 contains the corresponding results which support the claim with some anomalies.\n4 Methodology\nThe authors of the original paper have open-sourced the code along with the data and pre-trained ComplEx KG embedding models. We have used the same codebase (commit:5d8fdbd4) and customized it for our purposes. In addition to this, we have added comprehensive documentation to make it more interpretable. Moreover, a commandline functionality is also added to easily configure various transformers models in the training workflow.\n4.1 Model descriptions As shown in Figure:1, EmbedKGQA has three modules:\n1. KGEmbeddingModule - Thismodule contains a KG embeddingmodel called ComplEx [8] to learn embeddings for all entities in the input KG. 4 pretrained models have been shared by the author which contains 2 models for MetaQA-KG-{Full, 50} as well as 2 models WebQSP-KG-{Full,50} dataset. Details about the dataset are mentioned in section:4.2.\n2. Question Embedding Module: Given a question q, head entity h and set of answer entities A, this module learns the question embeddings based on the score function defined by the KG embedding method used in 1.\n3. Answer Selection Module: This module uses the outputs of module:1 and 2 to select the final answer by scoring the<head-entity, question> pair against all possible answers. The strategy is mentioned in section:{4.4, 4.4.1} of the original paper respectively.\n4.2 Datasets There are two datasets used in the original paper. MetaQA [9] and WebQSP [10]. Both datasets have two portions. (1) KG data (2) QA data. KG data for both are further divided into two categories. (1) Using the full KG (indicated by suffix KG-Full) and (2) Using\nReScience C 7.2 (#15) \u2013 P and Sardana 2021 3\nExperiment-Alias is the name used for the respective datasets in experiments.\n\u03b3 = Contains all facts that are within 2-hops of any entity mentioned in the questions of WebQSP. \u03d5 = Contains only 50% of the triples (randomly selected without replacement).\n\u03c8 = Contains 50% of the edges sampled randomly from fbwq_full.\nonly 50% of the facts in the respective KGs (indicated by suffix KG-50). The details of generating custom KG datasets are discussed here2. Both datasets are taken from here3. Statistics for table:{1, 2} have been taken from [1]. For generating question embeddings the question is placed between <s> and </s> tags for all transformers except SentenceTransformer as it takes the input sentence in its pure form. The preprocessing used in the original code has been used here. No additional preprocessing has been performed from our end.\n4.3 Hyper-Parameters Hyper-parameters used to train themodels aren\u02bct explicitly shared in the codebase or the paper, hence we decided to use the default values provided in codebase2 to compensate for the lack of time. For reproduction, a pretrained model shared along with the data was used; ComplEx[8] was used as the knowledge graph embedding method for all the KG types, i.e., full and half of both datasets types. For reproducibility, hyper-parameters for training MetaQA and WebQSP QA models have been taken from section:{MetaQA4, WebQuestionsSP5} of the original codebase respectively. For RoBERTa [3], a pretrained model roberta-base has been taken fromHuggingFace transformers package [11]. Other hyper-parameters are populated by default values in codebase2.\n4.4 Experimental setup and code Experiments have been performed on the NVIDIA DGX-1 server with 8xV100 GPUs, out of which 6 were used in this work. The metric used for validating the claims is Hits@1. According to [12], Hits@k is the proportion of test triples ranking in the top-k results. The code for this work is open-sourced on GitHub6. In addition to this, we have shared a couple of Docker images7 for easy kick-starting of experiments without the hassle of\n2https://github.com/malllabiisc/EmbedKGQA 3https://drive.google.com/drive/folders/1RlqGBMo45lTmWz9MUPTq-0KcjSd3ujxc (As of January, 2021) 4https://github.com/malllabiisc/EmbedKGQA#metaqa 5https://github.com/malllabiisc/EmbedKGQA#webquestionssp 6https://github.com/jishnujayakumar/MLRC2020-EmbedKGQA 7https://github.com/jishnujayakumar/MLRC2020-EmbedKGQA#helpful-pointers\nReScience C 7.2 (#15) \u2013 P and Sardana 2021 4"}, {"heading": "Type MetaQA-KG-Full MetaQA-KG-50", "text": "For table:3, validate_every = The number of train routines before validation for a single epoch Total runs (r) = Number of times the training has been performed for a particular task Total train time (GPU hours) excluding early stopping, T = (total_epochs\u00d7 (t+ v))\u00d7 r\nsetting up the environment. Following trainedmodels aremade available in our Docker image7, chosen based on better performance in our extended study.\n\u2022 TuckER KG embedding model for Meta-QA-{Full, 50}\n\u2022 QAmodels trained using ComplEx as KG embeddingmodel and SBERTmentioned in table:4 as question embedding model for WebQSP-KG-{Full, 50}\n4.5 Computational requirements This work has been performed on 6 V100-16GB GPUs connected via NVLink. NVLink reduced multi-GPU training time by 1/4. The time required for various reproductions are mentioned in table:{3}.\n4.6 Extended Experiments Apart from reproducing the results mentioned in the original paper, a couple of extended experiments have been performed to find answers to the following two questions:\n1. Can recentKGembeddingmethods likeTuckER [13] givehigher accuracy onhigher levels of hops, i.e., 3-hop scenario to be specific compared to [8] used in the original paper?\n2. Can other transformer architectures like ALBERT [14], XLNet [15], Longformer [16] and SBERT [2]) improve the results on WebQSP [10]?\nDetails of hyper-parameters used for these experiments are available in our GitHub repository6. Various transformer models used for experiment-2 are mentioned in table:4.\n5 Results\nWe report results for reproducibility as well as our extended experiments. The results of reproduction have a mixed nature while the ones for our extended experiments show\nReScience C 7.2 (#15) \u2013 P and Sardana 2021 5\nFor table:{5, 6}, KG-Embedding-Model=ComplEx. RM=Relation Matching, 4= inclusion, 8= exclusion. The original values for EmbedKGQA are taken from [1]. Underline indicates anomaly due to the absence of RMmodule.\npositive signs to support claim-1, 2. Detailed discussion about the results can be found in section:6. For all tables in this report, bold values indicate better performance.\n5.1 Results reproducing original paper Weperform two experiments based on the two datasets introduced in section:4.2. These experiments provide vital information about the results mentioned in table:{2,5} of the original paper. The results of the two are reported in table:{5, 6} respectively. From the results of table:5 in [1] and table:6 in this report, it is evident that relationmatching(RM) is an important component inmulti-hop KGQAwhen the given KG is considerably large, i.e. {MetaQA, WebQSP} KG-Full; Definitely, WebQSP-KG-50 also shows improvement in presence of RM but the performance significantly improves when applied to KG-Full setting. The author of [1] had also expressed the same opinion in one of the virtual meetings. For table:{7, 8},\u2206= (TuckER Hits@k) - (ComplEx Hits@k).\nReScience C 7.2 (#15) \u2013 P and Sardana 2021 6\n5.2 Results beyond the original paper Wehave conducted twoadditional experiments fromour end tofindan answer to claim:{1,2}. The results in table:{7,8} support claim-1 but with a caveat. On the other hand, values in table:9 improve upon the results reported by the original paper creating a new SOTA baseline. Additional experiments ingest custom hyper-parameters mentioned in our codebase in absence of the original hyper-parameters. None of these experiments include the RMmodule.\n6 Discussion\nThe reproducibility results from table:{5,6} corroborate the claims mentioned in section:3 to some extent. Reproduced version is within the \u00b12.4 range (positive value indicates better performance and vice-versa) except for the MetaQA-KG-Full dataset s\u0313 3-hop and WebQSP-KG-Full scenario which has a significant drop of 22.5% and 18.5% respec-\nReScience C 7.2 (#15) \u2013 P and Sardana 2021 7\ntively. The absence of RM module has been reported and discussed here8,9,10. For a given question, the RM module uses it s\u0313 context to extract useful information from the available edges present in the KG. This information is further plugged into the answer selection module to select more relevant answers. Thus, relation matching is a vital component in multi-hop question answering, especially in the KG-Full setting where more edges are present w.r.t. KG-50 setting or any smaller KG w.r.t. the KG-Full setting. Results from table:{5,6} corroborates the previous statement. Moreover, MetaQA-KG-50 3-hop outperforms the original model by a margin of +0.9% without using RM which is an interesting observation. Apart from one reported anomaly, the reproduced results are pretty close to the original results in the case of the MetaQA dataset. The default set of hyper-parameters mentioned in the original codebase(Refer section: 4.3) were used in the reproducibility study. The anomaly in WebQSP-KG-Full,i.e. 18.5% drop bolsters the importance of RM in the KG-Full setting. The reproduced results for WebQSP-KG50 are within the \u00b17% range. The use of different hyper-parameters can be one of the possible answers to this variation. This value is significant but not w.r.t. WebQSP-KGFull s\u0313 drop of 18.5% which again strengthens the importance of RM in the KG-Full setting. As mentioned in 5.1, RM is highly useful when the KG is considerably large. From table:{7, 8}, it is clear that TuckER [13] performs better than ComplEx [8] for the 3-hop scenario for bothMetaQA-KG datasets, i.e., Full and 50. Though these results strengthen claim-1, a more comprehensive set of tests may lead to a concrete conclusion (e.g., experiments employing a broader set of hyper-parameters). According to table:9, in all the cases, SBERT [2] outperforms RoBERTa [3] used in the original paper creating a new SOTA benchmark which supports claim-2. Some experiments didn\u02bct work out due to the lack of time. E.g. Using RelationalTucker3 [17] and SimplE [18] to test claim-1. Furthermore, the hyper-parameter search couldn\u02bct be done due to the same reason hence we had to pick the default ones mentioned in the codebase. All these create room for further experiments and improvements.\n6.1 What was easy The paper was straightforward to understand. The open-sourced codebase helped us get kick-started.\n6.2 What was difficult The structure of the codebase made it difficult to navigate it. Since the code relied upon different techniques for the two datasets, the development of one function that trains different kinds of KG embeddings and another function that trains different kinds of QA models for both datasets was difficult. MetaQA uses LSTM/GRU [19] / [20] whileWebQSP uses RoBERTa [3] to perform the same task of generating question embeddings. Also, training KG embeddings for MetaQA yields files in the form of NumPy [21] files while WebQSP uses LibKGE [22] for the same purpose which produces LibKGE specific KG embedding(KGE) models. Reproduction and the extensive study were a bit hard in the beginning as KGE and question embedding methodology varied for both datasets. After having a couple of virtual meetings with the author and code review, it became easier to conduct the planned experiments. The unavailability of hyper-parameters used to train each module increased the experiment cycle multi-fold.\n6.3 Communication with original authors Wehad a couple of virtual meetings with the primary author of [1]. Though it was daunting to understand the codebase due to the reasons mentioned in section:6.2 with the\n8https://github.com/malllabiisc/EmbedKGQA/issues/1 9https://github.com/malllabiisc/EmbedKGQA/issues/51 10https://github.com/malllabiisc/EmbedKGQA/issues/56\nReScience C 7.2 (#15) \u2013 P and Sardana 2021 8\nhelp and support of the author, it became easier to navigate the codebase.\n6.4 Future Scope We think that there is a wide range of empirical analysis and experimentation that can be performed for multi-hop QA task, out of which we are sharing a few here:\n1. Using KG embedding compression techniques like [23] in KG Embedding Module.\n2. Using recent transformer models like Performer [24], Reformer [25] etc. for generating question embeddings.\n3. Using low-dimensional hyperbolic KG embeddings [26] in KG embedding module along with hyperbolic word embeddings [27] for question embedding module.\n4. A new approach for sentence embedding, SBERT-WK [28] instead of SBERT [2] can be tried out."}], "title": "[Re] Improving Multi-hop Question Answering over Knowledge Graphs using Knowledge Base Embeddings", "year": 2021}
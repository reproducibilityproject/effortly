{"abstractText": "Variational Fair Clustering (VFC) is a general variational fair clustering framework that is compatible with a large class of clustering algorithms, both prototype\u2010based and graph\u2010 based [1]. VFC is capable of handling large datasets and offers a mechanism that allows for a trade\u2010off between fairness and clustering quality. We run a series of experiments to evaluate the major claims made by the authors. Specifically, that VFC is on par with SOTA clustering objectives, that it is scalable, that it has a trade\u2010off control, and that it is compatible with both prototype\u2010based and graph\u2010based clustering algorithms.", "authors": [{"affiliations": [], "name": "Floor Eijkelboom"}, {"affiliations": [], "name": "Mark Fokkema"}, {"affiliations": [], "name": "Anna Lau"}, {"affiliations": [], "name": "Luuk Verheijen"}, {"affiliations": [], "name": "Koustuv Sinha"}, {"affiliations": [], "name": "Sharath Chandra Raparthy"}], "id": "SP:1dbbef3f993d3e3c90e3eed969923e765ec7307f", "references": [{"authors": ["I.M. Ziko", "J. Yuan", "E. Granger", "I.B. Ayed"], "title": "Variational Fair Clustering.", "venue": "Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 35", "year": 2021}, {"authors": ["N. Mehrabi", "F. Morstatter", "N. Saxena", "K. Lerman", "A. Galstyan"], "title": "A survey on bias and fairness in machine learning.", "venue": "ACM Computing Surveys (CSUR)", "year": 2021}, {"authors": ["F. Chierichetti", "R. Kumar", "S. Lattanzi", "S. Vassilvitskii"], "title": "Fair clustering through fairlets.", "year": 2018}, {"authors": ["S.K. Bera", "D. Chakrabarty", "N.J. Flores"], "title": "Negahbani. \u201cFair algorithms for clustering.", "venue": "arXiv preprint arXiv:1901.02393", "year": 2019}, {"authors": ["A. Backurs", "P. Indyk", "K. Onak", "B. Schieber", "A. Vakilian", "T. Wagner"], "title": "Scalable fair clustering.", "venue": "In: International Conference on Machine Learning. PMLR", "year": 2019}, {"authors": ["L. Huang", "S.H.-C. Jiang", "N.K. Vishnoi"], "title": "Coresets for clustering with fairness constraints.", "venue": "arXiv preprint arXiv:1906.08484", "year": 2019}, {"authors": ["C. R\u00f6sner", "M. Schmidt"], "title": "Privacy preserving clustering with constraints.", "venue": "arXiv preprint arXiv:1802.02497", "year": 2018}, {"authors": ["M. Schmidt", "C. Schwiegelshohn", "C. Sohler"], "title": "Fair coresets and streaming algorithms for fair k-means clustering.", "year": 2018}, {"authors": ["M. Kleindessner", "S. Samadi", "P. Awasthi", "J. Morgenstern"], "title": "Guarantees for spectral clustering with fairness constraints.", "venue": "In: International Conference on Machine Learning. PMLR", "year": 2019}, {"authors": ["L. Lin", "P.D. Sherman"], "title": "Cleaning data the Chauvenet way.", "venue": "The Proceedings of the SouthEast SAS Users Group, SESUG Proceedings, Paper", "year": 2007}, {"authors": ["D.-T. Dinh", "T. Fujinami", "V.-N. Huynh"], "title": "Estimating the optimal number of clusters in categorical data clustering by silhouette coefficient.", "venue": "In: International Symposium on Knowledge and Systems Sciences", "year": 2019}, {"authors": ["L.O. Hall"], "title": "Objective function-based clustering.", "venue": "In:Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery", "year": 2012}, {"authors": ["C. Cortes", "V. Vapnik"], "title": "Support-vector networks.\u201d In: Machine learning", "venue": "Eijkelboom et al. 2022 12 [Re] Reproduction Study of Variational Fair Clustering", "year": 1995}], "sections": [{"text": "R E S C I E N C E C"}, {"heading": "Replication / ML Reproducibility Challenge 2021", "text": "[Re] Reproduction Study of Variational Fair Clustering\nFloor Eijkelboom1,2, ID , Mark Fokkema1,2, ID , Anna Lau1,2, ID , and Luuk Verheijen1,2, ID 1University of Amsterdam, Amsterdam, the Netherlands \u2013 2Equal contributions\nEdited by Koustuv Sinha,\nSharath Chandra Raparthy\nReviewed by Anonymous Reviewers\nReceived 04 February 2022\nPublished 23 May 2022\nDOI 10.5281/zenodo.6574653"}, {"heading": "Reproducibility Summary", "text": ""}, {"heading": "Scope of Reproducibility", "text": "Variational Fair Clustering (VFC) is a general variational fair clustering framework that is compatible with a large class of clustering algorithms, both prototype\u2010based and graph\u2010 based [1]. VFC is capable of handling large datasets and offers a mechanism that allows for a trade\u2010off between fairness and clustering quality. We run a series of experiments to evaluate the major claims made by the authors. Specifically, that VFC is on par with SOTA clustering objectives, that it is scalable, that it has a trade\u2010off control, and that it is compatible with both prototype\u2010based and graph\u2010based clustering algorithms."}, {"heading": "Methodology", "text": "To reproduce the results from Ziko et al., the original code is altered by removing bugs. This code is used to perform reproduction experiments to test the four claims made by the authors, as described above. Furthermore, three replication experiments have been implemented as well: different values for the trade\u2010off parameter and Lipschitz constants have been investigated, an alternative dataset is used, and a kernel\u2010based VFC framework has been derived and implemented."}, {"heading": "Results", "text": "We found that that three of the four claims made by Ziko et al. are supported, and that one claim is partially supported. VFC is mostly on par with SOTA clustering objectives, if the trade\u2010off parameter and Lipschitz constant are tuned. Additionally, we verified that VFC is scalable on large\u2010scale datasets and found that the trade\u2010off control works as stated by the authors. Moreover, we conclude that VFC is capable of handling both prototype\u2010based and graph\u2010based datasets. Regarding the replicability of VFC, the ex\u2010 periment on the alternative dataset did not indicate that VFC is worse than SOTA base\u2010 lines. The proposed kernel\u2010based VFC performs on par with the original framework."}, {"heading": "What was easy and difficult", "text": "The original paper provides extensive theoretical derivations and explanations of the VFC approach, both through derviations and text. Moreover, the code of the original paper was publicly available. The original authors responded quickly to our mails and\nCopyright \u00a9 2022 F. Eijkelboom et al., released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Floor Eijkelboom (eijkelboomfloor@gmail.com) The authors have declared that no competing interests exist. Code is available at https://github.com/MarkiemarkF/FACT \u2013 DOI 10.5281/zenodo.6508390. \u2013 SWH swh:1:dir:016245babcdc02c28ac98547de32f7270c79f81f. Open peer review is available at https://openreview.net/forum?id=rq8fRhMm20F.\nReScience C 8.2 (#14) \u2013 Eijkelboom et al. 2022 1\nwere very willing to discuss our results. Although the VFC code was publicly available, it was undocumented and contained some bugs that were hard to find given the lack of documentation. Moreover, there were vast differences between the implementation of the original authors and the baseline models. This required conversions between the models for the comparisons. Lastly, running the VFC code took many hours, which resulted in us not being able to run all algorithm\u2010dataset combinations we wanted to.\nCommunication with original authors The original authors have been approached twice. The mail contact helped clarify im\u2010 plementation details, particularly regarding the Ncut algorithm. The authors explained and specified the usage of the trade\u2010off parameter and the Lipschitz constant. Addi\u2010 tionally, they explained how they obtained the K\u2010means baseline results. The authors have been informed about our proposed kernel\u2010based VFC framework and replied with enthusiasm.\nReScience C 8.2 (#14) \u2013 Eijkelboom et al. 2022 2\n1 Introduction\nFairness inmachine learning (ML) has received significant interest asML algorithms are used in, for example, financial, marketing, and educational decision purposes, thereby directly influencing human lives. However, achieving fairness is still a challenge due to neglected or unaware biases in the data and ambiguity of the definition [2]. One of the notions of fairness is fair clustering [3, 4, 5, 6, 7, 8, 9]. Fair clustering is a clus\u2010 tering approach where the resulting cluster assignment should not be disproportion\u2010 ately different for individuals with different protected attributes (e.g. gender). This is achieved by balancing the distribution of protected subgroups in each cluster. A limita\u2010 tion of state\u2010of\u2010the\u2010art (SOTA) fair clustering algorithms is that they can only be used for either prototype\u2010based or graph\u2010based objectives. For large datasets, graph\u2010based clus\u2010 tering algorithms pose additional difficulties since they are not computationally scal\u2010 able. In the paper Variational Fair Clustering (VFC), [1] address these problems. They propose the VFC framework that provides a general fair formulation for both prototype\u2010based and graph\u2010based clustering objectives by incorporating an original fairness term. This framework is implemented using three well\u2010known clustering objectives (K\u2010medians, K\u2010means, and Ncut), and are compared to their respective SOTA versions from [5], [4], and [9].\n2 Scope of reproducibility\nIn this reproducibility study, we focus on themain claims of Ziko et al. (original authors, OA) stated in their paper (original paper, OP). The SOTA fair clustering algorithms are referred to as baselines. The main claims of the OP are:\nClaim 1 VFC is on parwith state\u2010of\u2010the\u2010art clustering objectives on the Synthetic, Synthetic\u2010 unequal, Adult, Bank, and Census II datasets:\na VFCusingK\u2010medians has lower objective energies, lower fairness errors, and higher balances than the baseline [5]. b VFC using K\u2010means has lower objective energies than the baseline [4], but will achieve similar fairness errors and balances. c VFC using Ncut has slightly higher objective energies than the baseline [9], but achieves similar fairness errors and balances1.\nClaim 2 It is computationally feasible to run VFC using the Ncut algorithm on large\u2010scale datasets that have 2.5 million records. Claim 3 VFC provides the best clustering objective with the smallest \u03bb that satisfies a pre\u2010 defined fairness level \u2211 k DKL(U ||Pk) \u2264 \u03f5. Claim 4 VFC is capable of performing both prototype\u2010based and graph\u2010based clustering objectives.\n3 Methodology\nWe test the validity of the claims using the provided VFC framework. In the following sections we cover the description of this architecture, the used datasets and hyperpa\u2010 rameters. We include an experimental setup and code section which covers three repro\u2010 duction experiments and three replication exerpiments. The former is performed to evaluate the reported results, and the latter is conducted to further analyse the claims\n1The OA do not specify what is considered \u2018slightly\u2019 worse. If we consider the maximum relative deviation considered as \u2018slight\u2019 in the OP, we come to a relatively high figure of 100%. We decided to not formalise this idea for this was not needed interpreting our results.\nReScience C 8.2 (#14) \u2013 Eijkelboom et al. 2022 3\nand improve on the proposed framework. This work includes tuning hyperparameters, testing alternative datasets, and introducing a kernel\u2010based clustering approach.\n3.1 Model description The VFC objective is described by a variational trade\u2010off between a clustering objective and an original fairness objective. The fairness objective is given by the KL\u2010divergences between the demographic proportions in the data and the distributions of each cluster. The trade\u2010off is regulated by the hyperparameter \u03bb. The OA derive a general convex\u2010 concave formulation for the VFC objective, which is optimised using auxiliary functions (for the formal details, see the OP). The VFC requires a predefined number of clusters (K), a trade\u2010off parameter (\u03bb), and a sensitive attribute (e.g. gender).\n3.2 Datasets The VFC algorithm has been tested on five datasets, two of which were synthetically cre\u2010 ated by the OA. Both synthetic datasets have two demographic groups and 400 numeric data points. The Synthetic (SB) dataset is balanced, as both demographic groups contain 200 data points. The Synthetic-unequal (SU) dataset has 300 and 100 data points in the groups respectively. The OA also used three real datasets from the UCI machine learn\u2010 ing repository2: Bank3, Adult4, and Census II5. We use the same sensitive attributes and remove the same values within the datasets as the OP. Our replicability researchuses theVFCalgorithmon twodatasets: Student6 andDrugnet7. We use the sex or gender as sensitive attribute. An overview of the characteristics of the real datasets can be found in the appendix.\n3.3 Hyperparameters In the reproduction experiments, the hyperparameters are set to have the same value as in the OP. An overview of the hyperparameters can be found in the appendix. Note that different Lipschitz constants are used for different parts of reproduction, as is explained in more detail in paragraph 5. The OP conducted a hyperparameter search on the \u03bb and K parameters as two of their experiments, but did not draw any conclusions with regard to the value ofK. For our additional experiments, we perform hyperparameter searches for the \u03bb param\u2010 eter and Lipschitz constant on all datasets but the Census II dataset to improve the OP\u2019s results. We considered seven different Lipschitz constants, as shown in Figure 2, with 10 different seeds each. We conducted another manual search for the \u03bb parameter after fixing the Lipschitz constants. Here we tested the integer values 1 up to 10, in addition to 0.5 and 1.2 for Ncut. For K\u2010means and K\u2010medians 20 different values between 3000 and 10000 were tested. The tuned hyperparameters are reported in the appendix. For the kernel approach, a small manual search has been conducted over the integers 1 up to 10 for every parameter in the kernel.\n3.4 Experimental setup and code\nThe code provided by the OA8 was used to reproduce the experiments. This code con\u2010 tained some bugs, hence we created an updated codebase9 for our experiments. The\n2https://archive.ics.uci.edu/ml/index.php 3https://archive.ics.uci.edu/ml/datasets/Bank+Marketing 4https://archive.ics.uci.edu/ml/datasets/adult 5https://archive.ics.uci.edu/ml/datasets/US+Census+Data+(1990) 6https://archive.ics.uci.edu/ml/datasets/student+performance 7https://sites.google.com/site/ucinetsoftware/datasets/covert-networks/drugnet 8https://github.com/imtiazziko/Variational-Fair-Clustering 9https://github.com/MarkiemarkF/FACT\nReScience C 8.2 (#14) \u2013 Eijkelboom et al. 2022 4\ncode for theK\u2010means baseline10 [4] is used to create replication results. Due to limited time and resources, we have not implemented the baselines forK\u2010medians [5] and Ncut [9]. Lastly, the results on the Drugnet dataset obtained by Kleindessner et al. are used as baseline in one of the replication experiments. We conduct a total of three reproduction experiments and three replication experiments. The reproduction experiments consist of comparing the baselinemodels to VFC, testing the scalability of the Ncut algorithm, and recreating the \u03bb plots from the OP. The repli\u2010 cation experiments include tuning the Lipschitz constant, exploring the generalisability of VFC on other datasets, and introducing a kernel\u2010based VFC.\nReproduction experiments For the comparison experiments defined in Claim 1, the clustering algorithms K\u2010medians, K\u2010means, and Ncut are applied to all five datasets used in the OP. The performance of the algorithms is measured with three metrics as defined in the OP: clustering energy (objective), fairness error, and balance. Every algorithm\u2010dataset combination is run with different seeds to obtain a mean and a stan\u2010 dard deviation. All combinations are run with 30 different seeds except the Census II dataset and the Ncut algorithm, as these combinations take infeasibly long. These are run with only five different seeds. To prevent the metrics from taking outliers into ac\u2010 count, Chauvenet\u2019s criterion [10] is used (see appendix). We consider a statistic repro\u2010 ducible if is at least as good as the one reported results in the OP. Moreover, a result is unreproducible if the reproduction attempt is at least one standard deviation worse. All values in between are labelled inconsistent. Scalability, as defined in Claim 2, is evident from the results of the fair Ncut algorithm on the largest dataset, Census II. If the OP\u2019s results of this combination are successfully reproduced in a reasonable time frame, this implies scalability. To test Claim 3, the \u03bb plots in the OP\u2019s Figure 2 are reproduced by running the Fair K\u2010 means and Ncut algorithms on the Adult and Bank datasets with varying \u03bb values. The Ncut plots are generated with both a Lipschitz constant of 2.0 and 0.001. Albeit the OA discuss Figure 3 in the OP, no claim has been made on the impact of the value ofK for the algorithms. Therefore, this figure is not reproduced in this research. After failing to reproduce some reported results, it was established in communication with theOA that some reported\u03bb values are incorrect and therefore unknown. Amanual search is executed to test 10 \u03bb values ranging from 100 to 1500 for the K\u2010medians and K\u2010means algorithms on the SB dataset. The search is not feasible for Ncut algorithm on Census II, given the limited time and resources of this research. Note that the results for \u03bb = 0 can be interpreted as the performance of the algorithm not taking into account fairness at all.\nTuning the Lipschitz constant The effect of the unreported Lipschitz constant is inves\u2010 tigated by running the Adult and Bank datasets with seven different Lipschitz constants ranging from 10\u22125 to 2.0, with 10 different seeds for all three algorithms. Afterwards, 30 different seeds are tested for the tuned Lipschitz and \u03bb values for the Adult and Bank datasets. Lastly, we run the Ncut algorithm on Census II three times with Lipschitz 10\u22125 to retest scalability.\nExploring other datasets To evaluate the performance of the VFC framework, the ex\u2010 periment performed by the OA has been replicated. The implementation10 of the K\u2010 means baseline paper [4] used IBM\u2019s Cplex Optimiser11, which we were not able to get full access to. Given that we were therefore limited to using smaller datasets, only the Student dataset was used. This baseline uses a fairness trade\u2010off parameter \u03b4 de\u2010 scribing how loose the fairness condition is, with 0 \u2264 \u03b4 \u2264 1. The fairness condition is\n10https://github.com/nicolasjulioflores/fair_algorithms_for_clustering 11https://www.ibm.com/products/ilog-cplex-optimization-studio/resources\nReScience C 8.2 (#14) \u2013 Eijkelboom et al. 2022 5\nmet exactly when \u03b4 = 0, and is ignored when \u03b4 = 1. No \u03b4 has been specified in the work of the OA; we opted for a relatively high value of \u03b4 = 0.9 as a result of a small manual search: due to the small size of the dataset, all \u03b4 values up to 0.9 yielded an equal fair\u2010 ness error. We therefore opted to use the highest value to yield the best fairness error to favour the baseline. Furthermore, to verify whether the VFC\u2010algorithm can be applied to graph\u2010based struc\u2010 tures, as stated in Claim 4, the Fair Ncut algorithm is run on the Drugnet dataset. In the OP, the Ncut algorithm was only used on non\u2010graphical datasets that were converted to graphical data using pair\u2010wise affinities. In the derivation of the respective auxiliary function, the OA assume the adjacency matrix to be positive semi\u2010definite. Hence, we evaluate if the graph\u2010based framework also works on non\u2010synthetic adjacencies. This is evaluated by using the Drugnet dataset and comparing it to the Ncut baseline [9].\nKernel\u2010based clustering To derive a kernel\u2010based VFC framework, a reformulated ob\u2010 jective and corresponding auxiliary function have to be derived. Kernel\u2010based cluster\u2010 ing can be seen as a generalisation ofK\u2010means clustering. Rather than minimising the Euclidean distance between the individual points and their corresponding cluster cen\u2010 tres, a kernel\u2010based distance metric is minimised, i.e. the objective is given by:\nmin S \u2211 k \u2211 p sp,kd(xp, ck) s.t. sp \u2208 \u2207K\u2200p, (1)\nfor some kernel\u2010based distancemetric d. This definition provides a general formulation which combinedwith theVFC fairness term is refereed to as kernel\u2010basedVFC.Wemake use of the following fact:\nProposition 1 Given current clustering solution Si at iteration i, the auxiliary function for kernel-based clustering can be written in the following general form:\nHi(S) = \u2211 p stpa i p,\nwhere aip is given by a kernel-based distance metric d(xp, cik) (proof in section 9).\nWeconduct a third experiment to evaluate the effect of using a kernel in VFC. The kernel\u2010 based approach is implemented and evaluated with the polynomial kernel, the Gaus\u2010 sian kernel, and the hyperbolic tangent kernel. These decisions are motivated in the appendix. Given that no cluster labels are available, a measure of consistency within clusters, called silhouette coefficient (SC), is used as a measure, c.f. [11]. The fairness error and balance metric are used as well. To ensure that SC is not biased to any of the two algorithms, the cosine similarity is used for comparison. The use of a kernel implies a computational complexity of O(N2KM) and hence only the smaller datasets such as SB, SU, and 2,500 random entries from the Bank dataset are considered (more information on the complexity is given in the appendix). Due to time constraints, only a single run has been done for each dataset and kernel combination.\n3.5 Computational requirements All results were obtained on Windows 10 with an Intel i7\u201010875H CPU. The GPU is not used as the algorithms are optimised for CPU multiprocessing. In total, the runtime of all reported results in this paper was 107 hours. Including explorative experiments, the total runtime was 160 hours. Of this total, 135 hours were for conducting the experi\u2010 ments on the Census II dataset. Specific runtimes per algorithm\u2010dataset combination are given in the appendix.\nReScience C 8.2 (#14) \u2013 Eijkelboom et al. 2022 6\n4 Results\nWe have conducted the aforementioned experiments and gathered the results together in the following two subsections. The first subsection focuses on the findings of the reproduction experiments. The second subsection covers the findings of the replication experiments.\n4.1 Results reproducing original paper The results of the reproduction experiments are reported in their respective columns in Table 1. The mean is reported, and the standard deviation is given between paren\u2010 theses. The bold numbers indicate the best values for a given dataset. Table 6, Table 7, and Table 8 in section 10 visualise the comparison of the OP\u2019s results to ours using the parameters listed in Table 5. The red entries indicate results that were unreproducible with the original hyperparameters, and the orange entries correspond to those that were inconsistent.\nComparison between Backurs et al. and Fair K\u2010medians In total, 10 out of 12 results support Claim 1a with the initial hyperparameters. The fairness of the SB dataset is la\u2010 belled as an inconsistent reproduction, and the balance is labelled as an unreproducible result. Tuning the \u03bb improved the fairness, but the balance did still not reach baseline performance (Table 2). Given that the vast majority of results lie well within reproduc\u2010 tion range, and that the only deviating result is on a small synthetic dataset, Claim 1a is almost completely supported.\nComparison between Bera et al. and Fair K\u2010means The fairness error and balance for the SB dataset could only be reproduced after tuning \u03bb (Table 2). Furthermore, repro\u2010 duction of the fairness error and balance on the SU dataset was only achieved after the exclusion of bad seeds using Chauvenet\u2019s criterion (section 8). The seeds for all excluded\nReScience C 8.2 (#14) \u2013 Eijkelboom et al. 2022 7\noutliers are shown in appendix. All metrics for the Census II dataset deviated from the OP and were worse than the baseline results. However, three out of five runs achieved similar results to the OP. In this case, the two bad seeds were not flagged as outliers. Claim 1b is therefore also mostly supported, but less so than in the OP.\nComparison between Kleindessner et al. and Fair Ncut The reproduction results of the Ncut algorithm show similar performance compared to the baseline model. Note that, in our results, the Ncut algorithm performed better than the baseline in terms of the objective on the SU dataset. Regarding fairness, the reproduced VFC is on par with the baseline for both synthetic datasets, but worse for the Adult dataset. Moreover, the reproduced balance is only better for the Adult dataset. Thus, Claim 1c is also mostly supported.\nScalability The results for the Fair Ncut algorithm were not successfully reproduced for the Census II dataset using the reported hyperparameters in the OP. Adjusting the Lipschitz constant to 1.0, as suggested by the authors, did not solve this issue. Lowering the Lipschitz constant to 10\u22125 did enable convergence, taking 34 hours per run on aver\u2010 age. This achieved reasonable results, despite not reaching the reported performance in the OP. Thus, Claim 2 is supported, but less so than in the OP.\n\u03bb plots In Figure 1, the blue curve depicts the discrete\u2010valued clustering objective (K\u2010 means or Ncut) obtained at convergence as a function of \u03bb. The fairness error is denoted in red. As shown, increasing the \u03bb parameter lowers the fairness error. Unlike the OP\u2019s reported result of theK\u2010means objective for the Adult dataset, Figure 1a does not show the oscillating behaviour. Different from Figure 2 of the OP, the Lipschitz constant was set to 0.001 for the Ncut plots in Figure 1e and Figure 1f to improve convergence. This is reflected in the lower fairness errors. By choosing a \u03bb arbitrarily large, an arbitrarily small fairness error will be found as seen in 1. Hence, Claim 3 is supported.\n4.2 Results beyond original paper\nTuning the Lipschitz constant Figure 2 shows that Lipschitz constants down to 10\u22125 speed up convergence for K\u2010means and Ncut on the Bank dataset. These results are reflected for all three algorithms in both Synthetic datasets and the Adult dataset. This is also shown in the runtimes in Table 11, section 10. Further decreasing the Lipschitz constant leads to invalid results; NaN values impede convergence.\nReScience C 8.2 (#14) \u2013 Eijkelboom et al. 2022 8\nReScience C 8.2 (#14) \u2013 Eijkelboom et al. 2022 9\nIn all cases, the reproduced results with the original hyperparameters were equal to, or improved by, lower Lipschitz constants aside from the balance ofK\u2010medians on the Adult dataset, and the fairness error of K\u2010medians on the Bank dataset (Table 3). How\u2010 ever, the main improvement lies in the convergence.\nOther datasets For the Student dataset, the baseline algorithm resulted in a clustering objective of 128.012, a fairness error of 0.0056, and a balance of 0.8327. Additionally, the VFC using K\u2010means and \u03bb = 50 gave an objective of 341.892, a fairness error of 0.0032, and a balance of 0.8982, therefore having a higher objective, lower fairness error, and higher balance. Furthermore, running the VFC Fair Ncut algorithm on the Drugnet dataset resulted in an objective score of 0, a fairness error of 0.06, and a balance of 0.24. The baseline results are not exactly reported in [9]. However, the objective and balance can be interpreted from their Figure 5, which approximately equals an objective of 0.01, and a balance of 0.26. Thus, VFC obtains a lower objective and lower balance. Interestingly, the obtained objective score of 0 indicates that the optimal Ncut solution has been found. Hence, we can conclude that Claim 4 is supported.\nKernel\u2010based VFC The kernel\u2010based VFC obtains the same silhouette coefficients, fair\u2010 ness error, and balance as the standard VFC. The results are summarised in Table 13 in section 11.\n5 Discussion\nGiven the results shown in section 4 and the varying outcomes contrasting the results in the OP, we conclude that not all claims presented in section 2 are supported.\nReproduction Based on our results using the original hyperparameters, Claim 1 can\u2010 not be supported. We therefore discuss the validity of Claim 1 based on the tuned \u03bb values. RunningK\u2010medians on the SB dataset yielded a similar objective, but a dissimi\u2010 lar fairness error and balance. As expected, increasing the \u03bb parameter did improve the fairness error and balance, but did so at the cost of the clustering quality as suggested in Figure 1 and Table 2. For the other datasets, we were able to find hyperparameters that made the VFC framework compatible with the baseline, and hence Claim 1a is mostly supported. Surprisingly, the results for K\u2010means on the SB dataset did improve with a tuned \u03bb pa\u2010 rameter. The similarity between the results on the SU dataset was achieved after the removal of bad seeds. The K\u2010means algorithm performed differently on the Census II dataset than reported by theOA.Due to time constraints, wewere not able to explore this further. Given these judgements, we conclude that Claim 1b is also mostly supported. The reproduction results of the Ncut algorithm show that the SU dataset had a better clustering objective. The algorithm also performed better on the Adult dataset as the balance was higher. As mentioned in the OP, there are no baseline results that can be compared to our results for the Bank and Census II datasets. Hence, we compare these reproduced results only to the results obtained in the OP. For the Bank dataset, the objec\u2010 tive worsened, but the fairness and balance were improved. The results on the Census II dataset are not as reliable, since we ran the experiment a total of five times. All in all, Claim 1c is therefore partially supported. We have tuned the Lipschitz constant such that it did not return NaN values on the Cen\u2010 sus II dataset while using the Ncut algorithm. It was not feasible to run many experi\u2010 ments, as a Lipschitz constant of 10\u22125 took an average of 34 hours to converge. Thus,\nReScience C 8.2 (#14) \u2013 Eijkelboom et al. 2022 10\nwe observe that VFC using the Ncut algorithm scales to large datasets. Although our re\u2010 sults did not exactly reflect those of the OP, the performancewas still reasonable. Hence, Claim 2 is verified. As mentioned earlier, there is a trade\u2010off between the clustering objective and the fair\u2010 ness. Figure 1 shows that, when the \u03bb increases, the clustering objective increases and the fairness decreases. Observe that we do not have the oscillating behaviour as in the OP for the K\u2010means algorithm on the Adult dataset, whichmay be caused by the seed that was used to run this experiment. Unfortunately, we have not explored this further due to limited time. Thus, Claim 3 is supported.\nReplication We found that decreasing the Lipschitz\u2010constant to 10\u22125 improved the con\u2010 vergence speed, and in some instances performance. The proposed VFC algorithm does not perform worse than the K\u2010means baseline. The K\u2010means and K\u2010medians experi\u2010 ments have shown that VFC is capable of performing prototype\u2010based clustering objec\u2010 tives. The Drugnet dataset, combined with the Ncut algorithm, has shown that VFC can perform graph\u2010based clustering objectives as well, and that it is on par with its baseline. Hence, Claim 4 is supported. The results obtained with the kernel\u2010based VFC were in\u2010line with those found using the formulation of the OP, suggesting that the kernel\u2010based approach finds the same solutions. Due to limited time, no extensive parameter search has been done. Better parameters could improve the expressiveness of the kernels, potentially leading to better results.\nWhat was easy and difficult The original paper is well\u2010structured and contains elabo\u2010 rate theoretical derivations and explanations, whichmade the concept of the VFC easier to understand. During the reproduction of the experiments, the provided code from the original paperwas greatly beneficial. TheOA responded quickly andwere verywilling to help. Despite the access to the original code, it was initially challenging to use as it was undocumented. Another problem was that the OA used a different Lipschitz constant than was used in the code. This issue was found later, after communicating with the OA. However, it is still unknown which Lipschitz constant the OA used for their experi\u2010 ments. Next to that, the code to obtain the results for the baseline models was missing as well. This was necessary for the replication experiment of the Student dataset. The implementation of the K\u2010means baseline model was publicly available, but the metric used for clustering differed from those the OA used, which made comparison difficult. Hence, the results of the baseline needed to be converted into the measures that were used by the OA. Moreover, the K\u2010means baseline could not be implemented on large datasets, as there was no access to IBM\u2019s premium Cplex Optimiser.\nShortcomings of the original paper The shortcomings found in theOPare: correctness of the reported \u03bb parameters, not stating the correct Lipschitz value, and the errors in the provided code.\nConclusion This report shows both a reproducation and a replication of Variational Fair Clustering. We conclude that solely the OP and the provided code do not suffice to validate the claims stated by the OA. Investigating more large\u2010scale datasets and the effects of other Lipschitz constants are suggested for future research. Potentially, a Lips\u2010 chitz constant can be found that provides rigidness and fast convergence. This paper in\u2010 troduced the notion of a flexible kernel\u2010based approach. As its results are already on par with the VFC framework proposed by the OA, this approach looks promising. Further investigation by using different kernels, or improving parameters, may be beneficial. Unfortunately, due to limited time and resources, other aspects of the VFC framework were not examined. Investigating different fairness metrics and studying the influence\nReScience C 8.2 (#14) \u2013 Eijkelboom et al. 2022 11\nof largerK values on the clustering energy, fairness and balance, may improve the VFC performance. All in all, the VFC framework allows for a large class of clustering algorithms to be used in fair clustering. The framework is capable of handling large datasets and offers a mechanism that allows for a trade\u2010off between fairness and clustering quality. More\u2010 over, the resulting algorithms are competitive with SOTA fair clustering algorithms."}, {"heading": "Proof of Proposition 1", "text": "As seen in Equation 1, theK\u2010means objective can be altered to\nmin S \u2211 k \u2211 p sp,kd(xp, ck) s.t. sp \u2208 \u2207K\u2200p,\nwhere d is some kernel\u2010based distancemetric. Let \u03ba : X\u00d7X \u2192 R be an arbitrary kernel function. We can define the following distance\u2010based metric based on \u03ba [12]:\nd(xp, ck) = \u03ba(xp, xp)\u2212 2 \u2211n\nl=1 sl,k\u03ba(xl, xp)\u2211n l=1 sl,k +\n\u2211n q=1 \u2211n l=1 sq,ksl,k\u03ba(xq, xl)\n( \u2211n\nq=1 sq,k) 2\n. (2)\nBy a similar argument as given in Proposition 2 of the OP, it follows that\u2211 p sp,k(xp \u2212 ck)2 \u2264 \u2211 p sp,kd(xp \u2212 cik).\nhence, the auxiliary function for Kernel\u2010Based Clustering can be written as\nHi(S) = \u2211 p stpaip,\nwhere aip,k is given by d(xp, cik) as given in Equation 2.\n10 Experimental results\nComparison between OP and reproduction results\nReScience C 8.2 (#14) \u2013 Eijkelboom et al. 2022 14"}, {"heading": "Tuned Lipschitz hyperparameters", "text": "Excluded outlier seeds\nReScience C 8.2 (#14) \u2013 Eijkelboom et al. 2022 15\nRuntime\nRuntime in seconds Datasets K\u2010medians K\u2010means Ncut Ncut Lipschitz Synthetic 4.8(\u00b11.7)\u00d7 30 4.6(\u00b12.3)\u00d7 30 5.8(\u00b11.9)\u00d7 30 N/A Synthetic\u2010 unequal 3.7(\u00b10.9)\u00d7 30 4.0(\u00b11.6)\u00d7 30 2.5(\u00b11.4)\u00d7 30 N/A Adult 44.6(\u00b123.3)\u00d7 30 56.6(\u00b139.6)\u00d7 30 3785.0(\u00b1752.7)\u00d7 10 52.8(\u00b161.4)\u00d7 30 Bank 43.1(\u00b127.1)\u00d7 30 70.1(\u00b149.0)\u00d7 30 2835.4(\u00b1532.1)\u00d7 5 109.2(\u00b165.0)\u00d7 30 Census II 6423.5(\u00b14072.2)\u00d7 5 7838.7(\u00b16202.4)\u00d7 5 261.6(\u00b11.3) \u00d7 5 (invalid results) 127174.1(\u00b113039.6) \u00d73\nThree well\u2010known kernels to satisfy Mercer\u2019s condition are the polynomial kernel, the Gaussian kernel, and the hyperbolic tangent kernel, which is why these kernels are the ones analysed in this work.\nReScience C 8.2 (#14) \u2013 Eijkelboom et al. 2022 16\n11.3 Kernel results\nReScience C 8.2 (#14) \u2013 Eijkelboom et al. 2022 17"}], "title": "[Re] Reproduction Study of Variational Fair Clustering", "year": 2022}
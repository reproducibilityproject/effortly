{"abstractText": "The following paper is a reproducibility report for From Goals, Waypoints & Paths To Long Term Human Trajectory Forecasting [1]. The basic code was made available by the author at this https url. We have verified all claims and results from the experiments mentioned in the paper to support the claims. The central claim of YNet is that it sets state\u2010of\u2010the\u2010art short and long\u2010term prediction standards by a multi\u2010modal network em\u2010 ploying both segmentation matrices and past trajectory heat\u2010maps together.", "authors": [{"affiliations": [], "name": "Abhishek Shukla"}, {"affiliations": [], "name": "Sourya Roy"}, {"affiliations": [], "name": "Yogesh Chawla"}, {"affiliations": [], "name": "Avi Amalanshu"}, {"affiliations": [], "name": "Shubhendu Pandey"}, {"affiliations": [], "name": "Rudransh Agrawal"}, {"affiliations": [], "name": "Aditya Uppal"}, {"affiliations": [], "name": "Pradipto Mondal"}, {"affiliations": [], "name": "Anubhab Dasgupta"}, {"affiliations": [], "name": "Debashis Chakravarty"}, {"affiliations": [], "name": "Koustuv Sinha"}, {"affiliations": [], "name": "Sharath Chandra Raparthy"}], "id": "SP:eaa21ae4d17626c312ac2b91e3ddab2c9b10d4d6", "references": [{"authors": ["K. Mangalam", "Y. An", "H. Girase", "J. Malik"], "title": "From Goals, Waypoints & Paths To Long Term Human Trajectory Forecasting.", "venue": "Proc. International Conference on Computer Vision (ICCV). Oct. 2021. ReScience C", "year": 2021}, {"authors": ["O. Ronneberger", "P. Fischer", "T. Brox"], "title": "U-Net: Convolutional Networks for Biomedical Image Segmentation.", "venue": "CoRR abs/1505.04597", "year": 2015}, {"authors": ["A. Bhattacharyya", "M. Hanselmann", "M. Fritz", "B. Schiele", "C.-N. Straehle"], "title": "Conditional Flow Variational Autoencoders for Structured Sequence Prediction", "year": 2020}, {"authors": ["K. Mangalam", "E. Adeli", "K.-H. Lee", "A. Gaidon", "J.C. Niebles"], "title": "Disentangling Human Dynamics for Pedestrian Locomotion Forecasting with Noisy Supervision", "year": 2020}, {"authors": ["T. Salzmann", "B. Ivanovic", "P. Chakravarty", "M. Pavone"], "title": "Trajectron++: Dynamically-Feasible Trajectory Forecasting With Heterogeneous Data", "year": 2021}, {"authors": ["A. Gupta", "J. Johnson", "L. Fei-Fei", "S. Savarese", "A. Alahi"], "title": "Social GAN: Socially Acceptable Trajectories with Generative Adversarial Networks.", "year": 2018}, {"authors": ["A. Sadeghian", "V. Kosaraju", "N. Hirose", "S. Savarese"], "title": "SoPhie: An Attentive GAN for Predicting Paths Compliant to Social and Physical Constraints.", "year": 2018}, {"authors": ["A. Robicquet", "A. Sadeghian", "A. Alahi", "S. Savarese"], "title": "Learning Social Etiquette: Human Trajectory Understanding In Crowded Scenes.", "year": 2016}, {"authors": ["J. Bock", "R. Krajewski", "T. Moers", "S. Runde", "L. Vater", "L. Eckstein"], "title": "The inD Dataset: A Drone Dataset of Naturalistic Road User Trajectories at German Intersections.", "venue": "IEEE Intelligent Vehicles Symposium (IV)", "year": 2020}, {"authors": ["L. Biewald"], "title": "Experiment TrackingwithWeights and Biases", "venue": "Software available fromwandb.com", "year": 2020}, {"authors": ["N. Deo andM.M. Trivedi"], "title": "Trajectory Forecasts in Unknown Environments", "venue": "Conditioned on Grid-Based Plans", "year": 2021}, {"authors": ["J. Liang", "L. Jiang", "A. Hauptmann"], "title": "SimAug: Learning Robust Representations from Simulation for Trajectory Prediction", "year": 2020}, {"authors": ["K. Mangalam", "H. Girase", "S. Agarwal", "K.-H. Lee", "E. Adeli", "J. Malik", "A. Gaidon"], "title": "arXiv:2004.02025 [cs.CV", "venue": "It Is Not the Journey but the Destination: Endpoint Conditioned Trajectory Prediction", "year": 2020}, {"authors": ["H. Zhao"], "title": "TNT: Target-driveN Trajectory Prediction", "year": 2020}, {"authors": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "title": "Deep Residual Learning for Image Recognition.", "venue": "CoRR abs/1512.03385", "year": 2015}], "sections": [{"text": "R E S C I E N C E C Replication / ML Reproducibility Challenge 2021\n[Re] From goals, waypoints and paths to longterm human trajectory forecasting\nAbhishek Shukla1,2, ID , Sourya Roy1,2, ID , Yogesh Chawla1,2, ID , Avi Amalanshu1,2, ID , Shubhendu Pandey1,2, ID , Rudransh Agrawal1,2, ID , Aditya Uppal1,2, ID , Viswesh N1,2, ID , Pradipto Mondal1\u201e ID , Anubhab Dasgupta1\u201e ID , and Debashis Chakravarty1\u201e ID 1Indian Institute of Technology, Kharagpur, Kharagpur, West Bengal, India \u2013 2Equal contribution\nEdited by Koustuv Sinha,\nSharath Chandra Raparthy\nReviewed by Anonymous Reviewers\nReceived 04 February 2022\nPublished 23 May 2022\nDOI 10.5281/zenodo.6574699"}, {"heading": "Reproducibility Summary", "text": ""}, {"heading": "Scope of Reproducibility", "text": "The following paper is a reproducibility report for From Goals, Waypoints & Paths To Long Term Human Trajectory Forecasting [1]. The basic code was made available by the author at this https url. We have verified all claims and results from the experiments mentioned in the paper to support the claims. The central claim of YNet is that it sets state\u2010of\u2010the\u2010art short and long\u2010term prediction standards by a multi\u2010modal network em\u2010 ploying both segmentation matrices and past trajectory heat\u2010maps together."}, {"heading": "Methodology", "text": "The model essentially combines a segmentation map and past trajectory heatmaps to encode a combined input to three sub\u2010networks modelled after the U\u2010Net architecture [2]. The author\u2019s code was used to benchmark the claims, and some experiments were performed thereafter. Free\u2010to\u2010use platforms like Google Colaboratory and Kaggle were used to train these models. We have reproduced the code base in PyTorch Lightning (originally in PyTorch Ignite) and found consistent results across the board."}, {"heading": "Results", "text": "Through our testing, wewere able to comewithin 2% of the proposedmetrics on certain datasets like Stanford Drone Dataset (SDD) and ETH/UCY, implying the author\u2019s claims are sanguine and reproducible on varied hardware. However, certain results such as long\u2010term predictions on the Intersection Drone (InD) dataset were quite different; the probable reasons for which have been discussed."}, {"heading": "What was easy", "text": "Obtaining the proposed results on the SDD and InD datasets was easy. Well\u2010documented interactive notebooks for training and testing along with the requisite data for SDDwere provided with the codebase. The code could be run with minimal changes overall.\nCopyright \u00a9 2022 A. Shukla et al., released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Abhishek Shukla (shuklaabhishek@iitkgp.ac.in) The authors have declared that no competing interests exist. Code is available at https://github.com/Viswesh-N/MLRC-2021. \u2013 SWH swh:1:dir:3ddeeb8325dbac3f85d05e49621a9adef5f44ebb. Open peer review is available at https://openreview.net/forum?id=HV2zgpM7n0F.\nReScience C 8.2 (#37) \u2013 Shukla et al. 2022 1"}, {"heading": "What was difficult", "text": "The codebase and data provided by the authors were incomplete, and contained various redundancies and unused methods, making it difficult to follow. The requisite code and data required to reproduce the experiments on the ETH and UCY datasets were completelymissing. These factors were compounded by stringent computational power requirements, which were difficult to fulfill for students without access to server\u2010grade computation.\nCommunication with original authors Attempts were made to contact the authors regarding some doubts, which went without response. Running the experiments thereafter were done based on our understanding of the paper and code.\nReScience C 8.2 (#37) \u2013 Shukla et al. 2022 2\n1 Introduction\nThe paper reproduced in this report aims to tackle multiple pedestrian trajectory pre\u2010 dictions using rich multi\u2010modal predictions for the use of autonomous vehicles, social robots, etc. Earlier approaches to this problem have been auto\u2010regressive in nature [3][4][5], i.e., using n points (or, analogically, data from the last t seconds) from the dataset to produce the next immediate point, and recurring this process. In this paper, the trajectory distribution, viz. the path taken by a pedestrian is conceived to have been influenced majorly by two factors:\n\u2022 Epistemic: The conscious will of the pedestrian to reach a particular goal.\n\u2022 Aleatoric: The unknown and unexpected changes in the environment influencing the path they take to reach the goal.\nThe proposed architecture incorporates this multi\u2010modality. An explicit probability dis\u2010 tribution of the many possible broad future trajectories is predicted first (modelling the where of the agent). Then, random future points of the trajectory are taken in conjunc\u2010 tion with the sampled way\u2010points to obtain probability maps over the remaining pre\u2010 dicted points (modelling the how of the agent). To formulate this report, we have experimented on the author\u2019s code by adding/remov\u2010 ing social pooling layers and employing visualisation tools. We have tried the unique idea ofmulti\u2010dataset trainingwhereinwe train themodel for long on aparticular dataset, and then immediately introduce it to a completely new dataset. We also performed some experiments such as shifting the prediction origin to different previously predicted points instead of the one closest in time to the present. These experiments are explained in detail in the following sections.\n2 Scope of reproducibility\nThe problem of multi\u2010modal trajectory prediction is key to unlocking vehicular intelli\u2010 gence and autonomous navigation. The problem this particular paper aims to address is finding pedestrian trajectories in an environment crowded with similar and/ or dif\u2010 ferent interacting agents. By extension, the scope of using such architecture is beyond pedestrians, as virtually any human or non\u2010human agent navigating crowded terrains that may benefit from segmentation may employ such mechanics of trajectory predic\u2010 tion. The central claims of the paper can be summarized as follows:\n\u2022 Conditionedway\u2010point predictions: Themodel performsbetter thanpreviousworks as trajectories are conditioned in a two\u2010stage manner, with aleatoric predictions conditioned upon epistemic ones. This provides stricter constraints on the final set of predictions by modelling them explicitly, as opposed to SGAN [6], SoPhie [7] and other attention based mechanisms that produce a diverse set of trajectories.\n\u2022 Scene Segmentation: The model performs better than contemporary models as semantic information about the scene is accounted for. The paper considers as in\u2010 put, both the segmentation map and trajectory heatmap of probabilities. The seg\u2010 mentation step is a novel addition that classifies the possible trajectory avenues of the pedestrian. Intuitively, this can be thought of as follows: Given a predicted valid goal of the pedestrian, he is highly unlikely to climb a wall to achieve it. Rather, he shall traverse his current course (say, a park track). The segmentation steps performs better than previous non\u2010segmented attention mechanisms.\n\u2022 Long Term Prediction: The model uses these techniques to achieve significantly improved results on long horizon trajectory prediction as well as short horizon.\nReScience C 8.2 (#37) \u2013 Shukla et al. 2022 3\n3 Methodology\nWe used the GitHub repository provided by the author as the base. However, it only contained the base model for results on the different data sets. In order to reproduce the rest of the experiments, we had to make changes accordingly.\n3.1 Model descriptions The problem of multi\u2010modal trajectory prediction can be formulated as prediction of future trajectory given past positions of pedestrians in the scene. This section has been referenced from the original paper [1] (Section 3). The scene image is first processed by a segmentation network, producing segmentation map S (dividing the image in various classes) of the same spatial size as image. In a par\u2010 allel branch the past trajectories are embedded in a trajectory heatmap. Concatenation of both produces the heatmap tensorHs. For each frame n in the input, the heatmap is calculated as\nH(n, i, j) = 2 ||(i, j)\u2212 un||\nmax(x,y)\u03f5I ||(x, y)\u2212 un|| (1)\nThe heatmap and semantic maps are concatenated and fed into the encoder branch Ue of the network. The subsequent architecture consists of 3 sub\u2010networks Ue , Ug and Ut. Ue which is an encoder like U\u2010Net [2] is used in the model architecture to process the tensorHs. It has a total ofNUe blocks, it reduces the dimensions of the H \u00d7 W toHU \u00d7WU and increases the channel depth. The final representation is termed as HUe which is then passed in the goal decoder Ug and the trajectory decoder Ut. The next step is termed as the \u201dGoal &Waypoint Heatmap Decoder\u201d in which the output maps of Ue at various spatial resolutions are passed in Ug which is modelled fromU\u2010Net. The output is passed through a deconvolution layer, which involves the application of a transpose convolution, effectively expanding the previous feature map, spatially dou\u2010 bling the resolution in every block. The encoder map from the respectively sized input layer is concatenated. To attain the final resolution of the goal, heatmap feature merg\u2010 ing is done. Therefore, it can be said a U\u2010Net block consists of deconvolution, feature merging and convolution layers. The final branch Ut is termed as the \u201dTrajectory Heatmap Decoder\u201d. The waypoint dis\u2010 tributions from Ug are sampled using the softargmax operation\nsoftargmax(X) = \u2211 i i \u2211 j e Xij\u2211 i,j e Xij , \u2211 j j \u2211 i e Xij\u2211 i,j e Xij  Aheatmap tensorHUg is generated using these samples. Each heatmap is downsampled to its corresponding size from the architecture. These heatmaps are concatenated with the respective blocks from HUe which goes through Ut for a decoding phase.\n3.2 Datasets All annotationswere preprocessed tomatch the format[\u2019trackId\u2019, \u2019frame\u2019, \u2019x\u2019, \u2019y\u2019, \u2019sceneId\u2019, \u2019metaId\u2019]. For experiments based on varying thepredictionwin\u2010 dow, the data was preprocessed with different trajectory lengths.\nStanford DroneDataset (SDD): [8] The dataset by default contains annotations for 10,300 unique agents across 6 classes, of which 5232 belong to the class of pedestrians. Trajec\u2010 tories are sampled at FPS = 30 in 2D image coordinates. We use the pre\u2010processed data\nReScience C 8.2 (#37) \u2013 Shukla et al. 2022 4\nprovided by the authors, which has been downsampled to FPS = 2.5 for short term train\u2010 ing and FPS = 1 for long term. The lengths of the input sequences np are 8 and 5 respec\u2010 tively, while the those of the output nf are 12 and 60 respectively. All trajectories not belonging to the pedestrian class or of insufficient length (< nf + np) are dropped. The midpoints of the bounding boxes are considered to be the ground truth positions. Tra\u2010 jectories are split at temporal discontinuities and a staggered sliding window is used to split long trajectories. The resultant is a set of 1502 trajectories. A semantic map with 5 classes is generated. There is a train/test split of 30 scenes for training and 17 for testing.\nIntersection Drone Dataset (InD): [9] The dataset by default contains 11,500 trajectories across 3 classes, in 32 scenes at 4 distinct locations. Trajectories are sampled at FPS = 25 in 2D world coordinates. We perform the preprocessing described in the paper, which involves downsampling the data to FPS = 1 for np = 5 and nf = 30, filtering out non\u2010 pedestrians, filtering out short (< nf + np) trajectories, splitting long (using the sliding window technique) and discontinuous trajectories. The coordinates are brought into image coordinates by using the scale factors and cropping parameters provided in the paper as cited. The resultant is a set of 1396 trajectories. The scenes of one location (ID 4) are used for testing while those of the remaining 3 are used for training.\nETH and UCY datasets (ETH/UCY): Combined, the dataset contains trajectories for 1536 pedestrians, in 9 scenes at 5 distinct locations. Trajectories are sampled at FPS = 2.5 in 2D world coordinates. The authors claim to use preprocessed data from [6], however this is not usable on account of being normalized with unknown parameters and being in the incorrect format. We instead use preprocessed data provided by the authors in response to an issue raised on the GitHub repository. We take np = 8 and nf = 12 as per the paper. We use the homographymatrices providedwith the datasets to transform the pixels into world coordinates. A leave\u2010one\u2010out cross\u2010validation strategy is employed.\n3.3 Hyperparameters Several hyperparameters were experimented with in this paper. Those of particular im\u2010 portance are the following:\n\u2022 Ke: Themodel aims to produceKe possible future trajectories due to the epistemic uncertainty of final goal. This is a hyperparameter that can be tuned to find the\nReScience C 8.2 (#37) \u2013 Shukla et al. 2022 5\noptimal value for any given probability map as input.\n\u2022 Ka: After the end\u2010point prediction distribution, the path(s) taken to reach themost likely of them constitutes absolute randomness when not conditioned on aleatory factors and environmental interactions. Thus, given the goal, the model produces Ka separate predictions for path.\n\u2022 T : The temperature parameter T during sampling can be visualised as a scaling factor for the generated heat\u2010map. It is used to control the trade\u2010off between di\u2010 versity and precision; a lower value meaning the predictions are condensed in a smaller spatial density and vice versa. Intuitively, a higher value of T should be used for long\u2010term predictions, but this parameter can still be tuned to gauge the power of the model.\nAll hyper parameters were tuned by random searches and heuristic guesses instead of brute/ grid searches or Bayesian techniques, mainly due to constraints posed by very high computational resource requirements. However, the trends in accuracy could still be predicted and reasoned as the effects of changing the values were both experimen\u2010 tally visible and logically explainable. These points have further been discussed in the Results and Discussions sections.\n3.4 Experimental setup and code The code for this experiment is set\u2010up mainly in the train.py, evaluate.py and test.py Python files that import helper methods defined in python files in the utils folder. Python notebooks are given to facilitate running different parts of the code. De\u2010 tailed instructions about each, the presence of pre\u2010trainedweights and/ or pre\u2010processed files and other relevant information is given in the ReadMe section of the repository. The main metrics of interest are the ADE (mean L2\u2010norm distance between all future ground truth and predicted points) and FDE (mean L2\u2010norm distance between final fu\u2010 ture ground truth and predicted points). The accuracy of all experiments are validated with these metrics, where a lower value means a more accurate result.\n3.5 Computational requirements All experimentswere run usingGoogle Colaboratory, whose back\u2010end has the Tesla P100 GPU. The technical specification of the GPU is that it has 3584 CUDA cores, 16GB CRAM and a 4096\u2010bit memory interface. The run\u2010times we faced on such a setup for the different experiments is quite long. For example, running the code without any ablations on the SDD dataset took roughly 10 minutes for a single epoch. Of course, this value is dependant on other hyperparameters such as batch size.\nReScience C 8.2 (#37) \u2013 Shukla et al. 2022 6\n4 Results\nThe results we obtained are listed below. Upon comparison, we are confident that the results resemble those in the paper. However, due to the lack of extensive computational capabilities, we were forced to limit our training to a fraction of what was done in the original paper. Despite this, we have deeply analysed fitting and convergence trends and are confident that the model does at least as well as claimed, and even better in some experiments. All results were logged with ease with the WandB solution [10]. In general, extensive overview of error trends could be gauged from auto\u2010generated graphs, which cemented our beliefs of convergence and correctness.\n4.1 Results reproducing original paper\nPerformance of model as compared to baselines \u2014 Our reproduced model functions better than all previous baselines, and satisfactorily close to the reults of YNet as cited in the paper.\nPerformance of model for different datasets of ETH/UCY: Importance of social masking \u2014 This ta\u2010 ble is produced separately because it addresses the importance of social masking. The paper results are with masking, while ours are without.\nTurning TTST and CWS on and off \u2014 TTST and CWS are heuristics designed to improve sam\u2010 pling. TTST encourages clustering samples in high\u2010density regions by roughly thresh\u2010 olding and clustering the probability distribution. CWS discourages sampling erratic trajectories by assuming points to be sampled between two known points roughly divide the line segment joining them. The roughness is modelled using Gaussian distributions. We experiment with various possible state to verify their effect on error.\nReScience C 8.2 (#37) \u2013 Shukla et al. 2022 7\nHyperparameter tuning -Ka,Ke and T \u2014\n4.2 Results beyond original paper\nGeneralization \u2014 One of our main findings beyond the paper was the generalizing power of the model, abstracted by its potential to be used as a transfer learning model. Given that the data can be processed in a similar manner outside the domain of the actual model, we observed much\u2010improved results when trained for a very short time on a completely new dataset. To explore this further the idea of Fine\u2010tuning was explored in which once the Y\u2010net model was trained on Dataset A, the final weights were consid\u2010 ered as the pretrained weights for a new training and the model was further trained on Dataset B for very few epochs. In this way the model not only remembered the previous training features but also adapted the conditions for the new dataset. This method proved to improve the per\u2010 formance of the model and is computationally very inexpensive.\nReScience C 8.2 (#37) \u2013 Shukla et al. 2022 8\n5 Visualisations\nSome real world trajectories on actual reference images are provided below. The lines are enlarged for clarity. It can clearly be seen that the model works fantastically well in real\u2010life scenarios to predict trajectories. Segmentation has worked well in these cases, with no class overlap except cases when the trajectory itself goes across two different semantic classes like in figure (b).\n6 Discussion\nMany obstacles were faced in the reproduction of the results, particularly for students with limited access to server grade computational resources. The codebase and data had many redundancies and omissions, requiring some experiments to be recreated from scratch. Despite these challenges, our experiments achieve a satisfactory repro\u2010 duction of the paper. However, some discrepancies were observed. Our results on the InD dataset were significantly better than those cited in the paper. This may be due to model optimizaitons in PyTorch Lightning or fortunate random initialization of weights. The experiments on the SDD and ETH/UCY datasets were found to be consistent with the paper. The predicted trajectories represented state\u2010of\u2010the\u2010art accuracy, evenmore so with the TTST and CWS sampling techniques enabled. We observed enhanced accuracy with dataset dilution and marginal training on a new dataset. The long\u2010term prediction results were viable, viz. significantly better than contemporary models, enabling this model to be used in a real\u2010time prediction stack for trajectory prediction.\n6.1 Further discussion on the results Table 4 confirms that the usage of TTST and CWS markedly improves the accuracy of the final results by increasing the tendency to draw samples from relevant points in the probability distribution. However, this comes at the cost of increased computational complexity.\nReScience C 8.2 (#37) \u2013 Shukla et al. 2022 9\nThemodel is robust towards changes in context and hence can be extended to a wide va\u2010 riety of applications, as evidenced by Table 5. Good transfer performance indicates the architecture is the dominant factor in our results as opposed to extraneous factors such as sampling techniques, demonstrating its strength. This experiment also highlights the potential of transfer learning in improving neural network performance, especially for complex models like this, which reap the benefit of carrying over a dense field of features. The crux of the paper, the predictive power of the chosen multi\u2010modality, is succinctly demonstrated by Figure 2. We see a marked improvement in inference as we increase both Ka and Ke independently of each other. This direct relationship indicates that the approach of sequentially predicting epistemic and aleatoric distributions is signifi\u2010 cant, and verifies this paper\u2019s contribution to the state\u2010of\u2010the\u2010art of pedestrian trajectory prediction. There are significant increases in all errors upon removing social masking and pooling as seen in table 3. This is a central claim of a paper, i.e. aleatory interactions from the surroundings are a crucial factor in determining the best path taken. Modelling themusing the segmentationResNet\u2010101 [15] is evidently better thanusing deterministic criteria to model these interactions.\n6.2 What was easy The experiments on the SDDand InDdatasets requiredminimal effort to reproduce. The authors provide interactive Python notebooks for training and testing, along with all the requisite scripts and most of the data to run them. Due to the modularity of the code, performing the ablation study was also easy.\n6.3 What was difficult There were significant challenges faced in this reproduction. Due to limited computa\u2010 tional resources, training the extensive CNN was problematic (mainly owing to a per\u2010 epoch training time of 30\u201060 minutes, despite a small batch size of 4). Further, the code, data, pre\u2010trained weights, semantic maps, semantic models for the experiments on the ETH/UCY datasets were missing from the repository, rendering it impossible to exactly reproduce the authors\u2019 experiments. The paper suggests preprocessed data from [6] be used, however we found it was unusable as that data had been normalized with un\u2010 known parameters. The preprocessing functions provided by the authors for ETH/UCY could not be used as it was not possible to fulfill some arguments. There was an error in the pre\u2010trained weights provided for the long term SDD experiment, which caused a tensor dimension mismatch during testing. The codebase contained some unused methods. There were some redundant parame\u2010 ters, for example batch_size = 4 in the yaml configuration file and BATCH_SIZE = 8 declared in the training notebooks. Some lines of code were commented\u2010out without documentation. These factors made it difficult to follow and debug the code.\n6.4 Communication with original authors Multiple attempts to contact the authorsweremade over a 2month period. Some doubts with the paper and the absence of ETH/UCY experiments from the codebasewere raised. However, there was no response from the authors."}], "title": "[Re] From goals, waypoints and paths to longterm human trajectory forecasting", "year": 2022}
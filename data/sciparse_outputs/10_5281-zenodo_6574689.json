{"abstractText": "This report aims to reproduce the results in the paper Fairness and Bias in Online Selection [1]. The paper presents optimal and fair alternatives for existing Secretary and Prophet algorithms. Reproducing the paper involves validating three claims made by the au\u2010 thors [1]: (1) The presented baselines are either unfair or have low performance, (2) The proposed algorithms are perfectly fair, and (3) The proposed algorithms perform comparably to or even better than the presented baselines.", "authors": [{"affiliations": [], "name": "Roxana Petcu"}, {"affiliations": [], "name": "Pim Praat"}, {"affiliations": [], "name": "Jeroen Wijnen"}, {"affiliations": [], "name": "Manolis Rerres"}, {"affiliations": [], "name": "Koustuv Sinha"}, {"affiliations": [], "name": "Sharath Chandra Raparthy"}], "id": "SP:666733896e2344b549a80f8d66bab6fa3ed836c4", "references": [{"authors": ["J. Correa", "A. Cristi", "P. Duetting", "A. Norouzi-Fard"], "title": "Fairness and Bias in Online Selection.", "venue": "Proceedings of Machine Learning Research", "year": 2021}, {"authors": ["N. Buchbinder", "K. Jain", "M. Singh"], "title": "Secretary problems via linear programming.", "venue": "In: Mathematics of Operations Research", "year": 2014}, {"authors": ["S. Cayci", "S. Gupta", "A. Eryilmaz"], "title": "Group-Fair Online Allocation in Continuous Time.", "venue": "Advances in Neural Information Processing Systems", "year": 2020}, {"authors": ["E. Celis", "V. Keswani", "D. Straszak", "A. Deshpande", "T. Kathuria", "N. Vishnoi"], "title": "Fair and Diverse DPP-Based Data Summarization.", "venue": "Proceedings of the 35th International Conference on Machine Learning", "year": 2022}, {"authors": ["F. Chierichetti", "R. Kumar", "S. Lattanzi", "S. Vassilvtiskii"], "title": "Matroids, Matchings, and Fairness.", "venue": "Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics", "year": 2019}, {"authors": ["S. Moro", "P. Cortez", "P. Rita"], "title": "A Data-Driven Approach to Predict the Success of Bank Telemarketing.", "venue": "Decision Support Systems", "year": 2014}, {"authors": ["M.L. Takac"], "title": "Z\u00e1bovsk\u00fd. \u201cData analysis in public social networks.", "venue": "Scientific Conference and International Workshop Present Day Trends of Innovations (Jan", "year": 2012}, {"authors": ["E. Samuel-Cahn"], "title": "Comparison of Threshold Stop Rules and Maximum for Independent Nonnegative Random Variables.", "venue": "The Annals of Probability", "year": 1984}, {"authors": ["S. Ehsani", "M. Hajiaghayi", "T. Kesselheim", "S. Singla"], "title": "Prophet Secretary for Combinatorial Auctions and Matroids.", "year": 2017}, {"authors": ["J. Correa", "P. Foncea", "R. Hoeksma", "T. Oosterwijk", "T. Vredeveld"], "title": "Posted Price Mechanisms and Optimal Threshold Strategies for Random Arrivals.", "venue": "English. In: Mathematics of Operations Research", "year": 2021}, {"authors": ["Y.S. Chow", "H.E. Robbins", "D.O. Siegmund"], "title": "Great expectations: The theory of optimal stopping.", "year": 1971}, {"authors": ["J. Correa", "A. Cristi", "P. Duetting", "A. Norouzi-Fard"], "title": "Fairness and Bias in Online Selection (full version).", "year": 2021}], "sections": [{"text": "R E S C I E N C E C Replication / ML Reproducibility Challenge 2021\n[Re] Replication Study of \u201dFairness and Bias in Online Selection\u201d Roxana Petcu1, ID , Pim Praat1, ID , Jeroen Wijnen1, ID , and Manolis Rerres1, ID 1University of Amsterdam, Amsterdam, The Netherlands\nEdited by Koustuv Sinha,\nSharath Chandra Raparthy\nReviewed by Anonymous Reviewers\nReceived 04 February 2022\nPublished 23 May 2022\nDOI 10.5281/zenodo.6574689"}, {"heading": "Reproducibility Summary", "text": ""}, {"heading": "Scope of Reproducibility", "text": "This report aims to reproduce the results in the paper Fairness and Bias in Online Selection [1]. The paper presents optimal and fair alternatives for existing Secretary and Prophet algorithms. Reproducing the paper involves validating three claims made by the au\u2010 thors [1]: (1) The presented baselines are either unfair or have low performance, (2) The proposed algorithms are perfectly fair, and (3) The proposed algorithms perform comparably to or even better than the presented baselines."}, {"heading": "Methodology", "text": "We recreate the algorithms and perform experiments to validate the authors\u2019 initial claims for both problems under various settings, with the use of both real and synthetic data. The authors conducted the experiments in the C++ programming language. We mainly used the paper as a resource to reimplement all algorithms and experiments from scratch in Python, only consulting the authors\u2019 code base when needed."}, {"heading": "Results", "text": "For the Multi\u2010Color Secretary problem, we were able to recreate the outcomes, as well as the performance of the proposed algorithm (with a margin of 3\u20104%). However, one baseline within the second experiment returned different results, due to inconsisten\u2010 cies in the original implementation. In the context of the Multi\u2010Color Prophet problem, wewere not able to exactly reproduce the original results, as the authors ran their exper\u2010 iments with twice asmany runs as reported. After correcting this, the original outcomes are reproduced. A drawback of the proposed prophet algorithms is that they only select a candidate in 50\u2010 70% of cases. None results are often undesirable, so we extend the paper by proposing adjusted algorithms that pick a candidate (almost) every time. Furthermore, we show empirically that these algorithms maintain similar levels of fairness."}, {"heading": "What was easy", "text": "The paper provides pseudocode for the proposed algorithms, making the implementa\u2010 tion straightforward. More than that, recreating their synthetic data experiments was\nCopyright \u00a9 2022 R. Petcu et al., released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Jeroen Wijnen (j.wijnen@outlook.com) The authors have declared that no competing interests exist. Code is available at https://github.com/pimpraat/FACT-Ai. \u2013 SWH swh:1:dir:da9cb18759db5ecf30608639d8b35a4b247a483d. Open peer review is available at https://openreview.net/forum?id=S9gs3MmhAY.\nReScience C 8.2 (#32) \u2013 Petcu et al. 2022 1\neasy due to providing clear instructions."}, {"heading": "What was difficult", "text": "However, we did run into several difficulties: 1) There were a number of inconsistencies between the paper and the code, 2) Several parts of the implementation were missing in the code base, and 3) The secretary experiments required running the algorithm over one billion iterations, whichmakes verifying its results within a timelymanner difficult.\nCommunication with original authors The authors of the original paper were swift in their response with regard to our find\u2010 ings. Our main allegations regarding inconsistencies in both the Secretary and Prophet problems were confirmed by the authors.\n1 Introduction\nOnline selection is challenging, as candidates arrive sequentially and decisions need to bemadewith incomplete information. Such problems affect our lives in a profoundway. Algorithmic credit scores determinewho receives amortgage orwho can start a business. Automatic systems even decide who receives an organ transplant or who has priority in being admitted to an Intensive Care Unit. The growing importance of algorithms has prompted concerns about fairness alongside efficiency. Addressing these issues is essential. Research has long focused on the performance of such algorithms, but fairness was not a consideration until recently [2, 3]. The paper \u201dFairness and Bias in Online selection\u201d [1] aims to fill this gap. The authors propose three fair selection algorithms for the domain of online selection. In particular, they focus on two well\u2010known problems from the literature: the Secretary and the Prophet problems. The aim of this study is to validate the claims made in the paper and see if their results can be reproduced. Furthermore, we propose an adjusted version of their prophet al\u2010 gorithms, in order to reduce the number of occurrences where the algorithm does not pick any candidate.\n2 Scope of reproducibility\nThe focus of our study is to empirically verify the claims of the paper. Themathematical proofs and theorems lie outside our scope. The authors of the original paper propose three online algorithms, namely oneMulti\u2010Color Secretary and twoMulti\u2010Color Prophet approaches that are both fair and efficient. They also present several existing baseline algorithms. The main empirical claims of the paper are:\n\u2022 The used baselines are either unfair or have low performance.\n\u2022 The proposed algorithms are perfectly fair.\n\u2022 The proposed algorithms perform comparably or even better than the presented baselines.\nThese claims are supported by experiments where all algorithms select a candidate based on a variety of datasets. The original authors consider an algorithm fair when \u201dthe solution obtained is balanced with respect to some sensitive attribute (e.g. nation\u2010 ality, race, gender)\u201d [1]. This notion is consistent with previous work [4, 5]. More pre\u2010 cisely, algorithms are considered fair when they respect the prior probability p that the\nReScience C 8.2 (#32) \u2013 Petcu et al. 2022 2\nbest candidate belongs to a certain group. Performance is defined as the probability of selecting the optimal candidate (in the Secretary setting) and the average value of the selected candidate (in the Prophet setting). We validate their claims by recreating the algorithms and experiments from scratch in Python. We use the description in the paper as a guideline, referring to the original code only when necessary.\n3 Methodology\n3.1 The Secretary Algorithm\nAlgorithm 1 describes the original au\u2010 thors\u2019 fair secretary algorithm. Candi\u2010 dates appear in increasing order of their arrival time \u03c4 . The algorithm calculates one threshold t \u2208 [0, 1]k per group c, us\u2010 ing Formula 1.\nt\u2217k = (1\u2212 (k \u2212 1)pk) 1 k\u22121\nt\u2217j = t \u2217 j+1\n( \u2211j r=1\npr j\u22121 \u2212 pj\u2211j\nr=1 pr j\u22121 \u2212 pj+1\n) 1 j\u22121\nfor 2 \u2264 j \u2264 k \u2212 1\nt\u22171 = t \u2217 2 \u00b7 e\np2 p1 \u22121\n(1)\nAlgorithm 1 Fair Secretary\nInput: t \u2208 [0, 1]k, a time threshold per group n candidates scores Output: i \u2208 [n], index of chosen candi\u2010 date for i\u2190 1 to n do\nif \u03c4i\u2032 > tc(i) then if i\u227b max {i\u2032 | \u03c4i\u2032 \u2264 \u03c4i, c (i\u2032 |) = c(i)}\nthen return i\nend end\nend This threshold determines fromwhich point the algorithm could pick a candidate. Once the thresholds are computed, they are used as input to Algorithm 1 along with the data. The algorithm will return its best candidate.\n3.2 Prophet algorithm In contrast to the secretary setting, the prophet algorithm knows the distribution that the scores are drawn from. Furthermore, all prophet experiments occur in a setting where each candidate is in a unique group, meaning each group has a size of one. This constraint aims to create an algorithm that gives candidates in each arrival position the same probability of being picked. Each group represents a position in the queue and arrival order of the candidates in this problem is not random. The original authors consider two settings in their paper: one where each candidate is drawn from a separate distribution, and one where the scores are i.i.d.. Pseudocode for both models is illustrated in Algorithms1 2 and 3.\n1Since the original authors refer to Algorithm 2 as the Fair General Prophet and FairPA interchangeably, it makes sense for us to do the same.\nReScience C 8.2 (#32) \u2013 Petcu et al. 2022 3\nAlgorithm 2 Fair General Prophet Input: F1...Fn, distributions\nq1...qn, fair optimal pick proba\u2010 bility n candidates scores Output: i \u2208 [n], index of chosen can\u2010 didate for i\u2190 1 to n do\nif vi \u2265 F\u22121i ( 1\u2212 qi/21\u2212s/2 ) then\nreturn i end s\u2190 s+ qi\nend\nAlgorithm 3 Fair IID Prophet Input: F1...Fn, distributions\nq1...qn, fair optimal pick proba\u2010 bility n candidates scores Output: i \u2208 [n], index of chosen can\u2010 didate for i\u2190 1 to n do\nif vi \u2265 F\u22121 ( 1\u2212 2/3n1\u22122(i\u22121)/3n ) then\nreturn i end\nend\n3.3 Evaluation metrics For evaluating the experiments, the authors set several metrics that reflect both the fair\u2010 ness and efficacy of their study. For the Secretary algorithm they report the number of candidates picked by each model, the number of times the chosen candidates corre\u2010 spond to themaximumvaluemax Cj within their group, and the probability of choosing the maximummax C from the data. Meanwhile, the Prophet algorithms are compared based on the balance in selection rates across arrival order and the average value of the picked candidates.\n4 Code implementation\nImplementation of the experiments was done in Python, making use of the descriptions in the paper and the published code base 2. The original authors conducted their exper\u2010 iments in C++. The code was factorized neatly into different files for retrieving the data, implementation of algorithms and experiments. We were largely able to reproduce all of the code. However, three important elements of the code were lacking:\n\u2022 the experiments on the prophet algorithms\n\u2022 the production of plots and summary statistics of both experiments\n\u2022 the data preprocessing for real datasets\nDue to these issues, wewere unable to review the exact settings of the experiments. This made it difficult to determine the reason behind different results in our reimplementa\u2010 tion. Details are expanded on in the following section. As a consequence, we contacted the authors for further specifications of their approach. Moreover, the naming of the baselines and proposed algorithms in the original imple\u2010 mentation is inconsistent with the naming in the paper. The original papers of the base\u2010 lines were needed to figure out the used naming conventions. Lastly, it is important to note that our implementation does not utilise GPUs or paralleli\u2010 sation because we have sequential process. Therefore the results could not be sped up using high performance clusters. As a result, one of our experiments could not be run in a timely manner as it took over 40 hours for 1/5 of the data.\n2Original code: https://github.com/google-research/google-research/tree/master/fairness_and_bias_in_online_ selection. Our full implementation is open\u2010sourced and can be found on: https://github.com/pimpraat/FACT-Ai\nReScience C 8.2 (#32) \u2013 Petcu et al. 2022 4\n5 Experimental setup\n5.1 Secretary problem Data: The paper uses four different datasets for the Secretary problem, out of which two are synthetic. For each dataset, the algorithm runs 20,000 times. For the first dataset we divide candidates into four groups with 10, 100, 1000, and 10, 000 occurrences. The probability p of the best candidate coming from this group is the same for all colors, namely (p = .25). In the second setting, this condition is changed and group probabilities differ: p = (.3, .25, .25, .2). Thirdly, the authors use a dataset of phone calls made by a Portuguese banking institution [6]. For the purpose of this exper\u2010 iment, the score is the length of the phone call. The group probabilities are set to be equal (p = .2). Lastly, the algorithm is tested on a dataset of influencers of the social network \u2018Pokec\u2019[7]. The influencers\u2019 score is their number of followers and they are di\u2010 vided into five groups with equal probability: (p = .2) for each group.\nBaselines: The authors test their fair Secretary algorithm by contrasting it to two base\u2010 lines. Secretary algorithm (SA) computes themaximum score value assigned in the first 1/e part of the arrival sequence of the candidates. After that, it compares the rest of the values with the aforementioned picked one and returns the maximum value across the whole streamline. It does not consider a candidate\u2019s group. The Single\u2010color secretary algorithm (SCSA) selects a color with a probability proportional to the provided values of p, and then considers only candidates of that color.\n5.2 Prophet problem Data: The prophet algorithms are tested on two synthetic datasets. In the original paper, each algorithm runs 50, 000 times. In the first experiment, 50 samples are drawn from a uniform distribution [0, 1]. In the second experiment, 1000 samples are drawn from a binomial distribution with 1000 trials and probability of success of 1/2.\nBaselines: The authors compare their devised algorithmswith four baseline algorithms: First, the SC algorithm [8], which places a single threshold such that it finds a candidate 50 % of the time. Second, the EHKS algorithm [9] where each candidate is selected with probability 1n . Thirdly, the CFHOV algorithm [10], which uses a succession of thresh\u2010 olds derived from the probabilities that candidates are accepted. Lastly, the DP algo\u2010 rithm [11] that uses a differential equation to create thresholds. This last algorithm is excluded from their plots, as it is so unbalanced that it distorts the readability of the graph. During implementation we noticed that both the SC and EHKS algorithms were signif\u2010 icantly quicker. This is due to their property of using a constant calculated threshold for each run of the algorithm, instead of recalculating the threshold after seeing each candidate.\n6 Replication of results\n6.1 Secretary problem Figure 1 shows the results of the Secretary experiments from our implementation. Our algorithm is equally fair and appears to pick the optimal candidate with roughly the same frequency in three out of four experiments. The results from the original paper can be found in the Appendix (Figure 4). Table 1 shows the evaluationmetrics (as described in section 3.3) for all experiments. Our scores are generally comparable to those in the original paper, with a margin of just 3\u20104%.\nReScience C 8.2 (#32) \u2013 Petcu et al. 2022 5\nThe only algorithm in which our results differ is the SA, illustrated as U\u2010Pick and U\u2010 Max. The SA algorithm showed inconsistencies in two respects. To begin with, the authors\u2019 experiments show that in setting (a) (synthetic dataset with equal p), SA almost exclusively returns candidates from group 4. However, in setting (b) (when p differs per group) it selects from multiple groups. This change is striking, as the SA algorithm should not take into account the probabilities of different groups. We raised these observations in a chain of discussionswith the authors. They confirmed our suspicions that the results of the SA algorithm are not intuitive, but did not know the reason for the discrepancies. They indicated that one possible reason would be the manner of sampling synthetic data. Given their explanation, we chose to further analyze their C++ implementation and figure out whether our results are incorrect or if there are other reasons for these differences. We found out that there are several inconsistencies in their original implementation as compared to the paper:\n\u2022 New synthetic data are generated for each of the 20,000 iterations of the experi\u2010 ment instead of using the same dataset for all iterations\n\u2022 When testing whether the returned candidate at index i is the maximum from its group Cj , the authors apply a margin of 10. They verify whether score(i) \u2208 [max Cj \u2212 10], wheremax Cj represents the maximum score of color j.\n\u2022 Even though the original paper states that the probabilities p are not taken into account by algorithm SA, the original implementation does take into account the probabilitieswhen creating the synthetic data. It adds bias towards a certain group by assigning one candidate from that group theupper limit value of aunsigned int 64 data type in C++ ( 264 \u2212 1). This happens only in the second experiment.\nReScience C 8.2 (#32) \u2013 Petcu et al. 2022 6\nBecause of these implementation inconsistencies, parts of the experiments were not easily reproducible. We claim that they cause a difference in results for experiment (b). We test our claim by running the original code, but without the three inconsistencies mentioned above. The modified implementation outputs results that are much closer to our findings. They are illustrated in the Appendix in Figure 6. Furthermore, the SA algorithm also returned different results for dataset (d) on Influ\u2010 enceMaximization. Thepaper illustrates thatU\u2010pick selects candidates from twogroups, namely Under and Normal. However, our algorithm picks candidates only from the Normal group. To understandwhy this happened, we ran this experiment using the original code. The authors included neither the data nor the preprocessing steps, so we used our own preprocessed data. The results can be found in the Appendix in Figure 73. When using the same input data, the original code yields exactly the same results as our im\u2010 plementation. Therefore, the found inconsistencies originate from the data itself, and correcting the BMI formula from the original code should result in identical outcomes.4 We can thus conclude that the Influence Maximization experiment would be exactly re\u2010 produced if we were to have access to the originally prepossessed data.\n6.2 Prophet problem Figure 2 shows the experiment outcomes of our replicatedFairPAandFairIID algorithms. Even though the general trends in the plots match, our overall number of picks is far lower for each of the algorithms. The original authors appear to pick a candidate every single time.5 In some cases, the number of picks even exceeds the number of experi\u2010 ments run, which should not be possible.6 By contrast, our reproduced FairPA algorithm returns a None result 50% of the time, and FairIID 30%. This makes sense, as the algorithm was designed to pick each candidate with probability of q/2.7 We also ran the original code, after making minor adjustments to get it running and to deal with None picks. Running on this code shows identical results to our own reproduced implementation. The most probable explanation for both discrepancies in the reproduced results is that the original authors ran 100, 000 experiments, instead of 50, 000. Figures 2c and 2d show\n3The authors ran approximately 1 billion iterations over the Pokec dataset. Due to time constraints we had to restrict our experiment to 20,000 iterations. For a clearer comparison between the groups frequency and the experiment results, we downsampled the size of the input\n4For our experiment, we used the formula BMI = weight/height2 and defined the health groups as described by the WHO.\n5For instance the number of picked candidates per position for their FairPA algorithm in the uniform distribution is 1000. This corresponds to 50 positions x 1000 picks = 50,000 total picks, the same as the number of iterations used.\n6The number of picks of the original FairIID algorithm in the uniform distribution dataset hovers around 1200, which wouldmean 1200 picks x 50 positions = 60,000 total picks, far more than the 50,000 iterations. The same is true for the FairIID algorithm under the binomial setting. The line is somewhat obscured by other algorithms, but appears to be consistently higher based on the reported number of experiments.\n7q is the probability of an optimal offline algorithm choosing a certain candidate. This offline algorithm has a None rate of zero.\nReScience C 8.2 (#32) \u2013 Petcu et al. 2022 7\nthat when running our algorithms with this number of experiments, the results are strongly comparable to those of the original authors. We also contacted the authors about this discrepancy. They confirmed that their reported number of picks was too high. Similarly to us, they assumed to have run the experiments twice as often as re\u2010 ported. However, they were not able to confirm this at the time. Since the implementa\u2010 tion of the Prophet experiments themselves are not included in the code base, we were not able to definitively diagnose the reason for the discrepancy. Table 2 shows the originally reported mean values, as well as our replication results. As is clear, we were able to closely approximate the original authors\u2019 results. However, we were only able to do this after assigning None results a value of zero. Neither the ICML\u2010 version nor the full version of the paper mentions how their metrics deals with None picks. Nevertheless, as taking None picks as values of zero generated the same results, we assumed they used this approach.\nAdditionally, the original FairPA and FairIID algorithms selected candidates with an av\u2010 erage value of \u201d66.71% and 88.01% (for the uniform case), and 58.12% and 75.82% (for\nReScience C 8.2 (#32) \u2013 Petcu et al. 2022 8\nthe binomial case), of the \u201doptimal, but unfair, online algorithm\u201d average. 8 9 Here, we again found found the same results (deviation < 1%).\n7 Fair online decision making with higher pick-rates\nAs mentioned in section 6.2 the paper\u2019s proposed prophet algorithms pick a candidate in only 50% of cases. This is often not useful in practice. For this reason, we extended on the original paper by adjusting the (mathematical) parameters used for the FairPA and FairIID algorithms. We contacted the authors to ask about their reasoning for us\u2010 ing their parameters. They replied that their parameters achieved: \u201dthe best possible approximation ratio guarantee of a 1/2. However, they added: \u201dIt is possible that other algorithms also achieve the 1/2 guarantee, or something close to it, while having other interesting properties, for instance being less wasteful.\u201d Both algorithms 2 and 3 depend on calculating a top percentile that the candidate\u2019s value needs to be in. Each formula includes a constant of 1. We change this constant to pa\u2010 rameter \u03f5:\n\u2022 The FairProphet algorithm depends essentially on 1\u2212 qi/21\u2212s/2 . We change this frac\u2010 tion to 1\u2212 qi/2\u03f5\u2212s/2\n\u2022 TheFairIID algorithmdepends on 1\u2212 2/3n1\u22122(i\u22121)/3n , whichwe change to 1\u2212 2/3n \u03f5\u22122(i\u22121)/3n .\nand perform a grid search to approximately find the optimal values. For this parameter search, we used values slightly above and below the original parameters. We hypoth\u2010 esise that choosing a lower \u03f5 should decrease the top percentile a candidate needs to belong to in order to get selected. This should decrease the probability of finishing without picking any candidate, with the downside of achieving possibly a lower mean value. Figure 3 shows the results from our grid search, for the FairPA setting. The experiments for the FairIID setting show similar trends, as can be seen in Appendix section 8.3. As \u03f5 decreases, the number of picks goes up significantly. The algorithm remains approxi\u2010 mately equally fair10. However, when \u03f5 becomes too low, fairness starts to suffer. This is because the algorithm always chooses a candidate before getting to the end, meaning it never sees the last candidates in line. Our updated version of both the FairPA and FairIID increases performance on almost all originally used metrics in the paper for both distributions (see Appendix section 8.3). For the best found epsilon values, the None rate is close to zero. When excluding None results from the mean value of candidates, our optimal version performs slightly worse than the original authors\u2019 algorithm. This makes sense, as our algorithm is less picky and will also accept candidates with slightly lower scores. On the other hand, when including None results as a 0 value in the average, our algorithm outperforms that of the original authors.\n8During communication with the authors it was brought to our attention that the results for the DP differ in the ICML version and the full version of the original paper, \u201ddue to a small issue in the calculation of the DP in the ICML version.\u201d. This results in the DP achieving an average score of 0.964 and 548.94 for the uniform and binomial distribution respectively. This then also changes the value of the optimal, but unfair algorithm to the following: \u201d 51.97% and 68.57% (for the uniform case), and 54.35% and 70.91% (for the binomial case)\u201d [12]. However, we focus on the ICML paper and thus focus on the presented results in this version. Partly due to the issue that no sufficient documentation could be found in order to solve this addressed issue in the DP algorithm.\n9While the paper does not specify explicitly which unfair algorithm they mean in the paper, this seemed to refer to the DP algorithm.\n10We would like to mention that we have not mathematically proven that our version is indeed \u2019fully\u2019 fair as the original authors did\nReScience C 8.2 (#32) \u2013 Petcu et al. 2022 9\n8 Conclusion\nTo summarise this study: for both the Secretary and the Prophet problems we found that the results are largely reproducible. We did however find some inconsistencies in one of the baselines of the secretary problem, and on the scale of the prophet results. After further investigation, these discrepancies could be attributed to inconsistencies in the original authors\u2019 code. After this reproducibility study we conclude that the main claims made in the paper still hold. The paper and the provided code base provided a good resource for reproducing the code. However, due to the absence of several parts of their code and the mentioned inconsistencies, the replication of the (exact) results took longer than expected. Fortu\u2010 nately, the authors showed to be very helpful and willing to answer our questions and concerns. A drawback of the proposed prophet algorithms is that they only select a candidate in 50% (FairPA) and 30% (IID) of cases. Having such a None result is often undesirable, so we introduced two adjusted prophet algorithmswhich have a pick rate of (close to) 100%. Our results suggest that these algorithms maintain similar levels of fairness. As a point of discussion, we would like to note that knowing the group probabilities p beforehand is, in some cases, quite counter intuitive. This fell outside of the scope of this reproducibility study, but it would be an interesting approach for further research to handle this critique."}, {"heading": "Appendix", "text": "8.1 Plots from original paper\nReScience C 8.2 (#32) \u2013 Petcu et al. 2022 12\n8.2 Plots from original code\nReScience C 8.2 (#32) \u2013 Petcu et al. 2022 13\n8.3 Extension: parameter grid search In this section, we present the results from our hyperparameter search on \u03f5 for both Fair Prophet algorithms. The original value of \u03f5 was 1.0 for both algorithms. As \u03f5 decreases, the None rate goes down. Optimal values appear to be 0.5 for FairPA and 0.7 for the FairIID algorithm. If \u03f5 becomes lower than that, fairness suffers. The algorithm is then so unstrict, that it always makes a pick before seeing the last candidates in the queue.\nReScience C 8.2 (#32) \u2013 Petcu et al. 2022 14"}], "title": "[Re] Replication Study of \u201dFairness and Bias in Online Selection\u201d", "year": 2022}
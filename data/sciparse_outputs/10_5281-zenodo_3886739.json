{"abstractText": "DOI 10.5281/zenodo.3886739 This article reports on the effort to reproduce the results shown in Storage Tradeoffs in a Collaborative Backup Service for Mobile Devices1, an article published in 2006, more than thirteen years ago. The article presented the design of the storage layer of such a backup service. It included an evaluation of the efficiency and performance of several storage pipelines, which is the experiment we replicate here. Additionally, this article describes a way to capture the complete dependency graph of this article and the software and data it refers to, making it fully reproducible, end to end. Using GNU Guix2, we bridge together code that deploys the software evaluated in the paper, scripts that run the evaluation and produce plots, and scripts that produce the final PDF file from LATEXsource and plots. The end result\u2014and the major contribution of this article\u2014is approximately 400 lines of code that allow Guix to rebuild the whole article and the experiment it depends on with a well-specified, reproducible software environment.", "authors": [{"affiliations": [], "name": "Ludovic Court\u00e8s"}], "id": "SP:af291f27d7bc6d3e41a902ef60148d07326545cf", "references": [{"authors": ["L. Court\u00e8s", "M.-O. Killijian", "D. Powell"], "title": "Storage Tradeoffs in a Collaborative Backup Service for Mobile Devices.", "venue": "Proceedings of the Sixth European Dependable Computing Conference", "year": 2006}, {"authors": ["L. Court\u00e8s", "R. Wurmus"], "title": "Reproducible and User-Controlled Software Environments in HPC with Guix.", "venue": "International Workshop on Reproducibility in Parallel Computing (RepPar). Vienna,", "year": 2015}, {"authors": ["L. Court\u00e8s"], "title": "Libchop. https://nongnu.org/libchop. Accessed 2020/04/28", "year": 2020}, {"authors": ["E. Dolstra", "M. de Jonge", "E. Visser"], "title": "Nix: A Safe and Policy-Free System for Software Deployment.", "venue": "Proceedings of the 18th Large Installation System Administration Conference (LISA). Atlanta, Georgia, USA: USENIX,", "year": 2004}, {"authors": ["L. Court\u00e8s"], "title": "Code Staging in GNU Guix.", "venue": "ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences (GPCE\u201917)", "year": 2017}, {"authors": ["L. Court\u00e8s"], "title": "Towards reproducible Jupyter notebooks", "year": 2019}, {"authors": ["K. Hinsen"], "title": "A Data and CodeModel for Reproducible Research and Executable Papers.", "venue": "Procedia Computer Science", "year": 2011}, {"authors": ["M. Akhlaghi", "T. Ichikawa"], "title": "Noise-Based Detection and Segmentation of Nebulous Objects.", "venue": "The Astrophysical Journal Supplement Series", "year": 2015}, {"authors": ["M. Akhlaghi.Maneage"], "title": "Managing Data Lineage", "venue": "http://maneage.org/. Accessed", "year": 2020}, {"authors": ["L. Stanisic", "A. Legrand"], "title": "Effective Reproducible Research with Org-Mode and Git.", "venue": "1st International Workshop on Reproducibility in Parallel Computing", "year": 2014}, {"authors": ["P. Bizopoulos", "D. Bizopoulos"], "title": "Reconciler: A Workflow for Certifying Computational Research Reproducibility", "year": 2020}], "sections": [{"text": "R E S C I E N C E C"}, {"heading": "Replication / Fault Tolerance", "text": "[Re] Storage Tradeoffs in a Collaborative Backup Service for Mobile Devices Ludovic Court\u00e8s1, ID 1Inria, Bordeaux, France\nEdited by Tiziano Zito\nReviewed by Sabino Maggi ID\nReceived 28 April 2020\nPublished 09 June 2020\nDOI 10.5281/zenodo.3886739\nThis article reports on the effort to reproduce the results shown in Storage Tradeoffs in a Collaborative Backup Service for Mobile Devices1, an article published in 2006, more than thirteen years ago. The article presented the design of the storage layer of such a backup service. It included an evaluation of the efficiency and performance of several storage pipelines, which is the experiment we replicate here. Additionally, this article describes a way to capture the complete dependency graph of this article and the software and data it refers to, making it fully reproducible, end to end. Using GNU Guix2, we bridge together code that deploys the software evaluated in the paper, scripts that run the evaluation and produce plots, and scripts that produce the final PDF file from LATEXsource and plots. The end result\u2014and the major contribution of this article\u2014is approximately 400 lines of code that allow Guix to rebuild the whole article and the experiment it depends on with a well-specified, reproducible software environment.\n1 Getting the Source Code\nThe first author s\u0313 younger self, a PhD student, would follow good practices: the libchop library3 benchmarked in the article, the article itself, and the benchmarking scripts were all under version control. Libchop was published as free software, but the other repositories had never been published, which is not-so-good practice. Thus, the first task in replicating this analysis was to find the initial repositories. Luckily, the repositories were found on a dusty hard disk drive. However, they were repositories for the GNU Arch version control system, also known as tla4\u2014one of the first free software distributed version control systems, which saw its last release in 2006, around the time Git started to get momentum. Having deployed tla, the author was able to convert the following repositories, thanks to the git archimport command, still distributed with Git:\n\u2022 https://gitlab.inria.fr/lcourtes-phd/edcc-2006 contains the source of the paper itself\u2014i.e., the text and figures, but neither the benchmarking scripts nor the source of libchop. It turned out to not be of any use for this replication.\n\u2022 https://gitlab.inria.fr/lcourtes-phd/chop-eval contains the scripts used to run the benchmarks that led to Figure 5 of the paper1.\nThe code of libchop itself was published as free software in 2007 and continued to evolve in the following years3. As of this writing, there have been no changes to its source code since 2016.\nCopyright \u00a9 2020 L. Court\u00e8s, released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Ludovic Court\u00e8s (ludovic.courtes@inria.fr) The authors have declared that no competing interests exist. Code is available at https://gitlab.inria.fr/lcourtes-phd/edcc-2006-redone. \u2013SWHswh:1:rev:36fde7e5ba289c4c3e30d9afccebbe0cfe83853a;origin=https://gitlab.inria.fr/lcourtesphd/edcc-2006-redone. Open peer review is available at https://github.com/ReScience/submissions/issues/32.\nReScience C 6.1 (#6) \u2013 Court\u00e8s 2020 1\n2 Building the Source Code\nLibchop is written in C and accessible from Scheme thanks to bindings for GNU Guile, an implementation of the Scheme programming language. The benchmarking scripts mentioned above rely on those Scheme bindings.\n2.1 Dependencies In addition to Guile, it has a number of dependencies, among which:\n\u2022 the GNU DBM key/value database (gdbm);\n\u2022 the GNU Libgcrypt cryptography library;\n\u2022 the zlib, bzip2, and lzo compression libraries;\n\u2022 support for ONC Remote Procedure Calls (RPC), formerly provided as part of the GNU C Library (glibc), but nowadays available separately as part of TI-RPC;\n\u2022 G-Wrap, a now defunct binding generator for Guile.\nAdditionally, libchop uses the GNU \u201cAutotools\u201d as its build system: Autoconf, Automake, and Libtool.\n2.2 Software Deployment as Code It should come as no surprise that the author, who has been working on reproducible software deployment issue for several years now, felt the need to address the software deployment issue using GNU Guix2. GNU Guix allows users to deploy software in a way similar to popular \u201cpackage managers\u201d such as Fedoras\u0313 RPM, Debians\u0313 APT, or CONDA. Unlike those, it follows a functional deployment paradigm, inherited from Nix5. \u201cFunctional\u201d in this context means that Guix views software build processes as pure functions that take inputs\u2014source code, build scripts, compilers, libraries\u2014and produce output\u2014libraries, programs. It arranges so that build processes run in well-defined environments that contain nothing but the declared inputs. Thus, given the same inputs, deterministic build processes always produce the same output, bit for bit. Consequently, Guix supports reproducible software deployment, which we consider a prerequisite for computational experiments\u2014 the digital counterpart of the pen-and-paper lab book. Guix can be programmed in Scheme, a language of the Lisp family. It provides high-level interfaces that allow users to define software packages in a declarative fashion that does not require familiarity with Scheme6. For the purposes of this replication, the author wrote definitions of the required packages, as we will see below, as well as definitions of each of the stages leading to the final PDF file, as will be explained in Section 4.\n2.3 Choosing a Revision Shouldwe run the latest revision of libchop, dated 2016, or shouldwe rather run the 2006 revision that was used at the time the paper was written? The latest libchop revision is available as a GNU Guix package. Unfortunately, the benchmarking scripts mentioned above are stuck in 2006\u20132007, so to speak: they require libchop programming interfaces that changed after that time, and they also require interfaces specific to Guile 1.8, the version that was current at the time (the latest version of Guile today is 3.0.2; it has seen three major versions since 2006). The author chose to use libchop, Guile, and G-Wrap from 2006, but reusing as many as possible of today s\u0313 software packages apart from these. Building from a source tarball\u2014a\nReScience C 6.1 (#6) \u2013 Court\u00e8s 2020 2\ntar.gz archive\u2014produced by the Autotools (with make dist) is as simple as running ./configure; make. The nice property here is that users do not need to install the Autotools to do that: all they need is a shell and make, along with the tools needed to build the software itself. Unfortunately, no release of libchop had been published as a source tarball back then. Thus, we had to build it from a version-control checkout, which requires the Autotools so we can generate the configure script and related files. The author quickly found out that building the 2006 libchop would also require building versions of Autoconf, Automake, and Libtool that were current back then since today s\u0313 versions are incompatible. Fortunately, the \u201cdowngrade cascade\u201d stops here.\nThe Guix-Past channel for GNUGuix was developed to provide reproducible, unambiguous definitions for all these software packages: https://gitlab.inria.fr/guix-hpc/guix-past. It provides a 2006 revision of libchop, along with 2006 versions of the aforementioned software. This channel can be used with today s\u0313 Guix, bringing software from the past to the present. The libchop revision was chosen as dating to right before the submission of the paper for the European Dependable Computing Conference (EDCC), where it was eventually presented. The resulting dependency graph\u2014packages needed to build this libchop revision\u2014is of coursemore complex. It is shown in Figure 1 for reference (the reader is invited to zoom in or use a high-resolution printer). It is interesting to see that it is a unique blend of vintage 2006 packages with 2020 software. Section 4 will get back to this graph.\nReScience C 6.1 (#6) \u2013 Court\u00e8s 2020 3\nSection 4.2 of the original paper1 evaluates the efficiency and computational cost of several storage pipelines, on different file sets, each involving a variety of compression techniques.\n3.1 Input File Sets Figure 3 of the original article describes the three file sets used as input of the evaluation. Of these three file sets, only the first one could be recovered precisely: it is source code publicly available from https://download.savannah.gnu.org/releases/lout and in the Software Heritage archive. The two other file sets were not publicly available. With the information given in the paper, we decided to use similar file sets, publicly available this time. For the \u201cOgg Vorbis\u201d file set, we chose freely-redistributable files available from https://archive.org/download/nine_inch_nails_the_slip/. For the \u201cmailbox\u201d file set, we chose an mbox-formatted monthly archive of the guix-devel@gnu.orgmailing list. Table 1 summarizes the file sets used in this replication. This is an informal description, but rest assured: Section 4 will explain the \u201cexecutable specification\u201d of these file sets that accompanies this article.\n3.2 Evaluation Results Like in the original article, we benchmarked the configurations listed in Table 2. Running the benchmarking scripts using the libchop revision packaged earlier revealed a crash for some of the configurations. Fortunately, that problem had been fixed in later revisions of libchop, and we were able to \u201cbackport\u201d a small fix to our revision (most likely, the bug depended on other factors such as the CPU architecture and libc version and did not show up back in 2006). The original benchmarks run on a PowerPC G4machine running GNU/Linux. This time, we ran them on an x86_64 machine with an Intel i7 CPU at 2.6 GHz (the author playfully started looking for a G4 so that even the hardware setup could be replicated, but eventually gave up). The benchmarking results in Figure 5 of the original paper1 were squashed in a single, hard-to-read chart. Here we present them as two separate figures: Figure 2 shows the space savings (ratio of the resulting data size to the input data size) and Figure 3 shows the throughput of each storage pipeline, for each file set. The space savings in Figure 2 are about the same as in the original article, with one exception: the \u201cmailbox\u201d file set has noticeably better space savings in configurations A1\nReScience C 6.1 (#6) \u2013 Court\u00e8s 2020 4\nand C this time. This could be due to the mailbox file chosen in this replication exhibiting more redundancy; or it could be due to today s\u0313 zlib implementation having different defaults, such as a larger compression buffer, allowing it to achieve better compression.\nThe throughput shown in Figure 3 is, not surprisingly, an order of magnitude higher than that measured on the 2006-era hardware. The CPU cost of configurations relative\nReScience C 6.1 (#6) \u2013 Court\u00e8s 2020 5\nto one another is close to that of the original paper, though less pronounced. For example, the throughput for B2 is only half that of A1 in this replication, whereas it was about a third in the original paper. There can be several factors explaining this, such as today s\u0313 compiler producing better code for the implementation of the \u201cchopper\u201d based on Manber s\u0313 algorithm in libchop, or very low input/output costs on today s\u0313 hardware (using a solid-state device today compared to a spinning hard disk drive back then). Overall, the analysis in Section 4.2.2 of the original paper remains valid today. The part of evaluation that relates to the CPU cost is, as we saw, sensitive to changes in the underlying hardware. Nevertheless, the main performance characteristics of the different configurations observed in 2006 remain valid today.\n4 Reproducing this Article\nWe were able to replicate experimental results obtained thirteen years ago, observing non-significant variations. Yet, this replication work highlighted the weaknesses of the original work, which fall into three categories:\n1. Lack of a properly referenced public archive of the input data.\n2. Gaps in the document authoring pipeline: running the benchmarks was fully automated thanks to the scripts mentioned earlier, but the figure that appeared in the 2006 paper was made \u201cby hand\u201d from the output produced by the script.\n3. Lack of a way to redeploy the software stack: the 2006 article did not contain references to software revisions and version numbers, let alone a way to automatically deploy the software stack.\nThis section explains how we addressed, in a rigorous and reproducible way, all these issues.\n4.1 Deploying Software The original paper lacked references to the software. Figure 1 here provides much information, but how useful is it to someone trying to redeploy this software stack? Sure it contains version and dependency information, but it says nothing about configuration and build flags, about patches that were applied, and so on. It also lacks information about dependencies that are considered implicit such as the compiler tool chain. This calls for a formal and executable specification of the software stack. As mentioned in Section 2, we defined all the software stack as Guix packages: most of them pre-existed in the main Guix channel, and old versions that were needed were added to the new Guix-Past channel. By specifying the commits of Guix and Guix-Past of interest, one can build the complete software stack of this article. For example, the instructions below build the 2006 revision of libchop alongwith its dependencies, downloading pre-built binaries if they are available:\ngit clone https://gitlab.inria.fr/lcourtes-phd/edcc-2006-redone cd edcc-2006-redone guix time-machine -C channels.scm -- build libchop@0.0\nThe file channels.scm above lists the commits of Guix and Guix-Past to be used. Thus, recording the commit of edcc-2006-redone that was used is all it takes to refer unambiguously to this whole software stack. The key differences compared to a \u201ccontainer image\u201d are provenance tracking and reproducibility. Guix has a complete view of the package dependency graph; for example, Figure 1 is the result of running:\nReScience C 6.1 (#6) \u2013 Court\u00e8s 2020 6\nguix time-machine -C channels.scm -- graph libchop@0.0 \\ | dot -Tpdf > graph.pdf\nFurthermore, almost all the packages Guix provides are bit-reproducible: building a package at different times or on different machines gives the exact same binaries (there is a small minority of exceptions, often packages that record build timestamps). Last, each package s\u0313 source code is automatically looked up in Software Heritage should its nominal upstream location become unreachable.\n4.2 Reproducible Computations Often enough, software deployment is treated as an activity of its own, separate from computations and from document authoring. But really, this separation is arbitrary: a software build process is a computation, benchmarks like those discussed in this paper are computations, and in fact, the process that produced the PDF file you are reading is yet another computation. The author set out to describe this whole pipeline as a single dependency graph whose sink is the LATEX build process that produces this PDF. The end result is that, from a checkout of the edcc-2006-redone repository, this PDF, and everything it depends on (software, data sets, benchmarking results, plots) can be produced by running:\nguix time-machine -C channels.scm -- build -f article/guix.scm\nThefilesguix.scm andarticle/guix.scmdescribe the dependency graph above libchop. Conceptually, they are similar to amakefile and in fact, part of article/guix.scm is a translation of the makefile of the ReScience article template. Using the Scheme programming interfaces of Guix and its support for code staging, which allows users to write code staged for eventual execution6, these files describe the dependency graph and, for each node, its associated build process. For the purposes of this article, we had to bridge the gap from the benchmarking scripts to the actual plots by implementing a parser of the script s\u0313 standard output that would then feed it to Guile-Charting, the library used to produce the plots. They are chained together in the top-level guix.scm file. The graph in Figure 1 is also produced automatically as part of the build process, using the channels specified in channels.scm. Thus, it is guaranteed to describe precisely to the software stack used to produce the benchmark results in this document. What about the input data? Guix origin records allow us to declare data that is to be downloaded, along with the cryptographic hash of its content\u2014a form of content addressing, which is the most precise way to refer to data, independently of its storage location and transport. The three file sets in Figure 1 are encoded as origins and downloaded if they are not already available locally.\nListing 1. Representation of a content-addressed Git checkout.\n(define rescience-template (origin\n(method git-fetch) (uri (git-reference\n(url \u201dhttps://github.com/rescience/template\u201d) (commit \u201d93ead8f348925aa2c649e2a55c6e16e8f3ab64a5\u201d)))\n(sha256 (base32 \u201d10xrflbkrv6bq92nd169y5jpsv36dk4i6h765026wln7kpyfwk8j\u201d))))\nAs an example, Listing 1 shows the definition of a Git checkout. The origin form specifies the expected SHA256 content hash of the checkout; thus, should the upstream repository be modified in place, Guix reports it and stops. Guix transparently fetches the specified commit from the Software Heritage archive if the upstream repository is unavailable and, of course, assuming it has been archived.\nReScience C 6.1 (#6) \u2013 Court\u00e8s 2020 7\n4.3 Discussion The techniques described above to encode the complete document authoring pipeline as a fully-specified, executable and reproducible computation, could certainly be applied to a wide range of scientific articles. We think that, at least conceptually, it could very much represent the \u201cgold standard\u201d of reproducible scientific articles. Nevertheless, there are three points that deserve further discussion: handling input data, dealing with non-deterministic computations, and dealing with expensive computations. Our input file sets were easily handled using the standard Guix origin mechanism because they are relatively small and easily downloaded. This data is copied as contentaddressed items in the \u201cstore\u201d, which would be unsuitable or at least inconvenient for large data sets. Probably some \u201cout-of-band\u201d mechanism would need to be sought for those data sets\u2014similar to howGit-Annex provides \u201cout-of-band\u201d data storage integrated with Git. As an example, the developers of the Guix Workflow Language7 (GWL), which is used for bioinformatics workflows over large data sets, chose to treat each process and its data outside standard Guix mechanisms. The second issue is non-deterministic byproducts like the performance data of Figure 3. That information is inherently non-deterministic: the actual throughput varies from run to run and frommachine to machine. The functional model implemented in Guix5 is designed for deterministic build processes. While it is entirely possible to include non-deterministic build processes in the dependency graphwithout any practical issues, there is some sort of an \u201cimpedance mismatch\u201d. It would be interesting to see whether explicit support for non-deterministic processes would be useful. Last, the approach does not mesh with long-running computations that require highperformance computing (HPC) resources. Again, some mechanism is needed to bridge between these necessarily out-of-band computations and the rest of the framework. The GWL provides preliminary answers to this question.\n5 Related Work\nSoftware engineering around \u201creproducible research\u201d in a broad sense is a fast-moving field. Researchers interested in reproducibility these days are often familiar with tools such as Docker, Jupyter, and Org-Mode. This section explains how Guix and the technique described in Section 4 relates to these other tools and approaches. First, it is worth noting that these tools are not concerned with supporting reproducible computations in general: Docker focuses on software deploymentwhereas Jupyter Notebook focuses on document authoring. Conversely, our work in this article is about achieving reproducibility and provenance tracking end to end. Docker and similar \u201ccontainer tools\u201d, such as Singularity, really combine two tools: one to build \u201capplication bundles\u201d (or \u201ccontainer images\u201d), and one to run the software contained in such bundles. The latter is a thin layer above virtualization mechanisms built into the kernel Linux (in particular \u201cnamespaces\u201d), which provides much welcome flexibility to users. The former is about provisioning those container images, and we think it hinders provenance tracking and reproducibility. As an example, the \u201csource code\u201d of a container image built with Docker is a \u201cDocker file\u201d. Docker files start by importing an existing container image, which contains prebuilt software. This starting point already loses the connection to source code. Docker files go on by listing commands to run to install additional software in the image. Those commands typically download additional pre-built binaries from external servers. Consequently, the result of those commands depends on external state; it may vary over time, or even fail. In other words, Docker files describe non-reproducible computations and are opaque. At the other end of the spectrum, Jupyter Notebook and Jupyter Lab support literate programming, like Org-Mode. Users can write documents that interleave a narrative\nReScience C 6.1 (#6) \u2013 Court\u00e8s 2020 8\nand code snippets; Jupyter takes care of evaluating those code snippets and presenting their result in the document. Jupyter focuses on document authoring, leaving software deployment as an exercise for the user. For example, to evaluate a Jupyter notebook that contains Python code using the NumPy library, the user must install the right version of Python and NumPy. A common approach is to ship Docker containers that contain Jupyter Notebook and all the necessary dependencies, often delegating it to services such as https://mybinder.org/. With Guix-Jupyter, we proposed a different approach where users annotate notebooks with information about their software dependencies, which Guix automatically deploys in a reproducible fashion8. End-to-end documentation authoring pipelines have previously been explored from different angles notably with ActivePapers framework9, Maneage10,11, by combining literate programmingwithOrg-Mode and version controlwithGit12, andby combining scientific pipelines and a LATEXpipeline in Docker images13. Maneage is one of the few efforts to consider software deployment as part of the broader scientific authoring pipeline. However, software deployed with Maneage relies on host software such as a compilation tool chain, making it non-self-contained; it also lacks the provenance tracking and reproducibility benefits that come with the functional deployment model implemented in Guix. Reconciler13 connects the scientific software workflow to the document authoring pipeline through two distinct Docker images. It provides a way to check that the end result (the PDF) is bit-for-bit reproducible. Guix can check for the reproducibility of each computation\u2014package builds, benchmark runs, LATEXpipeline\u2014through its --check command-line option.\n6 Conclusion\nWe are glad to report that we were able to replicate the experimental results that appear in our thirteen-year-old article and that its conclusions in this area still hold1. But really, truth be told, the replication was also an excuse to prototype an end-to-end reproducible scientific pipeline\u2014from source code to PDF. We hope our work could serve as the basis of a template for reproducible papers in the spirit of Maneage. We are aware that, in its current form, our reproducible pipeline requires a relatively high level of Guix expertise\u2014although, to be fair, it should be comparedwith thewide variety of programming languages and tools conventionally used for similar purposes. We think that, with more experience, common build processes and idioms could be factorized as libraries and high-level programming constructs, making it more approachable. This articlewas built fromcommitcf110733aa03c2cf9c1051bb6a2c1ae8562c35c2 of the edcc-2006-redone repository. It is interesting to see that this single Git commit identifier, which can be looked up on Software Heritage, is enough to refer to whole pipeline leading to this article! We look forward to a futurewhere reproducible scientific pipelines become commonplace."}], "title": "[Re] Storage Tradeoffs in a Collaborative Backup Service for Mobile Devices", "year": 2020}
{"abstractText": "The central claim of the paper is that the consideration of negative (collision) cases in trajectory predictionmodels through a socially contrastive loss function Social\u2010NCEwill improve the robustness of themodels. We verify their claimon variousmodels, with spe\u2010 cial focus on improvements in the human trajectory prediction models Social\u2010STGCNN and Trajectron++ and on robot navigation through an imitation learning model.", "authors": [{"affiliations": [], "name": "Roopsa Sen"}, {"affiliations": [], "name": "Sidharth Sinha"}, {"affiliations": [], "name": "Animesh Jha"}, {"affiliations": [], "name": "Parv Maheshwari"}, {"affiliations": [], "name": "Koustuv Sinha"}, {"affiliations": [], "name": "Sharath Chandra Raparthy"}], "id": "SP:28a7f8ae8ec8fde940eb9842162887e588c37cf4", "references": [{"authors": ["Y. Liu", "Q. Yan", "A. Alahi"], "title": "Social NCE: Contrastive Learning of Socially-aware Motion Representations.", "venue": "arXiv preprint arXiv:2012.11717", "year": 2020}, {"authors": ["T. Salzmann", "B. Ivanovic", "P. Chakravarty", "M. Pavone"], "title": "Trajectron++: Multi-agent generative trajectory forecasting with heterogeneous data for control.", "year": 2020}, {"authors": ["A. Mohamed", "K. Qian", "M. Elhoseiny", "C. Claudel"], "title": "Social-STGCNN: A Social Spatio-Temporal Graph Convolutional Neural Network for HumanTrajectory Prediction.", "venue": "In:Proceedings of the IEEE/CVFConference onComputer Vision and Pattern Recognition", "year": 2020}, {"authors": ["C. Chen", "Y. Liu", "S. Kreiss", "A. Alahi"], "title": "Crowd-Robot Interaction: Crowd-aware Robot Navigation with Attentionbased Deep Reinforcement Learning.", "year": 2019}, {"authors": ["M. Hessel", "J. Modayil", "H. van Hasselt", "T. Schaul", "G. Ostrovski", "W. Dabney", "D. Horgan", "B. Piot", "M. Azar", "D. Silver"], "title": "Rainbow: Combining Improvements in Deep Reinforcement Learning.", "year": 2017}, {"authors": ["W. Falcon et al. \u201cPyTorch Lightning.\u201d In"], "title": "GitHub", "venue": "Note: https://github.com/PyTorchLightning/pytorch-lightning 3", "year": 2019}, {"authors": ["M. Gutmann", "A. Hyv\u00e4rinen"], "title": "Noise-contrastive estimation: A new estimation principle for unnormalized statistical models.", "venue": "Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics", "year": 2010}, {"authors": ["L. Biewald"], "title": "Experiment Tracking with Weights and Biases", "venue": "Software available from wandb.com", "year": 2020}, {"authors": ["N. Deo", "E. Wolff", "O. Beijbom"], "title": "Multimodal Trajectory Prediction Conditioned on Lane-Graph Traversals.", "venue": "Annual Conference on Robot Learning", "year": 2021}], "sections": [{"text": "R E S C I E N C E C Replication / ML Reproducibility Challenge 2021\n[Re] Reproducibility Report: Contrastive Learning of"}, {"heading": "Socially-aware Motion Representations", "text": "Roopsa Sen1,2, ID , Sidharth Sinha1,2, ID , Animesh Jha2, ID , and Parv Maheshwari2, ID 1Equal Contributions \u2013 2IIT Kharagpur, India\nEdited by Koustuv Sinha,\nSharath Chandra Raparthy\nReviewed by Anonymous Reviewers\nReceived 04 February 2022\nPublished 23 May 2022\nDOI 10.5281/zenodo.6574697"}, {"heading": "Reproducibility Summary", "text": "The following paper is a reproducibility report for \u201dSocial NCE: Contrastive Learning of Socially\u2010aware Motion Representations\u201d [1] published in ICCV 2021 as part of the ML Reproducibility Challenge 2021. The original code was made available by the author 1. We attempted to verify the results claimed by the authors and reimplemented their code in PyTorch Lightning."}, {"heading": "Scope of Reproducibility", "text": "The central claim of the paper is that the consideration of negative (collision) cases in trajectory predictionmodels through a socially contrastive loss function Social\u2010NCEwill improve the robustness of themodels. We verify their claimon variousmodels, with spe\u2010 cial focus on improvements in the human trajectory prediction models Social\u2010STGCNN and Trajectron++ and on robot navigation through an imitation learning model."}, {"heading": "Methodology", "text": "We used the codebase made publicly available by the authors for our work. We trained themodels used in the paper fromscratch and reimplemented the code in PyTorchLight\u2010 ning. We evaluated both, and compared them with the results in the original paper. Further, we attempted additional experiments to find suitable hyperparameters in the Trajectron++ and Social\u2010STGCNN models."}, {"heading": "Results", "text": "Wewere able to reproducemajority of the results claimed in the paper except the Social\u2010 LSTM and Directional\u2010LSTM models due to lack of time, and got a maximum of 2% de\u2010 viation from that of the original paper."}, {"heading": "What was easy", "text": "The publicly available codebases were well documented and easy to follow. The authors have also mentioned sources for the processed datasets that they have used. The simu\u2010 lation data generation code for the imitation learning model was also shared.\n1https://github.com/vita\u2010epfl/social\u2010nce\nCopyright \u00a9 2022 R. Sen et al., released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Roopsa Sen (roopsa.sen@kgpian.iitkgp.ac.in) The authors have declared that no competing interests exist. Code is available at https://github.com/RoopsaSen/social-nce-trajectron-plus-plus \u2013 DOI 10.5281/zenodo.6511007. \u2013 SWH swh:1:dir:ba72ac2acf3bac942d9b3a66e51091e6bcce6617. Open peer review is available at https://openreview.net/forum?id=SIQEl6f7h0Y.\nReScience C 8.2 (#36) \u2013 Sen et al. 2022 1"}, {"heading": "What was difficult", "text": "The proposed contrastive loss was implemented on different trajectory prediction mod\u2010 els, the understanding of which was required to reimplement the code from PyTorch to PyTorch Lightning. Experiments on the entire ETH and UCY dataset on restricted computational resources took a considerable amount of time and we had to restrict our ablation study to one model.\nCommunication with original authors We contacted the authors with some queries on their implementation and on the im\u2010 portance of some hyperparameters. They replied promptly and their input was pivotal while conducting experiments.\n1 Introduction\nHumans tend to develop a strong intuition towards predicting future motions of other people, while navigating in crowded spaces. This is essential for carrying out daily tasks without any discomfort and to maintain a safe distance from others while moving around. However, building neural models that can replicate similar nature of accurate predictions is often challenging, even with a large training set. Multi\u2010agent problems such as trajectory forecasting and robot navigation, require the model to learn socially aware motion representations. Previously, several papers have proposed neural network based models to achieve these tasks. However, these models still fail to generalize well with different scenarios, often outputting colliding trajecto\u2010 ries. The original authors aim to tackle this issue by feeding explicit negative examples into the network, while teaching the model to differentiate between the two using a newly proposed Social Contrastive Loss. We exhaustively carry out all the experiments done in the paper and verify all claims and tables. We then review the results and present an assessment. We further ported the code to the PyTorch Lightning framework. This allowed us to train the code flexibly over different platforms and automate the optimization process. We also expect this to help in future implementation or reproduction of the codebase. Then we proceed to present a few ablations in the original code, especially hyperparameter tuning.\n2 Scope of reproducibility\nExistingwork onmulti\u2010agent trajectory prediction problems sometimes output colliding trajectorieswhichmakes themunsuitable for deployment. The authors claim that this is due to the bias in existing datasetswhich only consist of safe trajectories andno collision scenarios, giving the models no negative cases to train on. The original paper proposes a modified contrastive loss (Social\u2010NCE) which incorporates ground truth knowledge to generate negative cases to reduce collision rates on several benchmarks. The details of this loss have been discussed later (in Methodology section) in the report. The key claims that we aim to verify in our reproducibility report are:\n1. Addition of the Social\u2010NCE loss in human trajectory forecasting models signifi\u2010 cantly decreases collision rate while maintaining similar final displacement error.\n2. Addition of the Social\u2010NCE loss in imitation learning models for robot navigation in crowded environments significantly decreases the collision rate.\n3. Addition of the Social\u2010NCE loss in reinforcement learning models increases sam\u2010 ple efficiency, and they obtain a collision\u2010free policy quickly.\nReScience C 8.2 (#36) \u2013 Sen et al. 2022 2\n3 Methodology\nThe authors have a detailed public repository2 on the addition of Social\u2010NCE on Tra\u2010 jectron++ [2], Social\u2010STGCNN [3], models for human trajectory prediction and on an existing imitation learning model [4] for robot navigation. Further, we contacted the authors and they gave us their implementation of Social\u2010NCE in reinforcement learn\u2010 ing using Rainbow DQN [5] as the baseline. We reproduced the findings of the paper based on these repositories. We focused primarily on the human trajectory prediction models Social\u2010STGCNN and Trajectron++ and attempted ablations on Social\u2010NCE hyper\u2010 parameters in the Trajectron++ model to improve its performance. Lastly we ported the codebase for Trajectron++, Social\u2010STGCNN and the imitation learningmodel to PyTorch Lightning [6].\n3.1 Social-NCE Loss and Negative Data Augmentation\nConsider M agents with index i \u2208 {1...M}, the state of agent i at time t is given by sit = (xit, y i t) which are its position coordinates. State of all agents combined is given by st = {s1t , s2t ....sMt }. Given s1:t the model predicts st+1:T . Encoder f(\u00b7) : Gives vector encoding( hit) for agent i at time t given state of all agents till time t and index of agent:\nhit = f(s1:t, i) (1)\nEncoder has two sub\u2010modules: sequential fs(.) and interaction fi(.) modules to make encoding of one agent dependent on the state of other agents. Decoder g(\u00b7) : Returns predicted state from vector encoding\nsit+1:T = g(h i t) (2)\nSocial-NCE loss \u2014 Embedding Models\n\u2022 Query: Projection head that embeds the vector encoding of the agent i till time t\nq = \u03c8(hit) (3)\n\u2022 Key: Encoder that embeds the future state of agent i at time t + \u03b4t where \u03b4t is the sampling horizon in a given range\nk = \u03d5(sit+\u03b4t, \u03b4t) (4)\nBoth the query and key are 2\u2010layer MLPs which return 8\u2010dimensional encoded vectors. Loss The InfoNCE Loss [7] is given by:\nLNCE = \u2212log exp(sim(q, k+)/\u03c4)\u2211N n=0 exp(sim(q, kn)/\u03c4)\n(5)\n2https://github.com/YuejiangLIU/social\u2010nce\u2010trajectron\u2010plus\u2010plus\nReScience C 8.2 (#36) \u2013 Sen et al. 2022 3\nIn standard InfoNCE loss the similarity function sim(q, k) is the cosine similarity be\u2010 tween the two vectors. In the Social\u2010NCE variation this similarity function has been modified to the dot product of the two embedded vectors returned from the encoders. The Social\u2010NCE Loss is given by:\nLSocial\u2212NCE = \u2212log exp((\u03c8(hit)\u00b7\u03d5(si,+t+\u03b4t, \u03b4t)/\u03c4)\u2211 \u03b4t\u2208\u039b \u2211N n=0 exp((\u03c8(h i t)\u00b7\u03d5(si,nt+\u03b4t, \u03b4t)/\u03c4)\n(6)\nThe three encoders f(\u00b7), \u03c8(\u00b7) and \u03d5(\u00b7) are jointly trained such that the query is encoded closer to the positive key and further from the negative keys. The keys aremade through data augmentation as discussed next. The final loss for a specific model would be given by the weighted sum of the model task loss and the Social\u2010NCE loss.\nData Augmentation \u2014Negative samples: The state of the agent i at time t + \u03b4t cannot be same as the state of any of the other agents at time t + \u03b4t, so the states of the M \u2212 1 elements other than the agent i can be used as negative keys for it. For each agent j \u2208 {1, ...M}\u2212{i}, 8 points are taken uniformly from a circle with radius of minimum distance of comfort around the agent j as negative keys for agent i\nsi,n\u2212t+\u03b4t = s j t+\u03b4t +\u2206sp + \u03f5 (7)\n\u2206sp = (\u03c1cos\u03b8p, \u03c1sin\u03b8p), \u03c1 being minimum distance of comfort and \u03b8p = 0.25p\u03c0, p \u2208 {0, 1, ..., 7} \u03f5 is a normally distributed added noise Each agent i thus has 8(M \u2212 1) negative keys. Positive samples: Single positive key is taken from state of agent i at time t + \u03b4t after adding normally distributed noise \u03f5\nsi,+t+\u03b4t = s i t+\u03b4t + \u03f5 (8)\nThe data augmentation is made clearer by the following diagram given by the authors [1]. For an agent i (in blue) the areas of Collision and Discomfort as shown are used as negative samples.\n3.2 Datasets The human trajectory prediction models were run on a processed version of ETH and UCY datasets. The original dataset is a collection of 5 video segments of pedestrian trajectories from which the states of each agent per frame id had been stored and the dataset had been pre\u2010divided into train, test and validation sets to maintain uniformity in accuracy comparison. The processed ETH and UCY datasets are are available in the repository linked3.\n3https://github.com/StanfordASL/Trajectron\u2010plus\u2010plus/tree/master/experiments/pedestrians/raw\nReScience C 8.2 (#36) \u2013 Sen et al. 2022 4\nThe imitation and reinforcement learning models used pedestrian data from an open\u2010 source simulator based on OpenAI gym library The dataset consisted of 5000 simulated situations in which the position of 5 random agents are stored for each time step. A validation split of 0.3 was taken.\n3.3 Hyperparameters Apart from the hyperparameters required for regular network training, the Social\u2010NCE included three additional hyperparameters, specific to the model. These were: the tem\u2010 perature hyperparameter \u03c4 , the sampling horizon \u03b4t and the contrastive weight \u03bb. In the original paper, there values were set by default. We improvised upon previous work by performing a thorough random search for these hyperparameters using WandB [8]. We further do a sensitivity analysis, and check whether hyperparameter tuning offers any significant benefit. The details of the search can be summarised as follows:\nDetails on the loss hyperparameters:\n\u2022 Temperature(\u03c4 ): Part of the Social\u2010NCE losswhich controls theweight of the penalty and reward for negative and postive samples respectively.\n\u2022 Sampling Horizon(\u03b4t): The future time step till which the negative samples are considered for data augmentation\n\u2022 Contrastive Weight(\u03bb): The weight between the main loss of the model and the Social\u2010NCE Loss\nA similar search was performed separately for the hyperparameters pertaining to data augmentation, with the default values for the hyperparameters discussed in the previ\u2010 ous section. These hyperparameters were: Minimum Separation, MaximumSeparation and the weight between maximum separation and noise. The details of this search can be summarised as follows:\nDetails on the augmentation hyperparmeters:\n\u2022 Minimum Separation: Minimum admissible value of \u03c1 in negative augmentation which is the minimum comfortable distance between two agents\n\u2022 Maximum Separation: Maximum admissible value of \u03c1 in negative augmentation which is the maximum distance after which agents can pass each other with colli\u2010 sion.\n\u2022 Weight between maximum separation and noise: The weight between the added normal noise and the position of the augmented sample.\nReScience C 8.2 (#36) \u2013 Sen et al. 2022 5\n3.4 Experimental setup and code The encoder models were trained with Adam Optimizer. For the training of the Tra\u2010 jectron++, Social\u2010STGCNN and imitation learning models 300, 500 and 200 epochs were used respectively. There were two runs of the reinforcement learning model on 2000 and 5000 episodes respectively. As mentioned in the original paper, the models were evaluated on the following metrics:\n\u2022 Final displacement error (FDE): the Euclidean distance between the predicted out\u2010 put and the ground truth at the last time step.\n\u2022 Collision rate (COL): the percentage of test cases where the predicted trajectories of agents run into collisions.\nA lower FDE is preferred, however the current reproduction mainly aims to see the de\u2010 crease in collision rate. The code was also integrated with WandB to conduct further experiments. This process involved constructing a config dictionary, which included the list of all possible hyperparameters and the values it could potentially take. The main function was modified with WandB initialisation and the logging function to log the value of the Loss after training is complete. The function was then passed to the WandB agent to carry out sweeps. The code can be found in this link 4.\n3.5 Computational requirements The training code for Trajectron++ and Social\u2010STGCNN was run on Kaggle with GPU (Tesla P100\u2010PCIE\u201016GB) and CPU (13GB RAM + 2\u2010core of Intel Xeon).The average training runtimes are listed in the tables below. It can be seen clearly that porting to lightning has not caused any increase in training time.\nThe following experiments support the claims made by the authors. We compared the results from training the model from scratch(Reproduced) and reimplementing the model in PyTorch Lightning (Ported Code)with the results given by the authors (Original Paper).\n4.1 Results reproducing original paper A comparison of the FDE (Final Displacement Error) and COL (Collision Rate) for the addition of Social\u2010NCE to Trajectron++ and Social\u2010STGCNN models in original paper, reproduced and ported code.\n4https://anonymous.4open.science/r/social\u2010nce\u2010stgcnn\u201062D5/README.md\nReScience C 8.2 (#36) \u2013 Sen et al. 2022 6\nA comparison of the collision rate and time taken for the robot to reach destination for the addition of Social\u2010NCE in the imitation learningmodel in original paper, reproduced and ported code.\nA table of reward vs number of episodes trained for the implementation of Social\u2010NCE on the reinforcement learning model.\nA similar search was performed separately for the hyperparameters pertaining to Data Augmentation:\nThe FDE and collision rate after training the Social\u2010STGCNN model for 400 epochs on the original (Original Parameters) and tuned hyperparameters(Tuned Parameters) are:\nOur results support the authors\u2019 claim that modelling of social knowledge through the addition of negative test cases reduce the collision rate of trajectory prediction models. In both training from scratch in the original code and in the ported code, the results have remained consistent with that of the original paper.\n1. In human trajectory forecasting, the addition of Social\u2010NCE to the models Trajec\u2010 tron++ and social\u2010STGCNN showed a 35.7% and 35.1% decrease in collision rate on average respectively(Table 4 and Table 5) in our reproduced results. The Final Displacement Error(FDE) showed deviation of less than 1%, showing that addition of Social\u2010NCE adds to the robustness of the models without affecting it\u2019s accuracy.\n2. In the imitation learning model the collision rate decreased by 68.9% on average in our reproduced results with the time taken showing little deviation (Table 6).\n3. The Social\u2010NCEaddition to theRainbow\u2010DQNbased reinforcement learningmodel, as in the original paper, achieves a reward of 0.6 in 2000 episodes in comparison to 4000 episodes of the original Reinforcement Learning model(Table 7).\nThe hyperparameter tuning conducted was also vastly helpful and lead to an increase of accuracy by 0.91 %. The loss hyperparameters, determined the sensitivity of the model. The contrastive weight, determined emphasis of the Social\u2010NCE loss. The more the em\u2010 phasis, the better the model learnt to differentiate between a positive and negative sam\u2010 ple, but at the expense of loss of proximity to the actual training examples. It remains\nReScience C 8.2 (#36) \u2013 Sen et al. 2022 8\ndifficult to analytically understand the effect of change in the temperature hyperparam\u2010 eter. Hyperparameter search, even though tedious, can lead to a great increase in accuracy. The tuning of hyperparameters involved in the model, lead to an overall increase in ac\u2010 curacy. In task like trajectory prediction and motion forecasting, it might be crucial to try and increase the accuracy as much as possible. However, one thing to be noted is that the Social\u2010STGCNN had a huge running time, and one sweep took a huge amount of time. The effect of the Data Augmentation hyperparameters, seem to be highly variable. It is natural that results are likely to vary greatly with the choice of dataset, and the nature of the problem statement. This is because these hyperparameters are physical constraints put on the model, and hence might lead to different results for different datasets. Further, it was found that best results were found when the value of the contrastive weight to be 16, while the default value was 2. The values might differ distinctly, but this reinforces confidence in the proposed Social\u2010NCE loss.\n5.1 What was easy The authors have provided a detailed public codebase on the implementation of Social\u2010 NCEonTrajectron++, Social\u2010STGCNNand imitation learningmodel. Further, they shared the codebase for the reinforcement learningmodel. All the codebases have instructions on how to set up the environment and logs the important metrics, which proved to be helpful in reproduction.\n5.2 What was difficult Theporting of the implementationof Social\u2010NCE in theTrajectron++ andSocial\u2010STGCNN models from PyTorch to PyTorch Lightning required an understanding of those models and their original codebase which required additional time. Training of the models from scratch required large computation power. All the training was done over cloud GPUs with limited runtimes which often fell short of the time required for training.\n5.3 Communication with original authors We mailed the authors listing down some of the queries we had on their code imple\u2010 mentation. We also had some queries regarding the important hyperparameters that we could tune to improvemodel performance. The authors gave a prompt reply to our ques\u2010 tions. They shared the codebase for the reinforcement learning model as well. Their contribution has helped us with some crucial points in the report.\n6 Future Work\nWeoriginally planned to perform the following additional experimentswhichwe couldn\u2019t finish due to lack of time. They have been listed down below and we believe that future work on this paper can be done in this direction.\n\u2022 A best hyperparameter search on Social\u2010NCE in Trajectron++, the imitation learn\u2010 ing model and the Rainbow\u2010DQN based Reinforcement Learning model as well and comparison of the variation in results for different models.\n\u2022 Implementation of Social\u2010NCE on the Social\u2010LSTM and Directional\u2010LSTM models on the Trajnet++ benchmark, the results for which have been given in the original paper.\nReScience C 8.2 (#36) \u2013 Sen et al. 2022 9\n\u2022 Implementation of Social\u2010NCE on state of the art models in other benchmarks such as on the PGP model [9] for the nuScences dataset."}], "title": "[Re] Reproducibility Report: Contrastive Learning of Socially-aware Motion Representations", "year": 2022}
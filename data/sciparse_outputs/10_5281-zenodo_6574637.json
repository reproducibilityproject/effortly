{"abstractText": "Our work attempts to verify twomethods to mitigate forms of inequality in ride\u2010pooling platforms proposed in the paperData-DrivenMethods for Balancing Fairness and Efficiency in Ride-Pooling [1]: (1) integrating fairness constraints into the objective functions and (2) redistributing income of drivers. We extend this paper by testing for robustness to a change in the neighbourhood selection process by using actual Manhattan neighbour\u2010 hoods and we use corresponding demographic data to examine differences in service based on ethnicity.", "authors": [{"affiliations": [], "name": "Sarah de Boer"}, {"affiliations": [], "name": "Radu Alexandru Cosma"}, {"affiliations": [], "name": "Lukas Knobel"}, {"affiliations": [], "name": "Yeskendir Koishekenov"}, {"affiliations": [], "name": "Benjamin Shaffrey"}, {"affiliations": [], "name": "Koustuv Sinha"}, {"affiliations": [], "name": "Sharath Chandra Raparthy"}], "id": "SP:1fe9e22ff321e4839c7f8bbc4b89a28ff8384666", "references": [{"authors": ["N. Raman", "S. Shah"], "title": "and J", "venue": "Dickerson. \u201cData-Driven Methods for Balancing Fairness and Efficiency in RidePooling.\u201d In: Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21. International Joint Conferences on Artificial Intelligence Organization,", "year": 2021}, {"authors": ["J.V. Hall", "A.B. Krueger"], "title": "An analysis of the labor market for Uber\u2019s driver-partners in the United States.", "venue": "Ilr Review", "year": 2018}, {"authors": ["P. Zhu", "H. Mo"], "title": "The potential of ride-pooling in VKT reduction and its environmental implications.", "venue": "Transportation Research Part D: Transport and Environment", "year": 2022}, {"authors": ["C. Turakhia"], "title": "Engineering more reliable transportation with machine learning and AI at Uber", "venue": "https://eng.uber. com/machine-learning/ [Accessed: 2022-01-22].", "year": 2017}, {"authors": ["C. Cook", "R. Diamond", "J. Hall", "J.A. List", "P. Oyer"], "title": "The gender earnings gap in the gig economy: Evidence from over a million rideshare drivers.", "venue": "Technical report, National Bureau of Economic Research", "year": 2018}, {"authors": ["A.E. Brown"], "title": "Ridehail revolution: Ride- hail travel and equity in Los Angeles.", "venue": "PhD thesis,", "year": 2018}, {"authors": ["S. Shah", "M. Lowalekar"], "title": "and P", "venue": "Varakantham. \u201cNeural Approximate Dynamic Programming for On-demand Ridepooling.\u201d In: Conference on Artificial Intelligence (AAAI). Full version: arXiv:1911.08842.", "year": 2020}, {"authors": ["Mart\u00edn Abadi"], "title": "TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems. Software available from tensorflow.org", "year": 2015}, {"authors": ["A. Paszke", "S. Gross", "F. Massa", "A. Lerer", "J. Bradbury", "G. Chanan", "T. Killeen", "Z. Lin", "N. Gimelshein", "L. Antiga"], "title": "Pytorch: An imperative style, high-performance deep learning library.", "venue": "Advances in neural information processing systems", "year": 2019}, {"authors": ["V.Mnih", "K. Kavukcuoglu", "D. Silver", "A.A. Rusu", "J. Veness", "M.G. Bellemare", "A. Graves", "M. Riedmiller", "A.K. Fidjeland", "G. Ostrovski"], "title": "Human-level control through deep reinforcement learning.", "year": 2015}, {"authors": ["L.-J. Lin"], "title": "Self-improving reactive agents based on reinforcement learning, planning and teaching.", "venue": "In:Machine learning", "year": 1992}, {"authors": ["H. Van Hasselt", "A. Guez"], "title": "and D", "venue": "Silver. \u201cDeep reinforcement learning with double q-learning.\u201d In: Proceedings of the AAAI conference on artificial intelligence. Vol. 30. 1.", "year": 2016}, {"authors": ["L.S. Shapley"], "title": "A value for n-person games.", "venue": "Contributions to the Theory of Games", "year": 1953}, {"authors": ["N.Y. City"], "title": "New York City TLC Trip Record Data", "venue": "https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page [Accessed: 2022-01-12].", "year": 2016}, {"authors": ["S. Lloyd"], "title": "Least squares quantization in PCM.", "venue": "IEEE transactions on information theory", "year": 1982}, {"authors": ["NYC Departmen"], "title": "for the Aging", "venue": "Planet dump retrieved from https://planet.osm.org. https://www1.nyc.gov/site/ dfta/news-reports/guide_to_community_and_neighborhood_resources.page.", "year": 2020}, {"authors": ["N.Y. City"], "title": "NYC Open Data", "venue": "https://data.cityofnewyork.us/City-Government/2010-Neighborhood-TabulationAreas-NTAs-/cpf4-rkhq [Accessed: 2022-01-25].", "year": 2010}, {"authors": ["S. Hochreite"], "title": "and J", "venue": "Schmidhuber. \u201cLong short-term memory.\u201d In: Neural computation 9.8 (1997), pp. 1735\u2013", "year": 1780}], "sections": [{"text": "R E S C I E N C E C Replication / ML Reproducibility Challenge 2021\n[Re] Data-Driven Methods for Balancing Fairness and"}, {"heading": "Efficiency in Ride-Pooling", "text": "Sarah de Boer1,2, ID , Radu Alexandru Cosma1,2, ID , Lukas Knobel1,2, ID , Yeskendir Koishekenov1,2, ID , and Benjamin Shaffrey1,2, ID 1University of Amsterdam, 1012 WX Amsterdam \u2013 2All authors have contributed equally\nEdited by Koustuv Sinha,\nSharath Chandra Raparthy\nReviewed by Anonymous Reviewers\nReceived 04 February 2022\nPublished 23 May 2022\nDOI 10.5281/zenodo.6574637"}, {"heading": "Reproducibility Summary", "text": ""}, {"heading": "Scope of reproducibility", "text": "Our work attempts to verify twomethods to mitigate forms of inequality in ride\u2010pooling platforms proposed in the paperData-DrivenMethods for Balancing Fairness and Efficiency in Ride-Pooling [1]: (1) integrating fairness constraints into the objective functions and (2) redistributing income of drivers. We extend this paper by testing for robustness to a change in the neighbourhood selection process by using actual Manhattan neighbour\u2010 hoods and we use corresponding demographic data to examine differences in service based on ethnicity."}, {"heading": "Methodology", "text": "The authors of the paper provide preprocessed data and code implemented in Tensor\u2010 Flow, which we transform into PyTorch. Experiments in this reproducibility study can be divided into 3 parts: (1\u20102) we reproduce the results regarding objective functions and income redistribution using data and settings provided in the paper and code; (3) we ap\u2010 ply this approach to the same data grouped into Manhattan neighbourhoods. Further, we examinediscrepancies between service rates of different ethnicities usingneighbourhood\u2010 specific demographic data as a proxy for this protected information."}, {"heading": "Results", "text": "The results in the original paper regarding different objective functions were repro\u2010 duced within a margin of error. Also, income redistribution is able to reduce wage inequality, albeit to a lesser degree. The objective functions appear to be sensitive to the neighbourhood selection mechanism. While the results of the rider\u2010fairness objec\u2010 tive functions are maintained, performance of the driver\u2010fairness objective functions declines. There appear to be only small differences in service rates between ethnicities, while rider\u2010side fairness seems to mitigate inequalities the most. However, this is only achieved byworsening the service for well\u2010served neighbourhoods instead of improving it for underserved ones.\nCopyright \u00a9 2022 S.D. Boer et al., released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Sarah de Boer (sarah.de.boer@student.uva.nl) The authors have declared that no competing interests exist. Code is available at https://github.com/reproducibilityaccount/reproducing-ridesharing \u2013 DOI 10.5281/zenodo.6501845. \u2013 SWH swh:1:rev:3beaa469b32b376f92b0fbae34493cdbe0e2ee3c. Open peer review is available at https://openreview.net/forum?id=BE3Ms3GXhCF.\nReScience C 8.2 (#6) \u2013 Boer et al. 2022 1"}, {"heading": "What was easy", "text": "The simulation logic as well as the training and testing procedures in the provided code were straightforward to execute."}, {"heading": "What was difficult", "text": "To be able to run the authors\u2019 code we needed to make several changes to it. Moreover, specific parts of the original research were not explicitly mentioned in the paper. An\u2010 other point of difficulty was the absence of preprocessing code which was not detailed properly and could not be fully reproduced. The reproducibility of the paper relied on the provided code, communication with the authors as well as previous works.\nCommunication with original authors We contacted the authors about the preprocessed data that was not hosted online due to licensing issues. They supplied it as well as responded very quickly and provided clarifications on the parameters and their values in the code.\n1 Introduction\nRide\u2010pooling, where drivers can servicemultiple requests from riders simultaneously, is becoming increasingly popular [2]. Since resources are shared, ride\u2010pooling has the po\u2010 tential to reduce the aggregate VKT (\u201dvehicle kilometres travelled\u201d) and with that reduce petroleum usage and carbon dioxide emissions [3]. To efficiently perform the match\u2010 ing of riders and drivers, machine learning algorithms are used [4], which optimise for income maximisation. However, with respect to ride pooling, previous works have ob\u2010 served a gender wage gap [5] as well as majority Asian and Hispanic neighbourhoods being associated with less service compared to white neighbourhoods [6]. Therefore, alternative fairness notions could also be useful. Shah, Lowalekar, and Varakantham7 introduce an algorithm to solve the ride\u2010pooling matching problem, which maximises the number of rider requests serviced based on a Markov decision process (MDP) in combination with deep learning. The authors of the paper Data-Driven Methods for Balancing Fairness and Efficiency in Ride-Pooling [1] extend this work to comparemultiple objective functions, defined on different fairnessmetrics. Next to that, they investigate the use of income redistribution. In this reproducibility study, we attempt to verify their results and extend their experiments.\n2 Scope of reproducibility\nThemain contribution of the paper is introducing and evaluatingmeasures to deal with the fairness issues arising in ride\u2010pooling. In our reproducibility study, we first focus on reimplementing their code (implemented in TensorFlow [8]) in PyTorch [9] and compare the results we achieve to their findings. Themain claimsmade in the original paper are:\n\u2022 The authors claim that they extend theMDP\u2010based framework (introduced in Shah, Lowalekar, andVarakantham7) by incorporating different definitions of fairness to perform non\u2010myopic optimisation. By incorporating fairness measures into the objective function, driver and rider inequality can be reduced while maintaining or even improving profitability.\n\u2022 The state\u2010of\u2010the\u2010art objective function [7] can outperform the fairness objective functions in certain settings in terms of rider\u2010fairness and increase the average income of drivers at the cost of a higher variance.\nReScience C 8.2 (#6) \u2013 Boer et al. 2022 2\n\u2022 Income redistribution can be used to reduce wage inequality while avoiding the free\u2010rider problem and guaranteeing a minimum wage for drivers.\nThe mathematical proof guaranteeing the minimum wage is not verified in our study. In addition to testing for reproducibility, we examine the robustness of the approach to changes in the neighbourhood selection method using actual tabulation areas. Using demographic data, we investigate whether the fairness objective functions are fair to all ethnicities. To investigate these aspects of the paper, we followed these steps:\n1. We inspect the provided codebase and identify, analyse and solve any barriers to running the code.\n2. Next, we transform the code to the PyTorch framework,matching the functionality as well as possible.\n3. With the PyTorch version we attempt to reproduce the results using the dataset preprocessed by the authors. To investigate potential differences, we use different seeds to examine the effect of randomness.\n4. To test the method\u2019s robustness we utilise the authors\u2019 approach on actual neigh\u2010 bourhoods in Manhattan and, using the neighbourhood demographic composi\u2010 tions (since individual protected data is confidential), we explore whether the in\u2010 troducedobjective functionsmitigate potential inequalities between ethnic groups.\n3 Theoretical background\nThe paper we are reproducing extends the method proposed in Shah, Lowalekar, and Varakantham7. The latter presents Neural Approximate Dynamic Programming (Neu\u2010 rADP), which uses offline\u2010online learning and approximates dynamic programming to match drivers and riders non\u2010myopically. The following subsections explain NeurADP and the two extensions proposed in Raman, Shah, and Dickerson1, fairness\u2010based ob\u2010 jective functions and income redistribution.\n3.1 NeurADP: Neural Approximate Dynamic Programming NeurADP uses neural network\u2010based value function approximation and updates it using the Bellman equation [10]. To break temporal dependencies between samples, mini\u2010 batch experience replay is used [11]. The neural network is used to rank feasible actions for each agent. To receive the opti\u2010 mal choices, an integer linear program (ILP) is solved considering the top 150 feasible actions. To update the neural network, the authors use a target network and Double Q\u2010learning [12]. The value function over individual vehicles is learned offline. When the approach is running online, the model computes the driver\u2010rider assignment that maximises the value function computed in the offline phase. Further details regarding the neural network inputs and its architecture are in Appendix A.\n3.2 Fairness-based objective functions Prior work used profitability metrics as objective functions. The authors introduce two new objective functions to improve both driver\u2010side and rider\u2010side fairness [1] and com\u2010 pare them using different evaluation strategies.\nReScience C 8.2 (#6) \u2013 Boer et al. 2022 3\nProfitability objectives There are two profitability measures used: the number of rid\u2010 ers serviced (o1) and the total income (o2).\no1(R,W ) = n\u2211 i=1 |pi|+ |si|, o2(R,W ) = n\u2211 i=1 \u2211 u\u2208pi\u222asi\nEg,e + \u03b4\ufe38 \ufe37\ufe37 \ufe38 \u03c0i\n. (1)\nThe total number of rides serviced by driver i consists of the number of ongoing requests |pi| and completed requests |si|. The total income is calculated by adding the incomes \u03c0i of the individual drivers i. The income for any request u is the sum of the variable cost Eg,e (depending on the start and end locations g and e) and the fixed part of ride\u2010pooling pricing, represented by the constant \u03b4.\nFairness objectives The authors define two fairnessmetrics for rider\u2010side (o3) anddriver\u2010 side (o4) fairness.\no3(R,W ) = \u2212\u03bbVar ( hj kj ) + n\u2211 i=1 \u03c0i, o4(R,W ) = \u2212\u03bbVar(\u03c0i) + n\u2211 i=1 \u03c0i. (2)\nThe former is quantified by the variance of the success rates which is computed by the ratio between serviced and total requests ( hj kj ) originating in neighbourhood j. Each crossing is mapped to one of H neighbourhoods. o4 is based on the spread of incomes \u03c0i. Both objective functions incorporate the total income o2 into the equation, \u03bb controls the importance of the variance term.\nEvaluation strategy To measure the effect of different objective functions, the authors introduce two fairness metrics. They evaluate rider\u2010fairness by comparing the overall and minimum success rates across neighbourhoods. They then utilise the income dis\u2010 tributions to assess driver\u2010fairness.\n3.3 Income redistribution The authors also introduce an income redistribution scheme to mitigate income fluc\u2010 tuation and inequality in driver wages. To help estimate the true contribution of each driver, Shapley values [13] are used. In this ride\u2010pooling setting, a Shapley value can be intuitively interpreted as the average profit lost when a specific driver does not con\u2010 tribute. To reduce the difference between a driver\u2019s pre\u2010redistribution income \u03c0i, and Shapley value vi, the authors use a risk parameter, 0 \u2264 r \u2264 1, which designates what fraction of a driver\u2019s income is kept. The model collects \u2211n =1(1 \u2212 r)\u03c0i from all drivers and re\u2010\ndistributes it proportional to the difference between their value and earnings, which is max(0, vi \u2212 r\u03c0i). The driver\u2019s income after redistribution, qi, is\nqi = rvi + max(0, vi \u2212 r\u03c0i)\u2211n\nj=1 max(0, vj \u2212 r\u03c0j) n\u2211 j=1 (1\u2212 r)vj (3)\nEvaluation strategy Tomeasure the correlation between the Shapley value and income after redistribution, the gain metric gi is defined as the ratio of change in qi to vi when vi is doubled. The gain g is calculated as the average over gi. To test the effect of income redistribution, the authors determine gain and the standard deviation of the ratio of qi to vi for varying values of r. The most desirable outcome is that the driver\u2019s redistribution value is as close as possible to their Shapley value, i.e. std = 0 and that if they double their contribution, they double their earnings after redistribution, i.e. g = 1.\nReScience C 8.2 (#6) \u2013 Boer et al. 2022 4\n4 Methodology\nIn this section, the approaches used in our reproducibility study are outlined.\n4.1 Datasets The following shows the original dataset and the demographic data to the Manhattan neighbourhoods.\nNYC yellow taxi data Manhattan \u2014 Similar to Raman, Shah, and Dickerson1, we use the dataset \u2019Yellow taxi trip records\u2019 from New York City [14] for training and evaluation. The original dataset contains pick\u2010up and drop\u2010off coordinates for taxi passengers. We follow the assumption of the original paper that the spatial and temporal distribution of rider requests between ride\u2010pooling and taxi rides are similar. The preprocessing done inRaman, Shah, andDickerson1 consists of the following steps. First, the dataset of New York City is filtered to only comprise trips starting and ending in Manhattan. Next, the coordinates are discretised into |L| locations, which are identified by taking the street network of the city from openstreetmap [15] using osmnx with \u2019drive\u2019 as network type. We take the largest strongly connected component of the network discarding nodes that do not have outgoing edges. The resulting network has 4373 locations (street intersections) and 9540 edges. The pick\u2010 up time is converted to batches of requests corresponding to theminutes. Furthermore, the locations are grouped into 10 neighbourhoods using K\u2010means clustering [16]. The dataset contains on average 322714 requests in a day (on weekdays) and 19820 requests during the peak hour. The preproccessed dataset was not publicly available, although mentioned otherwise in the paper. The authors confirmed that this was due to licensing issues and provided us with the preprocessed data. The model is trained using the data from March 26th \u2010 28th 2016. The fairness objective functions are tested on the data from April 4th.\nDemographics by Neighborhood Tabulation Area \u2014 The dataset \u201dDemographics by Neighbor\u2010 hood Tabulation Area\u201d for New York City [17] allows us to investigate whether the ride demand of racial or ethnic minorities is indeed satisfied in the same way. It contains demographic data for each neighborhood tabulation area (NTA) in New York City. A NTA is an area for which census data is gathered. The demographic data relevant to this report are the race/ethnicity percentages per neighbourhood, namely Hispanic/Latino, White, Black/African\u2010American, Asian, Other. Instead of running K\u2010means clustering to obtain the neighbourhoods, we take the neighbourhoods corresponding to these NTA ar\u2010 eas in Manhattan. This results in 29 instead of 10 neighbourhoods for Manhattan. To be able to determine which nodes in the graph are situated in which NTA, we made use of the \u201d2010 Neighborhood Tabulation Areas\u201d dataset [18] which contains coordinates specifying an approximation of the polygon shape of each neighbourhood.\n4.2 Code Our implementation is based on the code of the paper which is publicly available at GitHub 1. The repository was updated after we started reproducing the paper, but we refer to the commit specified above unless stated otherwise. The published code is not functioning and does not include the preprocessing steps. However, the main frame\u2010 work for testing and training is provided and hyperparameters can be configured using setting files. We re\u2010implemented the model in the PyTorch framework [9], ensuring\n1https://github.com/naveenr414/ijcai\u2010rideshare/tree/78d81d0f417ad4fd54ea2e967010bb221fc4e177\nReScience C 8.2 (#6) \u2013 Boer et al. 2022 5\nthat the default behaviour of TensorFlow which was implicitly used in the authors\u2019 im\u2010 plementation is replicated. This includes weight initialisation and hyperparameters of the optimiser. To transfer the masking mechanism used to pad the sequences, we em\u2010 ployed PyTorch\u2019s packed sequence implementation. Since the new framework does not support backwards LSTM, we used a bidirectional LSTM and ignored the forward pass to achieve the same functionality. In accordance with the original code, we used the CPLEX optimiser [19] to solve the ILP. To support the number of drivers and, therefore, bigger linear systems, the academic or commercial version is necessary. There were some rare situations in which the ILP failed to satisfy the constraints (one or two agents were not assigned any actions) which led to an error. This was fixed by assigning the \u201dtake no action\u201d action to those agents. In addition, we implemented the preprocessing steps on the original dataset [14], as this code was not available. For this, we perform the same steps indicated in Section 4.1.1, but we simplified the estimation of the travel times as this was not clear from the paper. Our code is available at GitHub. 2\n4.3 Hyperparameters Focusing on reproducing the original paper [1], we tried to stay close to the original paper\u2019s approach and did not perform hyperparameter optimisation. Hyperparameter values missing in the paper (e.g. minimum number of experiences and samples) were retrieved from the authors\u2019 code. Additionally, there were inconsistencies, when some hyperparameters had different values in different parts of code (e.g. embedding dimen\u2010 sion). In this case, we reached out to the authors for clarification. More details on hy\u2010 perparameters are in Appendix C.\n4.4 Computational requirements To increase the available computational resources, we used multiple computers with different hardware (see Table 5 in the Appendix). In general, the training time is dom\u2010 inated by the simulation of the environment and solving the ILP. The training of the neural network plays only a minor role. Hence, GPUs are not crucial for training, the training time is mostly determined by the single\u2010core performance of the CPU. A run consisting of training on three days and testing on one typically takes about 2.5 to 3 hours. In total, running all experiments took 202 hours.\n4.5 Experimental setup\nExperiment 1 (Objective Func\u2010 tions) To reproduce the results regarding claims 1 and 2, dif\u2010 ferent settings are needed, pre\u2010 sented in Table 1. All com\u2010 binations of these settings are used. The requests and income objective functions do not have lambda values. Furthermore, the embeddings are trained (fur\u2010 ther details are in Appendix A.1).\nWe use the same training/testing split as in the paper (described in Section 4.1), and evaluate the results based on overall and minimum success rates as well as income dis\u2010 tribution. To test if the differences between our findings and the original results are caused by ran\u2010 domness, we rerun the experiments using different seeds. Due to limited resources, we\n2https://github.com/reproducibilityaccount/reproducing\u2010ridesharing\nReScience C 8.2 (#6) \u2013 Boer et al. 2022 6\nrerun only a subset of setting combinations. Further details can be found in Appendix B.\nExperiment 2 (Income Redistribution) In accordance with the original paper, the re\u2010 sults of the Objective Functions experiments are reused to evaluate the income redistri\u2010 bution for claim 3. The analysis is focused on the 200 drivers with the requests objective function using gain and standard deviation (see Section 3.3).\nExperiment 3 (Neighbourhood Demographics) To test robustness we use the 29 pre\u2010 defined neighbourhoods and train the models using the configurations of for only 200 drivers. To incorporate the demographic data for the analysis presented in step 4 (see Section 2), we map the results per neighbourhood to the five different ethnicities, un\u2010 der the assumption that the distribution of ethnicities living in a neighbourhood corre\u2010 sponds to the distributions of riders\u2019 ethnicities. For each group, we calculate the mean across all neighbourhoods weighted by the percentage of this group living in that area. This results in five different values per objective function. The higher this value is, the more requests of the corresponding group are serviced. Since we are interested in the difference across groups, we subtract the average of this rate. Values above zero indicate a group that is serviced above average and, hence, could be interpreted as advantaged. In addition, we evaluate the overall, minimum and per neighbourhood success rates.\n5 Results\nIn the following, we will present the results of the three different experiments.\n5.1 Reproducibility result 1 - Fairness objective functions\nLooking at our findings in Figure 2a, we conclude that for 50 drivers the results for the rider\u2010fairnessmetric can be reproduced, the success rates for the different objec\u2010 tive functions match. Using the driver\u2010fairness objective function improves both the success rate and the rider equality. For 200 drivers, there are mi\u2010 nor discrepancies between our results and the original.\nThey can, however, be explained by stochasticity introduced by different seeds. How\u2010 ever, for rider\u2010fairness with \u03bb = 1010, the difference can not be explained by random\u2010 ness. The requests objective function often results in more profit and better rider equal\u2010 ity. For each objective function, the payment distribution for 200 drivers is shown in Figure 2b. The variance of the distributions are similar in magnitude, the means however are slightly shifted. Looking at the differences between the results for different seeds, this could be explained by randomness. The driver\u2010fairness objective function is able to reduce the variance in income between drivers, but the profitability is also decreased. Appendix E shows the results presented in the original paper, the results of the different seeded runs are visualised in Figure 10.\nReScience C 8.2 (#6) \u2013 Boer et al. 2022 7\n5.2 Reproducibility result 2 - Income redistribution The authors\u2019 findings regarding the effect that varying the risk parameter r has on the gain and the standard deviation of the ratio qivi were not reproducible on the basis of the information in the paper alone, nor were they immediately reproducible from the code itself. Upon further communication with the authors, they updated their code. There was also a typo in the formula given in Equation 3 (Equation 12 in Raman, Shah, and Dickerson1). The correct equation is:\nqi = r\u03c0i + max(0, vi \u2212 r\u03c0i)\u2211n\nj=1 max(0, vj \u2212 r\u03c0j) n\u2211 j=1 (1\u2212 r)\u03c0j , (4)\nwhere it can be seen that the use of Shapley values in the first term and last factor have been replaced by the amounts before redistribution. With these corrections in place, our Income Redistribution experiments yielded the results seen in Figure 3. For values of 0.4 \u2264 r \u2264 0.6 the gain is non\u2010zero whilst maintaining a spread close to zero for the redistribution income to Shapley value ratio. In the original paper, this condition held for values of 0.5 \u2264 r \u2264 0.9. Furthermore, the magnitude of the gain is far smaller at the point at which the spread begins to increase. This indicates that when r = 0.6, drivers only receive a 40% increase in their wages whilst still earning close to their true contribution. This is in contrast with the original, where, for r = 0.9, drivers receive an 80% increase in their wages while minimising the free\u2010rider problem. This leads us to conclude that the results of this redistribution scheme were not reproducible in this setting. The original results are shown in Figure 8 in the Appendix.\nReScience C 8.2 (#6) \u2013 Boer et al. 2022 8\n5.3 Results for Manhattan neighbourhoods and incorporating demographic data We retrained the model (see Section 4.5). Comparing the resulting Figure 4 to previous findings in Figure 2a, we observe that by changing the neighbourhoods the performance of the driver\u2010fairness objective functions deteriorates themost. The rider\u2010fairness objec\u2010 tive functions share some similarities between the two experiments but the latter now performs best in terms of fairness across neighbourhoods (minimum request success rate).\nFigure 4b shows that there are small differences in the percentage of requests ser\u2010 viced per ethnicity. The rider\u2010fairness objective func\u2010 tion for \u03bb = 1010 seems to be best at mitigating inequal\u2010 ity. However, as seen in Fig\u2010 ure 4a, rider\u2010fairness results in low success rates. This might indicate that the ob\u2010 jective function merely low\u2010 ers success rates for oth\u2010 erwise well\u2010serviced neigh\u2010 bourhoods rather than im\u2010 provingunder\u2010serviced ones. To confirm this, we visu\u2010 alised the success rate per neighbourhood and objec\u2010\ntive function (see Figure 5). It can be seen that rider\u2010fairness indeed exhibits notably reduced variance but also a lower mean when compared to the other objective func\u2010 tions which tend to have an upward skew. This shows that rather than benefiting under\u2010 serviced neighbourhoods, applying rider\u2010fairness only lessens the success rate of well\u2010 served ones.\n6 Discussion\nCombining the results from the reproducibility experiments (Objective Functions exper\u2010 iment and Income Redistribution experiment in Section 4.5), we find that the first claim mentioned in Section 2 is supported by our results for 50 drivers. Furthermore, our re\u2010\nReScience C 8.2 (#6) \u2013 Boer et al. 2022 9\nsults substantiate the second claim. The \u2018requests\u2019 objective function can improve the rider\u2010fairness for 200 drivers. Additionally, it results in the highest average income per driver but exhibits a higher variance than the driver\u2010fairness objective function. These observations are in accordance with the ones of the original paper. For the 200 drivers setting, specific results were more sensitive to sources of stochastic\u2010 ity than for 50 drivers. After inspecting the code, we found that the minimum number of experiences needed to start the training of the neural network is never exceeded for the 50 drivers setup. In the 200 drivers configuration, it is reached and hence the neural network is trained. Since theweights of themodel are randomly initialised, itmight con\u2010 verge to a different local minimum which yields a different value function. This could explain the variance in the corresponding results. For 50 drivers, in contrast, no learn\u2010 ing is involved. Hence, the result goes through a randomly initialised model. Weights are typically initialised to preserve themean and variance of the input, which should be unaffected by the specific seed used. This could explain the strong similarity between our results and the original results for the 50 drivers setup. Differences found in reproducing the income redistribution scheme may also be ac\u2010 counted for by the above. However, while our results are not exactly the same, the third claim still holds, although to a considerably lesser degree than in the original paper. When employing the actual Manhattan neighbourhoods, the relative standing of the various objective functions was different compared to the ones determined by K\u2010Means. This indicates that the proposed method is sensitive to the neighbourhood selection mechanism. Looking at the demographic data, it can be seen that all objective functions exhibit small differences between ethnicities. These, however, could be attributed to stochasticity. In any case, rider\u2010fairness results in the least variance across ethnicities at the price of mean success rate. However, this result does not imply that rider\u2010fairness achieves this low variance by better servicing neighbourhoods with a lower percentage of accepted requests, but rather by servicing better\u2010served neighbourhoods less well. Importantly, the ethnicity\u2010based analyses are built on the assumption that the distribution of the ethnicities of residents and riders in a neighbourhood is similar. However, ride pooling might be used by other people like commuters or tourists. Furthermore, there could be differences between the ethnic populations regarding the percentage of ride\u2010sharing users.\n6.1 What was easy Part of the code, namely the simulation logic, did not need any modifications. This logic is responsible for telling drivers of possible rides to accept as well as executing the drivers\u2019 choices and keeping the simulation consistent with respect to the existing constraints. The training and testing procedure was also straightforward to execute.\n6.2 What was difficult The codebase was not originally executable and required modifications. In addition to that, several aspects of the original research were not explicitly mentioned in the paper. Although, in the end, we were able to reproduce most results, this would not have been possible without consulting either the code, the authors or the paper about NeurADP [7]. Another challenge was the absence of preprocessing code which together with the lack of a detailed description in the paper (specifically for travel time estimates)made its implementation difficult. With the limited time resources we had, we did not succeed in testing if our preprocessing implementation affected the results.\nReScience C 8.2 (#6) \u2013 Boer et al. 2022 10\n6.3 Communication with original authors The authors were very helpful, kind and responded very quickly, often within the same day. This was a very important factor in the production of this reproducibility report as the preprocessed data could not be hosted online due to licensing issues. Furthermore, they also provided useful clarifications with respect to the parameters used in the code and discrepancies between different parameter values in different places. The authors also updated the codebase following our discussions."}, {"heading": "Appendix", "text": "A Neural network details\nThe inputs to the neural network model are the current location of the vehicle, the in\u2010 formation about the remaining delay, and locations for the current requests that have been accepted. First, authors order them according to their trajectory and feed them as inputs to an LSTM [20] after an embedding layer. The embeddings for the locations are calculated separately and are the byproduct of a two\u2010layer neural network that attempts to estimate the travel times between two locations (see Appendix A.1). Additional inputs to the neural network are the information about the current decision epoch, the number of vehicles in the vicinity of the vehicle of interest and the total num\u2010 ber of requests that arrived in the epoch. This information is used to stabilise learning because the value of being in a given state is dependent on the competition it faces from other drivers when it is in that state. These inputs are concatenated with the output of the LSTM from the previous paragraph and, after 2 dense layers, used to predict the value. An overview of the details of the neural network can be seen in Table 2.\nReScience C 8.2 (#6) \u2013 Boer et al. 2022 12\nA.1 Embeddings training\nIn accordance with Shah, Lowalekar, and Varakantham7, the embedding model, shown in Table 3, was trained for 1000 epochs with batch size 1024 and Adam optimiser with default settings. The training also utilises early stopping with patience 15.\nB Seeds\nThe settings selected for seeded runs, have to meet several conditions. First of all, we wanted to rerun at least one setting for all four objective functions. Next to that, for the rider\u2010fairness, we rerun all lambda values because this objective function differed the most between our results and the original paper\u2019s. For the driver\u2010fairness, we only chose a lambda value of 4/6, since all lambda values yield similar results and only this one is used to examine both, driver\u2010 and rider\u2010side fairness metrics. By default, the seed 874 is used. If further seeds are used for experiments, the following four are utilised: 688701, 490013, 423376, 191758.\nC Hyperparameters\nReScience C 8.2 (#6) \u2013 Boer et al. 2022 13\nD Hardware configurations\naOne Nvidia GTX1080Ti GPU with 3 CPUs provided by SURFsara\u2019s LISA cluster. For more info see: https: //userinfo.surfsara.nl/systems/lisa/description\nE Results of the original paper\nReScience C 8.2 (#6) \u2013 Boer et al. 2022 14\nF Results for different seeds\nReScience C 8.2 (#6) \u2013 Boer et al. 2022 15\nReScience C 8.2 (#6) \u2013 Boer et al. 2022 16"}], "title": "[Re] Data-Driven Methods for Balancing Fairness and Efficiency in Ride-Pooling", "year": 2022}
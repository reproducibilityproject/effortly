{"abstractText": "TheWisconsinCard Sorting Test is a psychological test used to evaluate cognitive flexibility capacities in patients with decision-making deficits, to evaluate among other things, some mechanisms dysfunctions of frontal lobe. In the test it is proposed to match several cards, composed of several colored forms, by the 3 different criteria: color, figures or quantity, according to 4 reference cards (Heaton, R.K, (1981))[1]. The subject is told to match the cards, but the rule must be found by trials and errors and might change without notice. The ability of the subject to adapt to the changes is measured in the test. In 1991, S. Dehaene and J.P. Changeux have created a neuronal network model to resolveWisconsin Card Sorting Test (Dehaene & Changeux, 1991)[2], enhancing 3 cognitive components necessary to pass the test:", "authors": [{"affiliations": [], "name": "Pauline Bock"}, {"affiliations": [], "name": "Fr\u00e9d\u00e9ric Alexandre"}, {"affiliations": [], "name": "Qihong Lu"}], "id": "SP:68c23ab586b44f76818b5c6776387deb129afdf4", "references": [{"authors": ["R.K. Heaton"], "title": "Wisconsin card sorting test manual.", "venue": "Psychological Assessment Resources", "year": 1981}, {"authors": ["S. Dehaene", "J.-P. Changeux"], "title": "The Wisconsin Card Sorting Test: Theoretical analysis and modeling in a neuronal network.", "venue": "Cerebral Cortex", "year": 1991}], "sections": [{"text": "R E S C I E N C E C"}, {"heading": "Replication / Computational Neuroscience", "text": "[Re] The Wisconsin Card Sorting Test: Theoretical analysis and modeling in a neuronal network\nPauline Bock1,2,3 and Fr\u00e9d\u00e9ric Alexandre2,1,3 1LaBRI, Universit\u00e9 de Bordeaux, Institut Polytechnique de Bordeaux, Centre National de la Recherche Scientifique, UMR 5800, Talence, France \u2013 2INRIA Bordeaux Sud-Ouest, Bordeaux, France \u2013 3IMN, Universit\u00e9 de Bordeaux, CNRS, UMR5293, Bordeaux, France\nEdited by Olivia Guest ID\nReviewed by Andrea Caso ID\nQihong Lu ID\nReceived September 5, 2019\nPublished December 9, 2019\nDOI 10.5281/zenodo.3545905\n1 Introduction\nTheWisconsinCard Sorting Test is a psychological test used to evaluate cognitive flexibility capacities in patients with decision-making deficits, to evaluate among other things, some mechanisms dysfunctions of frontal lobe. In the test it is proposed to match several cards, composed of several colored forms, by the 3 different criteria: color, figures or quantity, according to 4 reference cards (Heaton, R.K, (1981))[1]. The subject is told to match the cards, but the rule must be found by trials and errors and might change without notice. The ability of the subject to adapt to the changes is measured in the test. In 1991, S. Dehaene and J.P. Changeux have created a neuronal network model to resolveWisconsin Card Sorting Test (Dehaene & Changeux, 1991)[2], enhancing 3 cognitive components necessary to pass the test:\n\u2022 the ability to change a followed strategy/rule when an error occurs\n\u2022 the ability to memorise wrong strategies to avoid repeating them\n\u2022 the ability of auto-evaluation, i.e comparing different situations and their outcomes referring to a memory of the past.\nThismodel refers to somebiologicalmechanisms and their supposed implementation in the brain circuitry, and is interesting to model some flexible processes used in decisionmaking and executive control. Although this model has been published in 1991, no implementations have been shared. We have implemented this model in Python with some new mechanisms, trying to reach the author s\u0313 theoretical results.\n2 Method\n2.1 Model of Dehaene and Changeux The model, depicted below in figure 1, is composed of several layers of neuronal units that are called clusters to emphasize the fact that each unit does not implement the processing of a single neuron but rather of a population of neurons. Each unit or cluster is activated by a sigmoid function whose formula is available in annexes. Clusters of neurons have only 2 activity states: either they are active or they are inactive. Their activity\nCopyright \u00a9 2019 P. Bock and F. Alexandre, released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Fr\u00e9d\u00e9ric Alexandre (frederic.alexandre@inria.fr) The authors have declared that no competing interests exists. Code is available at https://github.com/PaulineBock/WCSTDehaeneChangeux \u2013 DOI 10.5281/zenodo.3553566. Open peer review is available at https://github.com/ReScience/submissions/issues/7.\nReScience C 5.1 \u2013 Bock and Alexandre 2019 1\nvaries between 0 and 1, the switch from a state to another being defined by a threshold fixed at 0.5 by the authors. The layers are linked by some connections composed of a multiplication of a short-term and a long-term component. A short-term component represents heterosynaptic influences on a connection between 2 clusters, coming from another third modulator neuron: it is what the authors calls a \u201dsynaptic triad\u201d. This component varies between 0 and 1. A long-term component varies between 0 and a maximum value, representing direct influence from a layer to another. For one test trial, i.e a response card to match to one of the reference cards, the order of activation of the layers is the following: first, the response cards features are coded in the input layer, they are separated in 3 assemblies, one for each dimension. The input is then connected to a memory layer, to keep the card features in mind during autoevaluation. There is a competition mechanism for each assembly to ensure that only one feature is activated per dimension. Then memory is partially connected to an intention layer. In these connections are coded the features of the 4 reference cards. These connections are modulated by the rule-coding layer clusters. Only one rule can be activated at a time by competition and will increase the connections of the dimension assembly associated, while the others will be decreased, influencing the activation of an intention. A mechanism of competition will then ensure that only one intention is activated at a time. The intention layer is connected to an output layer and to an error cluster. A go unit modulates the intention-to-output connections to wait before making an action. In the paper, this unit is activated externally without more details. The connections from intention to the error cluster is where the auto-evaluation component is encoded. Indeed, the error cluster can be either activated by the reward input (when the choice lead to an error) or by the intention activities. This error cluster, when activated, will change the rule-coding layer in what the authors call a \u201dgenerator of diversity\u201d, i.e the autoexcitatory connection of the rule cluster activated will be depressed until the rule cluster totally deactivates because of the inhibition of other rule clusters. The competition will activate an other rule. The memory of rejected rules is coded in a recovery rate of each rule that will make the rule become competitive again more or less quickly.\n2.2 Implementation and modifications The model was implemented with Python and Numpy library. Several matrices were implemented for the short-term and long-term components of the connections, and for the activities of the layers. They were initialised with the values given in the paper, and updated with the formulas given there too. Some elements have then been added to get closer to the theoretical results reported in the paper, as a simple implementation of the components described in the paper was not sufficient to have the same results. Indeed, there were some problems of memory to bemaintainedwhile auto-evaluation, or with the activation of the go unit. In fact, the behaviour of themodel could be good enough but the algorithms used to activates the go unit were not inspired by some biologicalmechanisms. As said before, when the go unit is activated, the intention is transmitted to the output units. In the original paper, it is written that the go unit is activated by an external signal and the following comment is given: \u201dThe go clustermight also be activated by endogenous decision processes, but we do not use this possibility in the following simulations\u201d. Consequently, in the reported simulations in the original paper, the go unit was triggered by the programmer. What we did in this paper is to add some neuronal units to implement the mentioned endogenous process and have, without an external signal, the same experimental results.\n3 units have been added:\n\u2022 a neuronal cluster of confidence, whose role is to compute the error activity \u201dinverse\u201d, its activity is high when error activity is low and low when error activity is\nReScience C 5.1 \u2013 Bock and Alexandre 2019 2\nhigh.\n\u2022 a neuronal cluster of \u201dreflexion\u201d controlling response card inputs within memory layer, in order to have enough time for auto-evaluation according to previous card.\n\u2022 a neuronal cluster of \u201dinhibition\u201d, controlling go and reflexion units activation, delaying motor output and action choice while memory is changing.\nThe new model architecture is shown in the figure 2:\n2.3 Model functioning Firstly, all neuronal activities are set to 0 before network activation, except for one rulecoding cluster, whose activity is set near 1, as the first decision is supposed to be random at the test begining, having no a priori about which rule to sort by. Then, the connection components and activity thresholds are initialised with different values. These values are the ones for which the model has the best stability, dynamics and neuron activity behaviors. The initialised values and formulas of activity and connection updates computations are available in Annexes. In order to evaluate the auto-evaluation ability, the authors have created a modified version of the Wisconsin Card Sorting Test, using only 36 ambiguous cards, i.e response cards that match a reference card according to 2 dimensions. The rule changes whenever the agentmade three consecutive correct assignment according to the current right rule, meaning a criterion is reached. The test is finished when 6 criteria are reached\nReScience C 5.1 \u2013 Bock and Alexandre 2019 3\n(color-shape-quantity twice) or when all the 36 cards have been used. So, while the 6 criteria are not reached , the network activity is computed. The order of unit activation within a trial is as follows: inhibition and confidence units are computed, followed by reflexion: it allows to know if we are in a auto-evaluation phase on the previous card or in an active phase to choose a reference card to sort the new response card accordingly.\nMemory is then updated or not according to reflexion activity, and transmitted to intention according to rule-coding clusters modulation on the connections. Then, go unit activates or not according to reflexion activity. When go unit is activated, the intention is transmitted to the output. Intention is as well transmitted to the error cluster for the auto-evaluation part. The error is moreover influenced by a reward input. There are 2 types of reward possible: when at least one output cluster have an activity higher than 0.5, an action is made, and an external reward is received, equal to 1 if the choice was an error, to activates error cluster, or equal to 0 if the choice was right, not to influence\nReScience C 5.1 \u2013 Bock and Alexandre 2019 4\nerror activity. The other reward is one that has been added to the model. While reflex ion isn\u02bct active, a \u201dfake\u201d reward is computed in order to realise a better auto-evaluation on the past events. Its value is depending on the previous external reward received, and on the previous card chosen that lead to this reward. This choice is compared to the new intention according to a new rule followed. 5 different events can exist according to the previous true reward from the last trial and the comparison between intentions as showed in the following figure 3. Then the synaptic efficacy of the connections are updated: input-to-memory connections are modulated by reflexion activity, memory-to-intention short-term component by rule-coding cluster activities and long-term component by error, intention andmemory activities according to an Hebbian learning rule. Intention-to-output short-term component are modulated according to go activity. Rule-coding cluster auto-excitatory short-term components are updated according to error and self rule activities. Finally, output and inhibition auto-excitatory short-term components are updated. Output short-term components are modulated by output activity itself, allowing output activity not to stay active for too long, delayingmotor output. Inhibition is updated by confidence activity, its auto-excitatory long-term component decreases when confidence is high, to let reflexion and go unit become activated, as a confident intention is done, and on the contrary the long-term component increases when error is high, to stay in a auto-evaluation phase.\n2.4 Neuronal Network test In order to evaluate the performance of themodel according to the one described in the original paper, statistical computations have been done. It has been chosen to only implement and test the model with auto-evaluation and memory functioning, using modified WCST version, to evaluate these components as it has been done in the paper. The different computations that have been done are the following ones: the speed of learning, the one-trial learning rate and the perseveration rate. Speed of learning statistics are computed by increasing an error accumulator each time an external negative reward is received. It is saved in a list and re-initialised each time a criterion is reached. Then the mean of this list is computed in order to have the mean negative trial number necessary to reach a criterion.\nReScience C 5.1 \u2013 Bock and Alexandre 2019 5\nThe single-trial learning is the percentage of immediate succes obtained after only one negative trial. It is computed by counting the number of success following a negative trial (thanks to reward history) divided by the number of success plus the number of failure following one negative trial multiplied by 100. The perseveration rate is computed as follows: if the previous trial was negative, and the actual trial also, if the active rule is the same as in the previous trial, then it is a perseveration error. These perseveration errors are counted and divided by the total number of errors, multiplied by 100. A script has been implemented to compute these statistics on 500 tests like in the paper. Furthermore, the activities of some units have been saved and displayed at the end of a test, to evaluate the model behaviour according to different situations. Some of these graphs can be found in Annexes.\n3 Compared results\nThe 500 test statistical computations have led to the results visible in figure 4.\nSome differences of results can be found between the optimal model of the original paper and the model implemented, but it can be explained by seeing activities of the clusters. For example, it can sometimes take 2 trials instead of one to immediately succeed, as sometimes when there is a negative trial, the auto-evaluation on the previous\nReScience C 5.1 \u2013 Bock and Alexandre 2019 6\ncard can lead to choose a different intention than the wrong one, following the 2 other rules, if the features of the response cards were pointing to the same card. As it is said in the paper, then the rule is believed to be the right one, because it has led to another intention than thewrong one, but in fact, it is the other rule thatmust have been chosen. An example of this event can be seen in one of the activity graphs reported in figure 5:\nOther differences can be seen between the lesioned modified model and the lesioned model in the original article, the modified model has better results even when lesioned but the results are still worse than the ones for the no-lesioned model. When the modifiedmodel is lesioned, the test is no longer successful and only ameanof 1 or 3 criterions are reached instead of the 6 required to succeed.\n4 Conclusion\nAn implementationof themodel ofWisconsinCard SortingTest ofDehaene andChangeux has been done, adding somemodifications to try to reach the paper results for themodel with auto-evaluation and memory abilities, as there was some lack of information or misunderstandings in the paper to reach these results without modifications. There can be some errors coming from model stability, but the results obtained are close to the paper ones concerning the optimal model. The modifications that have been done, compared to the model without modifications, have improved the basic model in terms of biological mechanisms, as the go unit is now activated by units that give a focus on perception and are influenced by a computation of confidence on the auto-evaluation.\nReScience C 5.1 \u2013 Bock and Alexandre 2019 7\n5 Annexes\n5.1 S.Dehaene and JP.Changeux model computations For the new added units, the initialising values have been set respecting the order of magnitude of the paper values. Here are the fixed values at the beginning:\n\u2022 Long-term: input-to-memory: 3, memory-to-intention: 3, intention-to-output: 3, intention-to-error: 5, reward-to-error: 6, inhibition-to-go: -6, reflexion-to-go: 3, output-to-inhibition: 5, error-to-confidence: 4, confidence-to-reflexion: 3, inhibitionto-reflexion: -6.\n\u2022 Short-term: 0 for all, except for the auto-excitatory short-term of the rule-coding cluster randomly activated at the begining. Short-term that will not be update during the test are set to 1.\n\u2022 Thresholds: memory and intention: 3, output: 4, rule-coding clusters: 2, error: 5.5, go: 3, reflexion: 5, inhibition: 4.\nFor neurons activation:\nsi(t+ 1) = F \u2211 j Wij(t)sj(t)\u2212 Ti +N  (1) where si(t) is the i cluster activity at t time,Wij(t) the synaptic efficacy from cluster j to cluster i, Ti the activation threshold of cluster i and N is a noise term with uniform distribution whose range is between -0.7 and 0.7 in the paper, but that has been decreased to -0.5 to 0.5 to avoid some memory competition problems. F(x) function is a sigmoid:\nF (x) = 1/ ( 1 + e\u2212x ) (2)\nSynaptic efficacyWij(t) is computed as follows: Wij(t) = Sij(t)Lij(t) WithSij(t) the short-termcomponent representing other cluster influences on the synapse and Lij(t) the long-term component."}, {"heading": "Short-term updates", "text": "The short-term components that will be updated during the test, are set to 0 at the beginning. The influence of the cluster m on a synapse between cluster i and j is mesured at each time step by the following formula:\nSij(t+ 1) = { \u03b1Sij(t) + 1\u2212 \u03b1, if sm(t) > 0.5 \u03b1Sij(t), if sm(t) < 0.5\n(3)\nWith \u03b1 = 0.4. The connections concerned are the following ones: input-to-memory, memory-to-intention, intention-to-output, output-to-output and inhibition-to-inhibition. For the intention-to-output short-term updates, another thing has been added, the connection are decreased if go activity is below 0.5 or if there is some hesitation about the intention, i.e if at least 2 intentions have an activity above 0.02 to avoid go activity to trigger a motor output when memory is changing and so intentions are changing. This 0.02 value is rather extreme but by analysing intention activities and testing different thresholds, it is the best and the most accurate value possible.\nReScience C 5.1 \u2013 Bock and Alexandre 2019 8\nThe auto-excitatory connections update of the rule-coding clusters aremade accordingly to error and rule activities: :\nSii(t+ 1) = [\u03c3Sii(t) + 1\u2212 \u03c3] [1\u2212Q(t)] + \u03b4Sii(t)Q(t)\n(4)\nwith \u03c3 the recovery rate of a synapse (equal to 0.99 for a long memory of rejected rules) and \u03b4 = 0.97. With\nQ(t) = [sr(t)si(t)] 2 (5)\n, where sr(t) is error cluster activity, and si(t) the one of rule-coding cluster i.\nFinally, the last short-term components to be updated are the ones connecting intention to error layer:\nSir(t+ 1) = { \u03b4Sir(t) + 1\u2212 \u03b4, if sr(t) > 0.5 and si(t) > 0.5 \u03b4Sir(t), else\n(6)\nAll the other short-term components are set to 1 during all the test."}, {"heading": "Long-term components update", "text": "Only memory-to-intention long-term components are updated in the test, using a learning Hebbian rule linked to error:\nLij(t+ 1) =Lij(t)\u2212 \u03b2sr(t)Sij(t)sj(t) \u00b7 [2si(t)\u2212 1]\n(7)\n5.2 Other activities graphs. Here is an activities graph of a completeWCST test, showing the behaviour of themodel, trying different rules when an error is made. We can see that the rule activities fit rather well to the hidden rules to be found.\nReScience C 5.1 \u2013 Bock and Alexandre 2019 9\nFi gu\nre 6.\nRe co\nrd in g of\ncl us\nte rs\nac tiv\niti es\nm ad\ne w ith\nm at pl ot lib\nlib ra ry\nan d py\npl ot\nm od\nul e.\nTh e ca\nrd le ge\nnd co\nlo rs\nre pr\nes en\nts ea\nch re fe re nc\ne ca\nrd s(\nca rd\n1 re d,\nca rd\n2 bl ue\n,c ar\nd 3 gr\nee n an\nd ca\nrd 4 vi ol et ).\nIn ru\nle ac\ntiv iti\nes ,a\nlig ht\ngr ee n da\nsh re pr\nes en\nts a su\ncc es sf ul\ntr ia la\nnd a da\nrk re d da\nsh ,a\nne ga\ntiv et\nri al .I\nn ot he\nrg ra\nph s,\nth e\ntr ia ls\nar er\nep re se nt\ned by\ndo tt ed\n-b la ck\n-d as\nh.\nReScience C 5.1 \u2013 Bock and Alexandre 2019 10"}], "title": "[Re] The Wisconsin Card Sorting Test: Theoretical analysis and modeling in a neuronal network", "year": 2019}
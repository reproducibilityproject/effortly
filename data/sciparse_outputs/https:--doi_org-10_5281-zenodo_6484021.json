{"abstractText": "Habits, or habitual behaviors, are experiencing a resurgence of interest in cognitive science. After cognitivism put them in the background as not needing internal repre\u2010 sentations, a more recent trend is more aware of their fundamental role in explaining the cognition. With the rise of the notions of embodiment, of the importance of sen\u2010 sorimotor interactions and of self\u2010organization processes in the brain, new simulation models of habits are needed. We are particularly interested in such a model, proposed by Egbert and Barandiaran [1] which puts forward self\u2010organization asmesoscopic processes that leads tomacroscopic self\u2010organization of behavioral habits through repetition in a continuous sensorimotor space. This model does not claim any biological plausibility and is meant more as a \u201clogical\u201d modelization of habits. The idea is to identify, and question, key characteris\u2010 tics of habits about their development, their interference, their adaptation. The model is based on a \u201cIterant Deformable SensorimotorMedium\u201d (IDSM) where past sensorimo\u2010 tor trajectories are more likely to attract the current trajectory, ending up in trajectories similar to the most frequent past ones. Habits, in short. In another work, Egbert and Ca\u00f1amero, show how this model [2] can lead to reinforcement of habits that keeps an artificial homeostatic agent in its viability zonewithout the need of an explicit reinforce\u2010 ment signal. Our interest lies in exploring the limits of the IDSM framework, especially regarding the bootstrapping of behaviors and how different behaviors can coexist, influence them\u2010 selves and be adapted to the needs of the agent. For that, a first step has been to try to reproduce the work of [1] where basic elements and properties of the IDSM are tested. As explained in section 2, we have implemented the IDSM\u2010based model in python. The next sections show that we indeed succeeded in replicatingmost of the previous results: basic influence of several nodes on the behavior (section 2.6 and 2.7); recreating a previ\u2010 ously forced behavior (section 3); training functional habits (section 4). But it is difficult to reproduce the last part of the original paper. Section 5 shows that the peculiar behav\u2010 iors produced in the original paper seem to be quite rare in our own experiments. We discuss the reasons that can explain this discrepancy before concluding our work.", "authors": [{"affiliations": [], "name": "Tristan Gillard"}, {"affiliations": [], "name": "J\u00e9r\u00e9my Fix"}, {"affiliations": [], "name": "Alain Dutech"}, {"affiliations": [], "name": "Anne Urai"}, {"affiliations": [], "name": "Beno\u00eet Girard"}], "id": "SP:df9b24fecd05f5bd721e12372568614fb8d377fb", "references": [{"authors": ["M.D. Egbert", "X.E. Barandiaran"], "title": "Modeling habits as self-sustaining patterns of sensorimotor behavior.", "venue": "Frontiers in Human Neuroscience", "year": 2014}, {"authors": ["M. Egbert", "L. Ca\u00f1amero"], "title": "Habit-Based Regulation of Essential Variables.", "venue": "Artificial Life 14: Proceedings of the Fourteenth International Conference on the Synthesis and Simulation of Living Systems", "year": 2014}, {"authors": ["M. Egbert"], "title": "Investigations of an Adaptive and Autonomous Sensorimotor Individual.", "venue": "The 2019 Conference on Artificial Life", "year": 2018}, {"authors": ["M. Zarco", "M. Egbert"], "title": "Different Forms of Random Motor Activity Scaffold the Formation of Different Habits in a Simulated Robot.", "venue": "Artificial Life Conference Proceedings. MIT Press", "year": 2019}], "sections": [{"text": "R E S C I E N C E C Replication / Computational Neuroscience\n[Re] Modeling habits as self-sustained patterns of sensorimotor behavior Tristan Gillard1,2, J\u00e9r\u00e9my Fix1,3, ID , and Alain Dutech1,4 1Loria, UMR 7503, Nancy, France \u2013 2Universit\u00e9 de Lorraine\u201e Nancy, France \u2013 3Centrale Supelec\u201e Metz, France \u2013 4INRIA Nancy Grand-Est, Nancy, France\nEdited by Georgios Is. Detorakis ID\nReviewed by Anne Urai ID\nBeno\u00eet Girard ID\nReceived 17 March 2021\nPublished 23 April 2022\nDOI 10.5281/zenodo.6478462\n1 Introduction\nHabits, or habitual behaviors, are experiencing a resurgence of interest in cognitive science. After cognitivism put them in the background as not needing internal repre\u2010 sentations, a more recent trend is more aware of their fundamental role in explaining the cognition. With the rise of the notions of embodiment, of the importance of sen\u2010 sorimotor interactions and of self\u2010organization processes in the brain, new simulation models of habits are needed. We are particularly interested in such a model, proposed by Egbert and Barandiaran [1] which puts forward self\u2010organization asmesoscopic processes that leads tomacroscopic self\u2010organization of behavioral habits through repetition in a continuous sensorimotor space. This model does not claim any biological plausibility and is meant more as a \u201clogical\u201d modelization of habits. The idea is to identify, and question, key characteris\u2010 tics of habits about their development, their interference, their adaptation. The model is based on a \u201cIterant Deformable SensorimotorMedium\u201d (IDSM) where past sensorimo\u2010 tor trajectories are more likely to attract the current trajectory, ending up in trajectories similar to the most frequent past ones. Habits, in short. In another work, Egbert and Ca\u00f1amero, show how this model [2] can lead to reinforcement of habits that keeps an artificial homeostatic agent in its viability zonewithout the need of an explicit reinforce\u2010 ment signal. Our interest lies in exploring the limits of the IDSM framework, especially regarding the bootstrapping of behaviors and how different behaviors can coexist, influence them\u2010 selves and be adapted to the needs of the agent. For that, a first step has been to try to reproduce the work of [1] where basic elements and properties of the IDSM are tested. As explained in section 2, we have implemented the IDSM\u2010based model in python. The next sections show that we indeed succeeded in replicatingmost of the previous results: basic influence of several nodes on the behavior (section 2.6 and 2.7); recreating a previ\u2010 ously forced behavior (section 3); training functional habits (section 4). But it is difficult to reproduce the last part of the original paper. Section 5 shows that the peculiar behav\u2010 iors produced in the original paper seem to be quite rare in our own experiments. We discuss the reasons that can explain this discrepancy before concluding our work.\nCopyright \u00a9 2022 T. Gillard, J. Fix and A. Dutech, released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Alain Dutech (alain.dutech) The authors have declared that no competing interests exists. Code is available at https://gitlab.inria.fr/openbiscuit/rescience_egbert14 \u2013 DOI 10.5281/zenodo.6477279.. Open peer review is available at https://github.com/ReScience/submissions/issues/51.\nReScience C 7.1 (#13) \u2013 Gillard, Fix and Dutech 2022 1\n2 Method\n2.1 Generalities about IDSM Egbert andBarandiaran introduced the \u201cIterantDeformable SensorimotorMedium\u201d (IDSM) as a abstract model to study the formation of habits. This model has no biological plau\u2010 sibility and is only a conceptual tool for discussing matters about habits, where habits are thought as a tendency to reproduce previously seen sensorimotor trajectories. The core elements of the IDSM are sensorimotor nodes that act as a kind of memory of what the agent experienced before. A node is essentially situated in the sensorimotor space (component Np of the model) but also encodes what is the \u201cpreferred\u201d evolution of the sensorimotor trajectories in its vicinity using a velocity component Nv. As de\u2010 picted on Figure 1, at a given instant in time, the agent being in sensorimotor state p, an existing node exerts two influences on this current sensorimotor state:\n1. a node \u201cpushes\u201d the agent with a force proportionnal to the component Nv (force V),\n2. a node \u201cattracts\u201d the agent to the node\u2019s position Np (force A).\nThus, every existing node influences the current sensorimotor trajectory of the agent. Themain idea behind this is to get the agent to try to reproducememorized sensorimotor trajectories. This capacity is further induced as a node will be more influent the more frequently the agent \u201ctravels\u201d near this node (by increasing the weight Nw of the node). On the contrary, the weight of a node which is never \u201cvisited\u201d will decay.\nDuring the initialization phase of the IDSM, the agent creates nodes along sensorimotor trajectories it experiences. There is no relation between the number of nodes and the dimensions of the sensorimotor space. But, bigger (in term of the number of dimen\u2010 sions) sensorimotor spaces would require a larger number of node to be paved, keeping in mind that all parts of the normalized sensorimotor space are maybe not reachable by the agent. One of the open problems with the IDSM, outside of the scope of this paper, is thus to know what are innate behaviors (or reflexes) and the conditions that will produce these initial trajectories.\n2.2 Model The original model of [1] is described with text and equations in the article. We suspect that this model has been implemented and tested using the python language, but the code was not released with the publication.\nReScience C 7.1 (#13) \u2013 Gillard, Fix and Dutech 2022 2\nWe have chosen to reproduce this model and the experiments by using python (3.6.9), numpy (1.17.4) and matplotlib (3.1.1). We provide a virtual environment to make it eas\u2010 ier to run the python code with all required dependencies (see Appendix A). All symbols and parameters used in the various equations describing the IDSM model are listed in table 1. The core of the IDSM model is based on \u201cnodes\u201d that help maintain a history of sen\u2010 sorimotor dynamics. More formally, a node N is a tuple made of two vectors and two scalars.\nN = \u27e8p,v, w, a\u27e9 (1)\nwhere\n\u2022 p indicates the position of the node N , in sensorimotor space SM\n\u2022 v indicates the velocity of the change in sensorimotor space SM\n\u2022 w is a scalar which indicates the influence of a node, as described later.\n\u2022 a is the age of the node.\nThe age a of a node is not an attribute of a node in the original work, we have added it as it simplifies some explanation later in the paper (in particular in section 2.5). Itmust also be noted that p and v are computed in normalized sensorimotor spacewhere the range of all sensors and motors values are linearly scaled to lie in [0, 1]. Example of such normalization (and denormalization) can be found later in the paper, as code snippets attached to the experiments. The components of a node will be referred to using subscript notation, so the SM\u2010position, SM\u2010velocity, weight and age of the nodeN are written Np, Nv, Nw and Na. The dynamics of themodel involves first order differential equations. The original work does not specify how these are numerically integrated. In our simulations, we use for\u2010 ward Euler integration with a time step dt= 0.01.\n2.3 Creation of nodes As an agent controlled by the IDSM moves through sensorimotor states, new nodes are created if the current density \u03d5N (x) of nodes at the normalized position x of the agent is lower than a scalar threshold kt.\n\u03d5N (x) = \u2211 N \u03c9(Nw).d(Np,x) (2)\n\u03c9(Nw) = 2\n1 + exp(\u2212k\u03c9Nw) (3)\nd(Np,x) = 2\n1 + exp(kd\u2225Np \u2212 x\u22252) (4)\nIn equation (2), N is the set of all nodes. The distance factor (equation 4) and weight factor (equation 3) are depicted on figure 2. Concretely, in our python code, the creation of a node uses the function create_node( self, pos, vel) in the class IDSM of IDSM.py. The function is called in the step() function of the same class.\n\u2022 the velocity Nv is computed as the difference between the previous sensorimotor position (self.sm_pos_1) and the current sensorimotor position (sm_pos argu\u2010 ment of step(), see line 185 of listing 1) divided by the time step dt of the Euler integration. The first time step() is called, no node is added as self.sm_pos_1 is initialized as None (lines 187\u2010189 of the same listing).\nReScience C 7.1 (#13) \u2013 Gillard, Fix and Dutech 2022 3\n\u2022 for stability numerical reason, the numerator and denominator in the computa\u2010 tion of the distance d (see equation 4) are multiplied by exp(\u2212kd\u2225Np \u2212 x\u22252) to prevent an explosion of the exponential when a node is far away from the current sensorimotor position, as kd\u2225Np \u2212 x\u22252 can become quite large. See lines 39 and 40 of listing 2 where RBF(self, sm_pos, pos=None) computes d(Np, x).\n\u2022 as in the code provided to us by M. Egbert, a node is created only if the squared norm of the velocity component is less than 10 (||Nv||2 < 10).\ndef reset_dsm(self): 186 self.sm_pos_1 = None\n188 def step(self, dt, sm_pos):\n190 if self.sm_pos_1 is None: self.sm_pos_1 = sm_pos.copy() 192 return\n194 # Increment the age of all the nodes self.nodes[\u2019age\u2019] += dt 196 # Computes the density at sm_pos 198 phi, dists = self.phi(sm_pos)\n200 # Update the weights self.nodes[\u2019weight\u2019] += dt * (-1.0 + 10.0 * dists) 202 # Do we need to create new nodes ? 204 if phi < self.Kt: dsm_pos = (sm_pos - self.sm_pos_1)/dt\nListing 1. A step creates nodes in line 203, updates the weights w according to equation 5 in line 198 using d computed in line 195, in file IDSM.py\ndef RBF(self, sm_pos, nodes_positions=None): 36 if nodes_positions is None: nodes_positions = self.nodes[\u2019position\u2019] 38 l2 = np.sum((nodes_positions - sm_pos)**2, axis=1) coeff = np.exp(-self.Kd * l2) 40 dists = 2.0 * coeff / (coeff + 1.0)\nreturn dists\nListing 2. Compute distance d according to equation 4, in file IDSM.py. The position of the nodes is optionally provided as the nodes_position argument and is used to provide either the subset of the active nodes or all the nodes which is the default if none is provided.\n2.4 Update of nodes After it has been created, theweight of a nodewill change as described by the differential equation (5). Its age is also increased at each time step by dt. Two factors influence this update rule. There is a steady decrease of the weight (the \u22121 coefficient) thus a node positioned where the agent never comes back will slowly have null influence on the agent decision. But, every time the agent comes near the position Np of the node, its weight will be increased thanks to the r(N,x) factor.\ndNw dt = \u22121 + r(N,x) (5) r(N,x) = 10.d(Np,x) (6)\nReScience C 7.1 (#13) \u2013 Gillard, Fix and Dutech 2022 4\nIn our simulation, we use the forward Euler method to numerically integrate that equa\u2010 tion, with dt= 0.01, as seen in the step() function of listing 1, line 198.\n2.5 Influence of Nodes on the motor Only nodes which have been created for some period of time \u03c4 will influence the motor state of the agent. This set of active nodes at time t is denoted A(t), often written A when t is implicit.\nA(t) = {N \u2208 N|Na > \u03c4} (7)\nand thus we can define a density function \u03d5A using only active nodes by:\n\u03d5A(x) = \u2211 A \u03c9(Nw).d(Np,x) (8)\nThis density is computed over the active nodes, compared with the density \u03d5N (equa\u2010 tion 2) used for deciding if a node is to be created and computed over all the nodes. The influence of an active node N on the agent is twofold. The first, a \u201cvelocity factor\u201d, is simply the motor component of the SM\u2010velocity Nv of the node. The second is an \u201cat\u2010 traction factor\u201d that is akin to a force drawing the agent to the SM\u2010position Np of the node. The idea is to attract the agent to part of the SM\u2010space with a higher density of nodes. For a given node N , the attraction factor creates a force which is perpendicular to the Nv of this node by subtracting from the raw attraction the component which is parallel to Nv. See equations (10, 11).\nV (x) = \u2211 A \u03c9(Nw).d(Np,x).[Nv] \u00b5 (9)\nReScience C 7.1 (#13) \u2013 Gillard, Fix and Dutech 2022 5\nwhere [Nv]\u00b5 is the projection to the motor part of the SM\u2010space.\nA(x) = \u2211 A \u03c9(Nw).d(Np,x).[\u0393(Np \u2212 x, Nv)]\u00b5, (10)\n\u0393(a, Nv) =\n{ a\u2212 \u27e8 a, Nv\u2225Nv\u2225 \u27e9 Nv\n\u2225Nv\u2225 if Nv \u0338= 0 a otherwise , (11)\nwhere \u27e8x, y\u27e9 is the scalar product of the vectors. We introduced the case Nv = 0 in equation (11) which was not present in the original paper. Then the motor command \u00b5 of the agent is updated according to the differential equa\u2010 tion (12)\nd\u00b5 dt =\n{ V (x)+A(x)\n\u03d5A(x) if \u03d5A(x) > \u03f5\n0 otherwise (12)\nWe introduced the case \u03d5A(x) < \u03f5 in equation (12). In our code, we set \u03f5 to the small\u2010 est floating point value as returned by numpy (see IDSM.py, line 158). Using only the active nodes for computing the influence is justified in the original work, in section 2.2, where it is written: \u201cA short period of time after creation (10 simulated timeunits), nodes are activated, meaning that they are added to the pool of nodes that influence the motor state\u201d. Thus, the motor command is computed as the current motor part of the sensorimotor space to which d\u00b5 is added. In short:\n\u00b5t = [x] \u00b5 (13)\n\u00b5t+dt = \u00b5t + d\u00b5\ndt \u00d7 dt (14)\nwhere, in addition, wemake sure (by clamping) that \u00b5t+dt lies in [0, 1]. This clamping is also present in the code provided to us by M. Egbert. The right plot of figure 3 depicts the influence d\u00b5dt (attraction plus velocity) of a single node, with weight Nw = 0, positioned at Np = (0.5, 0.5) in a 2\u2010motor, 0\u2010sensor IDSM.\nReScience C 7.1 (#13) \u2013 Gillard, Fix and Dutech 2022 6\nFor this node, the velocity vector is Nv = (0, 0.1), so it is exactly vertical and thus, all horizontal motions are only due to the attraction factor A of the IDSM (as seen on the middle plot of the figure) while the vertical motion is due to the velocity factor V of equation (12), shown in the left plot of the figure. Other parameters are k\u03c9 = 0.0025, kd = 1000 and the node is active.\n2.6 Influence of four nodes, role of the weights The plots of figure 4 provide a visualization of how the weights modulate the influence of nodes. In this example that we tried to replicate from the original work (see figure 3 of [1]), we plot the influence of four nodes (depicted as bold arrows) on a 2\u2010motor, 0\u2010sensor IDSM by displaying the motor field d\u00b5dt created by these nodes. The weights of all nodes are set to 0 except for the rightmost node (node0). The weight of this node (node0, in a circle on the plots) varies from \u2212500 to 100. The other values of the nodes, shown in table 2, stay constant. The four nodes are active. As explained below, in order to reproduce these results, we had to depart from the parameters indicated in the original paper. We use k\u03c9 = 0.025 (not 0.0025) and kd = 1000.\nIn fact, if we use the original weight and weight parameters of the paper (k\u03c9 = 0.0025), we get the plot of Figure 5 where the varying weights of node0 do not have as big an influence. Our first thought was to play with the velocity component of the nodes as this value is not given in the original paper. But, as we are plotting isolines, it is only the relative influence of the Velocity vs Attrac\u2010 tion part of d\u00b5 that is relevant. If the velocity is very low, attraction takes precedence and we get \u201csquared\u201d trajectories (see Figure 6, with Nv = 0.01). Note also that in this case, even if the velocity is low, since the attraction term is kept orthogonal to the veloc\u2010\nReScience C 7.1 (#13) \u2013 Gillard, Fix and Dutech 2022 7\nity, we do not get isoline pointing straight to the nodes. If the velocity is high, attraction is ignored and we get \u201crounded\u201d trajectories (see Figure 7, with Nv = 1000).\nSo, the only solution to replicate Egbert results was to play with the weight part in the equations (9, 10,12). To keep the sameweights, we have to change k\u03c9 and a \u201clucky\u201d guess did it with setting k\u03c9 = 0.025 ( just omitting one \u201c0\u201d). We did somemanual computation of the influence of the 4 nodes and found that, at posi\u2010 tion (0.55, 0.55)withweight of\u2212500 and k\u03c9 = 0.0025, the influence d\u00b5dt is (0.692,\u22120.308). It does not seem compatible with horizontal trajectories at this point as in the plot of the original paper. If we set the weight to \u22125000 or k\u03c9 to 0.025, we have d\u00b5dt = (1.0, 0) at position (0.55, 0.55).\n2.7 Influence of many nodes We replicate here the figure 4 of the original work [1]. The IDSM is again a 2\u2010motor, 0\u2010 sensor sensorimotor space. For the first 20 time units, the motor state (m1,m2) of the agent is externally forced according to the following equations:\nReScience C 7.1 (#13) \u2013 Gillard, Fix and Dutech 2022 8\nm1 = 0.75. cos( 2\u03c0\n10 t) m2 = 0.75. sin(\n2\u03c0 10 t). (15)\nThen (after t = 20), the weights of the IDSM are frozen and the agent is controlled by the IDSM. At time t = 30, the two motor values are changed to (m1,m2) = (0.5, 0.6) (these particular motor values are taken by the location of the star symbol from figure 4 of the original work) and driven by the IDSM.\nExperiments The figure 8, replicated from the original work, shows three plots. On the left, we plot the velocity influence V of d\u00b5, equation (12), of the IDSM at time t = 20. The center plot shows the attraction influence A of d\u00b5, equation (12). The right plot shows the resulting influence d\u00b5dt when combining velocity and attraction, and we plot in blue the trajectory of the agent from time t = 30 to time t = 50 starting from the star position. As in the original work, the perturbed agent is \u201cattracted\u201d by the IDSM to the forced behavior imposed on it during the first 20 time units. For the experiments, the value of the hyper\u2010parameters were k\u03c9 = 0.0025, kd = 1000, kt = 1 and dt = 0.01. In total, 99 nodes are created during the first 20 time units.\nReScience C 7.1 (#13) \u2013 Gillard, Fix and Dutech 2022 9\ndef norm_sm_state(m): 70 return (1.0 + m)/2.0\n72 def denorm_motor(m): return 2.0 * m - 1.0 74 def get_norm_sm_state(robot): 76 m = robot.get_motors() return norm_sm_state(m)\nListing 3. Normalizing and denormalizing \u201creal\u201d values to sensorimotor space, in file exp-001.py\n3 [Re] Recreating previous sensorimotor behavior\nThis experiment tries to replicate the experiment detailed in section 3.1 of [1]. The robot driven by the IDSM is a point x which evolves in a one\u2010dimensional environ\u2010 ment. A single light source, also represented by a point, is located at the origin of the environment. The SM\u2010state p of the IDSM is two\u2010dimensional andmade of amotor\u2010state m and a sensor\u2010state s, given by the following equations:\np = ( m s ) = normalization ( x\u0307 1\n1+x2\n) , (16)\nwhere x\u0307 is the velocity of the robot. The goal is to see to what extend the IDSM is able to memorize a sensorimotor pattern it is first forced to comply so as to keep showing the same behavior once the forcing pattern is removed. Thus, the experiment is made of three phases.\nTraining Phase At t = 0, the agent is positioned at x = \u22122.5. During the first 20 time units of the simulation, its velocity is not influenced by the IDSM but imposed by a controller with m = cos(t/2). Although the original paper said that the motor controlwas forced to cos(t/2)/2, our analyze of the original figure 5 shows that themotor amplitude is in fact 1, whereas the original formulation would have give an amplitude of 0.5. Indeed, integrating the motor command (cos(t/2)) leads to a position trajectory with an amplitude of 2, which is coherent with the figure 5 (top) of the original paper. As shown by the middle plot of figure 9, the controlled velocity of the training phase keeps the robot on the negative side of the light, moving back and forth. During this training phase, nodes are added to the IDSM and updated as explained in sections 2.3 and 2.4. In our experiment, 291 nodes are created during this phase, displayed in the bottom plots of figure 9 as gray dots in the sensorimotor space, behind the colored tra\u2010 jectories. The darker the dot, the lower the weights. In fact, the decreasing influence of equation (5) is stronger than the reinforcement part, leading \u201cold\u201d nodes to see their weights drop to negative values (\u2248 \u221217). \u201cNewer\u201d nodes are in lighter gray. The arrows depict the velocity component Nv of one of every 25 nodes, as in the original paper1.\nTesting Phase At time t = 20, the training phase ends and the only influence on the motor of the robot is given by the IDSM, as explained in section 2.5. At the end of this phase, there are still 291 nodes in the IDSM as no new node has been created.\n1Section 3.1,below figure 5 of the original paper: \u201cThe motor component of activated nodes are shown as gray arrows in the SMplots of Figure 5, with only every 25th node plotted for clarity\u201d\nReScience C 7.1 (#13) \u2013 Gillard, Fix and Dutech 2022 10\nRelocation At time t = 35, the robot is relocalized at position x = \u22122.5, with its \u201creal\u201d velocity changed to 0 (and a normed motor value of 0.5). As in the original paper, the IDSM quickly brings the agent back on the trained behavior. At the end of this phase, there are 460 nodes it the IDSM, 441 are active, their weights ranging from \u221270 to 0.3.\nExperiments For this experiment, we have to depart from the hyper\u2010parameters given in the original paper. With the \u201coriginal\u201d hyper\u2010parameters2, our simulation create a total of 87 nodes (at the end of the relocation phase). If we count the number of nodes in the bottom plots of the Figure 5 of the original work, at least 25 times the number of arrow, it appears that more than 15 \u00d7 25 = 275 nodes are created. Thus, we have to \u201cplay\u201d with the density function \u03d5A that drives the creation of nodes: if we set k\u03c9 = 0.025 (as in the experiment of section 2.6), we must set kd = 12500 to get a plot similar to the\n2In the original paper we can read k\u03c9 = 0.0025, kd = 1000, kt = 1, \u03c4 = 10 and dt = 0.1\nReScience C 7.1 (#13) \u2013 Gillard, Fix and Dutech 2022 11\noriginal plot without touching to kt. So, we used to following hyper\u2010parameters in our experiment: k\u03c9 = 0.025, kd = 12500, kt = 1, \u03c4 = 10 and dt = 0.01. In the code repository, file exp-002.py can be used to replicate the experiment and draw the plots. Lines 83\u201094 of listing 4 show how \u201creal\u201d sensor andmotor are normalized (and denormalized) to a [0, 1] sensorimotor space. The coefficients of the normalization and denormalization functions have been estimated using the Figure 5 of the original work using the following procedure. From the variation of the position x of the agent and the sensor function 11+x2 we can compute the maximum and minimum values of the sensor readings, lets call them sval_min and sval_max, respectively computed at 0.047 and 0.8. Using a ruler on Figure 5, the normalized minimum and maximum values (snor_min and snor_max) were manually estimated as 0.12 and 0.86. For the motor, it is a simple projection from [\u22122, 2] to [0, 1]. These values are then used in the normalization/denormalization proce\u2010 dure, as shown on listing 4.\nsval_min = 0.047 88 sval_max = 0.8 snor_min = 0.12 90 snor_max = 0.86\n92 def norm_sensor(s): return (s-sval_min)/(sval_max-sval_min)*(snor_max-snor_min) + snor_min 94 def denorm_sensor(s): 96 return (s-snor_min)/(snor_max-snor_min)*(sval_max-sval_min) +\nsval_min\n98 def norm_motor(m): return 0.5 + 0.25 * m\n100 def denorm_motor(m): 102 return (m - 0.5)/0.25\nListing 4. Part of exp-002.py file that link \u201creal\u201d world to the agent sensorimotor space.\n4 [Re] Training functional habits\nFor this experiment where we try to replicate the results of section 3.2 of the original work, the agent is modeled as a two\u2010wheel robot evolving in a two\u2010dimensional toric world where a single light lies at the origin of the environment. Figure 10 shows the agent with its two wheels and two light sensors. The agent is a circle with a radius r = 0.25, and the light sensors are situated on the circle, at an angle \u00b1\u03b2 from the heading of the agent. If (x, y, \u03b1) is the position (x and y) and orientation (\u03b1) of the agent and m = (ml,mr) is the speed of its wheels (left and right), the dynamic of the agent is governed by these differential equations:\nx\u0307 = cos(\u03b1)(ml +mr), (17) y\u0307 = sin(\u03b1)(ml +mr), (18) \u03b1\u0307 = mr \u2212ml\n2r = 2(mr \u2212ml). (19)\nThe activity of the sensors depends on the distanceD between the sensor and the light situated at (x = 0, y = 0) and also on the angle between the direction the sensor is facing\nReScience C 7.1 (#13) \u2013 Gillard, Fix and Dutech 2022 12\n(vector b) and the direction of the light seen from the sensor (vector c), see figure 10. The sensor activity is computed according to:\ns = \u230a \u27e8b, c\u27e9 \u2225b\u2225\u2225c\u2225 \u230b+ 1 1 +D2 , (20)\nwhere \u230a.\u230b+ is either 0 or the positive value of its argument and b = (cos(\u03b1+\u03b2), sin(\u03b1+\u03b2)) This equation, where the scalar product between vectors b and c is correctlywritten, and where c is normalized, replaces the equation (12) of the original paper s = \u230ab.\u2225c\u2225\u230b +\n1+D2 . It must also be noted that, in order to ensure a proper simulation of light sensing in a toric world of size 4 centered in (0, 0), we add 8 \u201cvirtual\u201d lights that lie outside the center section (at positions (3, 0), (3, 3), (0, 3), (\u22123, 3), ...) and compute the value of a sensor as the maximum value over all possible virtual lights. See exp-003.py, lines 132\u2010144.\nThus, the sensorimotor space of the agent is made of 4 dimensions, 2 for themotors and 2 for the sensors.\np =  ml mr sl sr  (21) As in the previous experiment, the agent has a training phase where its motors are con\u2010 trolled to impose upon it some desired behaviors. The controller issues a command \u03c7 which is used to change the motor value as described by equation 22.\ndm\ndt = (\u03c7\u2212m). (22)\nThree different behaviors have been used: phototaxis (the agent is drawn to the light), sinusoidal\u2010phototaxis (attracted to light but with a sinusoidal perturbation) and photo\u2010 phobia (turns the agent away from the light). In the original paper, the sensory input is denoted \u03c3 which, we suppose, is a normalization of the sensor values (but, in this set\u2010 ting, the sensor value s is always in [0, 1]). And, as in the original paper, the command \u03c7 is clipped to [\u22121, 1].\nSimple phototaxis\n\u03c7l = 1\u2212 1.5 \u221a \u03c3l (23) \u03c7r = 1\u2212 1.5 \u221a \u03c3r (24)\nReScience C 7.1 (#13) \u2013 Gillard, Fix and Dutech 2022 13\nSinusoidal\u2010phototaxis\n\u03c7l = 1\u2212 1.5 \u221a \u03c3l + sin(2t)/2 (25) \u03c7r = 1\u2212 1.5 \u221a \u03c3r + sin(2t)/2 (26)\n(27)\nSimple photophobia\n\u03c7l = 1\u2212 1.5 \u221a \u03c3r (28) \u03c7r = 1\u2212 1.5 \u221a \u03c3l (29)\nExperiments For these experiments, the values of the hyper\u2010parameters are the one written in the original paper (k\u03c9 = 0.0025, kd = 1000, kt = 1, \u03c4 = 10 and dt = 0.1). We draw the attention on the fact that in the original paper the \u03b2 for the position of the sensors is said to be \u03c03 . But using\u03b2 = \u03c0 3 in our first simulations led to results inconsistent with the original paper. In particular, the agent was not able to stop in front of the light, contrary to what is suggested by the two top row plots of the original Figure 7 (phototaxis). Indeed, with \u03b2 = \u03c03 and the phototaxis behavior of equations (23)\u2010(24), there is no way for the agent to stay still in front of the light (see Figure 12). A value of \u03b2 = \u03c06 (and thus an angle of \u03c0 3 between the sensors) seems to solves this issue by offering a\nReScience C 7.1 (#13) \u2013 Gillard, Fix and Dutech 2022 14\nnull velocity target attractor to the agent: in Figure 12 the leftmost intersection between the null velocity (red horizontal line) and the dotted \u03c7 velocity with \u03b2 = \u03c06 . At this point, the agent is at an approximate distance of 1.1 from the light. Oddly, the plots of the original paper (Figure 7) seem more consistent with a stopping distance of 0.65, which would suggest a bigger \u03b2 (approx. \u03c04.7 \u2248 0.668), leading to a fixed point very close to its unstable neighbor. Although the original paper indicated that the agent was relocated every 50 time\u2010units, we relocated it every 25 time\u2010units because it is the only way to have 10 trajectories in a 250 time\u2010units period as can be seen on the Figure 7 of the original paper.\nThe results of our own experiments are summarized in the Figure 11 of this paper. The bar chart, showing themean distance of the agent from the central light source, depicts the same trend than the original experiments. In general, the mean distance to the cen\u2010 ter of both phototaxis and sinusoidal phototaxis are approximately the same and lower than for photophobia. However, the exact values of the distances differ from the orig\u2010 inal paper. Photophobia keeps the agent at a mean (square) distance of approximately 2 from the center, phototaxis keeps the agent closer to the light (app. distance of 1.5), and sinusoidal phototaxis is close to taxis. Furthermore, the trajectories we get seem qualitatively different from the original paper. Our agent is generally animated with a larger velocity, which lead to trajectory that can \u201ccross\u201d the light at high speed, exiting the frame at one side to reenter at the opposite side (this is a world with \u201cperiodic bound\u2010 ary conditions\u201d, see Section 3.2 of [1]). Randomness plays its role here, and we cannot pretend that we should always have the same kind of trajectories. Indeed, changing the seed (we ran our experiments with a seed equals to 0) does change the observed behaviors. We have the impression that, besides our comments about the value of \u03b2, the normalization and clamping of the motor, or velocity, of the agent may be part of the explanation. The IDSM model, at its core, does not guarantee that the velocity of the agent stays within [0, 1] in the sensorimotor space. So, we suspect that some sort of clamping is used by the authors3. The original paper talks4 about clamping \u03c7 in [\u22121, 1] but by definition (equations (23)\u2010(29)), \u03c7 always lies in [\u22121, 1]. So we think that clamping\n3This has been confirmed by M. Egbert during our privates exchanges 4\u201cThe equation below describe the target [...] motor values (\u03c7l, \u03c7r) [...] which are limited to lie in range [\u22121, 1] and\nthen used to update [...] motors (ml,mr) [...] \u201d, Section 3.2, a bit above equations (13), in [1].\nReScience C 7.1 (#13) \u2013 Gillard, Fix and Dutech 2022 15\nis performed on the motors.\nIn the code repository, file exp-003.py can be used to replicate the experiment and draw the various plots of Figure 11. Listing 5 shows how \u201creal\u201d sensor and motor are normalized (and denormalized) to a [0, 1] sensorimotor space.\ndef norm_sensor(s): 104 return s\n106 def denorm_sensor(s): return s 108 def norm_motor(m): 110 return 0.5 + 0.5 * m\n112 def denorm_motor(m): return (m - 0.5)/0.5\nListing 5. Part of exp-003.py file that links \u201creal\u201d world to the agent sensorimotor space.\n5 [Re] Emergence of self-organized habits\nThese experiments, also taken from [1], were not very detailed in the original paper. The main idea is to let the agent behave randomly while creating nodes (the equivalent of a training phase) and then analyze the behaviors that are induced to detect some regularities or broad categorizations. The environment and the agent are similar to the previous experiment (see section 4) with one light source at the origin, the agent has thus a four\u2010dimensional sensorimotor space with 2motors and 2 light sensors.\nRandom initialization of IDSM In this phase, 5000 nodes are randomly created. To do this, 100 random walks in the SM\u2010space of the agent are generated, each starting from a random location l in the SM\u2010space. From every starting random location, 50 more locations li are generated using:\nli+1 = li + r for i \u2208 1, . . . , 50, (30)\nwhere r is a vector randomly generated in [\u22120.05, 0.05]4 using a uniform probability distribution. In the event where some components of r would lead the agent outside the bounds of the normalized SM\u2010space, these components are inverted. A new nodeN is created at every location li (except the last one) of the trajectories with the following values:\nNp = li\nNv = \u03b3(li+1 \u2212 li) (31) Nw = 0 (32)\n. \u03b3 is a scaling factor set to 1.0 in the original publication. At the end of this initialization period, all the nodes are activated.\nClarification needed for the experimental setup After the initialization phase, the au\u2010 thors generate agent trajectories that are identified as belonging to five categories (see Figure 8 of the original paper). For discussion, we can name these behaviors as:\n\u2022 large circle (cyan)\nReScience C 7.1 (#13) \u2013 Gillard, Fix and Dutech 2022 16\n\u2022 square (red)\n\u2022 small circle (green)\n\u2022 point (purple)\n\u2022 flower (blue)\nWewere unable to reproduce all these behaviors. While the initialization phase is clearly described in the paper, there remains several unanswered questions or concerns that may explain why we were unable to reproduce these results:\n1. is the arena still periodic ? The trajectories depicted in Figure 8 of the original paper do not have discontinuities that would reflect the periodic boundary condi\u2010 tions.\n2. are nodes created only in the initialization phase or also during the trajectory gen\u2010 eration ?\n3. are all the subsequent trajectories generated from the same initialized IDSM ?\n4. while the sensorimotor space is [0, 1]4, the PCA projection of the trajectories in Fig\u2010 ure 8 of the original paper has coordinates in [\u22123, 5]\u00d7 [\u22121, 6] which is surprising.\nClarificationby the authors about behavior generation Fruitful exchangeswithMatthew Egbert gave us some answers to questions 1, 2 and 3. Answering points 2) and 3) above, Egbert told us that one IDSM is initialized with 5000 nodes and then all subsequent trajectories (lasting 100 units of time) are generated in sequence, possibly adding their own new nodes to the IDSM. And the last 25 time units of every sequence are displayed and analyzed. Answering point 1), the arena is periodic in the original work. We are still puzzled by the plots of the Figure 8 so, for this experiment, we opted for a different implementa\u2010 tion of a periodic world. Instead of relocating the agent when it crossed the \u201cborders\u201d of the arena , as done in the previous experiment (see exp-003.py), we computed a \u201cvir\u2010 tual\u201d position of the agent (using the modulus operator) that is always in [\u22122, 2]\u00d7 [\u22122, 2] physical space, regardless of the real position of the agent in physical space. The sen\u2010 sor values, and thus the IDSMmotor command, are computed using this virtual position (see exp004.pywith \u2013repeating_env option). Trajectories are plotted using the real positions of the agent. Matthew Egbert sent us his code base, which is comprised of several developments for serveral experiments and papers over the years. We had a detailed look at this code but we were unable to run it, as it relies on GPU computing and the use of some unavailable library. Nevertheless, it helped us a lot in understanding small details that we men\u2010 tionned earlier (clamping \u00b5, conditions for the creation of a node, virtual lights, etc). M. Egbert was also very kind to correct many typos of the draft version of the paper we send him, and we are really thankful for the time he took in trying to understand with us why our results are different from what he obtained. As to what could explain the discrepancies between their results and ours in the experi\u2010 ments of this section, he puts forward three possible elements:\n\u2022 a possible difference in the sensor function used in our experiments. But this argument was based on a wrong interpretation of the description of the sensor function we used. AsM. Egbert provided the code for their function, we were able to check that we use the same sensor function.\n\u2022 the fact that, at the time of the conversation, we randomly initialized the IDSM before each trial. But we are now initializing only once, at the start.\nReScience C 7.1 (#13) \u2013 Gillard, Fix and Dutech 2022 17\n\u2022 the relative rates of change of the IDSM and the robot\u2019s activity in space. What he mean is this (quoted): \u201cwhen moving through the environment, the sensory activity changes at some rate (determined by the velocity of the robot and light, and the function describing the sensor activity). The motor state of the robot also changes at some rate (de termined by the distribution of nodes, and the magnitude of their velocity and attraction components). If the latter rate of change is very slow compared to the former, then the habits that tend to form tend to be quite uninteresting. Essentially, the nodes end up hav ing very little influence upon the motor state before they are departed because the sensory state is changing so quickly that any given node only influences the system for a short pe riod of time. In this case the selforganizing habits thatmight form in the 2D sensorimotor space depicted in Figure 5 [Figure 9 bottom in the present paper] would be (mostly) up and down, without much variation left and right...i.e. the motor state would be relatively constant. This would correspond to the primarily circular patterns you are seeing (motor state is changing very little). Youmight try increasing the magnitude of the random veloc ity vectors you are creating at the start to see if you observe more interesting patterns of behaviour.\u201d In fact, we tried with various values for the magnitude of the step r in equation 30 and with scaling up or down the norm of theNv component of nodes (by playing with the \u03b3 factor of equation 31) added during the initialization (these are the parameters rnd_step and rnd_scale in script exp-004.py). We also experimented with several values for kd and k\u03c9, and we were not able to observe flowers or square trajectories.\nFurthermore, we have not puzzled out the discrepancy we observe in the \u201csimple\u201d ex\u2010 periment with 4 nodes, detailed in section 2.6. As we were able to reproduce other ex\u2010 periments, this might have no link on us not being able to replicate the results from the last experiments.\nAnalysis of our experiments As illustrated by Figure 13, we mainly obtain circle trajectories of various radius5. The center of these circles usually drifts over time. Some curved trajectories are no more circles but look more like loops (e.g. 5th or 42nd plot). In agreement with the simulations of the authors, we observe small (2nd plot) and large circles (1st plot). We have seen no square nor flower trajectories. point patterns might in fact be \u2019thick\u2010circles\u2019 or even circles with very small radius, like for example plots 39 or 70. In Figure 14, we present the distribution of the diameters of circles observed in Figure 13. This figure must be taken with caution as the diameters measurements are very approx\u2010 imate. The python program figs/exp004_seed0_final/circle_radius.py lists these measurements and was used to create the plots of Figure 14. We clearly observe two prototypical circle radius (around 0.2 and 1.0).\nAny reasons for such a discrepancies with the original work ? It appears that several hyper\u2010parameters are crucial to the IDSM. In previous sections, we showed that setting kd and k\u03c9 to proper values was the key to replicating the experiments of the original work. In this last experiment, we explored a large range of value for the kd and k\u03c9 hyper\u2010 parameters but never succeeded in observing behaviors as diverse as the one of the original article. One must also be careful to use a Euler integration step dt that is small enough. Too big a step can prevent the creation of some nodes as only one node can be created at each time step. And also, a big time step can also explain behaviors where the trajectory of the agent changes very abruptly. As illustrated in Figures 6 and 7 of Section 2.6, the right balance between the velocity component Nv of node and the resulting attraction in equation (12) must be found in order to get square like trajectorieswith rounded corned. As a consequence, the random\n5command used: exp-004.py --repeating_env --seed 0 --num_trials 90\nReScience C 7.1 (#13) \u2013 Gillard, Fix and Dutech 2022 18\ninitialization of the IDSM and of the velocity of the agent when it is relocated could also play a role in what behaviors will subsequently be observed. Then, as pointed out before in the exchanges we had with Matthew Egbert: \u201cthe relative rates of change of the IDSM and the robot\u2019s activity in space\u201d is important. It means that the agent must move at a \u201ccorrect\u201d (or proper) speed so that the rate of change of its sensor is comparable to the rate of change induced by the IDSM nodes. This consideration also stresses the importance of the starting velocity of the agent, and of the initialization phase of the IDSM (i.e, the sensorimotor distribution of the created nodes). These points have been explored in some subsequent works of Egbert and colleagues, see [3, 4]. Besides, when the agent moves in the simulated environment, it can only roam in a small subpart of the sensor dimensions of the sensorimotor space. As the 5000 random nodes created during the initialization do not take this into consideration, many initial nodes will never have any influence on the agent: the exponential nature of the distance d between the agent and these nodes will always be null. This is one of the reason we tried to use smaller kd, but with no real impact on the results. In fact, in the large majority of our runs, we observe that the nodes created by the agent during the initialization phase are quickly less influent than the new nodes created dur\u2010 ing the trajectories. Indeed, during the 25 last steps, the agent is mostly influenced by \u201cnewer\u201d nodes and, very often, one or two different nodes only. This might also explain the prevalence of circle behavior as the velocity change thus induced lead to a kind or circling, sometime with a drift, for the agent.\n6 Conclusion\nThis paper explores the \u201cIterant Deformable Sensorimotor Medium\u201d (IDSM), a model to study the generation of habits in cognitive agents proposed by Egbert and Barandi\u2010 aran [1]. We give a python code to implement this model and to replicate most of the experiments of the original paper. The only part we are not able to reproduce is the \u201cEmergence of self\u2010organized habits\u201d (see our Section 5). As the original formulation of these experiments lacks some details, we highlight our choice and lay down some hypothesis explaining what we observe. This replication work is very instructive for us. We have a better and detailed under\u2010 standing of the IDSM and some interesting problems in the habits formation can be explicited in this formal model, and our current works aims at addressing several of theses questions.\n\u2022 The initialization phase is crucial and cannot be left to a random process. What kind of \u201creflex\u201d or \u201chard\u2010wired\u201d behavior can bootstrap the system. Egbert exper\u2010 imented with a new kind of random initialization in [3] but, again, some details are missing and the question is still largely open.\n\u2022 The IDSM, in its current state, does not seem compatible with \u201clearning\u201d several habits and combining them. How could it be altered to do so ?\nReScience C 7.1 (#13) \u2013 Gillard, Fix and Dutech 2022 20\n\u2022 Forgetting a habit is allowed through a decrease of the weights of the nodes. But re\u2010acquiring this habit can take as long as engraving it in the first time. Can we add some mechanisms to improve re\u2010acquisition of forgotten habits ?"}, {"heading": "Acknowledgment", "text": "Wewould like to thank Matthew Egbert for the fruitfull exchanges which helped to clar\u2010 ify the content of the reproduced paper and to correct typos in our original submission. Althought we were unable to reproduce all the results, we thank the author for the ef\u2010 forts of sharing his code base with us.\nA Python virtual environment\nIn order to make running the code easier, we provide a virtual environment for python. As such, installing requirements for the code can be easily donewith the following steps.\n## In a directory where the code has been cloned 2 ## create a virtual environment (named venv) for python3.6 $> virtualenv --python=python3.6 venv 4 ## activate this virtual environment 6 $> source venv/bin/activate\n8 ## and install the requires dependencies (requirements is a file provided in the code repository)\n$> pip install -r requirements 10 ## then run experiments, for example 12 $> cd python $> python exp-001.py 14 ## when done with the virtual environment, unlog from it 16 $> deactivate"}, {"heading": "1. M. D. Egbert and X. E. Barandiaran. \u201cModeling habits as self-sustaining patterns of sensorimotor behavior.\u201d In:", "text": "Frontiers in Human Neuroscience 8 (2014). 2. M. Egbert and L. Ca\u00f1amero. \u201cHabit-Based Regulation of Essential Variables.\u201d In: Artificial Life 14: Proceedings of the Fourteenth International Conference on the Synthesis and Simulation of Living Systems. The MIT Press, July 2014, pp. 168\u2013175. 3. M. Egbert. \u201cInvestigations of an Adaptive and Autonomous Sensorimotor Individual.\u201d In: The 2019 Conference on Artificial Life 30 (July 2018), pp. 343\u2013350. 4. M. Zarco and M. Egbert. \u201cDifferent Forms of Random Motor Activity Scaffold the Formation of Different Habits in a Simulated Robot.\u201d In: Artificial Life Conference Proceedings. MIT Press. 2019, pp. 582\u2013589.\nReScience C 7.1 (#13) \u2013 Gillard, Fix and Dutech 2022 21"}], "title": "[Re] Modeling habits as self-sustained patterns of sensorimotor behavior", "year": 2022}
{"abstractText": "This report summarizes our efforts to reproduce the results presented in the ACL2021 paperHate Speech Detection based on Sentiment Knowledge Sharing by Zhou et al. [1], as part of the ML Reproducibility Challenge 2021. We attempt to verify themain claims of the original study by reproducing the experiments comparing models with and without sentiment knowl\u2010 edge sharing. Although most scores in our replication study matches with the ones reported in the original paper, our experiments result in substantially lower scores for the full model with sentiment sharing. We also investigate variation in the scores, re\u2010 port additional scores (more suitable for the task), and discuss possible sources for the discrepancies observed.", "authors": [{"affiliations": [], "name": "Matteo Brivio"}, {"affiliations": [], "name": "\u00c7a\u011fr\u0131 \u00c7\u00f6ltekin"}, {"affiliations": [], "name": "Koustuv Sinha"}, {"affiliations": [], "name": "Sharath Chandra Raparthy"}], "id": "SP:2dffd7071e19989fffd16bdc5ac94d46ff42dc79", "references": [{"authors": ["X. Zhou", "Y. Yong", "X. Fan", "G. Ren", "Y. Song", "Y. Diao", "L. Yang", "H. Lin"], "title": "Hate Speech Detection Based on Sentiment Knowledge Sharing.", "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). Association for Computational Linguistics,", "year": 2021}, {"authors": ["T. Davidson", "D. Warmsley", "M. Macy", "I. Weber"], "title": "Automated Hate Speech Detection and the Problem of Offensive Language.", "venue": "Proceedings of the International AAAI Conference on Web and Social Media. Vol", "year": 2017}, {"authors": ["A. Schmidt", "M. Wiegand"], "title": "A Survey on Hate Speech Detection using Natural Language Processing.", "venue": "SocialNLP@EACL", "year": 2017}, {"authors": ["V. Basile", "C. Bosco", "E. Fersini", "D. Nozza", "V. Patti", "F.M. Rangel Pardo", "P. Rosso", "M. Sanguinetti"], "title": "SemEval2019 Task 5: Multilingual Detection of Hate Speech Against Immigrants andWomen in Twitter.", "venue": "Proceedings of the 13th International Workshop on Semantic Evaluation. Association for Computational Linguistics,", "year": 2019}, {"authors": ["W. Yin", "A. Zubiaga"], "title": "Towards generalisable hate speech detection: a review on obstacles and solutions.", "venue": "PeerJ Computer Science", "year": 2021}, {"authors": ["M. Zampieri", "P. Nakov", "S. Rosenthal", "P. Atanasova", "G. Karadzhov", "H. Mubarak", "L. Derczynski", "Z. Pitenis"], "title": "\u00c7\u00f6ltekin. \u201cSemEval-2020 Task 12: Multilingual Offensive Language Identification in Social Media (OffensEval 2020).", "venue": "Proceedings of the Fourteenth Workshop on Semantic Evaluation. Barcelona (online): International Committee for Computational Linguistics,", "year": 2020}, {"authors": ["N. Reimers", "I. Gurevych"], "title": "Reporting Score Distributions Makes a Difference: Performance Study of LSTMnetworks for Sequence Tagging.", "venue": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. Copenhagen, Denmark: Association for Computational Linguistics,", "year": 2017}, {"authors": ["\u00c7. \u00c7\u00f6ltekin"], "title": "Verification, Reproduction and Replication of NLP Experiments: a Case Study on Parsing Universal Dependencies.", "venue": "Proceedings of the Fourth Workshop on Universal Dependencies (UDW 2020). Barcelona, Spain (Online): Association for Computational Linguistics,", "year": 2020}, {"authors": ["O.E. Gundersen", "K. Coakley", "C. Kirkpatrick"], "title": "Sources of Irreproducibility in Machine Learning: A Review.", "year": 2022}, {"authors": ["N. Shazeer", "A. Mirhoseini", "K. Maziarz", "A. Davis", "Q. Le", "G. Hinton", "J. Dean"], "title": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer.", "year": 2017}, {"authors": ["J. Ma", "Z. Zhao", "X. Yi", "J. Chen", "L. Hong", "E.H. Chi"], "title": "Modeling Task Relationships in Multi-Task Learning with Multi-Gate Mixture-of-Experts.", "venue": "Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. KDD \u201918. London, United Kingdom: Association for Computing Machinery,", "year": 2018}, {"authors": ["A. Vaswani", "N. Shazeer", "N. Parmar", "J. Uszkoreit", "L. Jones", "A.N. Gomez", "L. Kaiser", "I. Polosukhin"], "title": "Attention Is All You Need.", "year": 2017}, {"authors": ["D. Shen", "G. Wang", "W. Wang", "M.R. Min", "Q. Su", "Y. Zhang", "R. Henao", "L. Carin"], "title": "On the Use of Word Embeddings Alone to Represent", "venue": "Natural Language Sequences", "year": 2018}, {"authors": ["J. Pennington", "R. Socher", "C.D. Manning"], "title": "GloVe: Global Vectors for Word Representation.", "venue": "Empirical Methods in Natural Language Processing (EMNLP)", "year": 2014}, {"authors": ["Mart\u0131\u0301n Abadi"], "title": "TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems.", "venue": "URL: https://www.tensorflow.org/. ReScience C", "year": 2015}], "sections": [{"text": "R E S C I E N C E C Replication / ML Reproducibility Challenge 2021\n[\u00acRe] Hate Speech Detection based on Sentiment"}, {"heading": "Knowledge Sharing", "text": "Matteo Brivio1, ID and \u00c7a\u011fr\u0131 \u00c7\u00f6ltekin1, ID 1University of T\u00fcbingen, T\u00fcbingen, Germany\nEdited by Koustuv Sinha,\nSharath Chandra Raparthy\nReviewed by Anonymous Reviewers\nReceived 04 February 2022\nPublished 23 May 2022\nDOI 10.5281/zenodo.6574639\n1 Reproducibility Summary\nThis report summarizes our efforts to reproduce the results presented in the ACL2021 paperHate Speech Detection based on Sentiment Knowledge Sharing by Zhou et al. [1], as part of the ML Reproducibility Challenge 2021. We attempt to verify themain claims of the original study by reproducing the experiments comparing models with and without sentiment knowl\u2010 edge sharing. Although most scores in our replication study matches with the ones reported in the original paper, our experiments result in substantially lower scores for the full model with sentiment sharing. We also investigate variation in the scores, re\u2010 port additional scores (more suitable for the task), and discuss possible sources for the discrepancies observed.\n1.1 Scope of Reproducibility The main goal of this reproducibility attempt is to confirm the effectiveness of the hate speech detection framework proposed by Zhou et al. [1]. In particular, our efforts are directed at validating their main claim that sentiment knowledge sharing in a multi\u2010 task learning setup improves the performance of the model in predicting hate speech. Besides reproducing their main results, we perform repeated experiments to assess the variability of the scores and carry out a hyperparameter search.\n1.2 Methodology The authors provide a code\u2010base which is available at https://github.com/1783696285/SKS. We reuse the available code, modifying it where necessary and integrating it with a few additional scripts for statistics computation and data preparation. Our code, data and results are available at https://github.com/matteobrv/repro-SKS.\n1.3 Results Our findings diverge substantially from the results reported in the original paper. In particular, in our reproduction experiments, including sentiment features appears to hurt the performance of the model in the hate speech detection task (approximately 0.5 to 2.0F1\u2010score) in the settingwe could reproduce based on the description in the original paper and published source code (and limited contact with the authors, see Section 1.6).\nCopyright \u00a9 2022 M. Brivio and \u00c7. \u00c7\u00f6ltekin, released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to \u00c7a\u011fr\u0131 \u00c7\u00f6ltekin (ccoltekin@sfs.uni-tuebingen.de) The authors have declared that no competing interests exist. Code is available at https://github.com/matteobrv/repro-SKS \u2013 DOI 10.5281/zenodo.6502870. \u2013 SWH swh:1:dir:d61b47330cc5c92d7ac4873269faa38a2e3c20bd. Open peer review is available at https://openreview.net/forum?id=SSSGs3M7nRY.\nReScience C 8.2 (#7) \u2013 Brivio and \u00c7\u00f6ltekin 2022 1\nRepeating the experiments with the different random initializations does not provide potential explanations for the differences.\n1.4 What was easy The paper provides some broad indications with respect to the training details and the code\u2010base is publicly available. Similarly, the data\u2010sets are also freely available and the authors provide links to them in their repository.\n1.5 What was difficult Like most \u2018research code\u2019, the code\u2010base is rather convoluted. Following the instruc\u2010 tions included in the authors\u2019 repository resulted in a number of exceptions caused by formatting issues, missing code snippets and hard\u2010coded values. The lack of a clear and comprehensive documentation also contributed to an arduous code review and repro\u2010 ducibility effort.\n1.6 Communication with original authors Wewere able to resolve some of the problems with running the original code (e.g., miss\u2010 ing code snippets) by contacting the authors through their public repository. Unfortu\u2010 nately, however, not all of our questions were answered, nor the issues were fixed (in a timelymanner) and we had to resort to \u2018reasonable defaults\u2019 for some of the unspecified or unclear aspects of the original experiments. We also did not receive responses to our questions via emails sent to the email addresses provided on the paper.\nReScience C 8.2 (#7) \u2013 Brivio and \u00c7\u00f6ltekin 2022 2\n2 Introduction\nBeing able to quickly and reliably detect hate speech in an automatic manner is an im\u2010 portant task. Due to the growing number of regulations concerning the use of hate speech and other forms of offensive language online this topic has gained increasing interest, both in academia and industry [2, 3, 4, 5, 6]. As in any supervised learning task, the availability and the size of labeled data\u2010sets pose significant challenges. The task is made even more arduous by its multilingual and multi\u2010domain nature. One way to alleviate such problems is to make use of additional data\u2010sets from potentially related tasks. The study by Zhou et al. that we attempt to reproduce describes a multi\u2010task learning framework for online hate speech detection that relies on the purportedly strong neg\u2010 ative sentiment characterizing this threatening form of communication. The model presented in the original paper, Sentiment Knowledge Sharing (SKS), is a multi\u2010head attention network that predicts whether the input text contains hate speech or not. The main claim of the paper revolves around the fact that the model is (optionally) trained in a multi\u2010task setting also for sentiment analysis, and it can incorporate information from a dictionary of derogatory words through \u2018category embeddings\u2019 (see Section 4.1 for further details). Based on experiments carried out on two benchmark data\u2010sets, the original study claims that training a model relying both on sentiment information and category embeddings allows to boost its performance in the task of hate speech detection.\n3 Scope of reproducibility\nThe work of Zhou et al. [1] is based on the intuition that hate speech detection and senti\u2010 ment analysis are two highly correlated tasks and that hate speech is likely to arise from derogatory words. Our reproduction attempt aims to verify the following claims:\n\u2022 A model relying both on Sentiment Knowledge Sharing (SKS) and a dictionary of derogatory words scores better than several strong baselines where sentiment fea\u2010 tures are not considered.\n\u2022 Ablating the sentiment knowledge component (-s) results in a poorer performance, as themodel relies solely on derogatory words features which, despite being likely indicators of hate speech, canmake themodel too sensitive too false positives (e.g., I\u2019m so fucking ready!).\n\u2022 A model where both sentiment knowledge and derogatory word features are ab\u2010 lated (-sc) scores the worst performance.\nBesides trying to reproduce the original results (see Table 3 in [1]), we carry out a hyper\u2010 parameter search to validate the values reported in the original paper. Since variation due to model initialization can be an important factor for irreproducibility [7, 8, 9], we run all experiments multiple times to check whether any observed differences stand when score variation is taken into consideration.\n4 Methodology\n4.1 Model description The SKS model relies heavily both on the Mixture\u2010of\u2010Experts (MoE) approach as intro\u2010 duced by Shazeer et al. [10] and the Multi\u2010gate Mixture\u2010of\u2010Experts (MMoE) presented by Ma et al. [11]. Its overall architecture consists mainly of three macro\u2010components: an input layer, a sentiment knowledge sharing layer and a gated attention layer.\nReScience C 8.2 (#7) \u2013 Brivio and \u00c7\u00f6ltekin 2022 3\nThe input layer \u2014 In the input layer, word embeddings are used to encode words of each target sentence. Specifically, every tokenwi of a given sentenceS = {w1, w2, ..., wi, ..., wN} is transformed into a real\u2010valued vector xi \u2208 Rd. Additionally, given that derogatory words represent a helpful marker of hate speech, each vector xi is concatenated with a category embedding vector ci \u2208 Rd i , such that x \u2032\ni = xi \u2295 ci. Category embeddings are created on the basis of a dictionary of derogatory words which allows to classify sentences into two categories, either containing derogatory words or not. The result of the classification is encoded as a vector ci and appended to each word embedding xi, such that the encoded sentence is S \u2032 = {x\u20321, x \u2032 2, ..., x \u2032 i, ..., x \u2032 N}.\nThe sentiment knowledge sharing layer \u2014 The sentiment knowledge sharing component re\u2010 lies on a multi\u2010task learning strategy which, according to the authors, would allow to take advantage of the high correlation between the two tasks of sentiment analysis and hate speech detection. In the proposed implementation, the two tasks share a bottom hidden layer based on the Mixture\u2010of\u2010Experts (MoE) approach. This layer is made up of multiple identical feature extraction units (Experts) each of which, in turn, is composed of a multi\u2010head attention layer using 4 heads and two feed forward neural networks. Each unit relies on the idea of multi\u2010head attention introduced by Vaswani et al. [12], where the input matrix X is mapped to query Q \u2208 R(n1\u00d7d1), key K \u2208 R(n1\u00d7d1), and value V \u2208 R(n1\u00d7d1) using linear transformations. Given these three matrices the attention parameters are computed as follows:\nAttention(Q,K,V) = softmax\n( QK\u22a4\nd1\n) V. (1)\nIn the implementation proposed by Zhou et al. K = V and d1 corresponds to the number of hidden layer units. The ith output of the multi\u2010head attention mechanism is:\nMi = Attention(QWQi ,KW K i ,VW V i ), (2)\nwhere the parameter matrices are WQi \u2208 Rn1\u00d7 d1 l , WKi \u2208 Rn1\u00d7 d1 l and WVi \u2208 Rn1\u00d7 d1 l . All outputs are then concatenated and multiplied by WO to get the final feature representa\u2010 tion Hs = concat(M1,M2, ...,Mi, ...,Ml)WO. Finally, the authors decide to use both maximum and average pooling [13] to fuse the feature representations, concatenating the two results:\nPm = Pooling_max(Hs), (3)\nPa = Pooling_average(Hs), (4)\nPs = concat(Pm,Pa). (5)\nThe gated attention layer \u2014 The third macro\u2010component is a gated attention mechanism which allows to select a subset of the feature extraction units from the previous layer. The output gk(x) of a specific gate k corresponds to the probability of selecting a specific unit. The subset of units selected through this process are then weighted and summed to get the final representation fk(x) for a given sentence, which is then passed to a feed\u2010 forward neural network to detect hate speech:\ngk(x) = softmax(Wgn \u2217 gate(x)), (6)\nfk(x) = n\u2211 i=1 gk(x)ifi(x), (7)\nReScience C 8.2 (#7) \u2013 Brivio and \u00c7\u00f6ltekin 2022 4\nyk = h kfk(x). (8)\n4.2 Datasets Following in the footsteps of Zhou et al. [1], we test the model and report results on two public hate speech data\u2010sets: SemEval2019 Task\u20105 (SE) [4]1 and Davidson (DV) [2].2 The former is freely available upon request, while the latter is openly distributed under an MIT License. The SE data\u2010set contains a total of 13, 000 tweets and is divided into training\u2010, validation\u2010 and test\u2010set, consisting of 9, 000, 1, 000 and 3, 000 samples, respectively. The training\u2010 set contains 3, 783 instances of hate speech and 5, 217 instances that are not. In the validation\u2010set 427 samples are classified as hate speech and 573 as non\u2010hate speech. The test\u2010set is split into 1, 260 hate speech samples and 1, 740 non\u2010hate speech ones. The DV data\u2010set contains a total of 24, 783 manually labeled tweets. Each tweet is as\u2010 signed to either one of three classes: hate speech (1, 430), offensive language (19, 190) or neither (4, 163). Zhou et al. merge the last two classes together and obtain 1, 430 tweets classified as hate speech and 23, 353 classified as non\u2010hate speech. Finally, the model relies also on a sentiment data\u2010set freely available on Kaggle3 under no specific license. Following the original study, we only use the training\u2010set which contains 31, 962 tweets, 2, 242 of which are classified as having a negative sentiment, while the remaining 29, 720 a positive one.\n4.3 Hyperparameters We begin our reproducibility attempt, relying solely on the hyperparameters reported in the original paper. Our results are summarized in Table 1. In the input layer, all word vectors are initialized using Glove Common Crawl Embed\u2010 dings (840B Token) [14] with a dimension of 300, while category embeddings are ran\u2010 domly initialized and have a dimension of 100. In the sentiment knowledge sharing layer, the multi\u2010head attention mechanism is im\u2010 plemented using 4 heads. The two feed\u2010forward networks in each expert unit have one layer with 400 units and two layers with 150 units, respectively. However, contrary to what we see in the implementation, it is worth noting that the original paper reports 200 units for the second network. After each layer a dropout rate of 0.1 is used. Themodel is trained bymini\u2010batches of 512 instances for 15 epochs, using the RMSprop optimizer and a learning rate of 0.001. The original study reports the use of learning rate decay and early stopping to avoid overfitting.\nHyperparameters tuning \u2014 The original work does not provide any details regarding hyper\u2010 parameters tuning and upon contacting the authors to inquire about it we received no answer. We tune learning rate (10\u22126 to 10\u22121, on a log scale), batch size (from 32 to 1024, on a log2 scale) and dropout rate (0.0 to 0.4 with increments of 0.1) on the SE data\u2010set using grid\u2010search with 60 epochs and find that the respective optimal values are 0.001, 256 and 0.0. Despite discrepancies with the original values the model\u2019s performance remains sim\u2010 ilar. In this respect, considering the model variation (see Table 1 and Figure 1), any differences are likely due to random initialization.\n1http://hatespeech.di.unito.it/hateval.html 2https://github.com/t-davidson/hate-speech-and-offensive-language/tree/master/data 3https://www.kaggle.com/dv1453/twitter-sentiment-analysis-analytics-vidya\nReScience C 8.2 (#7) \u2013 Brivio and \u00c7\u00f6ltekin 2022 5\n4.4 Experimental setup and code We try to reproduce the results presented in Table 3 of the original paper [1]. For both data\u2010sets the authors train three models: SKS, which relies both on sentiment knowl\u2010 edge sharing and category embeddings; -s, a model where the sentiment knowledge sharing component is ablated; -sc, a model that does without both sentiment knowl\u2010 edge sharing and category embeddings. We rely largely on the TensorFlow [15] imple\u2010 mentationmade available by the authors, modifying it where necessary and integrating it with a few additional scripts for statistics computation and data preparation. For each result reported in the original paper we repeat the corresponding experiment 10 times. Specifically, for each repetition the model is reinitialized and trained over 15 epochs. Wekeep the results from thebest epochof each repetition and then compute the average and the standard deviation for the originally employed measures i.e., accuracy and macro\u2010F1 score for the SE data\u2010set and accuracy and weighted\u2010F1 score for the DV data\u2010set. Given that the DV data\u2010set is highly unbalanced, the original study use a 5\u2010fold cross\u2010 validation approach tomeasure the performance of eachmodel. We follow in their foot\u2010 steps and adopt the 10 times repetition strategy for each 5\u2010fold experiment. Our code, data as well as the final and intermediate per\u2010iteration results are available at https://github.com/matteobrv/repro-SKS.\n4.5 Computational requirements We run all our experiments on an NVIDIA TITAN Xp with a 12 GB memory. Training the models on the SE data\u2010set took approximately 24 minutes for the SKS model and 7 minutes both for the -sc and -s model. On the DV data\u2010set the training took approx\u2010 imately 3 hours for the SKS model and 2 hours both for the -sc and -s model. The hyperparameters tuning step on the SE data\u2010set took approximately 33 hours.\n5 Results\nIn Table 1 we summarise the original results along the ones we obtained using the speci\u2010 fied hyperparameters. Comparing our findingswith those reported by the original study we observe a discrepancy in all three measures, accuracy, macro\u2010F1 and weighted\u2010F1 score, for both data\u2010sets. In the SE data\u2010set, the most notable differences concern the results of the SKS and -s models. In the DV data\u2010set, there are some noteworthy dis\u2010 crepancies only with respect to the SKSmodel. Looking at themean scores we obtain on the SE data\u2010set, the SKSmodel does not outper\u2010 form both ablated versions -s and -sc, thus contradicting the first and second claim in Section 3. In fact, while SKS obtains an accuracy of 61.04 and a macro\u2010F1 score of 60.88, the -smodel outperforms it, reaching an accuracy and a macro\u2010F1 score of 64.17 and 63.05, respectively. On the other hand, the third claim appears to hold. With an accuracy of 60.52 and amacro\u2010F1 score of 60.47 the -scmodel is the one registering the worst performance. Turning to the DV data\u2010set, none of the claims appear to be substantiated by our find\u2010 ings. The SKS model scores the lowest with an accuracy of 93.63 and a weighted\u2010F1 score of 93.62, while the ablated versions -s and -sc register similar values for both metrics, with an accuracy of 93.99 and 93.98 and a weighted\u2010F1 score of 94.11 and 94.12, respectively. For a visual inspection of the results presented in Table 1 we also plot box plots of the scores obtained in multiple reproduction attempts in Figure 1. Despite some overlap in the range of the obtained scores, themedian scores of the SKSmodel is lower than those of the ablated versions. The figure also shows that the scores reported in the original paper fall within the range \u00b11.5 standard deviation from the mean of the scores of the\nReScience C 8.2 (#7) \u2013 Brivio and \u00c7\u00f6ltekin 2022 6\n(a) F1\u2010weighted on DV data\u2010set\n(b) F1\u2010macro on SE data\u2010set\nmultiple reproduction experiments. However, for both data\u2010sets, the original scores of SKS is substantially above this range.\n5.1 Alternative metrics The original paper reports macro\u2010 or weighted\u2010averaged F1 scores, with the motivation of comparability to earlier research on these data\u2010sets. However, the task at hand is a binary classification task with a clear positive class. Incorporating the negative class score through averaging does not allow assessing the success of the classifier on the task. Furthermore, relying on weighted averaging without having a justified set of weights, but using weights proportional to the support of each class, rewards classifiers with majority bias even further. To present a more interpretable impression of the success of each model and provide further insight into the differences based on model ablation and alternations, Figure 2 depicts the distribution of precision, recall and F1\u2010scores for the different reproduction experiments carried out on the two data\u2010sets. Although there is a large overlap in the range of the scores, the plots indicate that jointly learning sentiment analysis (SKS) improves the precision of the hate speech detection on theDVdata\u2010set. Despite having a negative impact on the recall, it also yields a slightly better median F1 score. However, the effect of the sentiment task appears to be mostly negative on the SE data\u2010set.\nReScience C 8.2 (#7) \u2013 Brivio and \u00c7\u00f6ltekin 2022 7\n(a) Metrics distribution on DV data\u2010set\n(b) Metrics distribution on SE data\u2010set\n6 Discussion\nThe reproducibility results from Section 5 do not fully support the claims outlined in Section 3 for either data\u2010sets. In particular, our findings seem to suggest that the multi\u2010 task learning approach implemented by the authors to allow the SKS model to extract sentiment features and apply them to hate speech detection does not yield the expected results. However, considering the lack of a comprehensive documentation, the convo\u2010 luted structure of the code\u2010base and the insufficient communication with the original authors it is hard to draw definitive conclusions. In fact, there are a number of plausible explanations as to why our findings diverge from those reported in the original paper. For instance, considering the slight difference between the optimal hyperparameters we found and those reported by Zhou et al., as well as the large variation in the model\u2019s scores, one could speculate that, at least for part of the experiments, the study employed some parameters which have not been reported. This would also explain the difference between some of the values indicated in the paper and those used in the provided im\u2010 plementation. Another explanation could lie in the fact thatwe inadvertently deviated from the original implementationwhile trying to fix some of the issues we faced in running the code\u2010base. Whenever informationwasmissing or not completely clear assumptions had to bemade, and we tried to approximate the original results by trial and error. This was the case for the -scmodel where the procedure to ablate the category embeddings component was not given and the answer we received from the authors did not help us to overcome the problem. Yet another explanation revolves around the data. The main intuition behind the origi\u2010 nal study is the fact that hate speech typically carries a negative sentiment. Hence, the relation between these two tasks would help the model to better identify hate speech (arguably by increasing recall). However, a manual inspection of the data\u2010sets suggests that their contentmay actually be surprising for a classifier informed by sentiment anal\u2010 ysis. Both data\u2010sets are collected using keywords that are likely to contain hate speech, and the negative class (i.e., non\u2010hate speech one) contains posts that are either offen\u2010 sive (but not hate speech), or content generated by people counteracting earlier offen\u2010 sive content. That being the case, the sentiment of this class is not necessarily positive and helpful for discriminating hate speech in these data-sets. However, in a more realis\u2010\nReScience C 8.2 (#7) \u2013 Brivio and \u00c7\u00f6ltekin 2022 8\ntic environment, the original proposal may be promising. Givenmore \u2018normal\u2019 negative class instances, learning sentiment analysis jointly is likely to inform the hate speech de\u2010 tection task. The binary evaluation metrics presented in Figure 2 indicate that at least on the DV data\u2010set, the addition of sentiment may have some positive effects. Under\u2010 standing the reasons for these differences, and improving the joint learning model is a possible direction for future research.\n6.1 What was easy The paper provides some broad indications with respect to the training details and both the data\u2010sets and the code\u2010base are open\u2010sourced.\n6.2 What was difficult The lack of a comprehensive documentation, the convoluted structure of the code\u2010base and the insufficient communicationwith the original authors contributed to an arduous code review and reproducibility effort.\n6.3 Communication with original authors We first tried to review and run the provided code\u2010base by ourselves. However, after encountering some issues related to how the data\u2010sets were being processed and how to run the -sc model ablating category embeddings, we decided to reach out to the authors through GitHub. One of the corresponding authors provided some indications which, unfortunately, did not help us overcome the problems at hand. We also tried to contact the authors per email twice, inquiring about some aspects of the model implementation as well as the procedure they followed to tune the hyperpa\u2010 rameters. However, we never received an answer."}], "title": "[\u00acRe] Hate Speech Detection based on Sentiment Knowledge Sharing", "year": 2022}
{"abstractText": "This report covers our reproduction of the paper \u02bcExplaining Low dimensional Representation\u02bc [1] by Plumb et al. In this paper, a method (Transitive Global Translations, TGT) is proposed for explaining different clusters in low dimensional representations of high dimensional data. They show their method outperforms the Difference Between the Means (DBM) method, is consistent in explaining differences with few features and matches real patterns in data. We verify these claims by reproducing their experiments and testing their method on new data. We also investigate the use of more complex transformations to explain differences between clusters.", "authors": [{"affiliations": [], "name": "Rajeev Verma"}, {"affiliations": [], "name": "Jim J. O. Wagemans"}, {"affiliations": [], "name": "Paras Dahal"}, {"affiliations": [], "name": "Auke Elfrink"}], "id": "SP:3676a8ae77b7bdeda2c5e7a14d45a62918b2abb9", "references": [{"authors": ["G. Plumb", "J. Terhorst", "S. Sankararaman"], "title": "and A", "venue": "Talwalkar. Explaining Groups of Points in Low-Dimensional Representations.", "year": 2020}, {"authors": ["A. Paszke", "S. Gross", "F. Massa", "A. Lerer", "J. Bradbury", "G. Chanan", "T. Killeen", "Z. Lin", "N. Gimelshein", "L. Antiga"], "title": "Pytorch: An imperative style, high-performance deep learning library.", "year": 2019}, {"authors": ["C.M. Bishop"], "title": "Pattern Recognition and Machine Learning", "venue": "Springer,", "year": 2006}, {"authors": ["H. Xie", "J. Li"], "title": "and H", "venue": "Xue. A survey of dimensionality reduction techniques based on random projection.", "year": 2018}, {"authors": ["Y. Belinkov", "S. Gehrmann"], "title": "and E", "venue": "Pavlick. \u201cInterpretability and Analysis in Neural NLP.\u201d In: Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts. Online: Association for Computational Linguistics, July", "year": 2020}, {"authors": ["S. Verma", "J. Dickerson"], "title": "and K", "venue": "Hines. Counterfactual Explanations for Machine Learning: A Review.", "year": 2020}, {"authors": ["D.V. Carvalho", "E.M. Pereira", "J.S. Cardoso"], "title": "Machine learning interpretability: A survey on methods and metrics.", "year": 2019}, {"authors": ["L. Van der Maaten", "G. Hinton"], "title": "Visualizing data using t-SNE.", "venue": "Journal of machine learning research", "year": 2008}, {"authors": ["J. Ding", "A. Condon", "andS.P. Shah"], "title": "Interpretable dimensionality reduction of single cell transcriptomedatawith deep generative models.", "venue": "bioRxiv", "year": 2017}, {"authors": ["K. Shekhar"], "title": "Comprehensive Classification of Retinal Bipolar Neurons by Single-Cell Transcriptomics.", "venue": "Cell", "year": 2016}, {"authors": ["M. Abadi", "A. Agarwal", "P. Barham", "E. Brevdo", "Z. Chen", "C. Citro", "G.S. Corrado", "A. Davis", "J. Dean", "M. Devin"], "title": "Tensorflow: Large-scale machine learning on heterogeneous distributed systems.", "year": 2016}, {"authors": ["D.P. Kingm"], "title": "and M", "venue": "Welling. Auto-Encoding Variational Bayes.", "year": 2014}], "sections": [{"text": "R E S C I E N C E C"}, {"heading": "Replication / ML Reproducibility Challenge 2020", "text": "[Re] Explaining Groups of Points in Low-Dimensional"}, {"heading": "Representations", "text": "Rajeev Verma1, ID , Jim J. O. Wagemans1, Paras Dahal1, ID , and Auke Elfrink1 1University of Amsterdam, The Netherlands\nEdited by Koustuv Sinha\nReviewed by Anonymous Reviewers\nReceived 29 January 2021\nPublished 27 May 2021\nDOI 10.5281/zenodo.4835602"}, {"heading": "Reproducibility Summary", "text": ""}, {"heading": "Scope of Reproducibility", "text": "This report covers our reproduction of the paper \u02bcExplaining Low dimensional Representation\u02bc [1] by Plumb et al. In this paper, a method (Transitive Global Translations, TGT) is proposed for explaining different clusters in low dimensional representations of high dimensional data. They show their method outperforms the Difference Between the Means (DBM) method, is consistent in explaining differences with few features and matches real patterns in data. We verify these claims by reproducing their experiments and testing their method on new data. We also investigate the use of more complex transformations to explain differences between clusters."}, {"heading": "Methodology", "text": "We reproduce the original experiments using their source code. We also replicate their findings by re-implementing the authors\u02bc method in PyTorch [2] and evaluating on two of the dataset used in the paper and two new ones. Furthermore, we compare TGT with our own extension of TGT, which uses a larger class of transformations."}, {"heading": "Results", "text": "Wewere able to reproduce their results using their code, yielding mostly similar results. TGT generally outperforms DBM, especially when explanations use few features. TGT is consistent in terms of the features to which it attributes cluster differences, across different sparsity levels. TGTmatches real patterns in data. When extending the types of functions used for explanations, performance did not improve significantly, suggesting translations make for adequate explanations. However, the scaling extension shows promising performance on the modified synthetic data to recover the original signal."}, {"heading": "What was easy", "text": "The easiest part was running the existing code with the pre-trained model files. The original authors had set up their code base in an organized manner with clear instructions.\nCopyright \u00a9 2021 R. Verma et al., released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Rajeev Verma (rajeev.verma@student.uva.nl) The authors have declared that no competing interests exist. Code is available at https://github.com/elfrink1/FACT. \u2013 SWH swh:1:dir:445130f59283e6dce7df5eb72dd346a5c57c9230. Open peer review is available at https://openreview.net/forum?id=cqAHExg2f.\nReScience C 7.2 (#24) \u2013 Verma et al. 2021 1"}, {"heading": "What was difficult", "text": "The first difficulty that we encounter was finding the right environment. The source code depends on deprecated functionality. The clustering method they used, had to be re-implemented for us to use it in our replication. Another difficulty was the selection of clusters. The authors did not prove a consistent method for selecting clusters in a latent space representation. When retraining the providedmodels, we get a latent space representation different to the original experiments. The clusters have to be manually selected. The metrics that they used to evaluate their explanations are also depend on the clustering. This means that there is some variability in the exact verification of reproducibility.\nCommunication with original authors We asked the original authors for clarification on how to choose the \u03f5 hyper-parameter. However, it became apparent that we had misread, and the procedure is indeed adequately reported in the paper.\nReScience C 7.2 (#24) \u2013 Verma et al. 2021 2\n1 Introduction\nThe curse of dimensionality [3] is a long-standing problem in Machine Learning. Data in many domains and applications (e.g. Bioinformatics) has high-dimensional representations. Finding patterns in such high-dimensional data is a challenging task. To this end, dimensionality reduction [4] techniques have greatly helped in data-analysis, information extraction, building computational models, and in doing inference. Given an input x \u2208 Rd, dimensionality reduction learns a function r : x 7\u2192 r(x), r(x) \u2208 Rm, where m << d. Such a dimensionality reduction function r naturally arises in deep learning due to the expressivity and representational power of neural networks. The goal of r is to encode useful knowledge about the input space, thus providing distinctive information in the transformed output r(x). This results in \u201cclusters\u201d or \u201cgroups of points\u201d in the transformation space. The downside of this exercise, however, is that the output space is usually non-interpretable. There is usually no easy way to know what information is present in the transformed points r(x) and what sort of distinctive knowledge they contain. In this work, we reproduce the paper \u02bbExplaining Groups of Points in Low-Dimensional Representations\u02bc by Plumb et al. [1]. This paper proposes amethod for explaining different clusters in latent space representation. They look at the problem of explaining the points in the latent space representation through the lens of Interpretability inMachine Learning. We reproduce their findings and expand upon their work with our an extension. We extend their research by applying their method to a larger class of explanation functions and testing their method on new dataset. We further investigate the efficacy of the explanations using a probing classifier [5].\n2 Methodology\nCounterfactual Explanations [6] have emerged as an active research area in the field of Interpretable Machine Learning. A counterfactual explanation is defined as the smallest perturbation to the input that would change the output of amachine learningmodel. As such, these explanations are promising as they can provide suggestive recourse to the beneficiary in a machine learning based decision system. As an interpretable machine learning problem, Plumb et al. [1] aim to find such counterfactual explanations in order to explain the differences between the groups in latent space. To this end, they employ the function r itself to find what perturbation \u03b4 needs to be made to the input x \u2208 Rd so that r(x + \u03b4) belongs to the different target group. The goal is to find the global explanations that apply to the whole group as opposed to the local explanations which explain only individual examples [7]. Furthermore, the explanations need to be sparse for them to be interpretable by practitioners. Finally, these explanations should be be both symmetric and transitive. To obtain these Global Counterfactual Explanations(GCE), the authors propose the algorithm called, Transitive Global Translations (TGT), explained hereafter. Following the previous notation, let r : Rd \u2192 Rm denote our dimensionality reduction function, where d is the dimensionality of the input space and m is the latent space s\u0313 dimensionality. Suppose Xi, Xj \u2282 Rd get mapped to the clusters Ri, Rj \u2282 Rm respectively. The goal is to define the transformation ti\u2192j : Rd \u2192 Rd on x \u2208 Xi as x \u2032 = ti\u2192j(x), so that r(x \u2032 ) \u2208 Rj , or equivalently x\n\u2032 \u2208 Xj . The proposed algorithm TGT considers the transformations of the form ti\u2192j(x) = x + \u03b4i\u2192j . To find the optimal parameters of the transformation function, authors imply a compressed-sensing based objective function as below:\nl(\u03b4i\u2192j) = \u2016r(ti\u2192j(X\u0304i))\u2212 R\u0304j\u201622 + \u03bb\u2016\u03b4i\u2192j\u20161 (1)\nwhere \u03bb\u2016\u03b4i\u2192j\u20161 is a regularization term to incentivize sparser explanations, and X\u0304i \u2208\nReScience C 7.2 (#24) \u2013 Verma et al. 2021 3\nRd and R\u0304j \u2208 Rm denote the means of the clusters in the input space and latent space respectively. Given clusters 0, 1, . . . , n, we get a total of 12n(n + 1) transformations. To further increase sparsity, we can truncate \u03b4i\u2192j to only the k features with the largest absolute value, for some k. An issue with this is that the translation using the truncated \u03b4i\u2192j might no longer correctly transform inputs that get mapped to Ri into inputs that get mapped to Rj . Furthermore, the transformations ti\u2192j have to adhere to several mathematical properties. Namely, for any clusters i, j, k these transformations should be : a) Symmetric, i.e. ti\u2192j = tj\u2192i\n\u22121 and b) Transitive, i.e. tj\u2192k \u25e6 ti\u2192j = ti\u2192k. From these properties it follows that ti\u2192i is the identity function I as\nti\u2192i = ti\u21920 \u25e6 t0\u2192i = ti\u21920 \u25e6 ti\u21920\u22121 = I (2)\nWe define this condition as self-similarity. Furthermore, the group of translations is uniquely defined by t0\u21921, . . . , t0\u2192n, because for any i, j:\nti\u2192j = t0\u2192j \u25e6 ti\u21920 = t0\u2192j \u25e6 t0\u2192i\u22121 (3)\nPlumb et al. [1] compare their method against the naive baseline of Difference Between the Means (DBM). With DBM, each transformation is still a translation: ti\u2192j(x) = x + \u03b4i\u2192j . However, now \u03b4i\u2192j = (X\u0304j \u2212 X\u0304i). We also use this as a baseline for comparison in this report. Since translations are a very narrow class of functions, we expanded upon the research by investigating other transformations that still satisfy the GCE requirements. We investigate the transformations of the form t0\u2192i(x) = exp(\u03b30\u2192i) x + \u03b40\u2192i. These always have a well defined inverse, given by t0\u2192i\u22121(x) = exp(\u2212\u03b30\u2192i) (x \u2212 \u03b40\u2192i) and only have O(d) parameters. The inclusion of scaling could enhance performance, while the necessary components of GCE are maintained.\n2.1 Metrics to evaluate Global Counterfactual Explanations To measure the efficacy of the transformation function ti\u2192j , the authors propose two metrics, Coverage and Correctness.\n1. The Coverage (cv(ti\u2192j)) is the fraction of points a \u2208 Rj for which there is a point b \u2208 Xi such that \u2016r(ti\u2192j(b))\u2212 a\u20162 < \u03f5, i.e.\ncv(ti\u2192j) = 1 |Rj | \u2211 a\u2208Rj I [\u2203b \u2208 Xi|\u2016r(ti\u2192j(b)\u2212 a\u20162 < \u03f5] (4)\n2. The Correctness (cr(ti\u2192j)) is the fraction of points b \u2208 Xi for which there is some a \u2208 Rj such that \u2016r(ti\u2192j(b))\u2212 a\u20162 < \u03f5, i.e.\ncr(ti\u2192j) = 1 |Xi| \u2211 a\u2208Rj I [\u2203a \u2208 Rj |\u2016r(ti\u2192j(b)\u2212 a\u20162 < \u03f5] (5)\nNote that both these metrics have the hyperparameter \u03f5 which is to be chosen carefully. When i = j we do not count the point itself, there must be some other point within distance \u03f5. 1 Furthermore, the Similaritymetric measures the consistency of the explanations at different sparsity levels. Given two explanations e1, e2 where e1 is more sparse than e2, the similarity of e1 and e2 is defined as\nsim(e1, e2) =\n\u2211 i|e1[i]|1(e2[i] 6= 0)\n\u2016e1\u20161 (6)\nThis is equal to 1 if e1 uses a subset of the features that e2 uses. By definition, DBM always has similarity 1.\n1We use this definition to set the value for epsilon, as explained in the Methodology section of the original Paper.\nReScience C 7.2 (#24) \u2013 Verma et al. 2021 4\n3 Scope of Reproducibility\nWe investigate the following claims from the original paper:\n1. In terms of the average correctness and coverage, TGT performs equally well or better than the DBM method. This remains true, especially for sparser explanations.\n2. TGT explanations have similarity close to 1. It is consistent in which features it uses for explanations across different sparsities.\n3. TGT correctly identifies known causal structure in data.\n4. Furthermore, TGTexplanations are consistent. Whenaltering the dataset by adding a copy of a cluster with a specific feature altered, TGT recovers the modification with little change to the other explanations.\n4 Methodology of Reproducibility\nWe make use of the code made available by the original authors 2 for our pilot investigative study. We first verify that the provided models and explanations stay true to the claims made in the paper. We further retrain their models on the provided dataset. We also made our own PyTorch [2] implementation to to further verify the claims, and to perform experiments with the proposed extension.\n4.1 Model description Weassert that the scope of the original paper is to explain clusters in the low-dimensional representations. However, obtaining meaningful and discernible low-dimensional representations is an active area of research. The original authors employ a t-SNE [8] objective based Variational Autoencoder (called, henceforth, as scVIS) [9] as the r function. They make use of library3 by the original scVIS authors in their implementation. We also implement this model in Pytorch for our experiments. However, we deliberately decide not to match the model implementation exactly. This is done to study the modelagnosticism of the TGT algorithm. By design, TGT should be able to explain the clusters for any differentiable r function. However, we maintain that r should give discernible latent representations with preserved global structure in the data. In our implementation of the scVIS library, we therefore do not employ the hyperparameters and the training settings from the original library.\n4.2 Dataset Description We reproduce the findings of the authors on four datasets that they used. We use two of these datasets as well as two new ones to test our PyTorch implementation.\n1. Single cell RNA [10]: This dataset has 13166 features. We use the same number of clusters at the original authors, 18 in this case.\n2. UCI Boston housing This dataset has 506 entries with 13 features. We use 6 clusters for both reproduction and replication.\n3. UCI Heart disease This dataset has 303 entries with 13 features and 1 binary label. We used 8 clusters in the reproduction and 4 in the replication. The data was normalized to be in the range [0, 1].\n2https://github.com/GDPlumb/ELDR 3https://github.com/shahcompbio/scvis\nReScience C 7.2 (#24) \u2013 Verma et al. 2021 5\n4. UCI Iris This dataset has 150 entries with 4 features and 1 ternary label. Ran in the reproduction with 3 clusters. N = 150\n5. Breast Cancer Wisconsin (Diagnostic) 4 This dataset has 569 entries with 30 features and 1 binary label. We use 3 clusters in the replication.\n6. Pima Indians Diabetes Database 5 This dataset has 768 entries with 8 features and 1 binary label. We used 3 clusters in the replication. The data was normalized to be in the range [0, 1]. Note that the number of clusters depend on the latent-space representation, and thus, are user dependent.\n4.3 Hyperparameters Tensorflow [11] Experiments For the reproduction of the original experiments, we use the same hyperparameters as the original authors.\nPytorch For our implementation of the scVIS model, we use l2 regularization of 0.001, learning rate 0.01, and perplexity of 10. Furthermore, the degree-of-freedom for the studentT distribution is set to 2.0. Perplexity and the degree-of-freedom is used same as the original scVIS implementation. We use validation set to monitor the training process of the scVIS model, and stop training when the ELBO(Evidence Lower BOund)[12] stops improving. For training the TGT explanations, we closely follow the settings from Plumb et al. [1]. We initialize the deltas\u03b4s as zero vectors. We tune the regularization parameter \u03bb by grid search over a fixed range [0.0, 5.0] incremented by 0.5. Defining the metrics for TGT requires careful setting of the \u03f5 hyper-parameter. We follow the self-similarity condition (transformations of clusters to themselves should, theoretically, have correctness and coverage to be 1.0), and increase the \u03f5 in the range [0.0, 2.0] with increments of 0.02 until the correctness and coveragemetrics are greater than 0.95. Furthermore, we use the truncation values(TV)(refer Table 1) to evaluate on the sparsity of the explanations. For the Pima Indians Diabetes Database and Breast Cancer Wisconsin(Diagnostic) dataset, we use the same truncation values as for UCI Boston Housing dataset.\nDataset Truncation Values(TV) \u03f5 Single Cell RNA 50, 100, 250, 500, 1000, 15000 0.75 Heart Disease 1, 3, 5, 7, 9, 11, 13 1.0\nHousing 1, 3, 5, 7, 9, 11, 13 1.5 Iris 1, 2, 3, 4 0.75\nexplanations on CPU (Intel i5).\n5 Results\nFor the reproduction of the authors\u02bc experiments, we achieve approximately similar results to the original paper. The TGT method does seem to outperform DBM method. The TGT explanations also have high similarity across sparsity levels. However, the TGT algorithm is unable to identify known causal structure in synthetic data with as good precision as reported in the original paper. We are also unable to match the results on the modified and corrupted data to a good precision. We describe the results in the following sections:\n5.1 Results reproducing original paper\nCoverage, Correctness and similarity \u2014 In figure 1, we can see a comparison between the correctness, coverage and similarity of the TGT and DBM methods. Note that the DBM always has similarity 1. The similarity of TGT stays between 1 and 0.9, which supports claim 2. We see that the coverage and correctness are similar for the UCI Heart disease dataset. On the UCI Iris dataset, the coverage is comparable but the correctness is better for TGT. In both housing and RNA, the coverage and correctness are better at less features and similar for more features. Overall, these results support claim 1, especially for a small amount of features.\n5.2 Explaining Causal Structure in the Synthetic Data Weverify the claim that TGT identifies the causal structure in the data (claim 3). The synthetic dataset is generated same as the original paper, i.e. x1, x2 \u223c N (0, 0.2)+ Bern(0.5), x2 \u223c N (0, 0.05), x4 \u223c x1 +N (0, 0.05). Note that this dataset has four different clusters, caused by the first two dimensions x1 and x2, x3 is noise, and x4 is correlatedwith x1 and x2. The authors claim that for this synthetic data, TGT is able to find that x4 is not the cause for any group. However, the said claim cannot be re-verified. Interestingly, the re-run of their code doesn\u02bct provide the justification either to the degree as mentioned\nReScience C 7.2 (#24) \u2013 Verma et al. 2021 7\nin the paper. We observe that both TGT and DBM are able to identify x3 is not causing any groups. Thus, in this scenario, both TGT and DBM are comparable. Refer table 2 for the explanations obtained. We, hereby note, that the explanations vary across multiple runs and we use the experimental setup same as the original authors. However, the values across the third dimension are consistently approximately 0.\nFeature modifications \u2014 For each of the UCI datasets, the original authors add a \u02bbcorrupted\u02bc version where an extra cluster is added with artificial feature modification. With the exception of the modified features, the corrupted class is a copy of a chosen target class. They train TGT explanations using both the original scVIS model for the respective dataset and a model retrained on the corrupted dataset. We reproduce these experiments to see if TGT correctly attributes the difference between the target and corrupted class to the right features. Refer to Appendix 7.1 for the illustrated figures and description. Overall, we observe that TGT is unable to identify the modifications to as good a precision as reported in the original paper. TGT is able to identify the modification for the UCI Iris dataset. For UCI Heart Disease Dataset (figure 7), it does not identify the features modified and on the UCI Boston Housing Dataset (figure 6), it identifies noisy modifications. However, with the retrained scVIS model and new representations, TGT is consistent in identifying the modifications across all the datasets.\n5.3 Results beyond original paper\nPyTorch replication \u2014We also replicate the TGT algorithm in PyTorch. Our Pytorch implementation includes the entire method along with the scVIS clustering method. In our implementation, we use the Scikit learn 8 kmeans module for our cluster selection as opposed to the manual clustering in the Tensorflow implementation. However, our number of clusters argument to the kmeans algorithm was informed by the learned low-dimensional representations for each dataset. Due to differences in the clustering model and cluster selection, we cannot directly compare the coverage and correctness metrics between our Pytorch replication and the TensorFlow reproduction. We additionally experiment with our scaling extension to the TGT algorithm. In the scaling extension of the TGT algorithm, along with the \u03b4 (\u03b4) parameters, each cluster now has a \u03b3 (\u03b3) parameters. The transformation from cluster 0 to i is now given by: t0\u2192i = e\u03b3i x+\u03b4i The gammas(\u03b3s) are truncated just like the deltas and their L1 norm is added to the regularization term. Note that these transformations are strictly more expressive. If \u03b3 is the zero vector, these transformations reduce to regular TGT.\nUCI Heart Disease and UCI Boston Housing Dataset \u2014 In figure 2 we see the results of our replication on the UCI Boston Housing and UCI Heart Disease dataset. For the UCI Boston Housing data, the TGT method seems to slightly outperform DBM both with and without scaling. This supports claim 1. The deltas(\u03b4s) and gammas(\u03b3s) show high similarity, supporting claim 2. For the UCI Heart Disease dataset, we do not see a difference in performance without scaling while TGT with scaling performs slightly worse.\n8https://scikit-learn.org/stable/index.html\nReScience C 7.2 (#24) \u2013 Verma et al. 2021 8\nBreast Cancer Wisconsin (Diagnostic) and Pima Indians Diabetes Database \u2014 In figure 3 we see the results for the Pima Indians Diabetes and Breast Cancer Wisconsin (Diagnostic) dataset. For the diabetes dataset, TGTwith and without scaling outperforms DBMwhen more than one feature is used. This supports claim 1. Since the delta (\u03b4) similarity is close to 1, claim 2 is also supported. For the Breast Cancer dataset, we see similar performance for DBM and TGT and slightly worse performance with scaling. The deltas (\u03b4s) still have high similarity, supporting claim 2.\nScaling extension \u2014 In figure 2, we can see the difference in performance on two dataset included in the original experiments. Scaling does not seem to improve performance on the UCI Boston Housing dataset and slightly decreases performance on the UCI Heart Disease dataset. The similarity of the gammas (\u03b3s) is mostly above 0.9. In figure 3, we see the same metrics for the Breast Cancer and Pima Indians Diabetes Dataset. For theDiabetes dataset, the performance improves slightly and the gammas(\u03b3s) show high similarity. For the Breast Cancer dataset, the performance is about the same but the gammas(\u03b3s) show relatively low similarity. Altogether, these results suggest that the addition of scaling does not significantly improve the accuracy and correctness while making the transformations more complex. Based on our experiments, we do not recommend the addition of scaling in the explanation functions, and conclude that the original TGT is expressive enough.\nExperiment with Modified Synthetic Data \u2014 In order to study the efficacy of the proposed scaling function, we perform experiments on the synthetic dataset. We modify one of the groups of points G by performing the operation axki + b, where i corresponds to the group number and k denotes the feature dimension which we modify. We define a \u223c U(1.0, 2.0) and b \u223c U(\u22120.5, 1.0). We add modified groupG\u2032 into the original dataD to get the new data D \u2032 . We follow the experiment setup from the original paper as: a) r(G \u2032 ) should form a different group of its own. b)G \u2032 should bewithin the distribution of the originalD. In this study, we want to investigate whether the TGTwith scaling is able to recover themodifications, and if in doing so it affects the explanations between other groups. The sampling procedure gave a=2.0, b=0.60 and we keep k=0. We observe that the explanations with scaling are able to recover the modification to an approximate degree(scaling factor e\u03b3 \u2248 2.38, actual a=2.0), and give better correctness as compared to the regular TGT (refer figure 3). Interestingly, the translations explanations of the scaling extension are approximately equal to the deltas of the regular TGT. The exact results can be found in Table 3. Figures 8 and 9 in the appendix show the data spread and resulting translations.\nExperiments with Probing Classifier \u2014 To further investigate the efficacy of TGT explanations, we use a probing-classifier [5] as a proxy to study the qualitative differences of the features selected by TGT and DBM. For each cluster, we train a binary classifier with features ranked highest by TGT and DBM at different sparsity levels K. We compute the overall accuracy at each sparsity level using the ensemble of these binary classifiers.\nReScience C 7.2 (#24) \u2013 Verma et al. 2021 9\nAs can be seen in Figure 4, the results demonstrate that for sparser explanations, TGT selects features that lead to higher accuracy of the ensemble classifier than those selected by DBM. This further validates the paper s\u0313 claim that TGT leads to better sparse explanations as compared toDBM. Furthermore, we also use the probing classifier to understand the differences between the groups. For each pair of group, we train a Binary Linear Classifier to predict the group of a test point. We, then, investigate the feature importances of the classifier towards decision making. We ascertain that the features classifier give more importance to while decision making are the defining property of the class. Interestingly, we find that the more important features according to the classifier correspond to the explanations provided by the TGT algorithm. Refer to figure 11. This provides further evidence that TGT is able to find real distinctive signals as explanations.\n6 Discussion\nBased on the reproduction of the original experiments, claims 1 and 2 seem to hold, the experiments for claim 4 do not all support it, but the claim does seem to hold. Claim 1 and 2 seem to hold in particular for sparse explanations. The evidence for claim 3 is inconclusive. The coverage and correctness in our reproductionwere not always the same as in the original paper. It is difficult to compare these metrics for different clustering outcomes, as they depend on the \u03f5 parameter which depends on the clustering. A major difficulty in reproduction is the cluster selection. When retraining the scVIS model, the latent space representation structure changes. The authors provide determine the different clusters by visual inspection. Cluster selection could be an explanation for the differences in results between the original experiments and our reproduction. To verify the results with more confidence, a robust method for cluster selection might be required."}], "title": "[Re] Explaining Groups of Points in Low-Dimensional Representations", "year": 2021}
{"abstractText": "This paper aims to computationally reproduce my own statistical analysis from 16 years ago as part of the 10\u2010year reproducibility challenge1. The analysis examined seasonal patterns in coronary heart disease in multiple countries2. In most countries coronary heart disease deaths and emergency admissions to hospital have a strong seasonal pat\u2010 tern with a peak in winter and nadir in summer3. There is an interesting variability between\u2010countries in the size and timing of the winter peak. A better understanding of the differences between countries could help our understanding of the underlying causes of the winter peak in disease.", "authors": [{"affiliations": [], "name": "Adrian Barnett"}, {"affiliations": [], "name": "Konrad Hinsen"}, {"affiliations": [], "name": "Serge Stinckwich"}], "id": "SP:4f6fbe409cf91a0e082263b958b27f5284ac3feb", "references": [{"authors": ["K. Hinsen", "N. Rougier"], "title": "Challenge to test reproducibility of old computer code.", "venue": "Nature", "year": 2019}, {"authors": ["A.G. Barnett", "A.J. Dobson"], "title": "and For the WHO MONICA (monitoring trends and determinants in cardiovascular disease) Project", "venue": "\u201cEstimating trends and seasonality in coronary heart disease.\u201d In: Statistics in Medicine 23.22 (2004), pp. 3505\u20133523. DOI: 10.1002/sim.1927. URL: https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.", "year": 1927}, {"authors": ["S. Stewart", "A.K. Keates", "A. Redfern", "J.J.V. McMurray"], "title": "Seasonal variations in cardiovascular disease.", "venue": "Nature Reviews Cardiology", "year": 2017}, {"authors": ["M. Plummer", "N. Best", "K. Cowles", "K. Vines"], "title": "CODA: Convergence Diagnosis and Output Analysis for MCMC.", "venue": "In: R News", "year": 2006}, {"authors": ["A.G. Barnett"], "title": "On the use of the bispectrum to detect and model non-linearity.", "venue": "Bulletin of the Australian Mathematical Society", "year": 2003}, {"authors": ["H. Tunstall-Pedoe", "W.H.O.M. Project", "W.M. Project", "W.H. Organization"], "title": "MONICA, Monograph and Multimedia Sourcebook: World\u2019s Largest Study of Heart Disease, Stroke, Risk Factors, and Population Trends 1979-2002", "venue": "MONICA, Monograph and Multimedia Sourcebook: World\u2019s Largest Study of Heart Disease, Stroke, Risk Factors, and Population Trends 1979-2002 p. 1. World Health Organization,", "year": 2003}], "sections": [{"text": "R E S C I E N C E C Reproduction / Biology\n[Rp] Estimating trends and seasonality in coronary heart disease Adrian Barnett1, ID 1School of Public Health and Social Work, Queensland University of Technology, Brisbane, Australia\nEdited by Konrad Hinsen ID\nReviewed by Serge Stinckwich ID\nReceived 09 March 2020\nPublished 26 November 2020\nDOI 10.5281/zenodo.4290512\nThis is a computational replication of my SAS code from 16 years ago.\n1 Introduction\n1.1 Historical context\nThis paper aims to computationally reproduce my own statistical analysis from 16 years ago as part of the 10\u2010year reproducibility challenge1. The analysis examined seasonal patterns in coronary heart disease in multiple countries2. In most countries coronary heart disease deaths and emergency admissions to hospital have a strong seasonal pat\u2010 tern with a peak in winter and nadir in summer3. There is an interesting variability between\u2010countries in the size and timing of the winter peak. A better understanding of the differences between countries could help our understanding of the underlying causes of the winter peak in disease.\nThe analysis examinedmonthly time series of coronary events (fatal and non\u2010fatal) from 35 locations in 21 countries. The time series were 8 to 14 years in length and the earliest year of data was 1980. The analysis aimed to split the time series into a long\u2010term trend, seasonal pattern(s) and remaining noise. There were two approaches, one that used a two\u2010stage approach by first removing the trend, and another that estimated the trend and season together. The trend was estimated using the Kalman filter and the seasonal patterns were estimated using sinusoids. The estimates were made using Markov chain Monte Carlo.\n1.2 Original source code\nThe original code was written in SAS (version 8.00 for Windows) and chain convergence was checked using the \u201ccoda\u201d package (version unknown) in R4. The code was based on Matlab code that I wrote during my PhD5 at The University of Queensland. I converted the code to SAS because I did not have access to Matlab after finishing my PhD and I hoped that more people would be able to re\u2010use my SAS code to apply to their own time series data. The SAS code was first published in November 2004 with an update in August 2006, but I did not record what changes were made. The paper states the code was published in September 2002 but this is likely a typo in the year given that the paper was not submitted until January 2004.\nCopyright \u00a9 2020 A. Barnett, released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Adrian Barnett (a.barnett@qut.edu.au) The authors have declared that no competing interests exist. Code is available at https://github.com/agbarnett/tenyears. \u2013 SWH swh:1:dir:a7fef2d0e993aa8fcbe0949de721d46a2098ad23. Open peer review is available at https://github.com/ReScience/submissions/issues/21.\nReScience C 6.1 (#18) \u2013 Barnett 2020 1\nThe original code was published in an online appendix to the paper that was separate from the journal in November 2004 at this address: http://www4.ktl.fi/publications/monica/ chd_seasonal/appendix.htm. However, the site has sincemoved to: https://www.thl.fi/publications/ monica/chd_seasonal/appendix.htm (accessed 25 January 2020). The web site was created by the WHO MONICA Project specifically for appendices to papers that used the MONICA data. MONICA stands for monitoring trends and determinants in cardiovascular dis\u2010 ease. The MONICA Project was a large multi\u2010country study that aimed to examine sev\u2010 eral aspects of coronary heart disease6. It was a well\u2010managed project that had staffwho assisted with access to the data and helped add my code to the web.\n2 Results\n2.1 Retrieval of the software\nMost of my SAS code was easy to find, both on the web and on an old compact disc in a desk draw. I made this compact disc of my files when I moved jobs. I did not keep the data because I was more interested in other people using my code for their own data rather than replicating our published results. I believe that another reason for deleting the data was to save space, as the files were relatively large by the standards of the day (around 31,000 kilobytes for data in text format and 70,000 kilobytes for data in SAS format). Luckily the original data files were available in text files in fixed\u2010width format on a compact disc attached to the MONICA monograph published in 20036.\nMy SAS code contained the macros needed to run the two statistical analyses. There was also SAS code to simulate a seasonal time series as an example data set. I found SAS code to read the MONICA data on my compact disc, but not on the web. I could not find the SAS code that applied the two methods to each location.\n2.2 Replication execution\nI used SAS version 9.4 forWindows (MicrosoftWindows 10) to replicate the results; there was no need to use an earlier version of SAS.\nMy SAS files had relatively good instructions with a detailed header at the top of every file and comments throughout. However, some files had been adapted from the origi\u2010 nal analysis to secondary analyses, making the code a palimpsest with some commands commented out with notes such as, \u201cchanged for weather analysis\u201d and \u201csensitivity anal\u2010 ysis of Ghent\u201d. The correct data setwas also ambiguous because alternative data sets had also been used (e.g., fatal vs non\u2010fatal events). In hindsight I should have kept the exact data and syntax files needed to re\u2010create the published results.\nThe macros to run the analyses mainly needed only cosmetic edits, and I also put each macro in its own file rather than one overall file of macros. I also moved part of one macro, that estimated the standard deviation of the noise, into the macro that tested the periodogram for remaining seasonal structure. The largest change was having to re\u2010write the files that applied the macros to the MONICA data. My SAS programming was rusty and I could not automate the process for each centre, so instead I created a new file for each analysis in each of three centres.\nI did not repeat my analysis in all 35 locations, but instead did the three locations in the first figure as this felt sufficient to test the code.\nThe code to estimate the trend without the seasonal pattern used a slightly different parameterisation with \u201ctau\u201d as a ratio rather than an absolute value. \u201ctau\u201d controls\nReScience C 6.1 (#18) \u2013 Barnett 2020 2\nthe amount of change over time in the trend, with smaller values creating more linear trends. I cannot be sure that this version was the same code as the original.\n2.3 Closeness of the replicated results to the original\nThe original figure is shown in Figure 1 andmy replication in Figure 2. The figures show the estimates of the trend and season for three locations. The results are similar except for the confidence intervals for the trend for the two\u2010stage method, which are much narrower for the replication, but are centred on a similar mean. This may be because I could not be certain that I had found the original code to perform the Kalman filter smoothing because of the difference in how \u201ctau\u201d was parameterised. I also needed some trial\u2010and\u2010error to select \u201ctau\u201d which controls the smoothness of the trend and is defined by the user rather than being estimated by an algorithm.\nThe estimates of the seasonal patterns for the three locations are replicated in Table 1 which also shows the original results. The results are similar for the two\u2010stage method, with most differences being within \u00b1 0.1. The biggest difference being for the estimate of the noise standard deviation in Belfast (9.0 versus 8.8).\nThere were differences in the frequencies for the combinedmethod, as two seasonal fre\u2010 quencies were not included in the new results, one in Perth and one in Belfast. Although the amplitudes were relatively small (1.6 or less), hence these are smaller seasonal pat\u2010 terns that are marginally important.\nThe difference in seasonal frequencies could be because of a key ambiguity in the orig\u2010 inal paper regarding the decision to add additional seasonal components for the com\u2010 bined approach. After fitting a candidate model, the residuals were tested to look for ad\u2010 ditional seasonal structure. If structure existed, then the model was modified to add an additional seasonal component as necessary, followed by another test of the residuals. The code produced both the periodogram and the spectrum, which is a smoothed ver\u2010\nReScience C 6.1 (#18) \u2013 Barnett 2020 3\nsion of the periodogram. The periodogram tended to flag significant seasonal patterns when the spectrumdidnot, and I used the spectrum tomake the decisions because some of the statistically significant patterns found by the periodogram were only just above the 0.05 threshold used to judge statistical significance. This part of the replication was therefore somewhat subjective.\nSome of the discrepancy in results in Table 1 could be because the estimates are made using Markov chain Monte Carlo which uses random steps to make estimates. Hence the estimates will depend on the original random number seed. However, I used 5,000 estimates with a burn\u2010in of 500, so these differences should be minor and may explain some of the small differences in the first decimal place for the amplitude and noise estimates. This potential discrepancy would have been avoided if the original code had specified the random number seed.\nReScience C 6.1 (#18) \u2013 Barnett 2020 4\nOverall the replication took about 21 hours. This was mostly the fiddly task of working out which macros to run and re\u2010creating the figures and tables. Given the amount of code that had to be re\u2010created, I think that only someone familiar with SAS would have been able to replicate the results. My familiarity with the MONICA Project also helped me create the new code, hence I am not certain that an outsider could have replicated the results, perhaps only by trial\u2010and\u2010error.\nReScience C 6.1 (#18) \u2013 Barnett 2020 5\n3 Discussion\nIt was an interesting exercise to bring this old code back to life. It would have been easier and faster if my original code had been properly arranged and prepared solely to repeat the original analyses. However, I was not aware of guidelines for curating code back in 2004. My original code had many comments which were useful, but there were problems with the overall file structure and how the files related to one another. There were also ambiguities with the dates of the code, and the changes I made after posting the original files. This is now solved by sites that track and date\u2010stamp all changes, such as GitHub.\nMy main reason for sharing the original code was so that others could adapt it to their own data. However, of the 21 papers that cited the original paper which I could access, none of them stated that they re\u2010used my SAS code.\nOverall the replication was broadly successful in terms of re\u2010creating the key figure and estimates for three locations. There was subjectivity in modelling decisions concerning the smoothness of the trend and number of seasonal components, which made perfect replication difficult."}], "title": "[Rp] Estimating trends and seasonality in coronary heart disease", "year": 2020}
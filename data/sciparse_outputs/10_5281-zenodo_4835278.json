{"abstractText": "Hamiltons\u0313 equations are widely used in classical and quantum physics. The Hamiltonian Generative Network (HGN) is the first approach that aims to \u201dlearn the Hamiltonian dynamics of simple physical systems from high-dimensional observations without restrictive domain assumptions\u201d. To do so, a variational model is trained to reconstruct the evolution of physical systems directly from images by integrating the learnedHamiltonian. New trajectories can be sampled and rollouts can be performed forward and backward in time. In this work, we re-implement the HGN architecture and the physical environments (pendulum, body-spring system, and 2,3-bodies). We reproduce the paper experiments and we further expand them by testing on two new environments and one new integrator. Overall, we find that obtaining both good reconstruction and generative capabilities is hard and sensitive to the variational parameters.", "authors": [{"affiliations": [], "name": "Balsells Rodas"}, {"affiliations": [], "name": "Koustuv Sinha"}, {"affiliations": [], "name": "Sasha Luccioni"}], "id": "SP:7fe336e3bf7f2f496b78686f3600d45aa508209e", "references": [{"authors": ["A. Paszk"], "title": "et al", "venue": "\u201cPyTorch: An Imperative Style, High-Performance Deep Learning Library.\u201d In: Advances in Neural Information Processing Systems 32. Ed. by H. Wallach, H. Larochelle, A. Beygelzimer, F. d\u2019Alch\u00e9-Buc, E. Fox, and R. Garnett. Curran Associates, Inc.,", "year": 2019}, {"authors": ["D.J. Rezend"], "title": "and F", "venue": "Viola. Taming VAEs.", "year": 2018}, {"authors": ["I. Higgins", "L. Matthey", "A. Pal", "C. Burgess", "X. Glorot", "M. Botvinick", "S. Mohamed"], "title": "and A", "venue": "Lerchner. \u201cbeta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework.\u201d In: ICLR.", "year": 2017}, {"authors": ["H. Goldstein"], "title": "Classical Mechanics", "venue": "Addison-Wesley,", "year": 1980}, {"authors": ["P. Toth", "D.J. Rezende", "A. Jaegle", "S. Racani\u00e8re", "A. Botev"], "title": "and I", "venue": "Higgins. Hamiltonian Generative Networks.", "year": 2020}, {"authors": ["P. Virtanen"], "title": "SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python.", "venue": "Nature Methods", "year": 2020}, {"authors": ["G. Bradski"], "title": "The OpenCV Library.", "venue": "Dr. Dobb\u2019s Journal of Software Tools", "year": 2000}, {"authors": ["D.P. Kingm"], "title": "and M", "venue": "Welling. Auto-Encoding Variational Bayes.", "year": 2014}, {"authors": ["T. Karras", "T. Aila", "S. Laine"], "title": "and J", "venue": "Lehtinen. Progressive Growing of GANs for Improved Quality, Stability, and Variation.", "year": 2018}, {"authors": ["D.P. Kingm"], "title": "and J", "venue": "Ba. Adam: A Method for Stochastic Optimization.", "year": 2017}, {"authors": ["S. Greydanus", "M. Dzamba"], "title": "and J", "venue": "Yosinski. Hamiltonian Neural Networks.", "year": 2019}, {"authors": ["F. Segovia-Chaves"], "title": "The one-dimensional harmonic oscillator damped with Caldirola-Kanai Hamiltonian.", "venue": "Revista mexicana de f\u0131\u0301sica E", "year": 2018}, {"authors": ["T. Hull", "W. Enright", "B. Fellen", "A. Sedgwick"], "title": "Comparing numerical methods for ordinary differential equations.", "venue": "SIAM Journal on Numerical Analysis", "year": 1972}, {"authors": ["H. Yoshida"], "title": "Symplectic integrators for Hamiltonian systems: basic theory.", "venue": "In: Symposium-International Astronomical Union", "year": 1992}, {"authors": ["R.M. Neal"], "title": "MCMC using Hamiltonian dynamics.\u201d In:Handbook ofmarkov chainmonte carlo", "venue": "p. 2. ReScience C", "year": 2011}], "sections": [{"text": "Edited by Koustuv Sinha, Sasha Luccioni\nReviewed by Anonymous Reviewers\nReceived 29 January 2021\nPublished 27 May 2021\nDOI 10.5281/zenodo.4835278\nHamiltons\u0313 equations are widely used in classical and quantum physics. The Hamiltonian Generative Network (HGN) is the first approach that aims to \u201dlearn the Hamiltonian dynamics of simple physical systems from high-dimensional observations without restrictive domain assumptions\u201d. To do so, a variational model is trained to reconstruct the evolution of physical systems directly from images by integrating the learnedHamiltonian. New trajectories can be sampled and rollouts can be performed forward and backward in time. In this work, we re-implement the HGN architecture and the physical environments (pendulum, body-spring system, and 2,3-bodies). We reproduce the paper experiments and we further expand them by testing on two new environments and one new integrator. Overall, we find that obtaining both good reconstruction and generative capabilities is hard and sensitive to the variational parameters."}, {"heading": "Reproducibility Summary", "text": ""}, {"heading": "Scope of Reproducibility", "text": "Themain objective of the paper is to \u201dlearn theHamiltonian dynamics of simple physical systems from high-dimensional observations without restrictive domain assumptions\u201d. To do so, the authors train a generative model that reconstructs an inputted sequence of images of the evolution of some physical system. For instance, they learn the dynamics of a pendulum, a body-spring system, and 2,3-bodies. In addition to these environments, we further expand the testing on two new environments and we explore architecture tweaks looking for performance gains."}, {"heading": "Methodology", "text": "We implement the project with Python using Pytorch [1] as a deep learning library. Previous to ours, there was no public implementation of this work. Thus, we had to write the code of the simulated environments, the deep models, and the training process. The code can be found in this repository: https://github.com/CampusAI/HamiltonianGenerative-Networks A single training takes around 4 hours and 1910MB of GPU memory (NVIDIA GeForce RTX2080Ti).\nCopyright \u00a9 2021 C. Balsells Rodas, O. Canal Anton and F. Taschin, released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Taschin, Federico (taschin@kth.se) The authors have declared that no competing interests exist. Code is available at https://github.com/CampusAI/Hamiltonian-Generative-Networks \u2013 DOI 10.5281/zenodo.4673473. \u2013 SWH swh:1:dir:7c7cee4b1c4dc7dfa46b4b4bf5c3b8b20deb5b26. Open peer review is available at https://openreview.net/forum?id=Zszk4rXgesL.\nReScience C 7.2 (#18) \u2013 Balsells Rodas, Canal Anton and Taschin 2021 1"}, {"heading": "Results", "text": "We found the model s\u0313 input-output data slightly unclear in the original paper. First, it seems that themodel reconstructs the same sequence that has been inputted. Nevertheless, further discussion with the authors seems to indicate that they input the first few frames to the network and reconstructed the rest of the rollout. We test both approaches and analyze the results. We generally obtain comparable results to those of the original authors when just reconstructing the input sequence (30% average absolute relative error w.r.t. to their reported values) and worse results when trying to reconstruct unseen frames (107% error). In this report, we include our intuition on possible reasons that would explain these observations."}, {"heading": "What was easy", "text": "The architecture of the model and training procedure was easy to understand from the paper. Besides, creating simulation environments similar to those of the original authors was also straightforward."}, {"heading": "What was difficult", "text": "While the overall model architecture and data generation were easy to understand, we encountered the optimization to be especially tricky to perform. In particular, finding a good balance between the reconstruction loss and KL divergence loss was challenging. We implemented GECO [2] to dynamically adapt the Lagrangemultiplier but it proved to be surprisingly brittle to its hyper-parameters, resulting in very unstable behavior. We were unable to identify the cause of the problem and ended up training with simpler techniques such as using a fixed Lagrange multiplier as presented in [3].\nCommunication with original authors We exchanged around 6 emails with doubts and answers with the original authors.\n1 Introduction\nConsider an isolated physical system with multiple bodies interacting with each other. Let q \u2208 Rn be the vector of their positions, and p \u2208 Rn the vector of their momenta. The Hamiltonian formalism [4] states that there exists a functionH : (q,p) \u2208 Rn+n \u2192 R representing the energy of the system which relates q and p as:\n\u2202q \u2202t = \u2202H \u2202p , \u2202p \u2202t = \u2212\u2202H \u2202q (1)\nIn this work H is modeled with an artificial neural network and property 1 is exploited to get the temporal derivatives of both q and p. One can then use a numerical integrator (see Section 4.1) to solve the ODE and infer the system evolution both forward and backward in time given some initial conditions (see Figure 2). These initial conditions are inferred from a natural image sequence of the system evolution (see Figure 1). The authors propose a generative approach to learn low-dimensional representations of the positions and momenta (q0,p0). This allows us to sample new initial conditions and unroll previously unseen system evolutions according to the learned Hamiltonian dynamics.\nReScience C 7.2 (#18) \u2013 Balsells Rodas, Canal Anton and Taschin 2021 2\n2 Scope of reproducibility\nThemain claim of the paper is that the proposed architecture is able to \u201dlearn theHamiltonian dynamics of simple physical systems from high-dimensional observations without restrictive domain assumptions\u201d. This means that the architecture is capable of learning an abstract position and momentum in latent space from RGB images. Then, with the help of an integrator, the architecture will be capable of reconstructing the system evolution. Modifying the integrator time-step will result in a slow-motion or fastforward evolution. Moreover, the architecture can generate previously unseen system evolutions through sampling. Briefly, we will evaluate the following claims:\n\u2022 The architecture reconstructs RGB frames of a physical system evolution with an error comparable to [5].\n\u2022 The architecture can generate new samples qualitatively similar to the originals.\n\u2022 The timescale of the predicted evolution can be tuned as an integrator parameter without significant degradation of the resulting video sequence.\n3 Methodology\nTodate (Jan 1st 2021), authors didnot release their code. Therefore, we fully re-implement the Hamiltonian architecture, the integrators, and the simulated environments. To further evaluate the system, we implement two additional environments and one additional integrator. We developed our implementation in Python3 using PyTorch [1] machine learning library for the Hamiltonian architecture and the Scipy [6] ODE solver for the simulated environments, as well as OpenCV [7] for image manipulation. Our code can be found in this repository1. We runmost of the experiments using an NVIDIA GeForce RTX 2080Ti and some on an NVIDIA GTX 970.\n3.1 Hamiltonian Generative Network (HGN) The HGN [5] architecture can be split into two high-level components. The first (Figure 1) reads the initial k+1 frames of an environment rollout and extracts the abstract positions and momenta (qk,pk) correspondent to the k-th step. Second, a recurrent model takes (qk,pk) as first input and performs integration steps of a fixed \u2206t, predicting the evolution of the system in terms of abstract positions and momenta 2. For each step, the abstract position is decoded into an RGB image. As figures 1, 2 depict, this model is composed by four main networks:\n\u2022 Encoder: Parametrized by: \u03d5. 8-layer 64-filter Conv2D network with ReLU activations that takes a sampled video rollout from the environment and outputs the mean and variance of the encoder distribution q\u03d5(z) parametrized as a diagonal Gaussian with prior p(z) = N (0, I). The latent variable z is sampled from q\u03d5 with the reparametrization trick [8]. The input of this layer is constructed by concatenating all the rollout frames in the channel axis. Therefore, if working with RGB images, the input has shape: H \u00d7W \u00d7 3 \u00b7 N . Where H,W,N are Height, Width, and Number of frames, respectively.\n\u2022 Transformer: Parametrized by: \u03c8. Takes in the sampled latent variable z and transforms it into a lower-dimensional initial state sk = (qk,pk), by applying 3 Conv2D layers with ReLU activations, stride 2, and 64 filters.\n1https://github.com/CampusAI/Hamiltonian-Generative-Networks 2In addition, we test how the network performs when trained as an autoencoder, ie: fit the complete se-\nquence and reconstruct it. (Section 4)\nReScience C 7.2 (#18) \u2013 Balsells Rodas, Canal Anton and Taschin 2021 3\n\u2022 Hamiltonian: Parametrized by: \u03b3. It is a 6-layer 64-filter Conv2Dnetworkwith SoftPlus activations which takes in the abstract positions and momenta (qt,pt) and outputs the energy of the system et \u2208 R. This network is used by the integrator (Section 4.1) to compute the system state at the next time-step (qt+1,pt+1) exploiting Eq. 1. Since Eq. 1 involves partial derivatives of H w.r.t. q and p, the training process involves second-order derivatives of the Hamiltonian network weights. For this reason, SoftPlus activations are used instead of ReLU.\n\u2022 Decoder: Parametrized by: \u03b8. 3-residual block upsampling Conv2D network (as in [9]) which converts the abstract position qt into an image close to the source domain.\nGiven an input sequence: (x0, ...,xT ) and a value k+1 of input-length, the loss function 3 to optimize is:\nL(\u03d5, \u03c8, \u03b3, \u03b8;x0, ...,xT ) = 1\nT + 1\u2212 k T\u2211 t=k ( Eq\u03d5(z|x0,..xk) [ log p\u03c8,\u03b3,\u03b8(xt | qt) ]) \u2212 \u039b \u00b7KL ( q\u03d5(z) || p(z)\n) (2) Notice that the loss is the combination of two terms: first, the error coming from the reconstruction of the images, and second, a termwhich forces the latent distribution q\u03d5 to be close to a standard Gaussian. It is interesting to see that there is no conditioning over the behavior of latent positions and momenta during the rollout. The architecture connections are enough to force qk to encode the position information and pk themomenta information at timestep k. We use the same optimizer as in [5]: Adam [10] with a constant learning rate of lr = 1.5e\u22124 with the GECO algorithm presented in [2] to adapt the Lagrange multiplier \u039b during training. This Lagrange multiplier is dynamically updated according to an exponential moving average proportional to the reconstruction error of the assessed minibatch. The main parameters controlling the Lagrange multiplier are the exponential moving average constant \u03b1, the initial Lagrange multiplier, and a parameter to control its growth \u03bb. The authors did not include the values used in the paper, so we performed a grid search to find the most adequate ones for each environment (see Section 6). In addition, we trained a version of the model with a fixed Lagrange multiplier.\n3The formulation of the loss in Eq. 2 particularly w.r.t. the distribution q\u03d5 is different from that of the paper[5] where it was written as q\u03d5(z|x0, ...,xT ), which initially led us to think that the encoder had access to the whole rollout. Discussion with the authors clarified that the encoder reads only the first k frames. Therefore, we decided to slightly modify the loss notation in order to avoid confusion. Still, we show results with both approaches to get a more complete idea of the differences.\nReScience C 7.2 (#18) \u2013 Balsells Rodas, Canal Anton and Taschin 2021 4\nMass-spring. Assuming no friction, the Hamiltonian of a mass-spring system is H = p2 2m + 1 2kq 2, where m is the object s\u0313 mass and k is the spring s\u0313 elastic constant. We gen-\nReScience C 7.2 (#18) \u2013 Balsells Rodas, Canal Anton and Taschin 2021 5\nerate our data consideringm = 0.5, k = 2 and r \u223c U(0.1, 1.0).\nPendulum. An ideal pendulum is modelled by the HamiltonianH = p 2\n2ml2 + 2mgl(1\u2212 cos q), where l is the length of the pendulum and g is the gravity acceleration. The data is generated consideringm = 0.5, l = 1, g = 3 and r \u223c U(1.3, 2.3).\nTwo-/three- body problem. The n-body problem considers the gravitational interaction between n bodies in space. Its Hamiltonian is H = \u2211n i ||pi|| 2 2mi \u2212 \u2211n i \u0338=j gmimj ||qi\u2212qj ||\n, where mi corresponds to the mass of object i. In this dataset, we set {mi = 1}ni=1 and g = 1. For the two-body problem, we modify the observation noise to \u03c3 = 0.05 and set r \u223c U(0.5, 1.5). When considering three bodies, we set \u03c3 = 0.2 and r \u223c U(0.9, 1.2).\nDobule pendulum The double pendulum consists of a system where we attach a simple pendulum to the end of another simple pendulum. For simplicity, we conider both simple pendulums with identical properties (equal mass and length). The Hamiltonian of this system isH = 12ml2 p21+p 2 2+2p1p2cos(q1\u2212q2) 1+sin2(q1\u2212q2) +mgl ( 3\u22122 cos q1\u2212cos q2 ) , where {q1, p1} and {q2, p2} refer to the phase state of the first and second pendulum respectively. Our data is generated by settingm = 1, l = 1, g = 3 and r \u223c U(0.5, 1.3). In this scenario we consider a very low intense source of noise \u03c3 = 0.05.\nDamped oscillator The damped mass-spring system is obtained by considering a dissipative term in the equations of motion of the ideal mass-spring system. For such systems, one can obtain its dynamics using the Caldirola-Kanai HamiltonianH = e\u03b3t ( p2\n2m+\n1 2kq\n2 ) [12], where \u03b3 is the damping factor of the oscillator. In our experiments, we\nconsider an underdamped harmonic oscillator and set \u03b3 = 0.3, m = 0.5, k = 2, r \u223c U(0.75, 1.4) and \u03c3 = 0.1.\n3.4 Hyperparameters We set the same hyperparameters for all experiments as the original paper [5] except for GECO parameters, which were not included. Thus, we perform a grid search on each environment to find the most adequate ones (see Section 4.1).\n3.5 Computational requirements A standard training of 50K train samples using the Leapfrog integrator takes around 4 hours on an RTX 2080T GPU and requires around 1910MB.\nReScience C 7.2 (#18) \u2013 Balsells Rodas, Canal Anton and Taschin 2021 6\n4 Results\nWe first test whether the HGN [5] can learn the dynamics of the four presented physical systems by measuring the average mean squared error (MSE) of the pixel reconstructions of each predicted frame. Furthermore, we test the original HGN architecture along with different modifications: a version trained with Euler integration rather than Leapfrog integration (HGN Euler), and a version that does not include sampling from the posterior q\u03d5(z|x0...xT ) (HGN determ). Since we could not find suitable GECO[2] hyperparameters, we use a fixed Lagrange multiplier[3] in all the experiments. Table 1 shows the results of the experiments described previously along with the results of the original authors. As it can be seen, we achieve average pixel reconstruction errors that are similar (30% avg absolute error w.r.t. the reported values on the test set using Leapfrog integrator) to the ones reported in the original paper when reconstructing the same sequence that is inputted (we call this version autoencode). However, when attempting to train to reconstruct a rollout given only the first 5 frames our model performs poorly, with 107% average absolute error on the test set, using Leapfrog integrator. In Figure 4, we show some qualitative examples of the reconstructions obtained by the full version of HGN. The model can reconstruct the samples and its rollouts can be reversed in time, sped up, or slowed down by changing the value of the time step used in the integrator. Since theHGN is designed as a generativemodel, we can sample from the latent space to produce initial conditions and perform their time evolution. We show some rollouts obtained this way in figure 5. We observe that our model is only able to generate plausible and diverse samples in the mass-spring dataset. This behavior is different than the one shown by [5] and might be caused by different hyper-parameter configurations in the training procedure or some implementation mistake. We achieve slightly larger MSE in the autoencode version and significantly larger in the\nReScience C 7.2 (#18) \u2013 Balsells Rodas, Canal Anton and Taschin 2021 7\n5-frame inference problem on both the mass-spring and pendulum. The latter presents roughly double MSE probably because of a wider span of movement. In general, these two environments show worse results in comparison to two/three-bodies. For these last cases, our implementation using the autoencode setting outperforms the original HGN [5], and when using the 5-frame inference the results are similar. As we can see, these two environments show much less average pixel MSE compared to the first ones (almost one order of magnitude). We believe this may be due to the differences when rendering the instances of each dataset. The elements appearing in mass-spring and pendulum (represented by a large yellow ball) are larger than the ones present in the two/three bodies (two/three small coloured balls). Because of this, it would be reasonable to assume that localization errors aremore penalized in the first two environments, since the total difference in areas is larger. Furthermore, the dynamics representing mass-spring and pendulum show faster movements in comparison to two/three-bodies, resulting in being harder to represent with our HGN. Consequently, we hypothesise the following: larger elements and faster dynamics, produces higher average MSE on our model regardless of the difficulty of the environment physics. However, this is not the case for the original author s\u0313 results, who seem to strugglemore on the two/three-bodies. Surprisingly, it seems that our hyperparameter and architecture choices led to poorer reconstruction capabilities (higher MSE) but learning better physics (qualitatively more realistic movements).\n4.1 Additional experiments GECO parameter search The paper does not provide the values of GECO [2] used. In GECO, the Lagrangian multiplier is optimized at each step with a rate \u03b3. Figure 6 shows the behavior of GECO for \u03b3 \u2208 {0.1, 0.05, 0.01} in terms of reconstruction loss and KL divergence. Higher values of \u03b2 give a better reconstruction loss but greatly increase the KL divergence. However, we found that hyperparameters were not consistent among different environments and integrators. For this reason, we do not use GECO in our experiments.\nIntegrators Performing the integration step is key to generate the time evolution of a rollout given the initial state. In the HGN paper [5] the system is tested using Euler and\nReScience C 7.2 (#18) \u2013 Balsells Rodas, Canal Anton and Taschin 2021 8\nLeapfrog integration. Wewonder if using higher order integrationmethodsmight boost the performance of the rollout generation process. Therefore, we implement and test the HGN architecture with two additional numerical integration methods: the RungeKuttas\u0313 4th-order integrator [13] and the 4th-order Leapfrog integrator (Yoshidas\u0313 algorithm [14]). Table 2 shows a comparison of all four integrators on the Pendulum dataset. Both Leapfrog and Yoshida are symplectic integrators: they guarantee to preserve the special form of the Hamiltonian over time [15]. Table 2 shows the average pixel MSE, the averaged standard deviation of the output of the Hamiltonian network during testing, and the reconstruction time of a single batch (batch = 16) using the different integration methods that we have described previously. The model has been trained on the simple pendulum dataset. As we can see, the reconstruction time increases when using higher-order integration methods, since they require more integration steps. In general, we see that Euler integration offers a fast and sufficiently reliable reconstruction of the rollouts. Moreover, we observe that the fourth-order symplectic integrator (Yoshida) achieves the best performance. Surprisingly, the symplectic integration methods show more variance in the output of the Hamiltonian networks throughout a single rollout. This behavior is unexpected since using a symplectic integrationmethod should ideally keep the value of the Hamiltonian invariant. We conclude that more experiments need to be performed to guarantee that the implementation of both Leapfrog and Yoshida integration methods are faithful to their formulation.\nIntegrator modelling We train the modified architecture of Section 3.2 on the Pendulum dataset for 5 epochs. The architecture is the same as HGN, but the Hamiltonian Network now outputs\u2206q and\u2206p. The average MSE error over the whole Pendulum dataset is 1.485\u00d710\u22123, while in the test set it is 1.493\u00d710\u22123, which are both very close (\u223c \u00b12%) to those of autoencoding HGN (see Table 1). The modified architecture is still capable of performing forward slow-motion rollouts by modifying \u2206t. We set \u2206t\u2032 = \u2206t2 and we compute the averageMSE of the slow-motion reconstruction over 100 rollouts. Themodified architecture achieved an error of 8x10\u22124, while the standardHGN achieved 9x10\u22124. Note that reconstruction losses are smaller for slow-motion as the images change less between timesteps.\nExtra environments Apart from the four physical systems presented by [5] we test our re-implementation of the HGN with physical systems that do not have a simple Hamiltonian expression. As described previously, these are the damped harmonic oscillator and the double pendulum. On one hand, we are interested in a damped system since it introduces a dissipative term to the equations of motion; a feature that differs from the previous systems. On the other hand, the double pendulum is modelled by a non separable Hamiltonian: H(q,p) \u0338= K(p)+V (q) as described previously. In figure 7 we show some visual examples of the reconstructions provided by the HGN trained on the two systems. As we can see, HGN is able to reconstruct the damped oscillator with high reliability. Regarding the double pendulum, we observe that the model reconstructs well small oscillations, but fails when the trajectory is too chaotic as expected. The average\nReScience C 7.2 (#18) \u2013 Balsells Rodas, Canal Anton and Taschin 2021 9\npixel MSE of the reconstructions of the damped oscillator and the double pendulum are 6.39 \u00b710\u22124 and 6.91 \u00b710\u22124 respectively. TheHGN is able to provide better reconstructions for these systems in comparison to the mass-spring and pendulum systems.\n5 Discussion\nWe were able to implement and train an Hamiltonian Generative Network with similar reconstruction performance of the ones of the original paper (30% average absolute relative error wrt to their reported values when treating it as an autoencoder). These results show that the network is capable of exploiting the Hamiltonian equations to learn dynamics of a physical system from RGB images. However, the value of the resulting Hamiltonian does not remain constant throughout the system evolution. This means that the network is learning something that is different from the Hamiltonian equations described in Section 3.3. Tomake the variational samplingwork, we tried performing a grid search on the Geco[2] hyperparameters and using a fixed Lagrange multiplier as in [3]. However, despite our best efforts, the samples produced by the variational model have very poor quality. This is generally due to the difficulty in minimizing both KL divergence and reconstruction loss. We believe that further experiments are needed to understand better the behavior of the system and to improve it. Future work could include further testing on each network architecture, probably smaller networks would also be able to encode the needed information. Another next step is to try the approach onmore challenging (and realistic-looking) environments. In addition, it would be interesting to tackle the transfer learning capabilities of such architecture between different environments. How re-usable each network is? Howmuch faster the system is able to learn the newdynamics? Finally, another field which could benefit from this research is model-based reinforcement learning. A generative approach from which to sample example rollouts could be very useful for training agents without the need of directly interacting with the environment.\n5.1 What was easy Once we implemented the code it resulted quite easy to perform multiple experiments on different environments, architectures and hyper-parameters due to the code s\u0313 modularity and flexibility. We can define the the previously mentioned experiments and most common testing behaviors from a set of yaml files which can then be modified from command-line arguments. While this required extra planning and work at the beginning it really payed off when debugging and evaluating in later stages.\nReScience C 7.2 (#18) \u2013 Balsells Rodas, Canal Anton and Taschin 2021 10\n5.2 What was difficult The main challenge we encountered is finding the correct tools to debug a model composed of somany interconnected networks. The fact that it has a variational component with a dynamic Lagrange multiplier term makes it especially tricky to train. Furthermore, no public implementation existed and some details and parameters weremissing in the original paper leading to some necessary assumptions or parameter searches.\n5.3 Communication with original authors We first tried to understand and re-implement the code by ourselves. Nevertheless, at some point we had gathered a significant set of doubts and we decided to email them to the original authors, which they answered with great detail. From that point onwards, we sent a couple more set of doubts, also receiving answers.\nMost of our doubts were about network architecture clarifications (either of unclear or missing descriptions from the original paper), and loss function evaluation. Furthermore, they provided us with some of their environment images so we could more easily make our environments as similar as possible.\n5.4 Improving reproducibility Having worked in re-implementing the whole original work, we feel it is important to share our experience as well as providing a recommendation on how it could be made more easily reproducible. First, having the environments data or code to generate it available online would save the effort and, most importantly, it would constitute a baseline against which to compare future work. Secondly, publishing all the hyperparameters andmore details of thenetworks architecturewouldmake thewholeworkmuch easier to reproduce and require less training attempts, especially for what concerns GECO."}, {"heading": "Acknowledgements", "text": "We thank Stathi Fotiadis for voluntarily contributing with a GECO [2] implementation draft to the public repo and his useful feedback on code structuring. We thank the KTH Robotics, Perception, and Learning (RPL) Lab for the computational resources provided to us. In addition, we would like to thank the original authors for providing further details on the implementation."}], "title": "[Re] Hamiltonian Generative Networks", "year": 2021}
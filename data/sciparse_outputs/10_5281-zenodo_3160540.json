{"abstractText": "The ability to adapt to new situations and learn quickly is a cornerstone of human intelligence. When given a previously unseen task, humans can use their previous experience and learning abilities to perform well on this new task in a matter of seconds and with a relatively small amount of new data. Artificial learning methods have been shown to be very effective for specific tasks, often times surpassing human performance1,2). However, by relying on standard supervised-learning or reinforcement learning training paradigms, these artificial methods still require much training data and training time to adapt to a new task. An area of machine learning that learns and adapts from a small amount of data is called few-shot learning3. A shot corresponds to a single example, e.g. an image and its label. In few-shot learning the learning scope is expanded from the classic setting of a single task withmany shots to a variety of tasks with a few shots each. A promising approach for few-shot learning is the field of meta-learning. Meta-learning, also known as learning-to-learn, is a paradigm that exploits cross-task information and training experience to perform well on a new unseen task.", "authors": [{"affiliations": [], "name": "Arnout Devos"}, {"affiliations": [], "name": "Sylvain Chatel"}, {"affiliations": [], "name": "Matthias Grossglauser"}, {"affiliations": [], "name": "Koustuv Sinha"}], "id": "SP:36ba5b32377f929359f9d1c0b338cd3b0ea00a7d", "references": [{"authors": ["D. Silver", "A. Huang", "C.J. Maddison", "A. Guez", "L. Sifre", "G. Van Den Driessche", "J. Schrittwieser", "I. Antonoglou", "V. Panneershelvam", "M. Lanctot"], "title": "Mastering the game of Go with deep neural networks and tree search.", "year": 2016}, {"authors": ["A. Esteva", "B. Kuprel", "R.A. Novoa", "J. Ko", "S.M. Swetter", "H.M. Blau", "S. Thrun"], "title": "Dermatologist-level classification of skin cancer with deep neural networks.", "venue": "Nature", "year": 2017}, {"authors": ["L. Fei-Fei", "R. Fergus", "P. Perona"], "title": "One-shot learning of object categories.", "year": 2006}, {"authors": ["L. Bertinetto", "J.F. Henriques", "P. Torr", "A. Vedaldi"], "title": "Meta-learning with differentiable closed-form solvers.", "venue": "In: International Conference on Learning Representations", "year": 2019}, {"authors": ["C. Finn", "P. Abbeel", "S. Levine"], "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks.", "venue": "ICML (Mar. 2017)", "year": 2017}, {"authors": ["A. Nichol", "J. Schulman"], "title": "Reptile: a Scalable Metalearning Algorithm.", "venue": "arXiv preprint arXiv:1803.02999", "year": 2018}, {"authors": ["O. Vinyals", "C. Blundell", "T. Lillicrap", "K. Kavukcuoglu", "D. Wierstra"], "title": "Matching Networks for One Shot Learning.", "venue": "[cs, stat] (June", "year": 2016}, {"authors": ["N. Mishra", "M. Rohaninejad", "X. Chen", "P. Abbeel"], "title": "A Simple Neural Attentive Meta-Learner.", "venue": "[cs, stat] (July", "year": 2017}, {"authors": ["J. Snell", "K. Swersky", "R.S. Zemel"], "title": "Prototypical Networks for Few-shot Learning.", "venue": "en. In: arXiv:1703.05175 [cs, stat] (Mar", "year": 2017}, {"authors": ["V. Garcia", "J. Bruna"], "title": "Few-Shot Learning with Graph Neural Networks.", "venue": "en. In: arXiv:1711.04043 [cs, stat] (Nov. 2017)", "year": 2017}, {"authors": ["S. Ravi", "H. Larochelle"], "title": "Optimization as a model for few-shot learning.", "venue": "en. In: ICLR (2017),", "year": 2017}, {"authors": ["C. Finn"], "title": "Code for \u201dModel-Agnostic Meta-Learning for Fast Adaptation of Deep Networks\u201d: cbfinn/maml. original-date: 2017-06-18T01:36:06Z", "year": 2018}, {"authors": ["H. Mhaskar", "Q. Liao", "T. Poggio"], "title": "Learning functions: when is deep better than shallow.", "year": 2016}, {"authors": ["D.P. Kingma", "J. Ba"], "title": "Adam: A method for stochastic optimization.", "year": 2014}, {"authors": ["M. Abadi", "P. Barham", "J. Chen", "Z. Chen", "A. Davis", "J. Dean", "M. Devin", "S. Ghemawat", "G. Irving", "M. Isard"], "title": "Tensorflow: a system for large-scale machine learning.", "venue": "In: OSDI. Vol", "year": 2016}], "sections": [{"text": "R E S C I E N C E C Replication / Machine Learning\n[Re] Meta-learning with differentiable closed-form solvers Arnout Devos1,\u2020, ID , Sylvain Chatel1,\u2020, ID , and Matthias Grossglauser1 1Swiss Federal Institute of Technology Lausanne (EPFL), Switzerland \u2013 \u2020Equal contribution\nEdited by Koustuv Sinha ID\nReviewed by Anonymous reviewers\nReceived 04 May 2019\nPublished 22 May 2019\nDOI 10.5281/zenodo.3160540\n1 Introduction\nThe ability to adapt to new situations and learn quickly is a cornerstone of human intelligence. When given a previously unseen task, humans can use their previous experience and learning abilities to perform well on this new task in a matter of seconds and with a relatively small amount of new data. Artificial learning methods have been shown to be very effective for specific tasks, often times surpassing human performance1,2). However, by relying on standard supervised-learning or reinforcement learning training paradigms, these artificial methods still require much training data and training time to adapt to a new task. An area of machine learning that learns and adapts from a small amount of data is called few-shot learning3. A shot corresponds to a single example, e.g. an image and its label. In few-shot learning the learning scope is expanded from the classic setting of a single task withmany shots to a variety of tasks with a few shots each. A promising approach for few-shot learning is the field of meta-learning. Meta-learning, also known as learning-to-learn, is a paradigm that exploits cross-task information and training experience to perform well on a new unseen task.\nIn this work we reproduce the paper of Bertinetto et al.4 (referenced as \u201dtheir paper\u201d); it falls into the class of gradient-based meta-learning algorithms that learn a model parameter initialization for rapid fine-tuning with a few shots5,6. The authors present a newmeta-learning method that combines a deep neural network feature extractor with differentiable learning algorithms that have closed-form solutions. This reduces the overall complexity of the gradient based meta-learning process, while advancing the state-of-the-art in terms of accuracy across multiple few-shot benchmarks. We interacted with the authors through OpenReview1, bringing our reproducibility work and TensorFlow code2,3 to their attention. Because of this, they updated their original paper with more details to facilitate reproduction and they released an official PyTorch implementation4.\n2 Background in Meta-Learning\nThe objective of few-shot meta-learning is to train a model that can quickly adapt to a new task by using only a few datapoints and training iterations. In our work we will con-\n1https://openreview.net/forum?id=HyxnZh0ct7&noteId=BkxDPnDZMV 2our R2D2 and R2D2*: https://github.com/ArnoutDevos/r2d2 3our MAML on CIFAR-FS: https://github.com/ArnoutDevos/maml-CIFAR-FS 4Bertinetto et al.4 code: https://github.com/bertinetto/r2d2\nCopyright \u00a9 2019 A. Devos, S. Chatel and M. Grossglauser, released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Arnout Devos (arnout.devos@epfl.ch) The authors have declared that no competing interests exists. Code is available at https://github.com/ArnoutDevos/r2d2 \u2013 DOI 10.5281/zenodo.2662493. Open peer review is available at https://github.com/reproducibility-challenge/iclr_2019/pull/150.\nReScience C 5.2 (#1) \u2013 Devos, Chatel and Grossglauser 2019 1\nsider only classification tasks, but it should be noted that meta-learning is also generally applicable to regression or reinforcement learning tasks5).\nIn order to provide a solid definition of meta-learning, we need to define its different components. We denote the set of tasks by T. A task Ti \u2208 T corresponds to a classification problem, with a probability distribution of example inputs x and (class) labels y, (x, y) \u223c Ti. For each task, we are given training samples ZT = {(xi, yi)} \u223c T with K shots per class and evaluation samples Z \u2032T = {(x\u2032i, y\u2032i)} \u223c T with Q shots (queries) per class, all sampled independently from the same distribution T . In meta-learning, we reuse the learning experience used for tasks Ti, i \u2208 [0, L] to learn a new task Tj , where j > L, from only K examples, for every single one of the N classes in the task. Commonly, this is denoted as an N -way K-shot problem. To this end, in meta-learning two different kinds of learners can be at play: (1) a base-learner that works at the task level and learns a single task (e.g. classifier with N classes) and (2) a meta-learner that produces those model parameters that enable the fastest average fine-tuning (using the base-learner) on unseen tasks.\nThe authors put a specific view of meta-learning forward. Their meta-learning system consists of a generic feature extractor\u03a6(x) that is parametrized by \u03c9, and a task-specific predictor fT (X) that is parametrized by wT and adapts separately to every task T \u2208 T based on the few shots available. In the case of a deep neural network architecture, this task-specific predictor fT can be seen as the last layer(s) of the network and is specific to a task T . The preceding layers \u03a6 can be trained across tasks to provide the best feature extraction on which the task-specific predictor can finetune with maximum performance. The base-learning phase in their paper assumes that the parameters \u03c9 of the feature extractor \u03a6 are fixed and computes the parameters wT of fT through a closedform learning process \u039b. \u039b, on its own, is parametrized by \u03c1. The meta-learning phase in the paper learns a parametrization of\u03a6 and\u039b (respectively \u03c9 and \u03c1). In order to learn those meta-parameters, the algorithmminimizes the expected loss on test sets from unseen tasks in T with gradient descent. The base-learning and meta-learning phases are shown in Figures 1 and 2, respectively.\nReScience C 5.2 (#1) \u2013 Devos, Chatel and Grossglauser 2019 2\nMost of the recent meta-learning works are tested against image datasets and their feature extractor consists of a convolutional neural network (CNN). The variability between works resides mainly in the base learner fT and its parameter obtaining training procedure\u039b. Examples are an (unparametrized) k-nearest-neighbour algorithm7, a CNNwith SGD8, and a nested SGD5). Systems in Vinyals et al.7 and Snell, Swersky, and Zemel9 are based on comparing new examples in a learned metric space and rely on matching. In particular, MATCHINGNET from Vinyals et al.7 uses neural networks augmented with memory and recurrence with attention in a few-shot image recognition context. Mishra et al.8 build on this attention technique by adding temporal convolutions to reuse information from past tasks. Another example of a matching-based method is introduced in Garcia and Bruna10, where a graph neural network learns the correspondence between the training and testing sets.\nA different approach is to consider the SGD update as a learnable function for metalearning. In particular, sequential learning algorithms, such as recurrent neural networks and LSTM-basedmethods, enable the use of long-termdependencies between the data and gradient updates as pointed out by Ravi and Larochelle11. Finally, Finn, Abbeel, and Levine5 introduce a technique called model-agnostic meta-learning (MAML). In MAML, meta-learning is done by backpropagating through the fine-tuning stochastic gradient descent update of the model parameters.\n3 Analysis of the R2D2 Classifier\nIn their paper, Bertinetto et al.4 present a new approach that relies on using fast and simple base learners such as ridge regression differentiable discriminator (R2D2) or (regularized) logistic regression differentiable discriminator (LRD2). In our reproducibility work we will focus on the R2D2 algorithm, because it is the only proposed algorithm with a truly closed-form solver for the base-learner. For reproducibility purposes, we transformed the original textual description of R2D2 in their paper into an algorithmic description in Algorithm 1, elaborated upon in the following.\nReScience C 5.2 (#1) \u2013 Devos, Chatel and Grossglauser 2019 3\nAlgorithm 1 Ridge Regression Differentiable Discriminator (R2D2) Require: Distribution of tasks T. Require: Feature extractor \u03a6 parameterized by \u03c9. Require: Finetuning predictor fT with base-learning algorithm \u039b and task-specific pa-\nrameters wT , and meta-parameters \u03c1 = (\u03b1, \u03b2, \u03bb) 1: Initialize \u03a6, \u039b, and fT with pre-trained or random parameters \u03c90 and \u03c10 2: while not done do 3: Sample batch of tasks Ti \u223c T 4: for all Ti do 5: Sample K datapoints for every class from Ti and put in them in the training set ZTi 6: Base-learn fTi using \u039b:\nWi = wTi = \u039b(ZTi) = XTi (XiXTi + \u03bb.I)\u22121Yi withXi = \u03a6(ZTi) and Yi the one-hot labels from ZTi .\n7: Sample datapoints for every class from Ti and put in them in the evaluation set Z \u2032Ti 8: end for 9: Update meta-parameters \u03b8 = (\u03c9,\u03c1) through gradient descent :\n\u03b8 \u2190 \u03b8 \u2212 \u03b5. \u2211 i \u2207\u03b8L(fTi(\u03a6(Z \u2032Ti)), Y \u2032 i )\nwith \u03b5 the learning rate, L the cross-entropy loss, and fTi(X \u2032i) = \u03b1X \u2032iWi + \u03b2. 10: end while\nIn R2D2, during base-learning withZT , the linear predictor fT is adapted for each training task T , by using the learning algorithm \u039b; and the meta-parameters \u03c9 (of \u03a6) and \u03c1 (of \u039b) remain fixed. It is only in the meta-training phase that meta-parameters \u03c9 and \u03c1 are updated, by using Z \u2032T . The linear predictor is seen as fT (x) = xW withW a matrix of task-specific weights wT , and x the feature extracted version of x, x = \u03a6(x). This approach leads to a ridge regression evaluation such that it learns the task weights wT :\n\u039b(X,Y ) = argmin W\n\u2225XW \u2212 Y \u22252 + \u03bb \u2225W\u22252 (1)\n= (XTX + \u03bbI)\u22121XTY (2)\nwhere X contains all NK feature extracted inputs from the training set of the considered task. A key insight in their paper is that the closed-form solution of Equation 2 can be simplified using the Woodbury matrix identity yielding W = \u039b(X,Y ) = XT (XXT + \u03bbI)\u22121Y . This considerably reduces the complexity of the matrix calculations in the special case of few-shot learning. Specifically,XXT is of size NK \u00d7NK, in the case of an N -wayK-shot task; thismatrix will, together with the regularization, be relatively easily inverted. Normally, regression is not adequate for classification, but the authors noticed that it still has considerable performance. Therefore, in order to transform the regression outputs (which are only effectively calculated when updating the meta-parameters usingZ \u2032T ) to workwith the cross-entropy loss function, themeta-parameters (\u03b1, \u03b2) \u2208 R2 serve as a scale and bias, respectively:\nY\u0302 \u2032 = \u03b1X \u2032 [ XT (XXT + \u03bbI)\u22121Y ] + \u03b2 (3)\nReScience C 5.2 (#1) \u2013 Devos, Chatel and Grossglauser 2019 4\n4 Reproducibility\nAs a first step in the reproducibility, we reproduce the results of a baseline algorithm on different datasets used in their paper. In this perspective, we first consider the MAML algorithm from Finn, Abbeel, and Levine5. We use the official TensorFlow implementation of MAML12) to reproduce the baseline s\u0313 results. Then, we amend this MAML implementation to reproduce the results on the new CIFAR-FS dataset proposed by their paper4). When reproducing the R2D2 algorithm, our first consideration is that the feature extractors in MAML and R2D2 are very different. MAML uses four convolutional blockswith an organization of [32, 32, 32, 32] filters. Whereas, R2D2 s\u0313 four blocks employ a [96, 192, 384, 512] scheme, as shown in Figure 3. In other words, the feature extractor in R2D2 is more complex hence is expected to yield better results13). In order to provide a meaningful comparison, we implement and evaluate both the simple and more complex feature extractors for the R2D2 algorithm, denoted by R2D2* and R2D2 respectively.\nIn order tomake a working reproduction of their paper we had tomake the following assumptions. We first considered the aforementioned complex architecture and feature extractor. In particular, for the feature extractor, we made assumptions on some of the convolutional block options, which were not stated in their paper. We considered a 3x3 convolution block with a s\u0313ame\u02bc padding and a stride of 1. For the 2x2 maximum pooling, we use a stride of 2 and no padding. Second, concerning the ridge regression base-learner, we opted for amultinomial regression that returns the class with themaximumvalue through one-hot encoding. Following the guidelines for the feature extractor presented in Section 4.2 of their paper, we were not successful in reproducing the exact number of features at the output of the feature extractor. In their paper, the overall numbers of features at the output of the extractor are 3584, 72576 and 8064 for Omniglot, miniImageNet and CIFAR-FS, respectively. However, by implementing the feature extractor described in their paper, we obtain 3988, 51200 and 8192 respectively.\nFor comparison purposes, we use the same number of classes and shots during training and testing, despite their paper using a higher number of classes during training (16 for miniImageNet, 20 for CIFAR-FS) than during testing (5 forminiImageNet and CIFAR-FS). Also, their paper uses a random number of shots during training. This is different from the way most baselines are trained using the same number of shots per class during training and testing12,6,7. For comparability, it is paramount to keep the training and testing procedures similar, if not the same. In particular, as in their paper the 5-way results are exactly the same as those reported in MAML5, using the same number of classes and shots during training and testing allows for a fair comparison.\nFinally, a last assumption is made on the algorithms\u0313 stopping criterion. In their paper, the stopping criterion is vaguely defined as \u201dthe error on the meta-validation set does\nReScience C 5.2 (#1) \u2013 Devos, Chatel and Grossglauser 2019 5\nnot decrease meaningfully for 20,000 episodes\u201d. Therefore, in line with the MAML training procedure, we meta-train using up to 60,000 iterations. To update the meta-parameters, in line with their paper, we use the Adam optimizer14 with an initial learning rate of 0.005, dampened by 0.5 every 2,000 episodes. We use 15 examples (\u201dqueries\u201d) per class for evaluating the post-update meta-gradient. We use a meta batch-size of 4 and 2 tasks for 1-shot and 5-shot training respectively. For MAML we use a task-level learning rate of 0.01, with 5 gradient steps during training and 10 gradient steps during testing.\n5 Results and Contributions\nThe results of the different implemented architectures and algorithms for several datasets are shown in Figures 4 and 5. More detailed results with 95% confidence intervals are shown in Tables 1 and 2.\nOur implementations were made in Python 3.6.2 and TensorFlow 1.8.0 (Abadi et al.15).\nReScience C 5.2 (#1) \u2013 Devos, Chatel and Grossglauser 2019 6\nThe source code of all implementations is available5 online6. The simulations were run on a machine with 24 Xeon e5 2680s at 2.5 GHz, 252GB RAM and a Titan X GPU with 12 GB RAM. Although our results differ slightly from the original paper of Bertinetto et al.4, R2D2 (with its more complex network architecture) performs better than the MAML method for most simulations. It is not a surprise that, in all cases, with a more complex feature extractor better results are obtained for the same algorithm (R2D2 vs R2D2*). Overall, our study confirms that the R2D2 meta-learning method, with its corresponding complex architecture, yields better performance than basic MAML (with its simpler architecture). The differences between reproduced results and reported values might be due to our assumptions or the stopping criterion in the training. Also, as expected, the complexity (N-ways) and the amount of data (K-shots) play a major role in the classification accuracy. The accuracy drops when the number of ways increases and number of shots decreases. An outlier worth mentioning is our MAML simulation on miniImageNet: the 2-way 1-shot classification accuracy of 78.8 \u00b1 2.8% is much better than the 74.9\u00b1 3.0% reported in Finn, Abbeel, and Levine5.\nIn summary, we have successfully reproduced the most important results presented in Bertinetto et al.4. Although our reproduced results and their paper results differ slightly, the general observations of the authors remain valid. Their meta-learning with differentiable closed-form solvers yields state-of-the-art results and improves over another state-of-the-art method. The assumptions made, however, could have been clarified in their original paper. Indeed, these assumptions could be the source of the discrepancy in the reproduction results. In this reproducibility work we did not focus on the logistic regression based algorithm (LRD2) from their paper because the logistic regression solver does not have a closed-form solution. Overall, with this reproducibility project we make the following contributions:\n\u2022 Algorithmic description of the R2D2 version of meta-learning with differentiable closed-form solvers (Algorithm 1).\n\u2022 Evaluation of the MAML pipeline from Finn12 on two datasets: the existing miniImageNet and new CIFAR-FS for different few-shot multi-class settings.\n\u2022 Implementation of R2D2* in TensorFlow on the pipeline following Algorithm 1 with the original MAML feature extractor.\n\u2022 Implementation of R2D2 in TensorFlow on the pipeline followingAlgorithm1with the Figure 3 architecture as mimicked from in the original paper4.\n\u2022 Evaluation and insights in the reproducibility of Bertinetto et al.4. 5R2D2 and R2D2*: https://github.com/ArnoutDevos/r2d2 6MAML with CIFAR-FS: https://github.com/ArnoutDevos/maml-CIFAR-FS\nReScience C 5.2 (#1) \u2013 Devos, Chatel and Grossglauser 2019 7\n6 Conclusion\nIn this work we have presented a reproducibility analysis of the ICLR 2019 paper \u201dMetalearning with differentiable closed-form solvers\u201d by Bertinetto et al.4. Some parameters and training methodologies, which would be required for full reproducibility, such as stride and padding of the convolutional filters, and a clear stopping criterion, are not mentioned in the original paper or in its appendix4. However, by making reasonable assumptions, we have been able to reproduce the most important parts of the paper and to achieve similar results. Most importantly we have succeeded in reproducing the increase in performance of the proposed method over some reproduced baseline results, which supports the conclusions of the original paper. However, the different neural network architectures should be taken into consideration when comparing results."}, {"heading": "Acknowledgements", "text": "The authors would like to thank Martin Jaggi, Ruediger Urbanke, and the anonymous reviewers from the ICLR 2019 Reproducibility Challenge for feedback. This project is partially supported by the European Unions\u0313 Horizon 2020 research and innovation program under the Marie Sk\u0142odowska-Curie grant agreement No. 754354."}], "title": "[Re] Meta-learning with differentiable closed-form solvers", "year": 2019}
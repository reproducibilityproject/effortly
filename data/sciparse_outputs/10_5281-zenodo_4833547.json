{"abstractText": "Deep Fair Clustering (DFC) aims to provide a clustering algorithm that is fair, clusteringfavourable, andwhich canbeused onhigh-dimensional and large-scale data. In existing frameworks there is a trade-offbetween clustering quality and fairness. In this reportwe aim to reproduce a selection of the results of DFC; using two of four datasets and all four metrics that were used in the original paper, namely accuracy, Normalized Mutual Information (NMI), balance and entropy. We use the authors\u02bc implementation and check whether it is consistent with the description in the paper. As extensions to the original paper we look into the effects of 1) using no pretrained cluster centers, 2) using different divergence functions as clustering regularizers and 3) using non-binary/corrupted sensitive attributes.", "authors": [{"affiliations": [], "name": "Tobias Teule"}, {"affiliations": [], "name": "Nienke Reints"}, {"affiliations": [], "name": "Chris Al Gerges"}, {"affiliations": [], "name": "Pauline Baanders"}, {"affiliations": [], "name": "Koustuv Sinha"}], "id": "SP:2fabf9d1a2a774dd6c757d0ad130fdc78efcc0ea", "references": [{"authors": ["P. Li", "H. Zhao", "H. Liu"], "title": "Deep Fair Clustering for Visual Learning.", "venue": "The IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "year": 2020}, {"authors": ["R. Jenssen", "J.C. Principe", "D. Erdogmus", "T. Eltoft"], "title": "The Cauchy-Schwarz divergence and Parzen windowing: Connections to graph theory and Mercer kernels.", "venue": "Journal of the Franklin Institute", "year": 2006}], "sections": [{"text": "R E S C I E N C E C"}, {"heading": "Replication / ML Reproducibility Challenge 2020", "text": "[Re] Deep Fair Clustering for Visual Learning\nTobias Teule1, ID , Nienke Reints1, ID , Chris Al Gerges1, ID , and Pauline Baanders1, ID 1University of Amsterdam, Amsterdam, Netherlands\nEdited by Koustuv Sinha\nReviewed by Anonymous Reviewers\nReceived 29 January 2021\nPublished 27 May 2021\nDOI 10.5281/zenodo.4833547"}, {"heading": "Reproducibility Summary", "text": ""}, {"heading": "Scope of Reproducibility", "text": "Deep Fair Clustering (DFC) aims to provide a clustering algorithm that is fair, clusteringfavourable, andwhich canbeused onhigh-dimensional and large-scale data. In existing frameworks there is a trade-offbetween clustering quality and fairness. In this reportwe aim to reproduce a selection of the results of DFC; using two of four datasets and all four metrics that were used in the original paper, namely accuracy, Normalized Mutual Information (NMI), balance and entropy. We use the authors\u02bc implementation and check whether it is consistent with the description in the paper. As extensions to the original paper we look into the effects of 1) using no pretrained cluster centers, 2) using different divergence functions as clustering regularizers and 3) using non-binary/corrupted sensitive attributes."}, {"heading": "Methodology", "text": "Theopen source code of the authors has beenused. Thedatasets anddata-preprocessing has been donewith our code, since the authors did not provide the datasets in their code. Also the pretrained Variational Autoencoder (VAE) dataset had to be re-implemented for the Color Reverse MNIST . For the extensions we wrote extra functions. For measuring the influence of discarding the pretrained cluster centers, the codewas already provided by the authors."}, {"heading": "Results", "text": "For theMNIST-USPS dataset, we report similar accuracy and NMI values that are within 1.2% and 0.5% of the values reported in the original paper. However, the balance and entropy differed significantly, where our results werewithin 73.1% and 30.3%of the original values respectively. For the Color Reverse MNIST dataset, we report similar values on accuracy, balance and entropy, which are within 5.3%, 2.6% and 0.2% respectively. Only the value of the NMI differed significantly, namewithin 12.9% of the original value In general, our results still support the main claim of the original paper, even though on some metrics the results differ significantly.\nCopyright \u00a9 2021 T. Teule et al., released under a Creative Commons Attribution 4.0 International license. Correspondence should be addressed to Tobias Teule (Tobiasteule@gmail.com) The authors have declared that no competing interests exist. Code is available at https://github.com/topteulen/UVA-FACT. \u2013 SWH swh:1:dir:7058002f161d29f18e52a18ebe326b7911b1b616;. Open peer review is available at https://openreview.net/forum?id=DXVAJGohUKs.\nReScience C 7.2 (#4) \u2013 Teule et al. 2021 1"}, {"heading": "What was easy", "text": "The open source code of the authors was beneficial; it was well structured and ordered into multiple files. Furthermore, the code to use randomly initialized instead of pretrained cluster centers was already provided."}, {"heading": "What was difficult", "text": "First of all, the main difficulty in reproducing the paper was caused by the coding style; due to the lack of comments it was difficult to get a good understanding of the code. Secondly, we were required to download the data ourselves. However, these filenames and labels did not correspond to the included txt-files by the authors. Therefore, the model did not learn and we regenerated train_mnist.txt and train_usps.txt. Finally, the authors only included pretrained models for the MNIST-USPS dataset. As a consequence, we had to pre-train some parts of the DFC algorithm for the Color Reverse MNIST dataset.\nReScience C 7.2 (#4) \u2013 Teule et al. 2021 2\n1 Introduction\nWith the increased application of Machine Learning in automated systems, particularly in decisionmaking systems, it has become desirable that individuals are treated equally in such automated environments. However, there exists a trade-off between the fairness and the performance of machine learning algorithms in a given task [1]. In current fair clustering algorithms, fair and effective representations are learned by mainly using small-scale and low-dimensional data. In this paper, we consider representations to be \u02bceffective\u02bc if they yield good performance in clustering tasks. In addition, representations are considered to be \u02bcfair\u02bc when the algorithm is able to achieve great performance without using attributes like race and gender. DeepFair Clustering (DFC) is an algorithm that aims to learn fair and clustering-favorable representations for large-scale and high-dimensional data. In this context, feature representations are considered to be fair if they are statistically independent of sensitive attributes. Whether a particular attribute is sensitive or not; that is a cultural question that lies outside the scope of the paper. The aim of the paper is to show that we can pick an arbitrary attribute of an image, e.g. whether it comes from dataset X or dataset Y , and make sure that the feature representation is independent of the specific attribute. DFC consists of an encoder that produces the representations, and a discriminator that tries to predict the value of the sensitive attribute of a representation. A minimax game is used to learn fair representations in an adversarial manner. In order to preserve the utility of the representations, clustering is performed on all datapoints with the same sensitive attribute. This component is called s\u0313tructural preservation\u02bc because it preserves the clustering structure in each sensitive attribute. Finally, The KL-divergence is used as a clustering regularizer to prevent the formation of large clusters. All code is available on Github [2].\n2 Scope of reproducibility\nThe goal of this work is to validate the reproducibility of the DFC algorithm proposed by Li, Zhao, and Liu1 beyond the scope of the original paper. The main claims of the original paper are as follows:\nClaim 1: DFC produces a fair clustering partition on high dimensional and largescale visual data.\nClaim 2: DFC produces clustering-favorable representations under a fairness constraint.\nTo test the validity of claim 1, the balance and entropy scores will be examined and compared with the original paper. The validity of claim 2 will be tested similarly, where we instead examine the accuracy and normalized mutual information (NMI) score. Important to note is that the original paper mainly evaluated the DFC algorithm on binary sensitive attributes. As an example, in Li, Zhao, and Liu1 a sensitive attribute was defined as whether an image from the MNIST dataset has been reversed or not. Generally speaking, in the original paper the sensitive attributes could only take one out of two possible values. However, sensitive attributes in the real world, like race or gender, can take on multiple variables. To evaluate the robustness of claim 1, wewill perform the DFC algorithm for non-binary sensitive attributes. To do this, we modify one of the sensitive attributes chosen by the authors, particularly whether an image belongs to the MNIST dataset or whether it is a Color Reverse MNIST image. In the former case, all the pixels of the digit are white and the background pixels are all black; in the latter case it is the other way around. To make this attribute non-binary, images from both datasets will be corrupted; some\nReScience C 7.2 (#4) \u2013 Teule et al. 2021 3\npixel values will be flipped, and it is not the case anymore that we can distinguish the images purely on the background color. It would inspire confidence if DFC is still able to function properly. Furthermore, we will investigate the robustness of both claims by testing the DFC algorithm on different model configurations. Specifically, we will test out different clustering regularizers by replacing theKL-divergencewith other divergencemeasures, namely the Jensen-Shannondivergence (JS-divergence) and theCauchy-Schwarz divergence (CSdivergence). Finally, in the original paper it is mentioned that pretrained cluster centers were used in the DFC algorithm. However, the motivation of using pretrained cluster centers in DFC is omitted, which might suggest that pre-training cluster centers are not a necessary part of the DFC pipeline. Therefore, we will examine the influence of pretrained cluster centers in DFC.\n3 Methodology\n3.1 Model descriptions\nLi, Zhao, and Liu1 use a pretrained convolutional variational autoencoder (VAE). The available code only contained the pretrained encoder and decoder for the MNIST-USPS dataset [3]. We implemented and pretrained a convolutional VAE for the Color Reverse MNIST dataset. The encoder is build of four convolutional layers, followed by batch normalization and a ReLU activation function. Moreover, the decoder is implemented by reversing the layers of the encoder. Both the encoder and decoder contained 610K and 58.9K parameters respectively. The VAE is trained using the Adam-optimizer and a learning rate of 1e\u2212 3. Li, Zhao, and Liu1 also used pretrained cluster centers to start their DFC algorithm off with high accuracy clusters. They only provided pretrained cluster centers for the MNIST-USPS dataset: Therefore, in order to reproduce the results, we were required to obtain pretrained cluster centers for the Color Reverse MNIST dataset. For this task we used k-means clustering1 with k = 10. Because the original code of the authors used 64- dimensional cluster centers, we first scaled our 32\u00d732 images downwith amax pooling layer with 4 sized filters, so that the images would go from 32\u00d7 32 to 8\u00d7 8. After dimension reduction every image becomes a 1 \u00d7 64 vector. We then fit every image in the dataset using MiniBatchKMeans from the sklearn package2. With max_iter = 1000 and batch_size = 512. This results in our pretrained cluster centers which can be trained for every dataset. To examine during clustering whether fair representations are reached, a discriminator is used; when it cannot distinguish based on the sensitive attribute the representations are fair. This discriminator is a multilayer perceptron (MLP) using three linear layers, of which the first two are followed by a ReLU activation function and a dropout of 0.5: the final layer is followed by a sigmoid activation function. The discriminator is trained jointly with the encoder for 20000 epochs. Finally, the Adam optimizer is used with an initial learning rate of lrinit = 1e \u2212 4. The learning rate is adjusted with lr = lrinit(1 + 10t)\u22120.75, with t = 0 at the start of the training process; with every iteration t is linearly increased to t = 1 at the end of the training process. The objective function consists of three parts; the fairness-adversarial loss (Lf ), the structural preservation loss (Ls) and the clustering regularizer term (Lc). The task of the fairness-adversarial loss is to minimize the divergence between the cluster assignments of the different subgroups. In this way the term promotes a similar cluster distribution for all subgroups, hence, statistical independence between cluster assignments and the\n1https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html 2https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MiniBatchKMeans.html\nReScience C 7.2 (#4) \u2013 Teule et al. 2021 4\nparticular protected subgroup that the sample belongs to. The fairness-adversarial loss can be written as:\nLf := L(D \u25e6 A \u25e6 F(X), G), (1)\nwhere L denotes the cross-entropy loss and \u25e6 denotes the function composition: moreover, D, A, F denotes the discriminator, cluster assignment and encoder respectively. The fairness-adversarial loss encourages statistical independence of the cluster assignments and the sensitive attribute G, however, only optimizing Lf is not enough as it can lead to a degenerate solution, where the representations that are produced by the encoder are all constant. Of course, such a constant representation cannot lead to good clustering quality; it would hide, rather than illuminate, the fundamental structure in the data. The structural preservation loss prevents such a solution by penalizing it when the inner structure of a particular subgroup is altered in the DFC setting, as opposed to clustering the subgroup individually. The preservation loss, which was proposed by the authors [1] is given as follows:\nLs := \u2211\ng\u2208[M ] \u2223\u2223\u2223\u2223\u2223\u2223P\u0302gP\u0302Tg \u2212 PgPTg \u2223\u2223\u2223\u2223\u2223\u22232 , (2) where [M ] denotes the set of sensitive attributes, P\u0302g andPg denote the (soft) assignments of the g\u2212th protected subgroup when individually clustered and clustered with DFC, respectively. Following otherwork indeep clustering, DFCemploys a clustering regularizer to strengthen prediction confidence and to prevent large cluster sizes [1]. Contrary to earlier work, the clustering regularizer is chosen in such away that it encourages the members of a particular protected subgroup to be distributed equally over the clusters. To increase the confidence of the prediction an auxiliary target distribution Q is defined. This target distribution is defined in such a way that it favors current high confidence assignments and is calculated as:\nqk = (pk)\n2/ \u2211\nx\u2208Xg pk\u2211 k\u2032\u2208[K]((pk\u2032) 2/ \u2211 x\u2208Xg pk\u2032 , (3)\nwith pk the probability that sample x belongs to cluster k, and Xg the samples that belong to protected subgroup G. Then, the clustering regularizer loss is defined as the KL-divergence between soft assignment P and auxiliary target distribution Q:\nLc := KL(P ||Q) = \u2211\ng\u2208[M ] \u2211 x\u2208Xg \u2211 k\u2208[K] pk log pk qk . (4)\nAgain following the literature, the authors have chosen to use the Student t-distribution for soft cluster assignment [1]. The probability that the representation z (corresponding to a particular sample x) belongs to cluster ck is then given by:\npk = (1 + 1\u03b1 ||z \u2212 ck|| 2)\u2212 \u03b1+1 2\u2211\nk\u2032\u2208[K](1 + 1 \u03b1 ||z \u2212 ck\u2032 ||2)\n\u2212\u03b1+12 , (5)\nwith \u03b1 the degree of freedom of the Student s\u0313 t-distribution. In conclusion, the overall objective is defined as the following minimax strategy:\nmax F,A \u03b1fLf \u2212 \u03b1sLs \u2212 Lc, (6)\nmin D \u03b1fLf (7)\nwith \u03b1f and \u03b1s as trade-off hyperparameters.\nReScience C 7.2 (#4) \u2013 Teule et al. 2021 5\n3.3 Extensions\nDivergence Functions \u2014 Asmentioned earlier in Section 2, we examined the effect of using different divergence functions as clustering regularizers by replacing the KL-divergence with either the Jensen-Shannondivergence (JS-divergence) or the Cauchy-Schwarz divergence (CS-divergence). The JS-divergence is the smoothed and symmetric version of the KL-divergence and is calculated as follows:\nJS(P ||Q) = 1 2 KL(P ||M) + 1 2 KL(Q||M) (8)\nwhereM = 12 (P +Q) andKL(.||.) is the KL-divergence as defined in 4. Furthermore, the CS-divergence is a divergence function that is inspired by information theory. It is given by the following ([4]):\nCS(P ||Q) = \u2212 log \u222b p(x)q(x)dx\u221a\u222b\np2(x)dx \u222b q2(x)dx\n(9)\nThe CS-divergence is, like the JS-divergence, a symmetric measure. Furthermore, the CS-divergence has the range 0 \u2264 CS(P ||Q) \u2264 \u221e, where the minimum value of 0 is obtained if p(x) = q(x).\n3http://yann.lecun.com/exdb/mnist/ 4http://www.kaggle.com/bistaumanga/usps-dataset\nReScience C 7.2 (#4) \u2013 Teule et al. 2021 6\nCorrupted Sensitive Attribute \u2014 Another extension mentioned in Section 2 is that we consider the influence of the corrupted sensitive attribute. In theColorReverseMNIST dataset the presence of this attribute is clear in background color, The numbers are black in the case of MNIST-USPS and white in the case of Color Reverse MNIST , The background is defined by everything that is not the colour of the number. Corrupting the sensitive attribute in this dataset implies random modifications in the background color. We compare two corruption rates (0.1 and 0.4) against the original images; for example, a rate of 0.1 implies that a random 10% of the background pixels are changed from black to white or vice versa.\nPretrained Cluster Centers \u2014 The final extension mentioned in Section 2 is that we would examine the influence of pretrained cluster centers on the performance of DFC. If no pretrained cluster centers were used, they would be randomly initialized with Xavier initialisation using a uniform distribution.\n3.4 Evaluation To evaluate the models, we used the four metrics that were also used by Li, Zhao, and Liu1: accuracy and Normalized Mutual Information (NMI) were used to evaluate the cluster validity, while balance and entropy were calculated to evaluate the fairness of DFC. Equations 10-13 are used to calculate the metrics: the NMI is calculated using sklearn.\nAccuracy =\n\u2211n i=1 Iyi=map(y\u0302i)\nn (10)\nNMI =\n\u2211 i,j nij log\nn\u00b7nij ni+\u00b7n+j\u221a ( \u2211\ni ni+ log ni+ n )( \u2211 j n+j log n+j n )\n(11)\nBalance = min i ming |Ci \u2229Xg| ni+\n(12)\nEntropy = \u2212 \u2211 i |Ci \u2229Xg| ni+ log |Ci \u2229Xg| ni+ + \u03f5 (13)\nIn Eq. 10, yi and y\u0302i represent the correct and predicted cluster label respectively: map is a function that maps the cluster label y\u0302i to the correct label yi. In Eq. 11, nij denotes the co-occurrence number; ni+ and n+j denote the cluster size of the i-th and j-th clusters, in the obtained partition and ground truth, respectively. n is the total data instance number. Furthermore, Ci represents the i-th cluster andXg the g-th protected subgroup. Finally, in Eq. 13, \u03f5 = 1e\u2212 5, to ensure the log will always be defined. As mentioned before, accuracy and NMI are measures for the clustering quality. More specific, accuracy measures the correctness of clusters relative to a ground truth and NMI measures the similarity between the clustering obtained by DFC and the ground truth. For both metrics, a higher value indicates better clustering quality. Furthermore, balance and entropy evaluate the fairness of the obtained clustering. In particular, balance measures the homogeneity of the clustering across multiple sensitive attributes. A large value indicates that each cluster contains samples from multiple protected subgroups. If one cluster contains only instances of a particular protected subgroup, the balance has a score of 0. Entropy is a softer fairness metric than balance that measures the diversity of the clustering. Just like balance, a large entropy value indicates that samples from a protected subgroup are present in almost every cluster, which indicates a more fair clustering and thus more fair representations.\nReScience C 7.2 (#4) \u2013 Teule et al. 2021 7\n3.5 Computational requirements The codewas run locally on aGPU. TheGPU in question is a GeForce GTX 970with driver version 456.71. The CPU in thismachine is an Intel Core i7-4770K. Thememory usedwas 16.0 GB DDR3. For the main training of the adversarial network with 20000 iterations at 5000 iterations per evaluation the model ran in approximately 3.5 hours. This was the same computational cost to run DFC with a different divergence function. For the corruption extension we used 5000 iterations at 500 iterations per evaluation which took about 1.5 hours. The training of the VAE for the Color ReverseMNIST dataset took roughly 1 hour. The k-means clustering to obtain the pretrained clusters took approximately 15 minutes. Taking all this into account, the reproduction of the Color Reverse MNIST results from scratch took a total of circa 6.25 hours to compute. Finally, evaluating all the results with the saved models takes about 20 minutes. In conclusion, the code is not fast but it can be run on a local machine. A GPU is heavily recommended, because without one the code is about eight times slower.\n4 Results\n4.1 Reproduced Results\nThe original results from Li, Zhao, and Liu1 as well as the reproduced results can be found in Table 2.\nFirst of all, the reproduced accuracies on both datasets are very similar to the original values of Li, Zhao, and Liu1; differing 0.029 and 0.01 on Color Reverse MNIST and MNIST-USPS respectively. Secondly, similar to accuracy, the original and reproduced NMI values do not differ much; 0.88 on Color Reverse MNIST and 0.004 on MNIST-USPS . Thirdly, the reproduced balance on Color ReverseMNIST is close to the original; differing 0.02: however, the difference is larger on the MNIST-USPS dataset (0.049). Finally, the entropy values on Color Reverse MNIST are very similar in contrast to the original and reproduced entropy on MNIST-USPS .\n4.2 Results beyond original paper\nDivergence Functions \u2014 Table 3 shows the results for different divergence functions as clustering regularizers.\nReScience C 7.2 (#4) \u2013 Teule et al. 2021 8\nIn Table 3 it can be observed that the accuracy does not differ significantly on the Color ReverseMNIST dataset. Furthermore, using the CS-divergence seems to yield the highest accuracy. However, the NMI decreases significantly with JS- and CS-divergence as clustering regularizer. On top of that, the balance and entropy decrease significantly with CS-divergence. Using the JS-divergence also results in a decrease in balance and entropy on the Color ReverseMNIST dataset, even though that decrease is minor compared to the CS-divergence. In general, the KL-divergence outperforms the other two divergences on three of the four metrics on the Color Reverse MNIST dataset. On the MNIST-USPS dataset, it can be seen that the difference in accuracy and NMI is even less significant compared to the Color Reverse MNIST dataset. However, on the MNIST-USPS dataset all four metrics decrease when using the JS- or CS-divergence instead of the KL-divergence. Moreover, the balance and entropy seem to decrease more significantly than the accuracy andNMI. In general, on theMNIST-USPSdataset the JS- and CS-divergence perform worse than the KL-divergence.\nCorrupted Sensitive Attribute \u2014 The results of the corruption extension can be found in Table 4.\nAs can be seen in Table 4, both the accuracy and the NMI decrease when data has been corrupted. However, the decrease in accuracy and NMI seem to be more significant when the Color Reverse MNIST dataset is corrupted. Moreover, the balance and entropy decrease when the data is corrupted. In general, a higher corruption leads to lower values on all metrics. Finally, Table 4 shows that the balance drops significantly with a higher corruption rate.\nPretrained Cluster Centers \u2014 The final extension researches the influence of the pretrained cluster centers on the utility and fairness of the clusters. The results for both datasets\nReScience C 7.2 (#4) \u2013 Teule et al. 2021 9\ncan be found in Table 5.\nMost significantly, in Table 5, it is visible that the accuracy on theMNIST-USPS dataset is significantly higher than that on Color ReverseMNIST , both with and without pretrained cluster centers. Furthermore, for both datasets accuracy and NMI are higher when pretrained cluster centers are used. The difference in accuracy is larger on theMNIST-USPS dataset, whereas the difference in NMI is smaller on this dataset, compared to Color Reverse MNIST . Moreover, the difference in balance on MNIST-USPS is not significant (0.018) while this difference is approximately five times larger (0.089) on the Color Reverse MNIST dataset. Finally, the entropy does not change significantly on both datasets.\n5 Discussion\nOur experimental results support the main claims of the original paper; namely that DFC is able to produce fair and clustering-favorable representations of large-scale and high dimensional data, such as images. Furthermore, our extensions seem to add to the robustness of the model and strengthen the choices made by the original paper. First of all, the results of the different divergence functions show that both, CS- and JS-divergence, work but the default, KL-divergence, outperforms the two researched alternatives. Moreover, even though the Color ReverseMNIST dataset required the training of a new VAE and k-means clustering the results were still comparable; this speaks to the robustness of the algorithm that the original authors designed.\n5.1 What was easy The open source code of the authors was conveniently arranged. For example, the divergence function was put in the utils file, which made it easy to test other divergence functions as well. Also, the code had an implementation that randomly initialises cluster centers; to discard the pretrained cluster centers only modifications in the main file were needed. Once we understood the code base, the code structure became intuitive and easy to work with.\n5.2 What was difficult First of all, a difficulty while reproducing the research was caused by the coding style; due to the lack of comments it was difficult at the start to get a good understanding of the code. Secondly, we were required to download the data ourselves. However, these filenames and labels did not correspond to the included .txt-files by the authors. Therefore, the model did not learn and we were forced to produce our own train_mnist.txt and train_usps.txt. Thirdly, the algorithm uses pretrained models, a pretrained VAE, and a file with pretrained cluster centers. However, the authors solely provided these for one of the four datasets, namely MNIST-USPS . Thus, for Color Reverse MNIST we had to build our own VAE based on their structure and calculate our own cluster\nReScience C 7.2 (#4) \u2013 Teule et al. 2021 10\ncenters. The latter came with an extra difficulty since in the paper it is not stated how the clustering was performed. Therefore, we had to guess and chose k-means clustering. This made the reproduction of the Color Reverse MNIST dataset much harder than anticipated."}], "title": "[Re] Deep Fair Clustering for Visual Learning", "year": 2021}